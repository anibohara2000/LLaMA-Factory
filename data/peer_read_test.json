[
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ENGLISH-LITHUANIAN-ENGLISH MACHINE TRANSLATION LEXICON AND ENGINE: CURRENT STATE AND FUTURE WORK\nAbstract: ENGLISH-LITHUANIAN-ENGLISH MACHINE TRANSLATION LEXICON AND ENGINE: CURRENT STATE AND FUTURE WORK Gintaras Barisevi ius, Bronius Tamulynas Kaunas University of Technology This article overviews the current state of the English-Lithuanian-English machine translation system. The first part of the article describes the problems that system poses today and what actions will be taken to solve them in the future. The second part of the article tackles the main issue of the translation process. Article briefly overviews the word sense disambiguation for MT technique using Google.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Neural Language Model for Dynamically Representing the Meanings of Unknown Words and Entities in a Discourse\nAbstract: This study addresses the problem of identifying the meaning of unknown words or entities in a discourse with respect to the word embedding approaches used in neural language models. We proposed a method for on-the-fly construction and exploitation of word embeddings in both the input and output layers of a neural model by tracking contexts. This extends the dynamic entity representation used in Kobayashi et al. (2016) and incorporates a copy mechanism proposed independently by Gu et al. (2016) and Gulcehre et al. (2016). In addition, we construct a new task and dataset called Anonymized Language Modeling for evaluating the ability to capture word meanings while reading. Experiments conducted using our novel dataset show that the proposed variant of RNN language model outperformed the baseline model. Furthermore, the experiments also demonstrate that dynamic updates of an output layer help a model predict reappearing entities, whereas those of an input layer are effective to predict words following reappearing entities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EliXa: A modular and flexible ABSA platform\nAbstract: This paper presents a supervised Aspect Based Sentiment Analysis (ABSA) system. Our aim is to develop a modular platform which allows to easily conduct experiments by replacing the modules or adding new features. We obtain the best result in the Opinion Target Extraction (OTE) task (slot 2) using an off-the-shelf sequence labeler. The target polarity classification (slot 3) is addressed by means of a multiclass SVM algorithm which includes lexical based features such as the polarity values obtained from domain and open polarity lexicons. The system obtains accuracies of 0.70 and 0.73 for the restaurant and laptop domain respectively, and performs second best in the out-of-domain hotel, achieving an accuracy of 0.80.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: What\u2019s Cookin\u2019? Interpreting Cooking Videos using Text, Speech and Vision\nAbstract: We present a novel method for aligning a sequence of instructions to a video of someone carrying out a task. In particular, we focus on the cooking domain, where the instructions correspond to the recipe. Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript. We then refine this alignment using a state-of-the-art visual food detector, based on a deep convolutional neural network. We show that our technique outperforms simpler techniques based on keyword spotting. It also enables interesting applications, such as automatically illustrating recipes with keyframes, and searching within a video for events of interest.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Systems of natural-language-facilitated human-robot cooperation: A review\nAbstract: Natural-language-facilitated human-robot cooperation (NLC), in which natural language (NL) is used to share knowledge between a human and a robot for conducting intuitive human-robot cooperation (HRC), is continuously developing in the recent decade. Currently, NLC is used in several robotic domains such as manufacturing, daily assistance and health caregiving. It is necessary to summarize current NLC-based robotic systems and discuss the future developing trends, providing helpful information for future NLC research. In this review, we first analyzed the driving forces behind the NLC research. Regarding to a robot\u2019s cognition level during the cooperation, the NLC implementations then were categorized into four types \u201cNL-based control, NL-based robot training, NL-based task execution, NL-based social companion\u201d for comparison and discussion. Last based on our perspective and comprehensive paper review, the future research trends were discussed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SnapToGrid: From Statistical to Interpretable Models for Biomedical Information Extraction\nAbstract: We propose an approach for biomedical information extraction that marries the advantages of machine learning models, e.g., learning directly from data, with the benefits of rule-based approaches, e.g., interpretability. Our approach starts by training a feature-based statistical model, then converts this model to a rule-based variant by converting its features to rules, and \u201csnapping to grid\u201d the feature weights to discrete votes. In doing so, our proposal takes advantage of the large body of work in machine learning, but it produces an interpretable model, which can be directly edited by experts. We evaluate our approach on the BioNLP 2009 event extraction task. Our results show that there is a small performance penalty when converting the statistical model to rules, but the gain in interpretability compensates for that: with minimal effort, human experts improve this model to have similar performance to the statistical model that served as starting point.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Flexible and Creative Chinese Poetry Generation Using Neural Memory\nAbstract: It has been shown that Chinese poems can be successfully generated by sequence-to-sequence neural models, particularly with the attention mechanism. A potential problem of this approach, however, is that neural models can only learn abstract rules, while poem generation is a highly creative process that involves not only rules but also innovations for which pure statistical models are not appropriate in principle. This work proposes a memory-augmented neural model for Chinese poem generation, where the neural model and the augmented memory work together to balance the requirements of linguistic accordance and aesthetic innovation, leading to innovative generations that are still rule-compliant. In addition, it is found that the memory mechanism provides interesting flexibility that can be used to generate poems with different styles.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LATENT DIRICHLET ALLOCATION BASED ORGANISATION OF BROADCAST MEDIA ARCHIVES FOR DEEP NEURAL NETWORK ADAPTATION\nAbstract: This paper presents a new method for the discovery of latent domains in diverse speech data, for the use of adaptation of Deep Neural Networks (DNNs) for Automatic Speech Recognition. Our work focuses on transcription of multi-genre broadcast media, which is often only categorised broadly in terms of high level genres such as sports, news, documentary, etc. However, in terms of acoustic modelling these categories are coarse. Instead, it is expected that a mixture of latent domains can better represent the complex and diverse behaviours within a TV show, and therefore lead to better and more robust performance. We propose a new method, whereby these latent domains are discovered with Latent Dirichlet Allocation, in an unsupervised manner. These are used to adapt DNNs using the Unique Binary Code (UBIC) representation for the LDA domains. Experiments conducted on a set of BBC TV broadcasts, with more than 2,000 shows for training and 47 shows for testing, show that the use of LDA-UBIC DNNs reduces the error up to 13% relative compared to the baseline hybrid DNN models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Moving Toward High Precision Dynamical Modelling in Hidden Markov Models\nAbstract: Hidden Markov Model (HMM) is often regarded as the dynamical model of choice in many fields and applications. It is also at the heart of most state-of-theart speech recognition systems since the 70\u2019s. However, from Gaussian mixture models HMMs (GMMHMM) to deep neural network HMMs (DNN-HMM), the underlying Markovian chain of state-of-the-art models did not changed much. The \u201cleft-to-right\u201d topology is mostly always employed because very few other alternatives exist. In this paper, we propose that finely-tuned HMM topologies are essential for precise temporal modelling and that this approach should be investigated in state-of-the-art HMM system. As such, we propose a proof-of-concept framework for learning efficient topologies by pruning down complex generic models. Speech recognition experiments that were conducted indicate that complex time dependencies can be better learned by this approach than with classical \u201cleft-to-right\u201d models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Machine Comprehension Based on Learning to Rank\nAbstract: Machine comprehension plays an essential role in NLP and has been widely explored with dataset like MCTest. However, this dataset is too simple and too small for learning true reasoning abilities. (Hermann et al., 2015) therefore release a large scale news article dataset and propose a deep LSTM reader system for machine comprehension. However, the training process is expensive. We therefore try feature-engineered approach with semantics on the new dataset to see how traditional machine learning technique and semantics can help with machine comprehension. Meanwhile, our proposed L2R reader system achieves good performance with efficiency and less training data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems\nAbstract: User simulation is essential for generating enough data to train a statistical spoken dialogue system. Previous models for user simulation suffer from several drawbacks, such as the inability to take dialogue history into account, the need of rigid structure to ensure coherent user behaviour, heavy dependence on a specific domain, the inability to output several user intentions during one dialogue turn, or the requirement of a summarized action space for tractability. This paper introduces a data-driven user simulator based on an encoder-decoder recurrent neural network. The model takes as input a sequence of dialogue contexts and outputs a sequence of dialogue acts corresponding to user intentions. The dialogue contexts include information about the machine acts and the status of the user goal. We show on the Dialogue State Tracking Challenge 2 (DSTC2) dataset that the sequence-to-sequence model outperforms an agendabased simulator and an n-gram simulator, according to F-score. Furthermore, we show how this model can be used on the original action space and thereby models user behaviour with finer granularity.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural-based Noise Filtering from Word Embeddings\nAbstract: Word embeddings have been demonstrated to benefit NLP tasks impressively. Yet, there is room for improvement in the vector representations, because current word embeddings typically contain unnecessary information, i.e., noise. We propose two novel models to improve word embeddings by unsupervised learning, in order to yield word denoising embeddings. The word denoising embeddings are obtained by strengthening salient information and weakening noise in the original word embeddings, based on a deep feed-forward neural network filter. Results from benchmark tasks show that the filtered word denoising embeddings outperform the original word embeddings.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Building a Semantic Role Labelling System for Vietnamese\nAbstract: Semantic role labelling (SRL) is a task in natural language processing which detects and classifies the semantic arguments associated with the predicates of a sentence. It is an important step towards understanding the meaning of a natural language. There exists SRL systems for well-studied languages like English, Chinese or Japanese but there is not any such system for the Vietnamese language. In this paper, we present the first SRL system for Vietnamese with encouraging accuracy. We first demonstrate that a simple application of SRL techniques developed for English could not give a good accuracy for Vietnamese. We then introduce a new algorithm for extracting candidate syntactic constituents, which is much more accurate than the common node-mapping algorithm usually used in the identification step. Finally, in the classification step, in addition to the common linguistic features, we propose novel and useful features for use in SRL. Our SRL system achieves an F1 score of 73.53% on the Vietnamese PropBank corpus. This system, including software and corpus, is available as an open source project and we believe that it is a good baseline for the development of future Vietnamese SRL systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extracting Family Relationship Networks from Novels\nAbstract: We present an approach to the extraction of family relations from literary narrative, which incorporates a technique for utterance attribution proposed recently by Elson and McKeown (2010). In our work this technique is used in combination with the detection of vocatives \u2014 the explicit forms of address used by the characters in a novel. We take advantage of the fact that certain vocatives indicate family relations between speakers. The extracted relations are then propagated using a set of rules. We report the results of the application of our method to Jane Austen\u2019s Pride and Prejudice.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: CFO: Conditional Focused Neural Question Answering with Large-scale Knowledge Bases\nAbstract: How can we enable computers to automat-<lb>ically answer questions like \u201cWho created<lb>the character Harry Potter\u201d? Carefully<lb>built knowledge bases provide rich sources<lb>of facts. However, it remains a chal-<lb>lenge to answer factoid questions raised<lb>in natural language due to numerous ex-<lb>pressions of one question. In particular,<lb>we focus on the most common questions<lb>\u2014 ones that can be answered with a sin-<lb>gle fact in the knowledge base. We pro-<lb>pose CFO, a Conditional Focused neural-<lb>network-based approach to answering fac-<lb>toid questions with knowledge bases. Our<lb>approach first zooms in a question to<lb>find more probable candidate subject men-<lb>tions, and infers the final answers with<lb>a unified conditional probabilistic frame-<lb>work. Powered by deep recurrent neural<lb>networks and neural embeddings, our pro-<lb>posed CFO achieves an accuracy of 75.7%<lb>on a dataset of 108k questions \u2013 the largest<lb>public one to date. It outperforms the cur-<lb>rent state of the art by an absolute margin<lb>of 11.8%.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Developing a cardiovascular disease risk-factors annotated corpus of Chinese electronic medical records\nAbstract: Objective The goal of this study was to build a corpus of cardiovascular disease (CVD) risk-factor annotations based on Chinese electronic medical records (CEMRs). This corpus is intended to be used to develop a risk-factor information extraction system that, in turn, can be applied as a foundation for the further study of the progress of risk-factors and CVD. Materials and Methods We designed a light-annotation-task to capture CVD-risk-factors with indicators, temporal attributes and assertions explicitly displayed in the records. The task included: 1) preparing data; 2) creating guidelines for capturing annotations (these were created with the help of clinicians); 3) proposing annotation method including building the guidelines draft, training the annotators and updating the guidelines, and corpus construction. Results The outcome of this study was a risk-factor-annotated corpus based on de-identified discharge summaries and progress notes from 600 patients. Built with the help of specialists, this corpus has an inter-annotator agreement (IAA) F1-measure of 0.968, indicating a high reliability. Discussion Our annotations included 12 CVD-risk-factors such as Hypertension and Diabetes. The annotations can be applied as a powerful tool to the management of these chronic diseases and the prediction of CVD. Conclusion Guidelines for capturing CVD-risk-factor annotations from CEMRs were proposed and an annotated corpus was established. The obtained document-level annotations can be applied in future studies to monitor risk-factors and CVD over the long term. BACKGROUND AND SIGNIFICANCE Introduction Cardiovascular disease (CVD) has become the leading cause of death throughout the world; there were about 17.5 million deaths from CVD in 2012, most of which occurred in lowand middleincome countries.[1] In China, CVD occupies the leading position among causes of death and is responsible for 2 out of every 5 deaths.[2] This situation deeply impairs the health of the Chinese people and is a heavy burden on society. Fortunately, most CVD can be prevented by controlling the malleable risk-factors such as specific medical conditions and the adoption of unhealthy life-styles at early stages.[3] A risk-factor is a pattern of behavior or physical characteristic of a group of individuals that increases the probability of the future occurrence of one or more diseases in that group relative to comparable groups without or with different levels of the behavior or characteristic.[4] Risk-factors, including specific medical conditions such as hypertension and hyperglycemia/diabetes, unhealthy life-style choices such as smoking and alcohol abuse, and other factors such as age and family history, can have prominent effects on the progress of CVD.[3,5] Therefore, monitoring these risk-factors constitutes an important approach in avoiding CVD. CEMR is an utilizable medium for the CVD-risk-factors extraction and supervision. Actually, electronic medical record (EMR) is the storage of all health care data and information in electronic formats, along with the associated information processing and knowledge support tools necessary for the managing the health enterprise system.[6] A large amount of individuals\u2019 health narratives in CEMRs make this resource available for study by natural language processing (NLP) techniques especially information extraction (IE) techniques.[7] Furthermore, in 2010, the ministry of health in China published the basic norms of medical records writing[8] and the basic norms of electronic medical records[9] made this data more normative. All these made CEMR an available medium for the CVD-risk-factor extraction researches. Some related works[7,10\u201421] have been done, but no studies have been conducted on the CVD-risk-factors based on CEMRs. For this, we designed a task to extract CVD-risk-factors from CEMRs. For the extraction, we developed a CVD-risk-factor-annotation-corpus based on CEMRs because in biomedical field the utilized corpora are far less than other open fields and a specific corpus is so important for building an IE-system. The application of this corpus is to act as the basis for developing an automatic risk-factor extraction system and then a monitoring-platform could be established that can supervise CVD-risk-factors over time. Furthermore, based on these risk-factors comprehensively stored over long terms along with other health information, a function that could predict the trend of each risk-factor, manage these chronic diseases (such as hypertension and diabetes) and estimate the progress of CVD could be also included in the platform. To build the corpus, a light-annotation-task[22] is proposed, and we annotated 600 patients\u2019 de-identified discharge summaries and progress notes from CEMRs. Our work is similar to the 2014 i2b2/UTHealth risk-factor annotation shared task.[40] We adopted some technologies such as the formulation for annotation guidelines, workflow and the format for annotation results. However, compared to that task, there are four main differences: (1) the biggest difference is that the concerned text is Chinese EMRs; (2) we added additional risk-factors such as A2 and CKD based on the characteristics of CEMRs; (3) not all the risk-factors are explicitly described in the records, some indicators are also adopted in the 2014 i2b2 shared task. However, negative or below-threshold indicators also form a part of one\u2019s health condition and can be used to develop a long-term supervision system, so this information was appended for our annotations; (4) an exhaustive-annotation-strategy was applied. We found this strategy caused fewer difficulties for annotators and also resulted in a higher level of IAA despite consuming slightly more time. Related work Related works based on English EMRs The 2006 Informatics for Integrating Biology and the Bedside (i2b2) shared task focused on identifying smoking status from medical discharge records; 928 records covering five categories were annotated by two pulmonologists.[23] The 2008 i2b2 Obesity Challenge was an organized competition to find ways to recognize obesity and comorbidities from discharge summaries, and classify them into four classes: Present, Absent, Questionable, and Unmentioned; at the same time an annotated data set was provided.[24] In 2009, the challenge focused on extracting medication information from medical records, including the names of medications, their dosages, modes of administration, frequencies of administration, durations, and reasons for administration, and released a set of annotated discharge summaries.[25,26] In 2010 the challenge was a concepts, assertions, and relations identification task, and they gave an annotated gold-standard corpus for system training.[27] The Sixth i2b2 Natural Language Processing Challenge was concerned with the issues involved in recognizing temporal relations in clinical records, and offered a corpus of annotated discharge summaries with temporal information.[28,29] Subsequently, the 2014 i2b2/UTHealth NLP project focused on identifying risk-factors for Cardiac Artery Disease (CAD) in the narrative texts of EMRs, a set of 1304 medical records were annotated.[30,31] In 2016, follows were asked to classify psychotic patients into four severities based on their neuropsychiatric clinical records, and 433 records were annotated for training.[32] Other works, such as the ShARe/CLEF eHealth Evaluation Lab 2013, have been devoted to solving the difficulties involved in understanding the professional expressions (such as non-standard abbreviations, and ward-specific idioms) that clinicians use when describing their patients, and annotated corpora were provided for system building.[33,34] Another important project was undertaken during SemEval 2015. Its clinical TempEval sub-task was similar to the i2b2 2012 NLP shared task in that participants were asked to find ways to recognize time information, clinical events, and their relations in clinical narratives; manually annotated corpus based on 600 clinical notes and pathology reports was built[35]. Another sub-task of SemEval 2015 involved analyzing clinical text, it attracted the attention to named entity recognition and template slot filling, and the ShARe corpus of annotated clinical text was applied.[34,36] Meystre et al.[37] proposed a new information extraction system for congestive heart failure performance measure based on clinical notes from 1083 Veterans Health Administration patients, and domain experts annotated notes were created for gold standard. Ford et al.[38] studied that extracted information from EMRs text does improve case detection when combined with codes. Related works based on CEMRs Wang et al.[16] focused on recognizing and normalizing the names of symptoms in traditional Chinese medicine EMRs; for the judgement, a set of clinical symptom names were manually annotated. Jiang et al.[14] proposed a complete annotation scheme for building a corpus of word segmentation and part-of-speech (POS) from CEMRs. Yang et al.[11] focused on designing an annotation scheme and constructing a corpus of named entities and entity relationships from CEMRs; they formulated an annotation specification and built a corpus based on 992 medical discharge summaries and progress notes. Lei[17] and Lei et al.[18] focused on the recognition of named entities in Chinese medical discharge summaries and classified the entities into four categories: clinical problems, procedures, labs, and medications; a entities corpus was annotated based on CEMRs. Xu et al.[19] studied a joint model that performed segmentation and named entity recognition in Chinese discharge summaries and built a set of 336 annotated Chinese discharge summaries. Wang et al.[20] researched the extraction of tumor-related information from the Chinese-language operation notes of patients with hepatic carcinomas, and annotated a corpus contains 961 entities. He et al.[21] first proposed a comprehensive corpus of syntactic and semantic annotations from Chinese clinical texts. To sum up these works, research of CVD-risk-factor extraction from CEMRs has not been studied yet. Meanwhile, for the IE tasks studied for the biomedical field, accessible corpora are far less than those for more general extractions but are important for IE-system building. Thus, constructing a CVD-risk-factor annotated corpus is both necessary and fundamental. Moreover, compared with annotation tasks for texts that require little professional knowledge, linguists require the help of medical experts to perform annotations in the biomedical field. MATERIALS AND METHODS A light-annotation-task Annotating CVD-risk-factors from CEMRs, compared with traditional NLP tasks such as segmentation, POS tagging, parsing, and semantic analysis, is a task that is both distinctive and light. As Stubbs says,[22] we need only create a light-annotation-task for risk-factor annotation rather than implementing all the NLP tasks. Therefore, based on the annotation trials conducted by Stubbs and Uzuner,[31] a light-annotation-task in which we only focused on annotations of CVD-risk-factor with indicators, temporal attributes and assertions but no other NLP tasks was built. Meanwhile, an exhaustive-annotation-strategy\u2014we annotated all the occurrences of a CVD-risk-factor in the narrative of CEMRs, no matter how many times it appears\u2014was applied. Notably, in the annotation trials, the increased time consumption caused by exhaustive-annotation-strategy was compensated for by a higher level of IAA and fewer difficulties for the annotators. Data We obtained a snapshot of medical records from the Second Affiliated Hospital of Harbin Medical University (a large general hospital that offers clinical services, medical education, scientific research, disease prevention, healthcare and rehabilitation) for all of 2012. The data included images of the medical records for approximately 140,000 patients from 35 departments and 87 subdepartments, ranging from pediatrics to the ICU. To function as annotation tasks for CVD-risk-factors, we selected a subset of CEMRs from 600 patients composed of 344 randomly selected medical records of cardiovascular patients, 190 from cardiovascular surgery patients, and 66 from other departments. Each patient\u2019s medical records contained a series of documents consisting of their discharge summary, progress notes, medical examination reports, electrocardiograms and so on. The discharge summary and progress notes were regarded as the most important free-text of these.[7] A discharge summary is used to summarize the entire therapeutic process and treatment outcome, while the progress notes record the clinical manifestations, medical examinations and treatment periodicity. Therefore, discharge summaries and progress notes for the 600 patients mentioned above were suitable for annotation. Thereafter, preprocessing was conducted for these records as follows: (1) we used an optical character recognition (OCR) tool \u201cTesseract\u201d[39] to convert the original record images into text; (2) we manually fixed mistakes after the OCR process was complete, and removed identifying information such as patient names, addresses, hospital IDs and doctor names; (3) we encoded the text into Extensible Markup Language (XML) format and added a title section using an XML node. Figure 1 shows an example of a progress note in XML format after preprocessing which is prepared for annotation. Figure 1. A sample progress note after preprocessing Annotation guidelines As the light-annotation-task says, our goal was to annotate the CVD-risk-factors with indicators, temporal attributes and assertions from the narrative of the CEMRs. According to the characteristics of CEMRs and suggestions of clinicians, the guidelines for annotating these information are presented as follows. CVD-risk-factors and indicators An indicator is used to indicate the existence of a risk-factor that may not be explicitly recorded in the narratives of CEMRs but in a cryptic form (e.g. \u201c\u6700\u9ad8\u8840\u538b\u8fbe 150/100 mmHg\u201d (the highest blood pressure (Bp) is 150/100 mmHg) also manifests a hypertensive patient). Explicitly mentioned riskfactor and indirect expressions such as tests or treatments that can indicate the existence of risk-factor are given equal status, even indirect information such as quantitative values from medical examinations is more meaningful because it can capture additional details about a patient\u2019s condition. With the assistance of medical experts, we selected a set of risk-factors contains Overweight/Obesity (O2), Hypertension, Diabetes, Dyslipidemia, Chronic Kidney Disease (CKD), Atherosis, Obstructive Sleep Apnea Syndrome (OSAS), Smoking, Alcohol Abuse (A2), Family History of CVD (FHCVD), Age and Gender, and exploited the indicators of these risk-factors. Table 1 lists all 12 types of risk-factors with the risk-factors in the left column and the indicators on the right. Table 1 CVD-risk-factors and their indicators. Risk-factors Indicators O2 \uf09f Mention: A diagnosis of patient overweight or obesity, e.g. \u201c\u80a5\u80d6\u201d (obesity) Hypertension \uf09f Mention: A diagnosis or history of hypertension, e.g. \u201c\u9ad8\u8840\u538b\u75c5\u53f2 20\u5e74\u201d (a history of hypertension for 20 years) \uf09f High Bp: A measurement of Bp or a description of the patient\u2019s high Bp, e.g. Bp 150/100 mmHg \uf09f Regulate Bp: A description of Bp regulation or unsuccessful regulation, e.g. \u201c\u63a7\u5236 \u8840\u538b\u201d (regulating Bp) \uf09f Blood pressure drug: Patient takes medicine which is confirmed to control Bp, e.g. \u201c\u53e3\u670d\u964d\u538b\u836f\u201d (patient is taking hypotensor) Diabetes \uf09f Mention: A diagnosis or a history of diabetes, e.g. \u201c\u7cd6\u5c3f\u75c5\u201d (diabetes) \uf09f High blood glucose: A measurement of blood glucose or a description of the patient\u2019s high blood glucose, e.g. blood glucose: \u201c\u968f\u673a\u8840\u7cd6:14.5mmol/L\u201d (RBG (Random Blood Glucose): 14.5mmol/L) \uf09f Regulate blood glucose: A description of blood glucose regulation or unsuccessful regulation, e.g. \u201c\u8c03\u8282\u8840\u7cd6\u201d (regulating the glucose) \uf09f Hypoglycemic drug: Patient takes medications confirmed to control blood glucose, e.g. \u201c\u89c4\u5f8b\u7528\u80f0\u5c9b\u7d20\u201d (patient takes insulin regularly) Dyslipidemia \uf09f Mention: A diagnosis of dyslipidemia, hyperlipidemia or a history of hyperlipidemia, e.g. \u201c\u9ad8\u8840\u8102\u53f2\u201d (a history of hyperlipidemia) \uf09f High blood lipids: A measurement of blood lipids or a description of the patient\u2019s high blood lipids, e.g. TG (triglyceride): 1.96mmol/L \uf09f Regulate blood lipids: A description of blood lipids regulation or unsuccessful regulation, e.g. \u201c\u964d\u8102\u201d (to lower serum lipids) \uf09f Lipid-lowering drug: Patient takes medicine that is confirmed to control blood lipids, e.g. \u201c\u6cbb\u7597\u8ba1\u5212:\u7acb\u666e\u59a5 20 mg Qn po\u201d (Treatment plan: Lipitor (atorvastatin calcium) 20 mg, take orally, once per night) CKD \uf09f Mention: A diagnosis of CKD, e.g. \u201c\u6162\u6027\u80be\u708e\u201d (chronic nephritis) Atherosis \uf09f Mention: A diagnosis of atherosclerosis or atherosclerotic plaque, e.g. \u201c\u51a0\u8109\u7ca5\u6837 \u6591\u5757\u201d (atherosclerotic plaque) OSAS \uf09f Mention: A diagnosis of OSAS, e.g. \u201c\u963b\u585e\u578b\u7761\u7720\u547c\u5438\u6682\u505c\u7efc\u5408\u75c7\u201d (OSAS) Smoking \uf09f Mention: Smoking or a patient history of smoking, e.g. \u201c\u5438\u70df 40\u4f59\u5e74\u201d (smoking over 40 years) \uf09f Smoking cessation: A description of smoking cessation or that the patient has not yet quit smoking, e.g. \u201c\u672a\u6212\u70df\u201d (the patient has not yet quit smoking) \uf09f Smoking amount: A description of how much the patient smokes, e.g. \u201c\u6bcf\u5929 20 \u652f\u201d (20 cigarettes per day) A2 \uf09f Mention: Alcohol abuse, e.g. \u201c\u957f\u671f\u5927\u91cf\u996e\u9152\u53f2\u201d (a long history of heavy drinking) \uf09f Drinking amount: A description of how much the patient drinks, e.g. \u201c2\u4e24/\u65e5\u201d (\u6570\u503c\u8981\u5927\u4e8e 1)(100 grams of white spirit consumption per day (the number should be over 50 g)) FHCVD \uf09f Mention: Patient has a family history of CVD or has a first-degree relative (parents, siblings, or children) who has a history of CVD, e.g. \u201c\u54e5\u54e5\u6709\u51a0\u5fc3\u75c5\u75c5\u53f2\u201d (the patient\u2019s brother has a history of CVD) Age \uf09f Mention: The age of the patient, e.g. \u201c66\u5c81\u201d (66 years old) \uf09f Age group: The age group of the patient, e.g. \u201c\u8001\u5e74\u201d(elderly) Gender \uf09f Mention: The gender of patient, e.g. \u201c\u5973\u6027\u201d (female) Notably, given to construct a CVD-risk-factors timeline, we annotated all the quantitative values from medical examinations regardless of whether they were over the threshold (e.g., a patient whose Bp is 120/80 mmHg is also annotated for hypertension, even though the measurement is below the 140/90 mmHg criterion[5]). So that all the test values would be extracted and we can build a clear picture of risk-factors changes over time, and this is one of the big difference between the i2b2 2014 risk-factor task and ours. Temporal attributes To construct a health condition timeline, collecting temporal annotations is essential. Considering the time at which the indicators occurred, we divided the risk-factors into four timedependent categories: before the duration of hospital stay (DHS) (the risk-factor occurred before the DHS), during the DHS, after the DHS, and continuing (the risk-factor is continuous). For instance, \u201c\u5e73 \u65f6\u8840\u538b 130/90 mmHg\u201d (a patient whose ordinary Bp is 130/90 mmHg) is regarded as the high Bp indicator of hypertension with time before the DHS; \u201c\u67e5\u4f53:Bp 130/80 mmHg\u201d (physical examination: Bp 130/80 mmHg) indicates that the high Bp of Hypertension was made during the DHS; \u201c\u51fa\u9662\u533b\u5631: \u8c03\u8282\u8840\u7cd6\u201d (doctor advice to a patient after discharge: to regulate blood glucose) indicates that the diabetes indicator of regulate blood glucose occurred after the DHS; and \u201c\u8eab\u6750\u80a5\u80d6\u201d (a fat body) which is usually unchangeable over the short term would be annotated as a mention of O2 with time continuing. In this way, changes of risk-factors can be clearly presented. For example, no indicators of diabetes were presented during the previous DHS, but evidence shows that the patient exhibited diabetic indicators before the next DHS; therefore, the diabetes occurred between the two DHSs. Specially, age and gender are not included in temporal annotations. Assertions Different from the works of Stubbs and Uzuner,[30] we first proposed assertions of risk-factors in CEMRs. For example, \u201c\u65e0\u7cd6\u5c3f\u75c5\u75c5\u53f2\u201d (patient does not have a history of diabetes) also needs to be considered as such text can certainly show that the patient did not previously have diabetes. In detail, based on whether the risk-factor actually occurred on the patient, we created two modifiers: associated or not associated with the patient. Further, risk-factors associated with the patient are divided into three categories: present, absent and possible. Overall, assertions can be summarized as follows: \uf09f Present: the risk-factor definitely occurred on the patient, e.g. \u201c\u5e73\u65f6\u8840\u538b 130/90 mmHg\u201d (the patient\u2019s ordinary Bp is 130/90 mmHg) \uf09f Absent: the risk-factor was considered for the patient, but was negative, e.g. \u201c\u65e0\u7cd6\u5c3f\u75c5\u75c5\u53f2\u201d (the patient does not have a history of diabetes) \uf09f Possible: the risk-factor may possibly have occurred on the patient, e.g. \u201c\u4e34\u5e8a\u521d\u6b65\u8bca\u65ad:\u7cd6\u5c3f\u75c5\u201d (Primary diagnosis: diabetes) \uf09f Not associated with the patient: the risk-factor occurred on others, e.g. \u201c\u5f1f\u60a3\u7cd6\u5c3f\u75c5\u201d (the patient\u2019s brother has diabetes) Annotation method The annotation method involves three major tasks: building the guidelines draft, training the annotators and updating the guidelines, and corpus construction. These tasks can be seen in Figure 2. Figure 2. The flowchart for CVD-risk-factor annotation method Building the guidelines draft Based on annotation guidelines above, the linguists created a preliminary implementation of an annotation guidelines draft that included all 12 CVD-risk-factors, indicators, temporal attributes, and assertions along with their definitions, some positive annotations (expressions which should be marked) and negative annotations (expressions which should not be marked) by referencing the 2014 i2b2/UTHealth risk-factor annotation guideline.[40] Some annotation attempts were conducted under this draft using an annotation tool which was developed specifically for this task. Figure 3 shows a sample annotation. Figure 3. A sample annotation for CVD-risk-factors Using sample annotations, errors and inappropriate rules in the preliminary draft were corrected and both positive and negative examples were added to the draft. This process continued until no more modifications were needed; at that point, the specification were considered to be suitable for the next workflow. Training the annotators and updating the guidelines For domain annotation, annotators with specific knowledge backgrounds are desirable. Consequently, two Masters students in medicine were employed and trained as annotators. The training process follows an iterative method, each repetition can be summed up as follows: Phase 1: A set of discharge summaries and progress notes for 15 randomly selected patients were provided to both annotators for labeling. Phase 2: After completing the annotation, the IAA of the two annotated corpus was calculated to evaluate the degree to which the annotators were in agreement. For the IAA calculation, one annotated database is used as the gold standard, and the other is compared to the standard to compute the precision, recall, and F1-measure. Here, standard precision, recall, and F1-measure equations were adopted, the calculation equations were described as follows: ( 1, 2) ( 2) Agreement A A precision Annotation A = , (1) ( 1, 2) ( 1) Agreement A A recall Annotation A = , (2) 1 2 = . precision recall F precision recall \u00d7 \u00d7 + (3) Here, we regarded the annotations of annotator 1 A as gold standard and evaluated the quality of 2 A annotations. The ( ) 1, 2 Agreement A A refers to the same annotations of the two annotators. More calculation details can be found in Hripcsak et al.[41] Phase 3: The two annotations were compared. Moreover, any uncertainties would be discussed by both the linguists and the annotators. A voting method was used to obtain a final agreement. Phase 4: Annotation guidelines were updated. In particular, errors found during phase 3 were added to the positive or negative examples and, when necessary, the guidelines were modified. This procedure should be iteratively conducted until the IAA calculated in Phase 2 achieves a high value continuously. In total, five repetitions were carried out; the resulting IAA-values are listed in Table 2. Table 2. IAA-values achieved during the iterative training process Iteration 1 Iteration 2 Iteration 3 Iteration 4 Iteration 5 Precision 0.810 0.977 0.967 0.986 0.988 Recall 0.815 0.977 0.962 0.986 0.988 F1-measure 0.812 0.977 0.964 0.986 0.988 As Table 2 shows, the iterations obtained very high IAAs. All the F1-measures values were above 0.964 except for Iteration 1 in which the low score was probably caused by the initial unfamiliarity of annotators with the annotation guidelines and tools. Meanwhile, the subsequent iterations obtained surprisingly high scores, indicating that the annotators and guidelines were truly ready for the corpus annotation. Corpus construction The annotators were asked to capture annotations from CEMRs for the 600 patients using the updated annotation guidelines. Moreover, to create a high quality annotated corpus, three measures were taken. One was that, during the development of annotation tool, a button indicating that the labeling is uncertain was for annotators to press when they were unsure of the accuracy of a current annotation. Those uncertainties could be collected and discussed later. Another measure involved the use of overlapped documents (discharge summaries and progress notes of 25 patients), which were distributed to both annotators. These twice-annotated records can be used to calculate IAA and to monitor the quality of the entire annotation evaluation. The last measure was a random sampling check on the annotations (at least one third were selected) by the linguists. When problems were found, a discussion would be held and the guidelines were updated. RESULTS In total, in the CVD-risk-factor-annotation-corpus comprising the discharge summaries and progress notes for all the 600 patients, there are 9678 annotations associated with the 12 CVD-riskfactors. Of these, \u201cmention\u201d garners 63.5%, while \u201cdrug\u201d is rare (due to our restriction in the annotation guidelines that medication must be confirmed to be treated as a risk-factor). Among the risk-factors, hypertension is prominent in CEMR, with 3729 annotations; age and gender occur at the same rate as Bp because they are basic patient attributes that are routinely recorded before diagnosis. The distributions of the four assertions (present, absent, possible, and not associated with patient) were 69.7, 19.2, 11.0, and 0.1 percent, respectively. The \u201cpresent\u201d assertions occur most often, possibly because positive descriptions may have more significance when creating the medical records. Annotation quality and analysis Reasonably, the IAA-values for the final corpus should be as high as the IAA-values obtained during the training process due to the work performed before and during the formal annotation to guarantee sufficient quality. The final IAA calculations resulted in 0.971 for precision, 0.965 for recall and 0.968 for the F1-measure; these values demonstrate the high quality of the corpus. Table 3 shows the distribution of risk-factors, indicators, temporal attributes and assertions. Each row in the table shows the distribution of a single indicator over the entire corpus in different time and assertion partitions. Table 3. Distribution of CVD-risk-factors, indicators, their occurrence times, and assertions Risk-factors Indicators Before DHS During DHS After DHS Continuing P A Pb N Total P A Pb N Total P A Pb N Total P A Pb N Total Total O2 Mention 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 0 0 0 18 18 Hypertension Mention 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 526 401 471\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: One-Shot Neural Cross-Lingual Transfer for Paradigm Completion\nAbstract: We present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a lowresource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Part-of-Speech Relevance Weights for Learning Word Embeddings\nAbstract: This paper proposes a model to learn word embeddings with weighted contexts based on part-of-speech (POS) relevance weights. POS is a fundamental element in natural language. However, state-of-the-art word embedding models fail to consider it. This paper proposes to use position-dependent POS relevance weighting matrices to model the inherent syntactic relationship among words within a context window. We utilize the POS relevance weights to model each word-context pairs during the word embedding training process. The model proposed in this paper paper jointly optimizes word vectors and the POS relevance matrices. Experiments conducted on popular word analogy and word similarity tasks all demonstrated the effectiveness of the proposed method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bidirectional American Sign Language to English Translator\nAbstract: In the US alone, there are approximately 900,000 hearingimpaired people whose primary mode of conversation is sign language. For these people, communication with non-signers is a daily struggle, and they are often disadvantaged when it comes to finding a job, accessing health care, etc. There are a few emerging technologies designed to translate sign language to English in real time, but most of the current research attempts to convert raw signs into English words. This aspect of the translation is certainly necessary, but it does not take into account the grammatical differences between signed languages and spoken languages. In this paper, we outline our bidirectional translation system that converts sentences from American Sign Language (ASL) to English, and vice versa. To perform machine translation between ASL and English, we utilize a generative approach. Specifically, we employ an adjustment to the IBM word-alignment model 1 (IBM WAM1)[14] where we define language models for English and ASL, as well as a translation model, and attempt to generate a translation that maximizes the posterior distribution defined by these models. Using these models, we are able to quantify the concepts of fluency and faithfulness of a translation between languages.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Effects of Stop Words Elimination for AIR\nAbstract: The effectiveness of three stop words lists for Arabic Information Retrieval---General Stoplist, CorpusBased Stoplist, Combined Stoplist ---were investigated in this study. Three popular weighting schemes were examined: the inverse document frequency weight, probabilistic weighting, and statistical language modelling. The Idea is to combine the statistical approaches with linguistic approaches to reach an optimal performance, and compare their effect on retrieval. The LDC (Linguistic Data Consortium) Arabic Newswire data set was used with the Lemur Toolkit. The Best Match weighting scheme used in the Okapi retrieval system had the best overall performance of the three weighting algorithms used in the study, stoplists improved retrieval effectiveness especially when used with the BM25 weight. The overall performance of a general stoplist was better than the other two lists.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Joint Modeling of Content and Discourse Relations in Dialogues\nAbstract: We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrasebased content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members\u2019 understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: College of Information Science and Engineering, Ritsumeikan University, 1-1-1 Noji Higashi, Kusatsu, Shiga 525-8577, Japan Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo 182-8585, Japan Faculty of Computer Science and Systems Engineering, Okayama Prefectural University, 111 Kubogi, Soja-shi, Okayama 719-1197, Japan Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, 3-4-1 Ohkubo, Shinjuku, Tokyo 169-8555, Japan Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), AIST Tsukuba Central 1, 1-1-1 Umezono, Tsukuba, Ibaraki 305-8560, Japan\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Text Understanding from Scratch\nAbstract: This article demontrates that we can apply deep learning to text understanding from characterlevel inputs all the way up to abstract text concepts, using temporal convolutional networks(LeCun et al., 1998) (ConvNets). We apply ConvNets to various large-scale datasets, including ontology classification, sentiment analysis, and text categorization. We show that temporal ConvNets can achieve astonishing performance without the knowledge of words, phrases, sentences and any other syntactic or semantic structures with regards to a human language. Evidence shows that our models can work for both English and Chinese.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Self Talk: Image Understanding via Continuous Questioning and Answering\nAbstract: In this paper we consider the problem of continuously discovering image contents by actively asking image based questions and subsequently answering the questions being asked. The key components include a Visual Question Generation (VQG) module and a Visual Question Answering module, in which Recurrent Neural Networks (RNN) and Convolutional Neural Network (CNN) are used. Given a dataset that contains images, questions and their answers, both modules are trained at the same time, with the difference being VQG uses the images as input and the corresponding questions as output, while VQA uses images and questions as input and the corresponding answers as output. We evaluate the self talk process subjectively using Amazon Mechanical Turk, which show effectiveness of the proposed method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Machine Translation on Scarce-Resource Condition: A case-study on Persian-English\nAbstract: Neural Machine Translation (NMT) is a new approach for Machine Translation (MT), and due to its success, it has absorbed the attention of many researchers in the field. In this paper, we study NMT model on Persian-English language pairs, to analyze the model and investigate the appropriateness of the model for scarce-resourced scenarios, the situation that exist for Persian-centered translation systems. We adjust the model for the Persian language and find the best parameters and hyper parameters for two tasks: translation and transliteration. We also apply some preprocessing task on the Persian dataset which yields to increase for about one point in terms of BLEU score. Also, we have modified the loss function to enhance the word alignment of the model. This new loss function yields a total of 1.87 point improvements in terms of BLEU score in the translation quality. Keywords-component; neural machine translation; cost function; alignment model; text preprocessing\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Sentence Plausibility to Learn the Semantics of Transitive Verbs\nAbstract: The functional approach to compositional distributional semantics considers transitive verbs to be linear maps that transform the distributional vectors representing nouns into a vector representing a sentence. We conduct an initial investigation that uses a matrix consisting of the parameters of a logistic regression classifier trained on a plausibility task as a transitive verb function. We compare our method to a commonly used corpus-based method for constructing a verb matrix and find that the plausibility training may be more effective for disambiguation tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Numerically Grounded Language Models for Semantic Error Correction\nAbstract: Semantic error detection and correction is an important task for applications such as fact checking, speech-to-text or grammatical error correction. Current approaches generally focus on relatively shallow semantics and do not account for numeric quantities. Our approach uses language models grounded in numbers within the text. Such groundings are easily achieved for recurrent neural language model architectures, which can be further conditioned on incomplete background knowledge bases. Our evaluation on clinical reports shows that numerical grounding improves perplexity by 33% and F1 for semantic error correction by 5 points when compared to ungrounded approaches. Conditioning on a knowledge base yields further improvements.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies\nAbstract: The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture\u2019s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In recent times, data is growing rapidly in every domain such as news, social media, banking, education, etc. Due to the excessiveness of data, there is a need of automatic summarizer which will be capable to summarize the data especially textual data in original document without losing any critical purposes. Text summarization is emerged as an important research area in recent past. In this regard, review of existing work on text summarization process is useful for carrying out further research. In this paper, recent literature on automatic keyword extraction and text summarization are presented since text summarization process is highly depend on keyword extraction. This literature includes the discussion about different methodology used for keyword extraction and text summarization. It also discusses about different databases used for text summarization in several domains along with evaluation matrices. Finally, it discusses briefly about issues and research challenges faced by researchers along with future direction.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Attentive Convolutional Neural Network based Speech Emotion Recognition: A Study on the Impact of Input Features, Signal Length, and Acted Speech\nAbstract: Speech emotion recognition is an important and challenging task in the realm of human-computer interaction. Prior work proposed a variety of models and feature sets for training a system. In this work, we conduct extensive experiments using an attentive convolutional neural network with multi-view learning objective function. We compare system performance using different lengths of the input signal, different types of acoustic features and different types of emotion speech (improvised/scripted). Our experimental results on the Interactive Emotional Motion Capture (IEMOCAP) database reveal that the recognition performance strongly depends on the type of speech data independent of the choice of input features. Furthermore, we achieved state-of-the-art results on the improvised speech data of IEMOCAP.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Getting More Out Of Syntax with PROPS\nAbstract: Semantic NLP applications often rely on dependency trees to recognize major elements of the proposition structure of sentences. Yet, while much semantic structure is indeed expressed by syntax, many phenomena are not easily read out of dependency trees, often leading to further ad-hoc heuristic postprocessing or to information loss. To directly address the needs of semantic applications, we present PROPS \u2013 an output representation designed to explicitly and uniformly express much of the proposition structure which is implied from syntax, and an associated tool for extracting it from dependency trees.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss\nAbstract: Bi-directional long short-term memory (LSTM) networks have recently proven successful for various NLP sequence modeling tasks, but little is known about their reliance to input representations, target languages, data set size, and label noise. We address these issues and evaluate bi-LSTMs with word, character, and unicode byte embeddings for POS tagging. We compare bi-LSTMs to traditional POS taggers across languages and data sizes. We also present a novel biLSTM model, which combines the POS tagging loss function with an auxiliary loss function that accounts for rare words. The new model obtains state-of-the-art performance across 22 languages, and works especially well for morphologically complex languages. Our analysis suggests that biLSTMs are less sensitive to training data size and label corruptions (at small noise levels) than previously assumed.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Orthographic Syllable as basic unit for SMT between Related Languages\nAbstract: We explore the use of the orthographic syllable, a variable-length consonant-vowel sequence, as a basic unit of translation between related languages which use abugida or alphabetic scripts. We show that orthographic syllable level translation significantly outperforms models trained over other basic units (word, morpheme and character) when training over small parallel corpora.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Ontology-Aware Token Embeddings for Prepositional Phrase Attachment\nAbstract: Type-level word embeddings use the same set of parameters to represent all instances of a word regardless of its context, ignoring the inherent lexical ambiguity in language. Instead, we embed semantic concepts (or synsets) as defined in WordNet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts. We use the new, context-sensitive embeddings in a model for predicting prepositional phrase (PP) attachments and jointly learn the concept embeddings and model parameters. We show that using context-sensitive embeddings improves the accuracy of the PP attachment model by 5.4% absolute points, which amounts to a 34.4% relative reduction in errors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Classifying discourse in a CSCL platform to evaluate correlations with Teacher Participation and Progress\nAbstract: In Computer-Supported learning, monitoring and engaging a group of learners is a complex task for teachers, especially when learners are working collaboratively: Are my students motivated? What kind of progress are they making? Should I intervene? Is my communication and the didactic design adapted to my students? Our hypothesis is that the analysis of natural language interactions between students, and between students and teachers, provide very valuable information and could be used to produce qualitative indicators to help teachers\u2019 decisions. We develop an automatic approach in three steps (1) to explore the discursive functions of messages in a CSCL platform, (2) to classify the messages automatically and (3) to evaluate correlations between discursive attitudes and other variables linked to the learning activity. Results tend to show that some types of discourse are correlated with a notion of Progress on the learning activities and the importance of emotive participation from the Teacher.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: While deep learning parsing approaches have proven very successful at finding the structure of sentences, most neural dependency parsers use neural networks only for feature extraction, and then use those features in traditional parsing algorithms. In contrast, this paper builds off recent work using general-purpose neural network components, training an attention mechanism over an LSTM to attend to the head of the phrase. We get state-of-the-art results for standard dependency parsing benchmarks, achieving 95.44% UAS and 93.76% LAS on the PTB dataset, 0.8% and 1.0% improvement, respectively, over Andor et al. (2016). In addition to proposing a new parsing architecture using dimensionality reduction and biaffine interactions, we examine simple hyperparameter choices that had a profound influence on the model\u2019s performance, such as reducing the value of \u03b22 in the Adam optimization algorithm.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Document Decomposition of Bangla Printed Text\nAbstract: skew, Auto rotation. Abstract: Today all kind of information is getting digitized and along with all this digitization, the huge archive of various kinds of documents is being digitized too. We know that, Optical Character Recognition is the method through which, newspapers and other paper documents convert into digital resources. But, it is a fact that this method works on texts only. As a result, if we try to process any document which contains non-textual zones, then we will get garbage texts as output. That is why; in order to digitize documents properly they should be preprocessed carefully. And while preprocessing, segmenting document in different regions according to the category properly is most important. But, the Optical Character Recognition processes available for Bangla language have no such algorithm that can categorize a newspaper/book page fully. So we worked to decompose a document into its several parts like headlines, sub headlines, columns, images etc. And if the input is skewed and rotated, then the input was also deskewed and de-rotated. To decompose any Bangla document we found out the edges of the input image. Then we find out the horizontal and vertical area of every pixel where it lies in. Later on the input image was cut according to these areas. Then we pick each and every sub image and found out their height-width ratio, line height. Then according to these values the sub images were categorized. To de skew the image we found out the skew angle and de skewed the image according to this angle. To de-rotate the image we used the line height, matra line, pixel ratio of matra line.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Email Babel: Does Language Affect Criminal Activity in Compromised Webmail Accounts?\nAbstract: We set out to understand the effects of differing language on the ability of cybercriminals to navigate webmail accounts and locate sensitive information in them. To this end, we configured thirty Gmail honeypot accounts with English, Romanian, and Greek language settings. We populated the accounts with email messages in those languages by subscribing them to selected online newsletters. We hid email messages about fake bank accounts in fifteen of the accounts to mimic real-world webmail users that sometimes store sensitive information in their accounts. We then leaked credentials to the honey accounts via paste sites on the Surface Web and the Dark Web, and collected data for fifteen days. Our statistical analyses on the data show that cybercriminals are more likely to discover sensitive information (bank account information) in the Greek accounts than the remaining accounts, contrary to the expectation that Greek ought to constitute a barrier to the understanding of non-Greek visitors to the Greek accounts. We also extracted the important words among the emails that cybercriminals accessed (as an approximation of the keywords that they searched for within the honey accounts), and found that financial terms featured among the top words. In summary, we show that language plays a significant role in the ability of cybercriminals to access sensitive information hidden in compromised webmail accounts. Keywords\u2014webmail \u00b7 honeypot \u00b7 information theft \u00b7 language\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The emotional arcs of stories are dominated by six basic shapes\nAbstract: Advances in computing power, natural language processing, and digitization of text now make it possible to study our a culture\u2019s evolution through its texts using a \u201cbig data\u201d lens. Our ability to communicate relies in part upon a shared emotional experience, with stories often following distinct emotional trajectories, forming patterns that are meaningful to us. Here, by classifying the emotional arcs for a filtered subset of 1,737 stories from Project Gutenberg\u2019s fiction collection, we find a set of six core trajectories which form the building blocks of complex narratives. We strengthen our findings by separately applying optimization, linear decomposition, supervised learning, and unsupervised learning. For each of these six core emotional arcs, we examine the closest characteristic stories in publication today and find that particular emotional arcs enjoy greater success, as measured by downloads.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast, Flexible Models for Discovering Topic Correlation across Weakly-Related Collections\nAbstract: Weak topic correlation across document collections with different numbers of topics in individual collections presents challenges for existing cross-collection topic models. This paper introduces two probabilistic topic models, Correlated LDA (C-LDA) and Correlated HDP (CHDP). These address problems that can arise when analyzing large, asymmetric, and potentially weakly-related collections. Topic correlations in weakly-related collections typically lie in the tail of the topic distribution, where they would be overlooked by models unable to fit large numbers of topics. To efficiently model this long tail for large-scale analysis, our models implement a parallel sampling algorithm based on the Metropolis-Hastings and alias methods (Yuan et al., 2015). The models are first evaluated on synthetic data, generated to simulate various collection-level asymmetries. We then present a case study of modeling over 300k documents in collections of sciences and humanities research from JSTOR.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tracking Amendments to Legislation and Other Political Texts with a Novel Minimum-Edit-Distance Algorithm: DocuToads\nAbstract: Political scientists often find themselves tracking amendments to political texts. As different actors weigh in, texts change as they are drafted and redrafted, reflecting political preferences and power. This study provides a novel solution to the problem of detecting amendments to political text based upon minimum edit distances. We demonstrate the usefulness of two language-insensitive, transparent, and efficient minimum-edit-distance algorithms suited for the task. These algorithms are capable of providing an account of the types (insertions, deletions, substitutions, and transpositions) and substantive amount of amendments made between version of texts. To illustrate the usefulness and efficiency of the approach we replicate two existing studies from the field of legislative studies. Our results demonstrate that minimum edit distance methods can produce superior measures of text amendments to hand-coded efforts in a fraction of the time and resource costs. \u2217Post-Doctoral Researcher at the Centre for European Politics, Department of Political Science, University of Copenhagen (hajh@ifs.ku.dk). \u2020Lecturer in European Public Policy, School of Politics and International Relations, University College Dublin (james.cross@ucd.ie). ar X iv :1 60 8. 06 45 9v 1 [ cs .C L ] 2 3 A ug 2 01 6\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The paper describes the Egyptian Arabicto-English statistical machine translation (SMT) system that the QCRI-ColumbiaNYUAD (QCN) group submitted to the NIST OpenMT\u20192015 competition. The competition focused on informal dialectal Arabic, as used in SMS, chat, and speech. Thus, our efforts focused on processing and standardizing Arabic, e.g., using tools such as 3arrib and MADAMIRA. We further trained a phrase-based SMT system using state-of-the-art features and components such as operation sequence model, class-based language model, sparse features, neural network joint model, genrebased hierarchically-interpolated language model, unsupervised transliteration mining, phrase-table merging, and hypothesis combination. Our system ranked second on all three genres.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Enabling Medical Translation for Low-Resource Languages\nAbstract: We present research towards bridging the language gap between migrant workers in Qatar and medical staff. In particular, we present the first steps towards the development of a real-world HindiEnglish machine translation system for doctor-patient communication. As this is a low-resource language pair, especially for speech and for the medical domain, our initial focus has been on gathering suitable training data from various sources. We applied a variety of methods ranging from fully automatic extraction from the Web to manual annotation of test data. Moreover, we developed a method for automatically augmenting the training data with synthetically generated variants, which yielded a very sizable improvement of more than 3 BLEU points absolute.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules\nAbstract: Morphologically rich languages accentuate two properties of distributional vector space models: 1) the difficulty of inducing accurate representations for lowfrequency word forms; and 2) insensitivity to distinct lexical relations that have similar distributional signatures. These effects are detrimental for language understanding systems, which may infer that inexpensive is a rephrasing for expensive or may not associate acquire with acquires. In this work, we propose a novel morph-fitting procedure which moves past the use of curated semantic lexicons for improving distributional vector spaces. Instead, our method injects morphological constraints generated using simple language-specific rules, pulling inflectional forms of the same word close together and pushing derivational antonyms far apart. In intrinsic evaluation over four languages, we show that our approach: 1) improves low-frequency word estimates; and 2) boosts the semantic quality of the entire word vector collection. Finally, we show that morph-fitted vectors yield large gains in the downstream task of dialogue state tracking, highlighting the importance of morphology for tackling long-tail phenomena in language understanding tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Word Affect Intensities\nAbstract: Words often convey affect\u2014emotions, feelings, and attitudes. Lexicons of word\u2013 affect association have applications in automatic emotion analysis and natural language generation. However, existing lexicons indicate only coarse categories of affect association. Here, for the first time, we create an affect intensity lexicon with real-valued scores of association. We use a technique called best\u2013worst scaling that improves annotation consistency and obtains reliable fine-grained scores. The lexicon includes terms from general English as well as terms specific to social media communications. It has close to 6,000 entries for four basic emotions. We will be adding entries for other affect dimensions shortly.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Word Representations from Relational Graphs\nAbstract: Attributes of words and relations between two words are central to numerous tasks in Artificial Intelligence such as knowledge representation, similarity measurement, and analogy detection. Often when two words share one or more attributes in common, they are connected by some semantic relations. On the other hand, if there are numerous semantic relations between two words, we can expect some of the attributes of one of the words to be inherited by the other. Motivated by this close connection between attributes and relations, given a relational graph in which words are interconnected via numerous semantic relations, we propose a method to learn a latent representation for the individual words. The proposed method considers not only the co-occurrences of words as done by existing approaches for word representation learning, but also the semantic relations in which two words co-occur. To evaluate the accuracy of the word representations learnt using the proposed method, we use the learnt word representations to solve semantic word analogy problems. Our experimental results show that it is possible to learn better word representations by using semantic semantics be-\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Feature-based Classification Technique for Answering Multi-choice World History Questions: FRDC_QA at NTCIR-11 QA-Lab Task\nAbstract: Our FRDC_QA team participated in the QA-Lab English subtask of the NTCIR-11. In this paper, we describe our system for solving real-world university entrance exam questions, which are related to world history. Wikipedia is used as the main external resource for our system. Since problems with choosing right/wrong sentence from multiple sentence choices account for about two-thirds of the total, we individually design a classification based model for solving this type of questions. For other types of questions, we also design some simple methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MULTI-VIEW DIMENSIONALITY REDUCTION FOR DIALECT IDENTIFICATION OF ARABIC BROADCAST SPEECH\nAbstract: In this work, we present a new Vector Space Model (VSM) of speech utterances for the task of spoken dialect identification. Generally, DID systems are built using two sets of features that are extracted from speech utterances; acoustic and phonetic. The acoustic and phonetic features are used to form vector representations of speech utterances in an attempt to encode information about the spoken dialects. The Phonotactic and Acoustic VSMs, thus formed, are used for the task of DID. The aim of this paper is to construct a single VSM that encodes information about spoken dialects from both the Phonotactic and Acoustic VSMs. Given the two views of the data, we make use of a well known multi-view dimensionality reduction technique known as Canonical Correlation Analysis (CCA), to form a single vector representation for each speech utterance that encodes dialect specific discriminative information from both the phonetic and acoustic representations. We refer to this approach as feature space combination approach and show that our CCA based feature vector representation performs better on the Arabic DID task than the phonetic and acoustic feature representations used alone. We also present the feature space combination approach as a viable alternative to the model based combination approach, where two DID systems are built using the two VSMs (Phonotactic and Acoustic) and the final prediction score is the output score combination from the two systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Storytelling Agents with Personality and Adaptivity\nAbstract: We explore the expression of personality and adaptivity through the gestures of virtual agents in a storytelling task. We conduct two experiments using four different dialogic stories. We manipulate agent personality on the extraversion scale, whether the agents adapt to one another in their gestural performance and agent gender. Our results show that subjects are able to perceive the intended variation in extraversion between different virtual agents, independently of the story they are telling and the gender of the agent. A second study shows that subjects also prefer adaptive to nonadaptive virtual agents.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automatic Measurement of Pre-aspiration\nAbstract: Pre-aspiration is defined as the period of glottal friction occurring in sequences of vocalic/consonantal sonorants and phonetically voiceless obstruents. We propose two machine learning methods for automatic measurement of pre-aspiration duration: a feedforward neural network, which works at the frame level; and a structured prediction model, which relies on manually designed feature functions, and works at the segment level. The input for both algorithms is a speech signal of an arbitrary length containing a single obstruent, and the output is a pair of times which constitutes the pre-aspiration boundaries. We train both models on a set of manually annotated examples. Results suggest that the structured model is superior to the frame-based model as it yields higher accuracy in predicting the boundaries and generalizes to new speakers and new languages. Finally, we demonstrate the applicability of our structured prediction algorithm by replicating linguistic analysis of pre-aspiration in Aberystwyth English with high correlation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting English Writing Styles For Non Native Speakers\nAbstract: This paper presents the first attempt, up to our knowledge, to classify English writing styles on this scale with the challenge of classifying day to day language written by writers with different backgrounds covering various areas of topics.The paper proposes simple machine learning algorithms and simple to generate features to solve hard problems. Relying on the scale of the data available from large sources of knowledge like Wikipedia. We believe such sources of data are crucial to generate robust solutions for the web with high accuracy and easy to deploy in practice. The paper achieves 74% accuracy classifying native versus non native speakers writing styles. Moreover, the paper shows some interesting observations on the similarity between different languages measured by the similarity of their users English writing styles. This technique could be used to show some well known facts about languages as in grouping them into families, which our experiments support.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Distributed representations of words have been shown to capture lexical semantics, as demonstrated by their effectiveness in word similarity and analogical relation tasks. But, these tasks only evaluate lexical semantics indirectly. In this paper, we study whether it is possible to utilize distributed representations to generate dictionary definitions of words, as a more direct and transparent representation of the embeddings\u2019 semantics. We introduce definition modeling, the task of generating a definition for a given word and its embedding. We present several definition model architectures based on recurrent neural networks, and experiment with the models over multiple data sets. Our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better, and that a characterlevel convolution layer designed to leverage morphology can complement word-level embeddings. Finally, an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones\nAbstract: Syllabification does not seem to improve word-level RNN language modeling quality when compared to characterbased segmentation. However, our best syllable-aware language model, achieving performance comparable to the competitive character-aware model, has 18%\u201333% fewer parameters and is trained 1.2\u20132.2 times faster.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: End-to-End MAP Training of a Hybrid HMM-DNN Model\nAbstract: An hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use a maximum a-posteriori (MAP) criterion with a simple language model in the training stage, and a standard HMM decoder without approximations. Recognition results are presented using speech databases. Our method compares favorably to CTC in terms of performance, robustness and quality of alignments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator\nAbstract: The paper describes experiments on estimating emotion intensity in tweets using a generalized regressor system. The system combines lexical, syntactic and pretrained word embedding features, trains them on general regressors and finally combines the best performing models to create an ensemble. The proposed system stood 3rd out of 22 systems in the leaderboard of WASSA-2017 Shared Task on Emotion Intensity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Socially-Informed Timeline Generation for Complex Events\nAbstract: Existing timeline generation systems for complex events consider only information from traditional media, ignoring the rich social context provided by user-generated content that reveals representative public interests or insightful opinions. We instead aim to generate socially-informed timelines that contain both news article summaries and selected user comments. We present an optimization framework designed to balance topical cohesion between the article and comment summaries along with their informativeness and coverage of the event. Automatic evaluations on real-world datasets that cover four complex events show that our system produces more informative timelines than state-of-theart systems. In human evaluation, the associated comment summaries are furthermore rated more insightful than editor\u2019s picks and comments ranked highly by users.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Training Bi-directional Neural Network Language Model with Noise Contrastive Estimation\nAbstract: We propose to train bi-directional neural network language model(NNLM) with noise contrastive estimation(NCE). Experiments are conducted on a rescore task on the PTB data set. It is shown that NCE-trained bi-directional NNLM outperformed the one trained by conventional maximum likelihood training. But still(regretfully), it did not out-perform the baseline uni-directional NNLM.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards speech-to-text translation without speech recognition\nAbstract: We explore the problem of translating speech to text in low-resource scenarios where neither automatic speech recognition (ASR) nor machine translation (MT) are available, but we have training data in the form of audio paired with text translations. We present the first system for this problem applied to a realistic multi-speaker dataset, the CALLHOME Spanish-English speech translation corpus. Our approach uses unsupervised term discovery (UTD) to cluster repeated patterns in the audio, creating a pseudotext, which we pair with translations to create a parallel text and train a simple bag-of-words MT model. We identify the challenges faced by the system, finding that the difficulty of cross-speaker UTD results in low recall, but that our system is still able to correctly translate some content words in test data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Optimal Ratio Mask as Training Target for Supervised Speech Separation\nAbstract: Supervised speech separation uses supervised learning algorithms to learn a mapping from an input noisy signal to an output target. With the fast development of deep learning, supervised separation has become the most important direction in speech separation area in recent years. For the supervised algorithm, training target has a significant impact on the performance. Ideal ratio mask is a commonly used training target, which can improve the speech intelligibility and quality of the separated speech. However, it does not take into account the correlation between noise and clean speech. In this paper, we use the optimal ratio mask as the training target of the deep neural network (DNN) for speech separation. The experiments are carried out under various noise environments and signal to noise ratio (SNR) conditions. The results show that the optimal ratio mask outperforms other training targets in general.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory\nAbstract: Emotional intelligence is one of the key factors to the success of dialogue systems or conversational agents. In this paper, we propose Emotional Chatting Machine (ECM) which generates responses that are appropriate not only at the content level (relevant and grammatical) but also at the emotion level (consistent emotional expression). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor in three ways: modeling high-level abstraction of emotion expression by embedding emotion categories, changing of implicit internal emotion states, and using explicit emotion expressions with an external emotion vocabulary. Experiments show that our model can generate responses appropriate not only in content but also in emotion.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation and Representation Projection\nAbstract: The state-of-the-art named entity recognition (NER) systems are supervised machine learning models that require large amounts of manually annotated data to achieve high accuracy. However, annotating NER data by human is expensive and time-consuming, and can be quite difficult for a new language. In this paper, we present two weakly supervised approaches for cross-lingual NER with no human annotation in a target language. The first approach is to create automatically labeled NER data for a target language via annotation projection on comparable corpora, where we develop a heuristic scheme that effectively selects goodquality projection-labeled data from noisy data. The second approach is to project distributed representations of words (word embeddings) from a target language to a source language, so that the sourcelanguage NER system can be applied to the target language without re-training. We also design two co-decoding schemes that effectively combine the outputs of the two projection-based approaches. We evaluate the performance of the proposed approaches on both in-house and open NER data for several target languages. The results show that the combined systems outperform three other weakly supervised approaches on the CoNLL data.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Building a Pilot Software Quality-in-Use Benchmark Dataset\nAbstract: Prepared domain specific datasets plays an important role to supervised learning approaches. In this article a new sentence dataset for software qualityin-use is proposed. Three experts were chosen to annotate the data using a proposed annotation scheme. Then the data were reconciled in a (no match eliminate) process to reduce bias. The Kappa, statistics revealed an acceptable level of agreement; moderate to substantial agreement between the experts. The built data can be used to evaluate software quality-in-use models in sentiment analysis models. Moreover, the annotation scheme can be used to extend the current dataset. Keywords\u2014Quality in use, Benchmark dataset, software quality, sentiment analysis\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: CLaC at SemEval-2016 Task 11: Exploring linguistic and psycho-linguistic Features for Complex Word Identification\nAbstract: This paper describes the system deployed by the CLaC-EDLK team to the SemEval 2016, Complex Word Identification task. The goal of the task is to identify if a given word in a given context is simple or complex. Our system relies on linguistic features and cognitive complexity. We used several supervised models, however the Random Forest model outperformed the others. Overall our best configuration achieved a G-score of 68.8% in the task, ranking our system 21 out of 45.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Non-Parametric Bayesian Areal Linguistics\nAbstract: We describe a statistical model over linguistic areas and phylogeny. Our model recovers known areas and identifies a plausible hierarchy of areal features. The use of areas improves genetic reconstruction of languages both qualitatively and quantitatively according to a variety of metrics. We model linguistic areas by a Pitman-Yor process and linguistic phylogeny by Kingman\u2019s coalescent.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Experimental Support for a Categorical Compositional Distributional Model of Meaning\nAbstract: Modelling compositional meaning for sentences using empirical distributional methods has been a challenge for computational linguists. We implement the abstract categorical model of Coecke et al. (2010) using data from the BNC and evaluate it. The implementation is based on unsupervised learning of matrices for relational words and applying them to the vectors of their arguments. The evaluation is based on the word disambiguation task developed by Mitchell and Lapata (2008) for intransitive sentences, and on a similar new experiment designed for transitive sentences. Our model matches the results of its competitors in the first experiment, and betters them in the second. The general improvement in results with increase in syntactic complexity showcases the compositional power of our model.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mapping Instructions and Visual Observations to Actions with Reinforcement Learning\nAbstract: We propose to directly map raw visual observations and text input to actions for instruction execution. While existing approaches assume access to structured environment representations or use a pipeline of separately trained models, we learn a single model to jointly reason about linguistic and visual input. We use reinforcement learning in a contextual bandit setting to train a neural network agent. To guide the agent\u2019s exploration, we use reward shaping with different forms of supervision. Our approach does not require intermediate representations, planning procedures, or training different models. We evaluate in a simulated environment, and show significant improvements over supervised learning and common reinforcement learning variants.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating Chinese Classical Poems with RNN Encoder-Decoder\nAbstract: We take the generation of Chinese classical poem lines as a sequence-to-sequence learning problem, and build a novel system based on the RNN Encoder-Decoder structure to generate quatrains (Jueju in Chinese), with a topic word as input. Our system can jointly learn semantic meaning within a single line, semantic relevance among lines in a poem, and the use of structural, rhythmical and tonal patterns, without utilizing any constraint templates. Experimental results show that our system outperforms other competitive systems. We also find that the attention mechanism can capture the word associations in Chinese classical poetry and inverting target lines in training can improve\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dependency resolution and semantic mining using Tree Adjoining Grammars for Tamil Language\nAbstract: Tree adjoining grammars (TAGs) provide an ample tool to capture syntax of many Indian languages. Tamil represents a special challenge to computational formalisms as it has extensive agglutinative morphology and a comparatively difficult argument structure. Modelling Tamil syntax and morphology using TAG is an interesting problem which has not been in focus even though TAGs are over 4 decades old, since its inception. Our research with Tamil TAGs have shown us that we can not only represent syntax of the language, but to an extent mine out semantics through dependency resolution of the sentence. But in order to demonstrate this phenomenal property, we need to parse Tamil language sentences using TAGs we have built and through parsing obtain a derivation we could use to resolve dependencies, thus proving the semantic property. We use an in-house developed pseudo lexical TAG chart parser; algorithm given by Schabes and Joshi (1988), for generating derivations of sentences. We do not use any statistics to rank out ambiguous derivations but rather use all of them to understand the mentioned semantic relation with in TAGs for Tamil. We shall also present a brief parser analysis for the completeness of our discussions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating machine-executable plans from end-user\u2019s natural-language instructions\nAbstract: It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user\u2019s natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-basedso that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user\u2019s NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {\u201cdrill a hole\u201d, \u201cclean a spot\u201d, \u201cinstall a screw\u201d}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user\u2019s NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mining Measured Information from Text\nAbstract: We present an approach to extract measured information from text (e.g., a 1370 \u25e6C melting point, a BMI greater than 29.9 kg/m). Such extractions are critically important across a wide range of domains \u2014 especially those involving search and exploration of scientific and technical documents. We first propose a rule-based entity extractor to mine measured quantities (i.e., a numeric value paired with a measurement unit), which supports a vast and comprehensive set of both common and obscure measurement units. Our method is highly robust and can correctly recover valid measured quantities even when significant errors are introduced through the process of converting document formats like PDF to plain text. Next, we describe an approach to extracting the properties being measured (e.g., the property pixel pitch in the phrase \u201ca pixel pitch as high as 352 \u03bcm\u201d). Finally, we present MQSearch: the realization of a search engine with full support for measured information.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Psychologically Motivated Text Mining\nAbstract: Natural language processing techniques are increasingly applied to identify social trends and predict behavior based on large text collections. Existing methods typically rely on surface lexical and syntactic information. Yet, research in psychology shows that patterns of human conceptualisation, such as metaphorical framing, are reliable predictors of human expectations and decisions. In this paper, we present a method to learn patterns of metaphorical framing from large text collections, using statistical techniques. We apply the method to data in three different languages and evaluate the identified patterns, demonstrating their psychological validity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Synergistic Union of Word2Vec and Lexicon for Domain Specific Semantic Similarity\nAbstract: Semantic similarity measures are an important part in Natural Language Processing tasks. However Semantic similarity measures built for general use do not perform well within specific domains. Therefore in this study we introduce a domain specific semantic similarity measure that was created by the synergistic union of word2vec, a word embedding method that is used for semantic similarity calculation and lexicon based (lexical) semantic similarity methods. We prove that this proposed methodology out performs word embedding methods trained on generic corpus and methods trained on domain specific corpus but do not use lexical semantic similarity methods to augment the results. Further, we prove that text lemmatization can improve the performance of word embedding methods. keywords: Word Embedding, Semantic Similarity, Neural Networks, Lexicon, word2vec\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Modeling Relation Paths for Representation Learning of Knowledge Bases\nAbstract: Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text. The source code of this paper can be obtained from https://github.com/mrlyk423/ relation_extraction.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Paradigm for Situated and Goal-Driven Language Learning\nAbstract: A distinguishing property of human intelligence is the ability to flexibly use language in order to communicate complex ideas with other humans in a variety of contexts. Research in natural language dialogue should focus on designing communicative agents which can integrate themselves into these contexts and productively collaborate with humans. In this abstract, we propose a general situated language learning paradigm which is designed to bring about robust language agents able to cooperate productively with humans. This dialogue paradigm is built on a utilitarian definition of language understanding. Language is one of multiple tools which an agent may use to accomplish goals in its environment. We say an agent \u201cunderstands\u201d language only when it is able to use language productively to accomplish these goals. Under this definition, an agent\u2019s communication success reduces to its success on tasks within its environment. This setup contrasts with many conventional natural language tasks, which maximize linguistic objectives derived from static datasets. Such applications often make the mistake of reifying language as an end in itself. The tasks prioritize an isolated measure of linguistic intelligence (often one of linguistic competence, in the sense of Chomsky (1965)), rather than measuring a model\u2019s effectiveness in real-world scenarios. Our utilitarian definition is motivated by recent successes in reinforcement learning methods. In a reinforcement learning setting, agents maximize success metrics on real-world tasks, without requiring direct supervision of linguistic behavior.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Nested Attention Neural Hybrid Model for Grammatical Error Correction\nAbstract: Grammatical error correction (GEC) systems strive to correct both global errors in word order and usage, and local errors in spelling and inflection. Further developing upon recent work on neural machine translation, we propose a new hybrid neural model with nested attention layers for GEC. Experiments show that the new model can effectively correct errors of both types by incorporating word and character-level information, and that the model significantly outperforms previous neural models for GEC as measured on the standard CoNLL14 benchmark dataset. Further analysis also shows that the superiority of the proposed model can be largely attributed to the use of the nested attention mechanism, which has proven particularly effective in correcting local errors that involve small edits in orthography.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ConceptNet 5.5: An Open Multilingual Graph of General Knowledge\nAbstract: Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expertcreated resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Studying the Wikipedia Hyperlink Graph for Relatedness and Disambiguation\nAbstract: Hyperlinks and other relations in Wikipedia are a extraordinary resource which is still not fully understood. In this paper we study the different types of links in Wikipedia, and contrast the use of the full graph with respect to just direct links. We apply a well-known random walk algorithm on two tasks, word relatedness and named-entity disambiguation. We show that using the full graph is more effective than just direct links by a large margin, that non-reciprocal links harm performance, and that there is no benefit from categories and infoboxes, with coherent results on both tasks. We set new state-of-the-art figures for systems based on Wikipedia links, comparable to systems exploiting several information sources and/or supervised machine learning. Our approach is open source, with instruction to reproduce results, and amenable to be integrated with complementary text-based methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: NOISE-ROBUST ASR FOR THE THIRD \u2018CHIME\u2019 CHALLENGE EXPLOITING TIME-FREQUENCY MASKING BASED MULTI-CHANNEL SPEECH ENHANCEMENT AND RECURRENT NEURAL NETWORK\nAbstract: In this paper, the Lingban entry to the third \u2018CHiME\u2019 speech separation and recognition challenge is presented. A timefrequency masking based speech enhancement front-end is proposed to suppress the environmental noise utilizing multichannel coherence and spatial cues. The state-of-the-art speech recognition techniques, namely recurrent neural network based acoustic and language modeling, state space minimum Bayes risk based discriminative acoustic modeling, and i-vector based acoustic condition modeling, are carefully integrated into the speech recognition back-end. To further improve the system performance by fully exploiting the advantages of different technologies, the final recognition results are obtained by lattice combination and rescoring. Evaluations carried out on the official dataset prove the effectiveness of the proposed systems. Comparing with the best baseline result, the proposed system obtains consistent improvements with over 57% relative word error rate reduction on the real-data test set.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Ask, and shall you receive?: Understanding Desire Fulfillment in Natural Language Text\nAbstract: The ability to comprehend desires and their fulfillment is important to Natural Language Understanding. This paper introduces the task of identifying if a desire expressed by a subject in a given short piece of text was fulfilled. We propose various unstructured and structured models that capture fulfillment cues such as the subject\u2019s emotional state and actions. Our experiments with two different datasets demonstrate the importance of understanding the narrative and discourse structure to address this task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unsupervised Induction of Contingent Event Pairs from Film Scenes\nAbstract: Human engagement in narrative is partially driven by reasoning about discourse relations between narrative events, and the expectations about what is likely to happen next that results from such reasoning. Researchers in NLP have tackled modeling such expectations from a range of perspectives, including treating it as the inference of the CONTINGENT discourse relation, or as a type of common-sense causal reasoning. Our approach is to model likelihood between events by drawing on several of these lines of previous work. We implement and evaluate different unsupervised methods for learning event pairs that are likely to be CONTINGENT on one another. We refine event pairs that we learn from a corpus of film scene descriptions utilizing web search counts, and evaluate our results by collecting human judgments of contingency. Our results indicate that the use of web search counts increases the average accuracy of our best method to 85.64% over a baseline of 50%, as compared to an average accuracy of 75.15% without web search.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: WEAKLY SUPERVISED SPOKEN TERM DISCOVERY USING CROSS-LINGUAL SIDE INFORMATION\nAbstract: Recent work on unsupervised term discovery (UTD) aims to identify and cluster repeated word-like units from audio alone. These systems are promising for some very low-resource languages where transcribed audio is unavailable, or where no written form of the language exists. However, in some cases it may still be feasible (e.g., through crowdsourcing) to obtain (possibly noisy) text translations of the audio. If so, this information could be used as a source of side information to improve UTD. Here, we present a simple method for rescoring the output of a UTD system using text translations, and test it on a corpus of Spanish audio with English translations. We show that it greatly improves the average precision of the results over a wide range of system configurations and data preprocessing methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Proposal for Linguistic Similarity Datasets Based on Commonality Lists\nAbstract: Similarity is a core notion that is used in psychology and two branches of linguistics: theoretical and computational. The similarity datasets that come from the two fields differ in design: psychological datasets are focused around a certain topic such as fruit names, while linguistic datasets contain words from various categories. The later makes humans assign low similarity scores to the words that have nothing in common and to the words that have contrast in meaning, making similarity scores ambiguous. In this work we discuss the similarity collection procedure for a multi-category dataset that avoids score ambiguity and suggest changes to the evaluation procedure to reflect the insights of psychological literature for word, phrase and sentence similarity. We suggest to ask humans to provide a list of commonalities and differences instead of numerical similarity scores and employ the structure of human judgements beyond pairwise similarity for model evaluation. We believe that the proposed approach will give rise to datasets that test meaning representation models more thoroughly with respect to the human treatment of similarity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mapping discourse annotations How consistent are our discourse annotations? Insights from mapping RST-DT and PDTB annotations\nAbstract: Discourse-annotated corpora are an important resource for the community. However, these corpora are often annotated according to different frameworks, making comparison of the annotations difficult. This is unfortunate, since mapping the existing annotations would result in more (training) data for researchers in automatic discourse relation processing and researchers in linguistics and psycholinguistics. In this article, we present an effort to map two large corpora onto each other: the Penn Discourse Treebank and the Rhetorical Structure Theory Discourse Treebank. We first propose a method for aligning the discourse segments, and then evaluate the observed against the expected mappings for explicit and implicit relations separately. We find that while agreement on explicit relations is reasonable, agreement between the frameworks on implicit relations is astonishingly low. We identify sources of systematic discrepancies between the two annotation schemes; many of the differences in annotation can be traced back to different operationalizations and goals of the PDTB and RST frameworks. We discuss the consequences of these discrepancies for future annotation, and the usability of the mapped data for theoretical studies and the training of automatic discourse relation labellers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discriminative Phrase Embedding for Paraphrase Identification\nAbstract: This work, concerning paraphrase identification task, on one hand contributes to expanding deep learning embeddings to include continuous and discontinuous linguistic phrases. On the other hand, it comes up with a new scheme TF-KLD-KNN to learn the discriminative weights of words and phrases specific to paraphrase task, so that a weighted sum of embeddings can represent sentences more effectively. Based on these two innovations we get competitive state-of-the-art performance on paraphrase identification.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Contrastive Analysis with Predictive Power: Typology Driven Estimation of Grammatical Error Distributions in ESL\nAbstract: This work examines the impact of crosslinguistic transfer on grammatical errors in English as Second Language (ESL) texts. Using a computational framework that formalizes the theory of Contrastive Analysis (CA), we demonstrate that language specific error distributions in ESL writing can be predicted from the typological properties of the native language and their relation to the typology of English. Our typology driven model enables to obtain accurate estimates of such distributions without access to any ESL data for the target languages. Furthermore, we present a strategy for adjusting our method to low-resource languages that lack typological documentation using a bootstrapping approach which approximates native language typology from ESL texts. Finally, we show that our framework is instrumental for linguistic inquiry seeking to identify first language factors that contribute to a wide range of difficulties in second language acquisition.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The effect of linguistic constraints on the large scale organization of language\nAbstract: This paper studies the effect of linguistic constraints on the large scale organization of language. It describes the properties of linguistic networks built using texts of written language with the words randomized. These properties are compared to those obtained for a network built over the text in natural order. It is observed that the \u201crandom\u201d networks too exhibit small-world and scale-free characteristics. They also show a high degree of clustering. This is indeed a surprising result one that has not been addressed adequately in the literature. We hypothesize that many of the network statistics reported here studied are in fact functions of the distribution of the underlying data from which the network is built and may not be indicative of the nature of the concerned network.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the e\u0080ectiveness of feature set augmentation using clusters of word embeddings\nAbstract: Word clusters have been empirically shown to o\u0082er important performance improvements on various tasks. Despite their importance, their incorporation in the standard pipeline of feature engineering relies more on a trial-and-error procedure where one evaluates several hyper-parameters, like the number of clusters to be used. In order to be\u008aer understand the role of such features we systematically evaluate their e\u0082ect on four tasks, those of named entity segmentation and classi\u0080cation as well as, those of \u0080ve-point sentiment classi\u0080cation and quanti\u0080cation. Our results strongly suggest that cluster membership features improve the performance.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A MACHINE LEARNING BASED ANALYTICAL FRAMEWORK FOR SEMANTIC ANNOTATION REQUIREMENTS\nAbstract: The Semantic Web is an extension of the current web in which information is given well-defined meaning. The perspective of Semantic Web is to promote the quality and intelligence of the current web by changing its contents into machine understandable form. Therefore, semantic level information is one of the cornerstones of the Semantic Web. The process of adding semantic metadata to web resources is called Semantic Annotation. There are many obstacles against the Semantic Annotation, such as multilinguality, scalability, and issues which are related to diversity and inconsistency in content of different web pages. Due to the wide range of domains and the dynamic environments that the Semantic Annotation systems must be performed on, the problem of automating annotation process is one of the significant challenges in this domain. To overcome this problem, different machine learning approaches such as supervised learning, unsupervised learning and more recent ones like, semi-supervised learning and active learning have been utilized. In this paper we present an inclusive layered classification of Semantic Annotation challenges and discuss the most important issues in this field. Also, we review and analyze machine learning applications for solving semantic annotation problems. For this goal, the article tries to closely study and categorize related researches for better understanding and to reach a framework that can map machine learning techniques into the Semantic Annotation challenges and requirements.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Word forms\u2014not just their lengths\u2014are optimized for efficient communication\nAbstract: The inverse relationship between the length of a word and the frequency of its use, first identified by G.K. Zipf in 1935, is a classic empirical law that holds across a wide range of human languages. We demonstrate that length is one aspect of a much more general property of words: how distinctive they are with respect to other words in a language. Distinctiveness plays a critical role in recognizing words in fluent speech, in that it reflects the strength of potential competitors when selecting the best candidate for an ambiguous signal. Phonological information content, a measure of a word\u2019s string probability under a statistical model of a language\u2019s sound or character sequences, concisely captures distinctiveness. Examining largescale corpora from 13 languages, we find that distinctiveness significantly outperforms word length as a predictor of frequency. This finding provides evidence that listeners\u2019 processing constraints shape fine-grained aspects of word forms across languages. Despite their apparent diversity, natural languages display striking structural regularities [1\u20133]. How such regularities relate to human cognition remains an open question with implications for linguistics, psychology, and neuroscience [2, 4\u20136]. Prominent among these regularities is the wellknown relationship between word length and frequency: across languages, frequently-used words tend to be short [7]. In a classic work, Zipf [7] posited that this pattern emerges from speakers minimizing total articulatory effort by using the shortest form for words that are used most often, following what he later called the Principle of Least Effort [8]. While the underlying cause has been the subject of debate [9\u201313], this relationship between word length and frequency remains one of the most robust statistical laws that describe human languages. Here, we propose a generalization of Zipf\u2019s analysis and present two possible listener-focused explanations. We show that a word\u2019s frequency is inversely related to its distinctiveness\u2014how easily it can be identified as the intended message for a given speech signal. While speakers prefer easier-to-produce less distinctive forms, they are constrained by listeners\u2019 need for sufficiently distinctive forms to differentiate each word from others, especially if a speaker\u2019s intended word has higher-frequency competitors. If word recognition is modeled as Bayesian inference [14, 15], the probability of successful recognition depends on both the prior probability of the intended word and on the number and strength of alternative words (\u201ccompetitors\u201d). We define a statistical measure of distinctiveness that succinctly captures the diagnosticity of a word form by assessing the aggregate strength of competitors in the language. We then show that distinctiveness should be inversely related to frequency, if languages are constructed to equalize error rates for low and high frequency words. Importantly, distinctiveness subsumes Zipf\u2019s observation regarding the relationship of length and frequency as a special case. Length is a n\u00e4\u0131ve approximation of the distinctiveness of a word form insofar as longer strings are simply less probable. We demonstrate that a more comprehensive measure of distinctiveness that takes into account the sound-to-sound (phoneme-to-phoneme or letter-to-letter) sequences in a language accounts for significantly more frequency-related variance 1 ar X iv :1 70 3. 01 69 4v 2 [ cs .C L ] 3 1 M ay 2 01 7 than does length across a broad sample of natural languages. This relationship between frequency and distinctiveness adds to a growing body of evidence that cognitive constraints influence the structural properties of natural languages [3, 6, 16]. Model We define a probabilistic language model to characterize the distinctiveness of word forms in terms of their constituent sound-to-sound transitions. This model can be fit using a large written sample of a particular language. The starting point for the model is formalizing the task of the listener as a rational statistical inference. Bayesian inference and distinctiveness Upon hearing a string of sounds s, a listener has to infer what word w was intended by the speaker. This can be formulated as a problem of Bayesian inference. The listener should calculate a posterior distribution P (w|s) over words based on the sounds. Applying Bayes\u2019 rule, this is given by P (w|s) = P (s|w)P (w) P (s) (1) where P (s|w) is the probability of hearing s if w is the intended word, P (w) is the prior probability of the word w intended by the speaker, and P (s) is the probability of hearing s. Assuming that sounds are produced faithfully, such that P (sw|w) is close to 1 for a particular string sw for each w and close to 0 otherwise, we obtain the approximation P (w|sw) \u2248 P (w) P (sw) (2) which expresses the probability that the word w is correctly identified as a function of its normalized frequency, P (w), and the probability of the string sw in the language, P (sw). We define the distinctiveness of a word to be inversely related to P (sw): intuitively, a word that shares the same sound sequences with many other words is necessarily less distinctive. Following this logic, we use the phonological information content (PIC) of a word to measure the distinctiveness of its phoneme-to-phoneme transitions [17], or its approximation in character-tocharacter transitions. Analogous to the metric of lexical surprisal (negative log conditional probability) used to measure the predictability of a word given preceding words [18\u201320], PIC is the negative log probability of the sequence of phonemes (distinct meaningful sounds) or letters in the string comprising a word. To obtain a compact representation of the probabilities of various phone or character sequences in a language we estimate an n-phone or n-character model (analogous to an n-gram model over words [21] but computed over individual phonemes or characters) from a corpus sample. To support a stronger test of the relationship between distinctiveness and frequency, we avoid the circularity that more probable words necessarily contain more probable sequences by estimating the transition probabilities using the type inventory (unique words) in the language. For the smaller datasets (those from the OPUS corpus) we also present the results for a model with token-weighted phonological transitions, though we note that interpreting the correlations obtained from the weighted model is challenging given this circularity. Under this model, the phonological information content PIC(w) of a word is defined as: PIC(w) = \u2212 logP (sw) (3) = \u2212 logP (l1, . . . , l|sw|) for l \u2208 sw (4)\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Me\u0301todos de Otimizac\u0327a\u0303o Combinato\u0301ria Aplicados ao Problema de Compressa\u0303o MultiFrases\u2217\nAbstract: The Internet has led to a dramatic increase in the amount of available information. In this context, reading and understanding this flow of information have become costly tasks. In the last years, to assist people to understand textual data, various Natural Language Processing (NLP) applications based on Combinatorial Optimization have been devised. However, for MultiSentences Compression (MSC), method which reduces the sentence length without removing core information, the insertion of optimization methods requires further study to improve the performance of MSC. This article describes a method for MSC using Combinatorial Optimization and Graph Theory to generate more informative sentences while maintaining their grammaticality. An experiment led on a corpus of 40 clusters of sentences shows that our system has achieved a very good quality and is better than the state-of-the-art.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Inferring Robot Task Plans from Human Team Meetings: A Generative Modeling Approach with Logic-Based Prior\nAbstract: We aim to reduce the burden of programming and deploying autonomous systems to work in concert with people in time-critical domains, such as military field operations and disaster response. Deployment plans for these operations are frequently negotiated on-the-fly by teams of human planners. A human operator then translates the agreed upon plan into machine instructions for the robots. We present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human team\u2019s planning conversation. Our approach combines probabilistic generative modeling with logical plan validation used to compute a highly structured prior over possible plans. This hybrid approach enables us to overcome the challenge of performing inference over the large solution space with only a small amount of noisy data from the team planning session. We validate the algorithm through human subject experimentation and show we are able to infer a human team\u2019s final plan with 83% accuracy on average. We also describe a robot demonstration in which two people plan and execute a first-response collaborative task with a PR2 robot. To the best of our knowledge, this is the first work that integrates a logical planning technique within a generative model to perform plan inference.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: S-NET: FROM ANSWER EXTRACTION TO ANSWER GENERATION FOR MACHINE READING COMPREHEN- SION\nAbstract: Most existing works on machine reading comprehension are built under the answer extraction approach which predicts sub-spans from passages to answer questions. In this paper, we develop an extraction-then-generation framework for machine reading comprehension, in which the answer is generated from the extraction results. Specifically, we build the answer extraction model to predict the most important sub-spans from the passage as evidence, and develop the answer generation model which takes the evidence as additional features along with the question and passage to further elaborate the final answers. We build the answer extraction model with state-of-the-art neural networks for reading comprehension, and the answer generation model with sequence-to-sequence neural networks. Experiments on the MS-MARCO dataset show that the generation based approach achieves better results than pure answer extraction.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper shows how one can directly apply natural language processing (NLP) methods to classification problems in cheminformatics. Connection between these seemingly separate fields is shown by considering standard textual representation of compound, SMILES. The problem of activity prediction against a target protein is considered, which is a crucial part of computer aided drug design process. Conducted experiments show that this way one can not only outrank state of the art results of hand crafted representations but also gets direct structural insights into the way decisions are made.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Image Pivoting for Learning Multilingual Multimodal Representations\nAbstract: In this paper we propose a model to learn multimodal multilingual representations for matching images and sentences in different languages, with the aim of advancing multilingual versions of image search and image understanding. Our model learns a common representation for images and their descriptions in two different languages (which need not be parallel) by considering the image as a pivot between two languages. We introduce a new pairwise ranking loss function which can handle both symmetric and asymmetric similarity between the two modalities. We evaluate our models on image-description ranking for German and English, and on semantic textual similarity of image descriptions in English. In both cases we achieve state-of-the-art performance.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Beyond Word-based Language Model in Statistical Machine Translation\nAbstract: Language model is one of the most important modules in statistical machine translation and currently the wordbased language model dominants this community. However, many translation models (e.g. phrase-based models) generate the target language sentences by rendering and compositing the phrases rather than the words. Thus, it is much more reasonable to model dependency between phrases, but few research work succeed in solving this problem. In this paper, we tackle this problem by designing a novel phrase-based language model which attempts to solve three key sub-problems: 1, how to define a phrase in language model; 2, how to determine the phrase boundary in the large-scale monolingual data in order to enlarge the training set; 3, how to alleviate the data sparsity problem due to the huge vocabulary size of phrases. By carefully handling these issues, the extensive experiments on Chinese-to-English translation show that our phrase-based language model can significantly improve the translation quality by up to +1.47 absolute BLEU score.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SMPOST: Parts of Speech Tagger for Code-Mixed Indic Social Media Text\nAbstract: Use of social media has grown dramatically during the last few years. Users follow informal languages in communicating through social media. The language of communication is often mixed in nature, where people transcribe their regional language with English and this technique is found to be extremely popular. Natural language processing (NLP) aims to infer the information from these text where Part-of-Speech (PoS) tagging plays an important role in getting the prosody of the written text. For the task of PoS tagging on Code-Mixed Indian Social Media Text, we develop a supervised system based on Conditional Random Field classifier. In order to tackle the problem effectively, we have focused on extracting rich linguistic features. We participate in three different language pairs, ie. English-Hindi, English-Bengali and English-Telugu on three different social media platforms, Twitter, Facebook & WhatsApp. The proposed system is able to successfully assign coarse as well as fine-grained PoS tag labels for a given a code-mixed sentence. Experiments show that our system is quite generic that shows encouraging performance levels on all the three language pairs in all the domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: D-Bees: A Novel Method Inspired by Bee Colony Optimization for Solving Word Sense Disambiguation\nAbstract: Word sense disambiguation (WSD) is a problem in the field of computational linguistics given as finding the intended sense of a word (or a set of words) when it is activated within a certain context. WSD was recently addressed as a combinatorial optimization problem in which the goal is to find a sequence of senses that maximize the semantic relatedness among the target words. In this article, a novel algorithm for solving the WSD problem called D-Bees is proposed which is inspired by bee colony optimization (BCO) where artificial bee agents collaborate to solve the problem. The D-Bees algorithm is evaluated on a standard dataset (SemEval 2007 coarse-grained English all-words task corpus) and is compared to simulated annealing, genetic algorithms, and two ant colony optimization techniques (ACO). It will be observed that the BCO and ACO approaches are on par. 1 ar X iv :1 40 5. 14 06 v1 [ cs .C L ] 6 M ay 2 01 4\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Coreferring Text-extracted Event Descriptions with the aid of Ontological Reasoning\nAbstract: Systems for automatic extraction of semantic information about events from large textual resources are now available: these tools are capable to generate RDF datasets about text extracted events and this knowledge can be used to reason over the recognized events. On the other hand, text based tasks for event recognition, as for example event coreference (i.e. recognizing whether two textual descriptions refer to the same event), do not take into account ontological information of the extracted events in their process. In this paper, we propose a method to derive event coreference on text extracted event data using semantic based rule reasoning. We demonstrate our method considering a limited (yet representative) set of event types: we introduce a formal analysis on their ontological properties and, on the base of this, we define a set of coreference criteria. We then implement these criteria as RDF-based reasoning rules to be applied on text extracted event data. We evaluate the effectiveness of our approach over a standard coreference benchmark dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: GOAL-ORIENTED DIALOGUE SYSTEMS\nAbstract: This paper presents the Frames dataset1, a corpus of 1369 human-human dialogues with an average of 15 turns per dialogue. We developed this dataset to study the role of memory in goal-oriented dialogue systems. Based on Frames, we introduce a task called frame tracking, which extends state tracking to a setting where several states are tracked simultaneously. We propose a baseline model for this task. We show that Frames can also be used to study memory in dialogue management and information presentation through natural language generation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Full-Time Supervision based Bidirectional RNN for Factoid Question Answering\nAbstract: Recently, bidirectional recurrent neural network (BRNN) has been widely used for question answering (QA) tasks with promising performance. However, most existing BRNN models extract the information of questions and answers by directly using a pooling operation to generate the representation for loss or similarity calculation. Hence, these existing models don\u2019t put supervision (loss or similarity calculation) at every time step, which will lose some useful information. In this paper, we propose a novel BRNN model called full-time supervision based BRNN (FTS-BRNN), which can put supervision at every time step. Experiments on the factoid QA task show that our FTS-BRNN can outperform other baselines to achieve the state-of-the-art accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Content analysis of scientific publications is a nontrivial task, but a useful and important one for scientific information services. In the Gutenberg era it was a domain of human experts; in the digital age many machine-based methods, e.g., graph analysis tools and machine-learning techniques, have been developed for it. Natural Language Processing (NLP) is a powerful machinelearning approach to semiautomatic speech and language processing, which is also applicable to mathematics. The well established methods of NLP have to be adjusted for the special needs of mathematics, in particular for handling mathematical formulae. We demonstrate a mathematics-aware part of speech tagger and give a short overview about our adaptation of NLP methods for mathematical publications. We show the use of the tools developed for key phrase extraction and classification in the database zbMATH.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Character Composition Model with Convolutional Neural Networks for Dependency Parsing on Morphologically Rich Languages\nAbstract: We present a transition-based dependency parser that uses a convolutional neural network to compose word representations from characters. The character composition model shows great improvement over the word-lookup model, especially for parsing agglutinative languages. These improvements are even better than using pre-trained word embeddings from extra data. On the SPMRL data sets, our system outperforms the previous best greedy parser (Ballesteros et al., 2015) by a margin of 3% on average.1\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An End-to-End Architecture for Keyword Spotting and Voice Activity Detection\nAbstract: We propose a single neural network architecture for two tasks: on-line keyword spotting and voice activity detection. We develop novel inference algorithms for an end-to-end Recurrent Neural Network trained with the Connectionist Temporal Classification loss function which allow our model to achieve high accuracy on both keyword spotting and voice activity detection without retraining. In contrast to prior voice activity detection models, our architecture does not require aligned training data and uses the same parameters as the keyword spotting model. This allows us to deploy a high quality voice activity detector with no additional memory or maintenance requirements.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Controlling Output Length in Neural Encoder-Decoders\nAbstract: Neural encoder-decoder models have shown great success in many sequence generation tasks. However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs. This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length. In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods.1 Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Natural-Parameter Networks: A Class of Probabilistic Neural Networks\nAbstract: Neural networks (NN) have achieved state-of-the-art performance in various applications. Unfortunately in applications where training data is insufficient, they are often prone to overfitting. One effective way to alleviate this problem is to exploit the Bayesian approach by using Bayesian neural networks (BNN). Another shortcoming of NN is the lack of flexibility to customize different distributions for the weights and neurons according to the data, as is often done in probabilistic graphical models. To address these problems, we propose a class of probabilistic neural networks, dubbed natural-parameter networks (NPN), as a novel and lightweight Bayesian treatment of NN. NPN allows the usage of arbitrary exponential-family distributions to model the weights and neurons. Different from traditional NN and BNN, NPN takes distributions as input and goes through layers of transformation before producing distributions to match the target output distributions. As a Bayesian treatment, efficient backpropagation (BP) is performed to learn the natural parameters for the distributions over both the weights and neurons. The output distributions of each layer, as byproducts, may be used as second-order representations for the associated tasks such as link prediction. Experiments on real-world datasets show that NPN can achieve state-of-the-art performance.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Hypernymy, textual entailment, and image captioning can be seen as special cases of a single visual-semantic hierarchy over words, sentences, and images. In this paper we advocate for explicitly modeling the partial order structure of this hierarchy. Towards this goal, we introduce a general method for learning ordered representations, and show how it can be applied to a variety of tasks involving images and language. We show that the resulting representations improve performance over current approaches for hypernym prediction and image-caption retrieval.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Integrating higher level visual and linguistic interpretations is at the heart of human intelligence. As automatic visual category recognition in images is approaching human performance, the high level understanding in the dynamic spatiotemporal domain of videos and its translation into natural language is still far from being solved. While most works on vision-to-text translations use pre-learned or pre-established computational linguistic models, in this paper we present an approach that uses vision alone to efficiently learn how to translate into language the video content. We discover, in simple form, the story played by main actors, while using only visual cues for representing objects and their interactions. Our method learns in a hierarchical manner higher level representations for recognizing subjects, actions and objects involved, their relevant contextual background and their interaction to one another over time. We have a three stage approach: first we take in consideration features of the individual entities at the local level of appearance, then we consider the relationship between these objects and actions and their video background, and third, we consider their spatiotemporal relations as inputs to classifiers at the highest level of interpretation. Thus, our approach finds a coherent linguistic description of videos in the form of a subject, verb and object based on their role played in the overall visual story learned directly from training data, without using a known language model. We test the efficiency of our approach on a large scale dataset containing YouTube clips taken in the wild and demonstrate state-of-the-art performance, often superior to current approaches that use more complex, pre-learned linguistic knowledge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Spotting Rumors via Novelty Detection\nAbstract: Rumour detection is hard because the most accurate systems operate retrospectively, only recognising rumours once they have collected repeated signals. By then the rumours might have already spread and caused harm. We introduce a new category of features based on novelty, tailored to detect rumours early on. To compensate for the absence of repeated signals, we make use of news wire as an additional data source. Unconfirmed (novel) information with respect to the news articles is considered as an indication of rumours. Additionally we introduce pseudo feedback, which assumes that documents that are similar to previous rumours, are more likely to also be a rumour. Comparison with other real-time approaches shows that novelty based features in conjunction with pseudo feedback perform significantly better, when detecting rumours instantly after their publication.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discriminating Similar Languages: Evaluations and Explorations\nAbstract: We present an analysis of the performance of machine learning classifiers on discriminating between similar languages and language varieties. We carried out a number of experiments using the results of the two editions of the Discriminating between Similar Languages (DSL) shared task. We investigate the progress made between the two tasks, estimate an upper bound on possible performance using ensemble and oracle combination, and provide learning curves to help us understand which languages are more challenging. A number of difficult sentences are identified and investigated further with human annotation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: BADREX: In situ expansion and coreference of biomedical abbreviations using dynamic regular expressions\nAbstract: BADREX uses dynamically generated regular expressions to annotate term definition\u2013term abbreviation pairs, and corefers unpaired acronyms and abbreviations back to their initial definition in the text. Against the Medstract corpus BADREX achieves precision and recall of 98% and 97%, and against a much larger corpus, 90% and 85%, respectively. BADREX yields improved performance over previous approaches, requires no training data and allows runtime customisation of its input parameters. BADREX is freely available from https://github.com/philgooch/BADREX-Biomedical-AbbreviationExpander as a plugin for the General Architecture for Text Engineering (GATE) framework and is licensed under the GPLv3.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Question Answering through Transfer Learning from Large Fine-grained Supervision Data\nAbstract: We show that the task of question answering (QA) can significantly benefit from the transfer learning of models trained on a different large, fine-grained QA dataset. We achieve the state of the art in two well-studied QA datasets, WikiQA and SemEval-2016 (Task 3A), through a basic transfer learning technique from SQuAD. For WikiQA, our model outperforms the previous best model by more than 8%. We demonstrate that finer supervision provides better guidance for learning lexical and syntactic information than coarser supervision, through quantitative results and visual analysis. We also show that a similar transfer learning procedure achieves the state of the art on an entailment task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A computational approach to politeness with application to social factors\nAbstract: We propose a computational framework for identifying linguistic aspects of politeness. Our starting point is a new corpus of requests annotated for politeness, which we use to evaluate aspects of politeness theory and to uncover new interactions between politeness markers and context. These findings guide our construction of a classifier with domain-independent lexical and syntactic features operationalizing key components of politeness theory, such as indirection, deference, impersonalization and modality. Our classifier achieves close to human performance and is effective across domains. We use our framework to study the relationship between politeness and social power, showing that polite Wikipedia editors are more likely to achieve high status through elections, but, once elevated, they become less polite. We see a similar negative correlation between politeness and power on Stack Exchange, where users at the top of the reputation scale are less polite than those at the bottom. Finally, we apply our classifier to a preliminary analysis of politeness variation by gender and community.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extractive Summarization: Limits, Compression, Generalized Model and Heuristics\nAbstract: Due to its promise to alleviate information overload, text summarization has attracted the attention of many researchers. However, it has remained a serious challenge. Here, we first prove empirical limits on the recall (and F1scores) of extractive summarizers on the DUC datasets under ROUGE evaluation for both the single-document and multi-document summarization tasks. Next we define the concept of compressibility of a document and present a new model of summarization, which generalizes existing models in the literature and integrates several dimensions of the summarization, viz., abstractive versus extractive, single versus multi-document, and syntactic versus semantic. Finally, we examine some new and existing single-document summarization algorithms in a single framework and compare with state of the art summarizers on DUC data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Integrative Semantic Dependency Parsing via Efficient Large-scale Feature Selection\nAbstract: Semantic parsing, i.e., the automatic derivation of meaning representation such as an instantiated predicate-argument structure for a sentence, plays a critical role in deep processing of natural language. Unlike all other top systems of semantic dependency parsing that have to rely on a pipeline framework to chain up a series of submodels each specialized for a specific subtask, the one presented in this article integrates everything into one model, in hopes of achieving desirable integrity and practicality for real applications while maintaining a competitive performance. This integrative approach tackles semantic parsing as a word pair classification problem using a maximum entropy classifier. We leverage adaptive pruning of argument candidates and large-scale feature selection engineering to allow the largest feature space ever in use so far in this field, it achieves a state-of-the-art performance on the evaluation data set for CoNLL-2008 shared task, on top of all but one top pipeline system, confirming its feasibility and effectiveness.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Word sense disambiguation via bipartite representation of complex networks\nAbstract: The word sense disambiguation (WSD) task aims at identifying the meaning of words in a given context for specific words conveying multiple meanings. This task plays a prominent role in a myriad of real world applications, such as machine translation, word processing and information retrieval. Recently, concepts and methods of complex networks have been employed to tackle this task by representing words as nodes, which are connected if they are semantically similar. Despite the increasingly number of studies carried out with such models, most of them use networks just to represent the data, while the pattern recognition performed on the attribute space is performed using traditional learning techniques. In other words, the structural relationship between words have not been explicitly used in the pattern recognition process. In addition, only a few investigations have probed the suitability of representations based on bipartite networks and graphs (bigraphs) for the problem, as many approaches consider all possible links between words. In this context, we assess the relevance of a bipartite network model representing both feature words (i.e. the words characterizing the context) and target (ambiguous) words to solve ambiguities in written texts. Here, we focus on the semantical relationships between these two type of words, disregarding the relationships between feature words. In special, the proposed method not only serves to represent texts as graphs, but also constructs a structure on which the discrimination of senses is accomplished. Our results revealed that the proposed learning algorithm in such bipartite networks provides excellent results mostly when topical features are employed to characterize the context. Surprisingly, our method even outperformed the 1 ar X iv :1 60 6. 07 95 0v 1 [ cs .C L ] 2 5 Ju n 20 16 support vector machine algorithm in particular cases, with the advantage of being robust even if a small training dataset is available. Taken together, the results obtained here show that the proposed representation/classification method might be useful to improve the semantical characterization of written texts.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Winning on the Merits: The Joint Effects of Content and Style on Debate Outcomes\nAbstract: Debate and deliberation play essential roles in politics and government, but most models presume that debates are won mainly via superior style or agenda control. Ideally, however, debates would be won on the merits, as a function of which side has the stronger arguments. We propose a predictive model of debate that estimates the effects of linguistic features and the latent persuasive strengths of different topics, as well as the interactions between the two. Using a dataset of 118 Oxford-style debates, our model\u2019s combination of content (as latent topics) and style (as linguistic features) allows us to predict audience-adjudicated winners with 74% accuracy, significantly outperforming linguistic features alone (66%). Our model finds that winning sides employ stronger arguments, and allows us to identify the linguistic features associated with strong or weak arguments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Information Density as a Factor for Variation in the Embedding of Relative Clauses\nAbstract: In German, relative clauses can be positioned in-situ or extraposed. A potential factor for the variation might be information density. In this study, this hypothesis is tested with a corpus of 17 th century German funeral sermons. For each referent in the relative clauses and their matrix clauses, the attention state was determined (first calculation). In a second calculation, for each word the surprisal values were determined, using a bi-gram language model. In a third calculation, the surprisal values were accommodated as to whether it is the first occurrence of the word in question or not. All three calculations pointed in the same direction: With in-situ relative clauses, the rate of new referents was lower and the average surprisal values were lower, especially the accommodated surprisal values, than with extraposed relative clauses. This indicated that information density is a factor governing the choice between in-situ and extraposed relative clauses. The study also sheds light on the intrinsic relationship between the information theoretic concept of information density and information structural concepts such as givenness which are used under a more linguistic perspective.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adversarially Regularized Autoencoders for Generating Discrete Structures\nAbstract: Generative adversarial networks are an effective approach for learning rich latent representations of continuous data, but have proven difficult to apply directly to discrete structured data, such as text sequences or discretized images. Ideally we could encode discrete structures in a continuous code space to avoid this problem, but it is difficult to learn an appropriate general-purpose encoder. In this work, we consider a simple approach for handling these two challenges jointly, employing a discrete structure autoencoder with a code space regularized by generative adversarial training. The model learns a smooth regularized code space while still being able to model the underlying data, and can be used as a discrete GAN with the ability to generate coherent discrete outputs from continuous samples. We demonstrate empirically how key properties of the data are captured in the model\u2019s latent space, and evaluate the model itself on the tasks of discrete image generation, text generation, and semi-supervised learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distant IE by Bootstrapping Using Lists and Document Structure\nAbstract: Distant labeling for information extraction (IE) suffers from noisy training data. We describe a way of reducing the noise associated with distant IE by identifying coupling constraints between potential instance labels. As one example of coupling, items in a list are likely to have the same label. A second example of coupling comes from analysis of document structure: in some corpora, sections can be identified such that items in the same section are likely to have the same label. Such sections do not exist in all corpora, but we show that augmenting a large corpus with coupling constraints from even a small, well-structured corpus can improve performance substantially, doubling F1 on one task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Design and Optimization of a Speech Recognition Front-End for Distant-Talking Control of a Music Playback Device\nAbstract: This paper addresses the challenging scenario for the distanttalking control of a music playback device, a common portable speaker with four small loudspeakers in close proximity to one microphone. The user controls the device through voice, where the speech-to-music ratio can be as low as \u221230 dB during music playback. We propose a speech enhancement front-end that relies on known robust methods for echo cancellation, doubletalk detection, and noise suppression, as well as a novel adaptive quasi-binary mask that is well suited for speech recognition. The optimization of the system is then formulated as a large scale nonlinear programming problem where the recognition rate is maximized and the optimal values for the system parameters are found through a genetic algorithm. We validate our methodology by testing over the TIMIT database for different music playback levels and noise types. Finally, we show that the proposed front-end allows a natural interaction with the device for limited-vocabulary voice commands.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sentiment analysis based on rhetorical structure theory: Learning deep neural networks from discourse trees\nAbstract: Prominent applications of sentiment analysis are countless, including areas such as marketing, customer service and communication. The conventional bag-ofwords approach for measuring sentiment merely counts term frequencies; however, it neglects the position of the terms within the discourse. As a remedy, we thus develop a discourse-aware method that builds upon the discourse structure of documents. For this purpose, we utilize rhetorical structure theory to label (sub-)clauses according to their hierarchical relationships and then assign polarity scores to individual leaves. To learn from the resulting rhetoric structure, we propose a tensor-based, tree-structured deep neural network (named RST-LSTM) in order to process the complete discourse tree. The underlying attention mechanism infers the salient passages of narrative materials. In addition, we suggest two algorithms for data augmentation (node reordering and artificial leaf insertion) that increase our training set and reduce overfitting. Our benchmarks demonstrate the superior performance of our approach. Ultimately, this work advances the status quo in natural language processing by developing algorithms that incorporate semantic information.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reading Wikipedia to Answer Open-Domain Questions\nAbstract: This paper proposes to tackle opendomain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval \u2013 finding the relevant articles \u2013 with that of machine comprehension of text \u2013 identifying the answer spans from those articles. Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information\nAbstract: With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Knowledge basebased question answering (KB-QA) is one of the most promising approaches to access the substantial knowledge. Meantime, as the neural networkbased (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is unable to express the proper information of the question. Hence, we present a neural attention-based model to represent the questions dynamically according to the different focuses of various candidate answer aspects. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. And it also alleviates the out of vocabulary (OOV) problem, which helps the attention model to represent the question more precisely. The experimental results on WEBQUESTIONS demonstrate the effectiveness of the proposed approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Query-Regression Networks for Machine Comprehension\nAbstract: We present Query-Regression Network (QRN), a variant of Recurrent Neural Network (RNN) that is suitable for end-to-end machine comprehension. While previous work largely relied on external memory and attention mechanism, QRN is a single recurrent unit with internal memory. Unlike most RNN-based models, QRN is able to effectively handle long-term dependencies and is highly parallelizable. In our experiments we show that QRN outperforms the state of the art in end-to-end bAbI QA tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Temporal Analysis of Language through Neural Language Models\nAbstract: We provide a method for automatically detecting change in language across time through a chronologically trained neural language model. We train the model on the Google Books Ngram corpus to obtain word vector representations specific to each year, and identify words that have changed significantly from 1900 to 2009. The model identifies words such as cell and gay as having changed during that time period. The model simultaneously identifies the specific years during which such words underwent change.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Balotage in Argentina 2015, a sentiment analysis of tweets (Balotaje Argentina 2015 a partir de un ana\u0301lisis de sentimiento de tweets)\nAbstract: Twitter social network contains a large amount of information generated by its users. That information is composed of opinions and comments that may reflect trends in social behavior. There is talk of trend when it is possible to identify opinions and comments geared towards the same shared by a lot of people direction. To determine if two or more written opinions share the same address, techniques Natural Language Processing (NLP) are used. This paper proposes a methodology for predicting reflected in Twitter from the use of sentiment analysis functions NLP based on social behaviors. The case study was selected the 2015 Presidential in Argentina, and a software architecture Big Data composed Vertica data base with the component called Pulse was used. Through the analysis it was possible to detect trends in voting intentions with regard to the presidential candidates, achieving greater accuracy in predicting that achieved with traditional systems surveys.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: END-TO-END ATTENTION-BASED DISTANT SPEECH RECOGNITION WITH HIGHWAY LSTM\nAbstract: End-to-end attention-based models have been shown to be competitive alternatives to conventional DNN-HMM models in the Speech Recognition Systems. In this paper, we extend existing end-to-end attentionbased models that can be applied for Distant Speech Recognition (DSR) task. Specifically, we propose an end-to-end attention-based speech recognizer with multichannel input that performs sequence prediction directly at the character level. To gain a better performance, we also incorporate Highway long short-term memory (HLSTM) which outperforms previous models on AMI distant speech recognition task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Natural Language Processing with Small Feed-Forward Networks\nAbstract: We show that small and shallow feedforward neural networks can achieve near state-of-the-art results on a range of unstructured and structured language processing tasks while being considerably cheaper in memory and computational requirements than deep recurrent models. Motivated by resource-constrained environments like mobile phones, we showcase simple techniques for obtaining such small neural network models, and investigate different tradeoffs when deciding how to allocate a small memory budget.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: How Much is 131 Million Dollars? Putting Numbers in Perspective with Compositional Descriptions\nAbstract: How much is 131 million US dollars? To help readers put such numbers in context, we propose a new task of automatically generating short descriptions known as perspectives, e.g. \u201c$131 million is about the cost to employ everyone in Texas over a lunch period\u201d. First, we collect a dataset of numeric mentions in news articles, where each mention is labeled with a set of rated perspectives. We then propose a system to generate these descriptions consisting of two steps: formula construction and description generation. In construction, we compose formulae from numeric facts in a knowledge base and rank the resulting formulas based on familiarity, numeric proximity and semantic compatibility. In generation, we convert a formula into natural language using a sequence-to-sequence recurrent neural network. Our system obtains a 15.2% F1 improvement over a non-compositional baseline at formula construction and a 12.5 BLEU point improvement over a baseline description generation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: PETRARCH 2 : PETRARCHer\nAbstract: PETRARCH 2 is the fourth generation of a series of Event-Data coders stemming from research by Phillip Schrodt1. Each iteration has brought new functionality and usability 2, and this is no exception. Petrarch 2 takes much of the power of the original Petrarch\u2019s dictionaries and redirects it into a faster and smarter core logic. Earlier iterations handled sentences largely as a list of words, incorporating some syntactic information here and there. Petrarch 2 (henceforth referred to as Petrarch) now views the sentence entirely on the syntactic level. It receives the syntactic parse of a sentence from the Stanford CoreNLP software, and stores this data as a tree structure of linked nodes, where each node is a Phrase object. Prepositional, noun, and verb phrases each have their own version of this Phrase class, which deals with the logic particular to those kinds of phrases. Since this is an event coder, the core of the logic focuses around the verbs: who is acting, who is being acted on, and what is happening. The theory behind this new structure and its logic is founded in Generative Grammar, Information Theory, and Lambda-Calculus Semantics.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Hadoop for Large Scale Analysis on Twitter: A Technical Report\nAbstract: Sentiment analysis (or opinion mining) on Twitter data has attracted much attention recently. One of the system\u2019s key features, is the immediacy in communication with other users in an easy, user-friendly and fast way. Consequently, people tend to express their feelings freely, which makes Twitter an ideal source for accumulating a vast amount of opinions towards a wide diversity of topics. This amount of information offers huge potential and can be harnessed to receive the sentiment tendency towards these topics. However, since none can invest an infinite amount of time to read through these tweets, an automated decision making approach is necessary. Nevertheless, most existing solutions are limited in centralized environments only. Thus, they can only process at most a few thousand tweets. Such a sample, is not representative to define the sentiment polarity towards a topic due to the massive number of tweets published daily. In this paper, we go one step further and develop a novel method for sentiment learning in theMapReduce framework. Our algorithm exploits the hashtags and emoticons inside a tweet, as sentiment labels, and proceeds to a classification procedure of diverse sentiment types in a parallel and distributed manner. Moreover, we utilize Bloom filters to compact the storage size of intermediate data and boost the performance of our algorithm. Through an extensive experimental evaluation, we prove that our solution is efficient, robust and scalable and confirm the quality of our sentiment identification.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Data representation is a fundamental task in machine learning. The representation of data affects the performance of the whole machine learning system. In a long history, the representation of data is done by feature engineering, and researchers aim at designing better features for specific tasks. Recently, the rapid development of deep learning and representation learning has brought new inspiration to various domains. In natural language processing, the most widely used feature representation is the Bag-of-Words model. This model has the data sparsity problem and cannot keep the word order information. Other features such as part-of-speech tagging or more complex syntax features can only fit for specific tasks inmost cases. This thesis focuses onword representation and document representation. We compare the existing systems and present our new model. First, for generating word embeddings, we make comprehensive comparisons among existing word embedding models. In terms of theory, we figure out the relationship between the two most important models, i.e., Skip-gram and GloVe. In our experiments, we analyze three key points in generating word embeddings, including the model construction, the training corpus and parameter design. We evaluate word embeddings with three types of tasks, and we argue that they cover the existing use of word embeddings. Through theory and practical experiments, we present some guidelines for how to generate a good word embedding. Second, in Chinese character or word representation, we find that the existing models always use theword embeddingmodels directly. We introduce the joint training of Chinese character and word. This method incorporates the context words into the representation space of a Chinese character, which leads to a better representation of Chinese characters and words. In the tasks of Chinese character segmentation and document classification, the joint training outperforms the existing methods that train characters or words with traditional word embedding algorithms. Third, for document representation, we analyze the existing document representation models, including recursive neural networks, recurrent neural networks and coniv \u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u8bcd\u548c\u6587\u6863\u8bed\u4e49\u5411\u91cf\u8868\u793a\u65b9\u6cd5\u7814\u7a76 volutional neural networks. We point out the drawbacks of these models and present our newmodel, the recurrent convolutional neural networks. In text classification task, the experimental results show that our model outperforms the existing models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: F2F: A Library for Fast Kernel Expansions\nAbstract: F2F is a C++ library for large-scale machine learning. It contains a CPU optimized implementation of the Fastfood algorithm in Le et al. (2013), that allows the computation of approximated kernel expansions in loglinear time. The algorithm requires to compute the product of Walsh-Hadamard Transform (WHT) matrices. A cache friendly SIMD Fast Walsh-Hadamard Transform (FWHT) that achieves compelling speed and outperforms current state-of-the-art methods has been developed. F2F allows to obtain non-linear classification combining Fastfood and a linear classifier.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Group Equivariant Convolutional Networks\nAbstract: We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. By convolving over groups larger than the translation group, G-CNNs build representations that are equivariant to these groups, which makes it possible to greatly increase the degree of parameter sharing. We show how G-CNNs can be implemented with negligible computational overhead for discrete groups such as the group of translations, reflections and rotations by multiples of 90 degrees. G-CNNs achieve state of the art results on rotated MNIST and significantly improve over a competitive baseline on augmented and non-augmented CIFAR-10.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Theory II: Landscape of the Empirical Risk in Deep Learning\nAbstract: Previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima. However, the practical observation is that, at least for the most successful Deep Convolutional Neural Networks (DCNNs) for visual processing, practitioners can always increase the network size to fit the training data (an extreme example would be ). The most successful DCNNs such as VGG and ResNets are best used with a small degree of \u201coverparametrization\u201d. In this work, we characterize with a mix of theory and experiments, the landscape of the empirical risk of overparametrized DCNNs. We first prove the existence of a large number of degenerate global minimizers with zero empirical error (modulo inconsistent equations). The zero-minimizers \u2013 in the case of classification \u2013 have a non-zero margin. The same minimizers are degenerate and thus very likely to be found by SGD that will furthermore select with higher probability the zero-minimizer with larger margin, as discussed in Theory III (to be released). We further experimentally explored and visualized the landscape of empirical risk of a DCNN on CIFAR-10 during the entire training process and especially the global minima. Finally, based on our theoretical and experimental results, we propose an intuitive model of the landscape of DCNN\u2019s empirical loss surface, which might not be as complicated as people commonly believe. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. 1 ar X iv :1 70 3. 09 83 3v 1 [ cs .L G ] 2 8 M ar 2 01 7\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Cross Language Text Classification via Subspace Co-Regularized Multi-View Learning\nAbstract: In many multilingual text classification problems, the documents in different languages often share the same set of categories. To reduce the labeling cost of training a classification model for each individual language, it is important to transfer the label knowledge gained from one language to another language by conducting cross language classification. In this paper we develop a novel subspace co-regularized multi-view learning method for cross language text classification. This method is built on parallel corpora produced by machine translation. It jointly minimizes the training error of each classifier in each language while penalizing the distance between the subspace representations of parallel documents. Our empirical study on a large set of cross language text classification tasks shows the proposed method consistently outperforms a number of inductive methods, domain adaptation methods, and multi-view learning methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Shaping Level Sets with Submodular Functions\nAbstract: We consider a class of sparsity-inducing regularization terms based on submodular functions. While previous work has focused on non-decreasing functions, we explore symmetric submodular functions and their Lov\u00e1sz extensions. We show that the Lov\u00e1sz extension may be seen as the convex envelope of a function that depends on level sets (i.e., the set of indices whose corresponding components of the underlying predictor are greater than a given constant): this leads to a class of convex structured regularization terms that impose prior knowledge on the level sets, and not only on the supports of the underlying predictors. We provide a unified set of optimization algorithms, such as proximal operators, and theoretical guarantees (allowed level sets and recovery conditions). By selecting specific submodular functions, we give a new interpretation to known norms, such as the total variation; we also define new norms, in particular ones that are based on order statistics with application to clustering and outlier detection, and on noisy cuts in graphs with application to change point detection in the presence of outliers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An optimal algorithm for the Thresholding Bandit Problem\nAbstract: We study a specific combinatorial pure exploration stochastic bandit problem where the learner aims at finding the set of arms whose means are above a given threshold, up to a given precision, and for a fixed time horizon. We propose a parameter-free algorithm based on an original heuristic, and prove that it is optimal for this problem by deriving matching upper and lower bounds. To the best of our knowledge, this is the first non-trivial pure exploration setting with fixed budget for which optimal strategies are constructed.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adaptive Stochastic Alternating Direction Method of Multipliers\nAbstract: The Alternating Direction Method of Multipliers (ADMM) has been studied for years. The traditional ADMM algorithm needs to compute, at each iteration, an (empirical) expected loss function on all training examples, resulting in a computational complexity proportional to the number of training examples. To reduce the time complexity, stochastic ADMM algorithms were proposed to replace the expected function with a random loss function associated with one uniformly drawn example plus a Bregman divergence. The Bregman divergence, however, is derived from a simple second order proximal function, the half squared norm, which could be a suboptimal choice. In this paper, we present a new family of stochastic ADMM algorithms with optimal second order proximal functions, which produce a new family of adaptive subgradient methods. We theoretically prove that their regret bounds are as good as the bounds which could be achieved by the best proximal function that can be chosen in hindsight. Encouraging empirical results on a variety of real-world datasets confirm the effectiveness and efficiency of the proposed algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-talker Speech Separation with Utterance-level Permutation Invariant Training of Deep Recurrent Neural Networks\nAbstract: In this paper we propose the utterance-level Permutation Invariant Training (uPIT) technique. uPIT is a practically applicable, end-to-end, deep learning based solution for speaker independent multi-talker speech separation. Specifically, uPIT extends the recently proposed Permutation Invariant Training (PIT) technique with an utterance-level cost function, hence eliminating the need for solving an additional permutation problem during inference, which is otherwise required by frame-level PIT. We achieve this using Recurrent Neural Networks (RNNs) that, during training, minimize the utterance-level separation error, hence forcing separated frames belonging to the same speaker to be aligned to the same output stream. In practice, this allows RNNs, trained with uPIT, to separate multi-talker mixed speech without any prior knowledge of signal duration, number of speakers, speaker identity or gender. We evaluated uPIT on the WSJ0 and Danish twoand three-talker mixed-speech separation tasks and found that uPIT outperforms techniques based on Non-negative Matrix Factorization (NMF) and Computational Auditory Scene Analysis (CASA), and compares favorably with Deep Clustering (DPCL) and the Deep Attractor Network (DANet). Furthermore, we found that models trained with uPIT generalize well to unseen speakers and languages. Finally, we found that a single model, trained with uPIT, can handle both two-speaker, and three-speaker speech mixtures.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LEARNING OPPOSITES USING NEURAL NETWORKS\nAbstract: Many research works have successfully extended algorithms such as evolutionary algorithms, reinforcement agents and neural networks using \u201copposition-based learning\u201d (OBL). Two types of the \u201copposites\u201d have been defined in the literature, namely type-I and type-II. The former are linear in nature and applicable to the variable space, hence easy to calculate. On the other hand, type-II opposites capture the \u201coppositeness\u201d in the output space. In fact, type-I opposites are considered a special case of type-II opposites where inputs and outputs have a linear relationship. However, in many real-world problems, inputs and outputs do in fact exhibit a nonlinear relationship. Therefore, type-II opposites are expected to be better in capturing the sense of \u201copposition\u201d in terms of the input-output relation. In the absence of any knowledge about the problem at hand, there seems to be no intuitive way to calculate the type-II opposites. In this paper, we introduce an approach to learn type-II opposites from the given inputs and their outputs using the artificial neural networks (ANNs). We first perform opposition mining on the sample data, and then use the mined data to learn the relationship between input x and its opposite x\u0306. We have validated our algorithm using various benchmark functions to compare it against an evolving fuzzy inference approach that has been recently introduced. The results show the better performance of a neural approach to learn the opposites. This will create new possibilities for integrating oppositional schemes within existing algorithms promising a potential increase in convergence speed and/or accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning in Finance\nAbstract: We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems \u2013 such as those presented in designing and pricing securities, constructing portfolios, and risk management \u2013 often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From Bayesian Sparsity to Gated Recurrent Nets\nAbstract: The iterations of many first-order algorithms, when applied to minimizing common regularized regression functions, often resemble neural network layers with prespecified weights. This observation has prompted the development of learningbased approaches that purport to replace these iterations with enhanced surrogates forged as DNN models from available training data. For example, important NPhard sparse estimation problems have recently benefitted from this genre of upgrade, with simple feedforward or recurrent networks ousting proximal gradient-based iterations. Analogously, this paper demonstrates that more powerful Bayesian algorithms for promoting sparsity, which rely on complex multi-loop majorizationminimization techniques, mirror the structure of more sophisticated long short-term memory (LSTM) networks, or alternative gated feedback networks previously designed for sequence prediction. As part of this development, we examine the parallels between latent variable trajectories operating across multiple time-scales during optimization, and the activations within deep network structures designed to adaptively model such characteristic sequences. The resulting insights lead to a novel sparse estimation system that, when granted training data, can estimate optimal solutions efficiently in regimes where other algorithms fail, including practical direction-of-arrival (DOA) and 3D geometry recovery problems. The underlying principles we expose are also suggestive of a learning process for a richer class of multi-loop algorithms in other domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scaling the Indian Buffet Process via Submodular Maximization\nAbstract: Inference for latent feature models is inherently difficult as the inference space grows exponentially with the size of the input data and number of latent features. In this work, we use Kurihara & Welling (2008)\u2019s maximization-expectation framework to perform approximate MAP inference for linearGaussian latent feature models with an Indian Buffet Process (IBP) prior. This formulation yields a submodular function of the features that corresponds to a lower bound on the model evidence. By adding a constant to this function, we obtain a nonnegative submodular function that can be maximized via a greedy algorithm that obtains at least a 13 approximation to the optimal solution. Our inference method scales linearly with the size of the input data, and we show the efficacy of our method on the largest datasets currently analyzed using an IBP model.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Look, Listen and Learn\nAbstract: We consider the question: what can be learnt by looking at and listening to a large amount of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself \u2013 the correspondence between the visual and the audio streams, and we introduce a novel \u201cAudio-Visual Correspondence\u201d learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good vision and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Network Traffic Decomposition for Anomaly Detection\nAbstract: In this paper we focus on the detection of network anomalies like Denial of Service (DoS) attacks and port scans in a unified manner. While there has been an extensive amount of research in network anomaly detection, current state of the art methods are only able to detect one class of anomalies at the cost of others. The key tool we will use is based on the spectral decomposition of a trajectory/hankel matrix which is able to detect deviations from both between and within correlation present in the observed network traffic data. Detailed experiments on synthetic and real network traces shows a significant improvement in detection capability over competing approaches. In the process we also address the issue of robustness of anomaly detection systems in a principled fashion.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Decoupling Exploration and Exploitation in Multi-Armed Bandits\nAbstract: We consider a multi-armed bandit problem where the decision maker can explore and exploit different arms at every round. The exploited arm adds to the decision maker\u2019s cumulative reward (without necessarily observing the reward) while the explored arm reveals its value. We devise algorithms for this setup and show that the dependence on the number of arms, k, can be much better than the standard \u221a k dependence, depending on the behavior of the arms\u2019 reward sequences. For the important case of piecewise stationary stochastic bandits, we show a significant improvement over existing algorithms. Our algorithms are based on a non-uniform sampling policy, which we show is essential to the success of any algorithm in the adversarial setup. Finally, we show some simulation results on an ultra-wide band channel selection inspired setting indicating the applicability of our algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Codebook based Audio Feature Representation for Music Information Retrieval\nAbstract: Digital music has become prolific in the web in recent decades. Automated recommendation systems are essential for users to discover music they love and for artists to reach appropriate audience. When manual annotations and user preference data is lacking (e.g. for new artists) these systems must rely on content based methods. Besides powerful machine learning tools for classification and retrieval, a key component for successful recommendation is the audio content representation. Good representations should capture informative musical patterns in the audio signal of songs. These representations should be concise, to enable efficient (low storage, easy indexing, fast search) management of huge music repositories, and should also be easy and fast to compute, to enable real-time interaction with a user supplying new songs to the system. Before designing new audio features, we explore the usage of traditional local features, while adding a stage of encoding with a pre-computed codebook and a stage of pooling to get compact vectorial representations. We experiment with different encoding methods, namely the LASSO, vector quantization (VQ) and cosine similarity (CS). We evaluate the representations\u2019 quality in two music information retrieval applications: queryby-tag and query-by-example. Our results show that concise representations can be used for successful performance in both applications. We recommend using top-\u03c4 VQ encoding, which consistently performs well in both applications, and requires much less computation time than the LASSO.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: FOVEATION-BASED MECHANISMS ALLEVIATE ADVERSARIAL EXAMPLES\nAbstract: We show that adversarial examples, i.e., the visually imperceptible perturbations that result in Convolutional Neural Networks (CNN) fail, can be alleviated with a mechanism based on foveations \u2014 applying the CNN in a different image region. To see this, first, we report results in ImageNet that lead to a revision of the hypothesis that adversarial perturbations are a consequence of CNNs acting too linearly: a CNN acts locally linearly, only to changes in the receptive fields with objects recognized by the CNN, otherwise the CNN acts non-linearly. Then, we corroborate the hypothesis that when the neural responses are in the linear region, applying the foveation mechanism to the adversarial example tends to reduce the effect of the perturbation. This is because CNNs in ImageNet are robust to changes produced by the foveation (scale and translation of the recognized objects), but this property does not generalize to transformations of the perturbation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Nearly-tight VC-dimension bounds for piecewise linear neural networks\nAbstract: We prove new upper and lower bounds on the VC-dimension of deep neural networks with the ReLU activation function. These bounds are tight for almost the entire range of parameters. Letting W be the number of weights and L be the number of layers, we prove that the VC-dimension is O(WL log(W )) and \u03a9(WL log(W/L)). This improves both the previously known upper bounds and lower bounds. In terms of the number U of non-linear units, we prove a tight bound \u0398(WU) on the VC-dimension. All of these results generalize to arbitrary piecewise linear activation functions.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unified Framework for Quantification\nAbstract: Quantification is the machine learning task of estimating test-data class proportions that are not necessarily similar to those in training. Apart from its intrinsic value as an aggregate statistic, quantification output can also be used to optimize classifier probabilities, thereby increasing classification accuracy. We unify major quantification approaches under a constrained multi-variate regression framework, and use mathematical programming to estimate class proportions for different loss functions. With this modeling approach, we extend existing binary-only quantification approaches to multi-class settings as well. We empirically verify our unified framework by experimenting with several multi-class datasets including the Stanford Sentiment Treebank and CIFAR-10.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Nonsmooth Regularized Risk Minimization with Continuation\nAbstract: In regularized risk minimization, the associated optimization problem becomes particularly difficult when both the loss and regularizer are nonsmooth. Existing approaches either have slow or unclear convergence properties, are restricted to limited problem subclasses, or require careful setting of a smoothing parameter. In this paper, we propose a continuation algorithm that is applicable to a large class of nonsmooth regularized risk minimization problems, can be flexibly used with a number of existing solvers for the underlying smoothed subproblem, and with convergence results on the whole algorithm rather than just one of its subproblems. In particular, when accelerated solvers are used, the proposed algorithm achieves the fastest known rates of O(1/T ) on strongly convex problems, and O(1/T ) on general convex problems. Experiments on nonsmooth classification and regression tasks demonstrate that the proposed algorithm outperforms the state-of-the-art.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Cross-Domain Multitask Learning with Latent Probit Models\nAbstract: Learning multiple tasks across heterogeneous domains is a challenging problem since the feature space may not be the same for different tasks. We assume the data in multiple tasks are generated from a latent common domain via sparse domain transforms and propose a latent probit model (LPM) to jointly learn the domain transforms, and a probit classifier shared in the common domain. To learn meaningful task relatedness and avoid over-fitting in classification, we introduce sparsity in the domain transforms matrices, as well as in the common classifier parameters. We derive theoretical bounds for the estimation error of the classifier parameters in terms of the sparsity of domain transform matrices. An expectation-maximization algorithm is derived for learning the LPM. The effectiveness of the approach is demonstrated on several real datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Nearly-optimal Robust Matrix Completion\nAbstract: In this paper, we consider the problem of Robust Matrix Completion (RMC) where the goal is to recover a low-rank matrix by observing a small number of its entries out of which a few can be arbitrarily corrupted. We propose a simple projected gradient descent method to estimate the low-rank matrix that alternately performs a projected gradient descent step and cleans up a few of the corrupted entries using hard-thresholding. Our algorithm solves RMC using nearly optimal number of observations as well as nearly optimal number of corruptions. Our result also implies significant improvement over the existing time complexity bounds for the low-rank matrix completion problem. Finally, an application of our result to the robust PCA problem (low-rank+sparse matrix separation) leads to nearly linear time (in matrix dimensions) algorithm for the same; existing state-of-the-art methods require quadratic time. Our empirical results corroborate our theoretical results and show that even for moderate sized problems, our method for robust PCA is an an order of magnitude faster than the existing methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stochastic Gradient Based Extreme Learning Machines For Online Learning of Advanced Combustion Engines\nAbstract: In this article, a stochastic gradient based online<lb>learning algorithm for Extreme Learning Machines (ELM) is<lb>developed (SG-ELM). A stability criterion based on Lyapunov<lb>approach is used to prove both asymptotic stability of estima-<lb>tion error and stability in the estimated parameters suitable<lb>for identification of nonlinear dynamic systems. The developed<lb>algorithm not only guarantees stability, but also reduces the<lb>computational demand compared to the OS-ELM approach<lb>[1] based on recursive least squares. In order to demonstrate<lb>the effectiveness of the algorithm on a real-world scenario, an<lb>advanced combustion engine identification problem is considered.<lb>The algorithm is applied to two case studies: An online regression<lb>learning for system identification of a Homogeneous Charge<lb>Compression Ignition (HCCI) Engine and an online classification<lb>learning (with class imbalance) for identifying the dynamic<lb>operating envelope of the HCCI Engine. The results indicate<lb>that the accuracy of the proposed SG-ELM is comparable to<lb>that of the state-of-the-art but adds stability and a reduction in<lb>computational effort.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Wavelet-Based Semantic Features for Hyperspectral Signature Discrimination\nAbstract: Hyperspectral signature classification is a quantitative analysis approach for hyperspectral imagery which performs detection and classification of the constituent materials at the pixel level in the scene. The classification procedure can be operated directly on hyperspectral data or performed by using some features extracted from the corresponding hyperspectral signatures containing information like the signature\u2019s energy or shape. In this paper, we describe a technique that applies non-homogeneous hidden Markov chain (NHMC) models to hyperspectral signature classification. The basic idea is to use statistical models (such as NHMC) to characterize wavelet coefficients which capture the spectrum semantics (i.e., structural information) at multiple levels. Experimental results show that the approach based on NHMC models can outperform existing approaches relevant in classification tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Investigating Recurrence and Eligibility Traces in Deep Q-Networks\nAbstract: Eligibility traces in reinforcement learning are used as a bias-variance trade-off and can often speed up training time by propagating knowledge back over time-steps in a single update. We investigate the use of eligibility traces in combination with recurrent networks in the Atari domain. We illustrate the benefits of both recurrent nets and eligibility traces in some Atari games, and highlight also the importance of the optimization used in the training.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning as a Tool to Predict Flow Patterns in Two-Phase Flow\nAbstract: In order to better model complex real-world data such as multiphase flow, one approach is to develop pattern recognition techniques and robust features that capture the relevant information. In this paper, we use deep learning methods, and in particular employ the multilayer perceptron, to build an algorithm that can predict flow pattern in twophase flow from fluid properties and pipe conditions. The preliminary results show excellent performance when compared with classical methods of flow pattern prediction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Kickback cuts Backprop\u2019s red-tape: Biologically plausible credit assignment in neural networks\nAbstract: Error backpropagation is an extremely effective algorithm for assigning credit in artificial neural networks. However, weight updates under Backprop depend on lengthy recursive computations and require separate output and error messages \u2013 features not shared by biological neurons, that are perhaps unnecessary. In this paper, we revisit Backprop and the credit assignment problem. We first decompose Backprop into a collection of interacting learning algorithms; provide regret bounds on the performance of these sub-algorithms; and factorize Backprop\u2019s error signals. Using these results, we derive a new credit assignment algorithm for nonparametric regression, Kickback, that is significantly simpler than Backprop. Finally, we provide a sufficient condition for Kickback to follow error gradients, and show that Kickback matches Backprop\u2019s performance on real-world regression benchmarks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Black-Box Optimization in Machine Learning with Trust Region Based Derivative Free Algorithm\nAbstract: In this work, we utilize a Trust Region based Derivative Free Optimization (DFO-TR) method to directly maximize the Area Under Receiver Operating Characteristic Curve (AUC), which is a nonsmooth, noisy function. We show that AUC is a smooth function, in expectation, if the distributions of the positive and negative data points obey a jointly normal distribution. The practical performance of this algorithm is compared to three prominent Bayesian optimization methods and random search. The presented numerical results show that DFO-TR surpasses Bayesian optimization and random search on various blackbox optimization problem, such as maximizing AUC and hyperparameter tuning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Differentially Private Online Learning for Video Recommendation with Social Big Data over Media Cloud\nAbstract: With the rapid growth in multimedia services and the enormous offers of video contents in online social networks, users have difficulty in obtaining their interests. Therefore, various personalized recommendation systems have been proposed. However, they ignore that the accelerated proliferation of social media data has led to the big data era, which has greatly impeded the process of video recommendation. In addition, none of them has considered both the privacy of users\u2019 contexts (e,g,. social status, ages and hobbies) and video service vendors\u2019 repositories, which are extremely sensitive and of significant commercial value. To handle the problems, we propose a cloud-assisted differentially private video recommendation system based on distributed online learning. In our framework, service vendors are modeled as distributed cooperative learners, recommending videos according to user\u2019s context, while simultaneously adapting the video-selection strategy based on user-click feedback to maximize total user clicks (reward). Considering the sparsity and heterogeneity of big social media data, we also propose a novel geometric differentially private model, which can greatly reduce the performance (recommendation accuracy) loss. Our simulation shows the proposed algorithms outperform other existing methods and keep a delicate balance between computing accuracy and privacy preserving level.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We prove that the empirical risk of most well-known loss functions factors into a linear term aggregating all labels with a term that is label free, and can further be expressed by sums of the loss. This holds true even for non-smooth, non-convex losses and in any rkhs. The first term is a (kernel) mean operator \u2013the focal quantity of this work\u2013 which we characterize as the sufficient statistic for the labels. The result tightens known generalization bounds and sheds new light on their interpretation. Factorization has a direct application on weakly supervised learning. In particular, we demonstrate that algorithms like sgd and proximal methods can be adapted with minimal effort to handle weak supervision, once the mean operator has been estimated. We apply this idea to learning with asymmetric noisy labels, connecting and extending prior work. Furthermore, we show that most losses enjoy a data-dependent (by the mean operator) form of noise robustness, in contrast with known negative results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deriving Neural Architectures from Sequence and Graph Kernels\nAbstract: The design of neural architectures for structured objects is typically guided by experimental insights rather than a formal process. In this work, we appeal to kernels over combinatorial structures, such as sequences and graphs, to derive appropriate neural operations. We introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces. Our recurrent modules compare the input to virtual reference objects (cf. filters in CNN) via the kernels. Similar to traditional neural operations, these reference objects are parameterized and directly optimized in end-to-end training. We empirically evaluate the proposed class of neural architectures on standard applications such as language modeling and molecular graph regression, achieving state-of-the-art results across these applications.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: NONNEGATIVE MATRIX FACTORIZATION WITH TRANSFORM LEARNING\nAbstract: Traditional NMF-based signal decomposition relies on the factorization of spectral data which is typically computed by means of the short-time Fourier transform. In this paper we propose to relax the choice of a pre-fixed transform and learn a short-time unitary transform together with the factorization, using a novel block-descent algorithm. This improves the fit between the processed data and its approximation and is in turn shown to induce better separation performance in a speech enhancement experiment.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A pragmatic approach to multi-class classification\nAbstract: We present a novel hierarchical approach to multiclass classification which is generic in that it can be applied to different classification models (e.g., support vector machines, perceptrons), and makes no explicit assumptions about the probabilistic structure of the problem as it is usually done in multi-class classification. By adding a cascade of additional classifiers, each of which receives the previous classifier\u2019s output in addition to regular input data, the approach harnesses unused information that manifests itself in the form of, e.g., correlations between predicted classes. Using multilayer perceptrons as a classification model, we demonstrate the validity of this approach by testing it on a complex ten-class 3D gesture recognition task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Robust Hashing for Multi-View Data: Jointly Learning Low-Rank Kernelized Similarity Consensus and Hash Functions\nAbstract: Learning hash functions/codes for similarity search over multi-view data is attracting increasing attention, where similar hash codes are assigned to the data objects characterizing consistently neighborhood relationship across views. Traditional methods in this category inherently suffer three limitations: 1) they commonly adopt a two-stage scheme where similarity matrix is first constructed, followed by a subsequent hash function learning; 2) these methods are commonly developed on the assumption that data samples with multiple representations are noise-free,which is not practical in reallife applications; 3) they often incur cumbersome training model caused by the neighborhood graph construction using all N points in the database (O(N)). In this paper, we motivate the problem of jointly and efficiently training the robust hash functions over data objects with multi-feature representations which may be noise corrupted. To achieve both the robustness and training efficiency, we propose an approach to effectively and efficiently learning low-rank kernelized 1 hash functions shared across views. Specifically, we utilize landmark graphs to construct tractable similarity matrices in multi-views to automatically discover neighborhood structure in the data. To learn robust hash functions, a latent low-rank kernel function is used to construct hash functions in order to accommodate linearly inseparable data. In particular, a latent kernelized similarity matrix is recovered by rank minimization on multiple kernel-based similarity matrices. Extensive experiments on realworld multi-view datasets validate the efficacy of our method in the presence of error corruptions. We use kernelized similarity rather than kernel, as it is not a squared symmetric matrix for data-landmark affinity matrix.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ONLINE SEMI-SUPERVISED LEARNING WITH DEEP HYBRID BOLTZMANN MACHINES AND DENOISING AUTOENCODERS\nAbstract: Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and the Deep Hybrid Denoising Auto-encoder, are proposed for handling semisupervised learning problems. The models combine experts that model relevant distributions at different levels of abstraction to improve overall predictive performance on discriminative tasks. Theoretical motivations and algorithms for joint learning for each are presented. We apply the new models to the domain of datastreams in work towards life-long learning. The proposed architectures show improved performance compared to a pseudo-labeled, drop-out rectifier network.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Individualized Risk Prognosis for Critical Care Patients: A Multi-task Gaussian Process Model\nAbstract: We report the development and validation of a data-driven real-time risk score that provides timely assessments for the clinical acuity of ward patients based on their temporal lab tests and vital signs, which allows for timely intensive care unit (ICU) admissions. Unlike the existing risk scoring technologies, the proposed score is \u201cindividualized\u201d\u2013 it uses the electronic health record (EHR) data to cluster the patients based on their static covariates into subcohorts of \u201csimilar\u201d patients, and then learns a separate temporal, non-stationary multi-task Gaussian Process (GP) model that captures the physiology of every subcohort. Experiments conducted on data from a heterogeneous cohort of 6,094 patients admitted to the Ronald Reagan UCLA medical center show that our risk score significantly outperforms the state-of-the-art risk scoring technologies, such as the Rothman index and MEWS, in terms of timeliness, true positive rate (TPR), and positive predictive value (PPV). In particular, the proposed score increases the AUC with 20% and 38% as compared to Rothman index and MEWS respectively, and can predict ICU admissions 8 hours before clinicians at a PPV of 35% and a TPR of 50%. Moreover, we show that the proposed risk score allows for better decisions on when to discharge clinically stable patients from the ward, thereby improving the efficiency of hospital resource utilization.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adaptive Random SubSpace Learning (RSSL) Algorithm for Prediction\nAbstract: We present a novel adaptive random subspace learning algorithm (RSSL) for prediction purpose. This new framework is flexible where it can be adapted with any learning technique. In this paper, we tested the algorithm for regression and classification problems. In addition, we provide a variety of weighting schemes to increase the robustness of the developed algorithm. These different wighting flavors were evaluated on simulated as well as on real-world data sets considering the cases where the ratio between features (attributes) and instances (samples) is large and vice versa. The framework of the new algorithm consists of many stages: first, calculate the weights of all features on the data set using the correlation coefficient and F-statistic statistical measurements. Second, randomly draw n samples with replacement from the data set. Third, perform regular bootstrap sampling (bagging). Fourth, draw without replacement the indices of the chosen variables. The decision was taken based on the heuristic subspacing scheme. Fifth, call base learners and build the model. Sixth, use the model for prediction purpose on test set of the data. The results show the advancement of the adaptive RSSL algorithm in most of the cases compared with the synonym (conventional) machine learning algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Biased Importance Sampling for Deep Neural Network Training\nAbstract: Importance sampling has been successfully used to accelerate stochastic optimization in many convex problems. However, the lack of an efficient way to calculate the importance still hinders its application to Deep Learning. In this paper, we show that the loss value can be used as an alternative importance metric, and propose a way to efficiently approximate it for a deep model, using a small model trained for that purpose in parallel. This method allows in particular to utilize a biased gradient estimate that implicitly optimizes a soft max-loss, and leads to better generalization performance. While such method suffers from a prohibitively high variance of the gradient estimate when using a standard stochastic optimizer, we show that when it is combined with our sampling mechanism, it results in a reliable procedure. We showcase the generality of our method by testing it on both image classification and language modeling tasks using deep convolutional and recurrent neural networks. In particular, in case of CIFAR10 we reach 10% classification error 50 epochs faster than when using uniform sampling.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Information-Theoretical Learning of  Discriminative Clusters for Unsupervised Domain Adaptation\nAbstract: We study the problem of unsupervised domain adaptation, which aims to adapt classifiers trained on a labeled source domain to an unlabeled target domain. Many existing approaches first learn domain-invariant features and then construct classifiers with them. We propose a novel approach that jointly learn the both. Specifically, while the method identifies a feature space where data in the source and the target domains are similarly distributed, it also learns the feature space discriminatively, optimizing an informationtheoretic metric as an proxy to the expected misclassification error on the target domain. We show how this optimization can be effectively carried out with simple gradient-based methods and how hyperparameters can be cross-validated without demanding any labeled data from the target domain. Empirical studies on benchmark tasks of object recognition and sentiment analysis validated our modeling assumptions and demonstrated significant improvement of our method over competing ones in classification accuracies.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Hidden Unit Contributions for Unsupervised Acoustic Model Adaptation\nAbstract: This work presents a broad study on the adaptation of neural network acoustic models by means of learning hidden unit contributions (LHUC) \u2013 a method that linearly re-combines hidden units in a speakeror environment-dependent manner using small amounts of unsupervised adaptation data. We also extend LHUC to a speaker adaptive training (SAT) framework that leads to more adaptable DNN acoustic model, which can work in both a speaker-dependent and a speaker-independent manner, without the requirement to maintain auxiliary speakerdependent feature extractors or to introduce significant speakerdependent changes to the DNN structure. Through a series of experiments on four different speech recognition benchmarks (TED talks, Switchboard, AMI meetings and Aurora4) and over 270 test speakers we show that LHUC in both its test-only and SAT variants results in consistent word error rate reductions ranging from 5% to 23% relative depending on the task and the degree of mismatch between training and test data. In addition we have investigated the effect of the amount of adaptation data per speaker, the quality of adaptation targets when estimating transforms in an unsupervised manner, the complementarity to other adaptation techniques, one-shot adaptation, and an extension to adapting DNNs trained in a sequence discriminative manner.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dyna-Style Planning with Linear Function Approximation and Prioritized Sweeping\nAbstract: We consider the problem of efficiently learning optimal control policies and value functions over large state spaces in an online setting in which estimates must be available after each interaction with the world. This paper develops an explicitly model-based approach extending the Dyna architecture to linear function approximation. Dynastyle planning proceeds by generating imaginary experience from the world model and then applying model-free reinforcement learning algorithms to the imagined state transitions. Our main results are to prove that linear Dyna-style planning converges to a unique solution independent of the generating distribution, under natural conditions. In the policy evaluation setting, we prove that the limit point is the least-squares (LSTD) solution. An implication of our results is that prioritized-sweeping can be soundly extended to the linear approximation case, backing up to preceding features rather than to preceding states. We introduce two versions of prioritized sweeping with linear Dyna and briefly illustrate their performance empirically on the Mountain Car and Boyan Chain problems. 1 Online learning and planning Efficient decision making when interacting with an incompletely known world can be thought of as an online learning and planning problem. Each interaction provides additional information that can be used to learn a better model of the world\u2019s dynamics, and because this change could result in a different action being best (given the model), the planning process should be repeated to take this into account. However, planning is inherently a complex process; on large problems it not possible to repeat it on every time step without greatly slowing down the response time of the system. Some form of incremental planning is required that, though incomplete on each step, still efficiently computes optimal actions in a timely manner. The Dyna architecture (Sutton 1990) provides an effective and flexible approach to incremental planning while maintaining responsiveness. There are two ideas underlying the Dyna architecture. One is that planning, acting, and learning are all continual, operating as fast as they can without waiting for each other. In practice, on conventional computers, each time step is shared between planning, acting, and learning, with proportions that can be set arbitrarily according to available resources and required response times. The second idea underlying the Dyna architecture is that learning and planning are similar in a radical sense. Planning in the Dyna architecture consists of using the model to generate imaginary experience and then processing the transitions of the imaginary experience by model-free reinforcement learning algorithms as if they had actually occurred. This can be shown, under various conditions, to produce exactly the same results as dynamic-programming methods in the limit of infinite imaginary experience. The original papers on the Dyna architecture and most subsequent extensions (e.g., Singh 1992; Peng & Williams 1993; Moore & Atkeson 1993; Kuvayev & Sutton 1996) assumed a Markov environment with a tabular representation of states. This table-lookup representation limits the applicability of the methods to relatively small problems. Reinforcement learning has been combined with function approximation to make it applicable to vastly larger problems than could be addressed with a tabular approach. The most popular form of function approximation is linear function approximation, in which states or state-action pairs are first mapped to feature vectors, which are then mapped in a linear way, with learned parameters, to value or next-state estimates. Linear methods have been used in many of the successful large-scale applications of reinforcement learning (e.g., Silver, Sutton & M\u00fcller 2007; Schaeffer, Hlynka & Jussila 2001). Linear function approximation is also simple, easy to understand, and possesses some of the strongest convergence and performance guarantees among function approximation methods. It is natural then to consider extending Dyna for use with linear function approximation, as we do in this paper. There has been little previous work addressing planning with linear function approximation in an online setting. Paduraru (2007) treated this case, focusing mainly on sampling stochastic models of a cascading linear form, but also briefly discussing deterministic linear models. Degris, Sigaud and Wuillemin (2006) developed a version of Dyna based on approximations in the form of dynamic Bayes networks and decision trees. Their system, SPITI, included online learning and planning based on an incremental version of structured value iteration (Boutilier, Dearden & Goldszmidt 2000). Singh (1992) developed a version of Dyna for variable resolution but still tabular models. Others have proposed linear least-squares methods for policy evaluation that are efficient in the amount of data used (Bradtke & Barto 1996; Boyan 1999, 2002; Geramifard, Bowling & Sutton 2006). These methods can be interpreted as forming and then planning with a linear model of the world\u2019s dynamics, but so far their extensions to the control case have not been well suited to online use (Lagoudakis & Parr 2003; Peters, Vijayakumar & Schaal 2005; Bowling, Geramifard, & Wingate 2008), whereas our linear Dyna methods are naturally adapted to this case. We discuss more specifically the relationship of our work to LSTD methods in a later section. Finally, Atkeson (1993) and others have explored linear, learned models with off-line planning methods suited to low-dimensional continuous systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Quad-networks: unsupervised learning to rank for interest point detection\nAbstract: Several machine learning tasks require to represent the data using only a sparse set of interest points. An ideal detector is able to find the corresponding interest points even if the data undergo a transformation typical for a given domain. Since the task is of high practical interest in computer vision, many hand-crafted solutions were proposed. In this paper, we ask a fundamental question: can we learn such detectors from scratch? Since it is often unclear what points are \"interesting\", human labelling cannot be used to find a truly unbiased solution. Therefore, the task requires an unsupervised formulation. We are the first to propose such a formulation: training a neural network to rank points in a transformation-invariant manner. Interest points are then extracted from the top/bottom quantiles of this ranking. We validate our approach on two tasks: standard RGB image interest point detection and challenging cross-modal interest point detection between RGB and depth images. We quantitatively show that our unsupervised method performs better or on-par with baselines.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Novel Family of Adaptive Filtering Algorithms Based on The Logarithmic Cost\nAbstract: We introduce a novel family of adaptive filtering algorithms based on a relative logarithmic cost. The new family intrinsically combines the higher and lower order measures of the error into a single continuous update based on the error amount. We introduce important members of this family of algorithms such as the least mean logarithmic square (LMLS) and least logarithmic absolute difference (LLAD) algorithms that improve the convergence performance of the conventional algorithms. However, our approach and analysis are generic such that they cover other well-known cost functions as described in the paper. The LMLS algorithm achieves comparable convergence performance with the least mean fourth (LMF) algorithm and extends the stability bound on the step size. The LLAD and least mean square (LMS) algorithms demonstrate similar convergence performance in impulse-free noise environments while the LLAD algorithm is robust against impulsive interferences and outperforms the sign algorithm (SA). We analyze the transient, steady state and tracking performance of the introduced algorithms and demonstrate the match of the theoretical analyzes and simulation results. We show the extended stability bound of the LMLS algorithm and analyze the robustness of the LLAD algorithm against impulsive interferences. Finally, we demonstrate the performance of our algorithms in different scenarios through numerical examples.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Metric Learning for Temporal Sequence Alignment\nAbstract: <lb>In this paper, we propose to learn a Mahalanobis distance to perform alignment<lb>of multivariate time series. The learning examples for this task are time series for<lb>which the true alignment is known. We cast the alignment problem as a struc-<lb>tured prediction task, and propose realistic losses between alignments for which<lb>the optimization is tractable. We provide experiments on real data in the audio to<lb>audio context, where we show that the learning of a similarity measure leads to<lb>improvements in the performance of the alignment task. We also propose to use<lb>this metric learning framework to perform feature selection and, from basic audio<lb>features, build a combination of these with better performance for the alignment.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extended Formulation for Online Learning of Combinatorial Objects\nAbstract: The convex hull of n-symbol Huffman trees is known to have exponentially many facets/constraints [17]. This makes the standard on-line learning techniques for learning Huffman trees impractical, since they use multiplicative updates followed by projections to satisfy all of the constraints. However, there are general extended formulation techniques that encode the convex hull of Huffman trees as a polytope in a higher dimensional space with only polynomially many facets. This extended formulation methodology can also be used to encode the n-element permutahedron in O(n log n) dimensions with only a polynomial number of facets. We develop a general technique for converting these extended formulations into efficient on-line algorithms with good relative loss bounds. The resulting algorithms have nearly the same regret bounds as state of the art algorithms for permutations, and are the first efficient algorithms for the on-line learning of Huffman trees.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Context-Aware Proactive Content Caching with Service Differentiation in Wireless Networks\nAbstract: Content caching in small base stations (SBSs) or wireless infostations is considered as a suitable approach to improve the efficiency in wireless content delivery. Due to storage limitations, placing the optimal content into local caches is crucial. Cache content placement is challenging since it requires knowledge about the content popularity distribution, which is often not available in advance. Moreover, content popularity is subject to fluctuations as mobile users with different interests connect to the caching entity over time. In this paper, we propose a novel algorithm for context-aware proactive cache content placement. By regularly observing context information of connected users, updating the cache content accordingly and observing the demands for cache content subsequently, the algorithm learns contextspecific content popularity online over time. We derive a sub-linear regret bound, which characterizes the learning speed and proves that our algorithm asymptotically maximizes the average number of cache hits. Furthermore, our algorithm supports service differentiation by allowing operators of caching entities to prioritize groups of customers. Our numerical results confirm that by exploiting contextual information, our algorithm outperforms state-of-the-art algorithms in a real world data set, with an increase in the number of cache hits of at least 14%.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Low-Rank Matrix Recovery from Row-and-Column Affine Measurements\nAbstract: We propose and study a row-and-column affine measurement scheme for lowrank matrix recovery. Each measurement is a linear combination of elements in one row or one column of a matrix X . This setting arises naturally in applications from different domains. However, current algorithms developed for standard matrix recovery problems do not perform well in our case, hence the need for developing new algorithms and theory for our problem. We propose a simple algorithm for the problem based on Singular Value Decomposition (SV D) and least-squares (LS), which we term SVLS . We prove that (a simplified version of) our algorithm can recover X exactly with the minimum possible number of measurements in the noiseless case. In the general noisy case, we prove performance guarantees on the reconstruction accuracy under the Frobenius norm. In simulations, our row-andcolumn design and SVLS algorithm show improved speed, and comparable and in some cases better accuracy compared to standard measurements designs and algorithms. Our theoretical and experimental results suggest that the proposed rowand-column affine measurements scheme, together with our recovery algorithm, may provide a powerful framework for affine matrix reconstruction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Robust Dictionary Learning Algorithm for Image Denoising\nAbstract: In many image processing applications, we encounter the problem of suppressing noise that obeys a nonGaussian statistics. It is well known in the signal processing community that, in case of heavy-tailed non-Gaussian noise corruption, `1 distortion is a more suitable metric for data fidelity. Dictionary based image denoising algorithms existing in the literature are typically aimed at minimizing the `2 distortion metric, and hence not suitable for suppressing non-Gaussian or impulsive noise. In this paper, we develop a dictionary learning algorithm by minimizing the `1 error. The proposed algorithm exploits the idea of iterative minimization of suitably weighted `2 error. We refer to this algorithm as robust dictionary learning (RDL). We demonstrate that the proposed algorithm results in higher atom detection rate compared to the state-of-the-art KSVD algorithm, both in case of Gaussian and non-Gaussian noise contamination. For real images, we observe clear superiority of the proposed RDL algorithm over its `2 based counterpart, namely the K-SVD algorithm, in terms of the quality of denoised output.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sparse stochastic inference for latent Dirichlet allocation\nAbstract: We present a hybrid algorithm for Bayesian topic models that combines the efficiency of sparse Gibbs sampling with the scalability of online stochastic inference. We used our algorithm to analyze a corpus of 1.2 million books (33 billion words) with thousands of topics. Our approach reduces the bias of variational inference and generalizes to many Bayesian hidden-variable models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Concentration in unbounded metric spaces and algorithmic stability\nAbstract: We prove an extension of McDiarmid\u2019s inequality for metric spaces with unbounded diameter. To this end, we introduce the notion of the subgaussian diameter, which is a distribution-dependent refinement of the metric diameter. Our technique provides an alternative approach to that of Kutin and Niyogi\u2019s method of weakly difference-bounded functions, and yields nontrivial, dimension-free results in some interesting cases where the former does not. As an application, we give apparently the first generalization bound in the algorithmic stability setting that holds for unbounded loss functions. We give two extensions of the basic concentration result: to strongly mixing processes and to other Orlicz norms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Unified Algorithmic Framework for Multi-Dimensional Scaling\nAbstract: In this paper, we propose a unified algorithmic framework for solving many known variants of MDS. Our algorithm is a simple iterative scheme with guaranteed convergence, and is modular; by changing the internals of a single subroutine in the algorithm, we can switch cost functions and target spaces easily. In addition to the formal guarantees of convergence, our algorithms are accurate; in most cases, they converge to better quality solutions than existing methods, in comparable time. We expect that this framework will be useful for a number of MDS variants that have not yet been studied. Our framework extends to embedding high-dimensional points lying on a sphere to points on a lower dimensional sphere, preserving geodesic distances. As a compliment to this result, we also extend the JohnsonLindenstrauss Lemma to this spherical setting, where projecting to a random O((1/\"2) log n)-dimensional sphere causes \"-distortion.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Unsupervised methods for learning distributed representations of words are ubiquitous in today\u2019s NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Evolution of active categorical image classification via saccadic eye movement\nAbstract: Pattern recognition and classification is a central concern for modern information processing systems. In particular, one key challenge to image and video classification has been that the computational cost of image processing scales linearly with the number of pixels in the image or video. Here we present an intelligent machine (the \u201cactive categorical classifier,\u201d or ACC) that is inspired by the saccadic movements of the eye, and is capable of classifying images by selectively scanning only a portion of the image. We harness evolutionary computation to optimize the ACC on the MNIST hand-written digit classification task, and provide a proof-of-concept that the ACC works on noisy multi-class data. We further analyze the ACC and demonstrate its ability to classify images after viewing only a fraction of the pixels, and provide insight on future research paths to further improve upon the ACC presented here.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Graphical Model Parameters with Approximate Marginal Inference\nAbstract: Likelihood based-learning of graphical models faces challenges of computational-complexity and robustness to model misspecification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Recent work has shown that deep neural networks are capable of approximating both value functions and policies in reinforcement learning domains featuring continuous state and action spaces. However, to the best of our knowledge no previous work has succeeded at using deep neural networks in structured (parameterized) continuous action spaces. To fill this gap, this paper focuses on learning within the domain of simulated RoboCup soccer, which features a small set of discrete action types, each of which is parameterized with continuous variables. The best learned agent can score goals more reliably than the 2012 RoboCup champion agent. As such, this paper represents a successful extension of deep reinforcement learning to the class of parameterized action space MDPs.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Clinical Intervention Prediction and Understanding using Deep Networks\nAbstract: Real-time prediction of clinical interventions remains a challenge within intensive care units (ICUs). This task is complicated by data sources that are noisy, sparse, heterogeneous and outcomes that are imbalanced. In this paper, we integrate data from all available ICU sources (vitals, labs, notes, demographics) and focus on learning rich representations of this data to predict onset and weaning of multiple invasive interventions. In particular, we compare both long short-term memory networks (LSTM) and convolutional neural networks (CNN) for prediction of five intervention tasks: invasive ventilation, non-invasive ventilation, vasopressors, colloid boluses, and crystalloid boluses. Our predictions are done in a forward-facing manner to enable \u201creal-time\u201d performance, and predictions are made with a six hour gap time to support clinically actionable planning. We achieve state-of-the-art results on our predictive tasks using deep architectures. We explore the use of feature occlusion to interpret LSTM models, and compare this to the interpretability gained from examining inputs that maximally activate CNN outputs. We show that our models are able to significantly outperform baselines in intervention prediction, and provide insight into model learning, which is crucial for the adoption of such models in practice.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Introspective Classifier Learning: Empower Generatively\nAbstract: In this paper we propose introspective classifier learning (ICL) that emphasizes the importance of having a discriminative classifier empowered with generative capabilities. We develop a reclassification-by-synthesis algorithm to perform training using a formulation stemmed from the Bayes theory. Our classifier is able to iteratively: (1) synthesize pseudo-negative samples in the synthesis step; and (2) enhance itself by improving the classification in the reclassification step. The single classifier learned is at the same time generative \u2014 being able to directly synthesize new samples within its own discriminative model. We conduct experiments on standard benchmark datasets including MNIST, CIFAR, and SVHN using state-of-the-art CNN architectures, and observe improved classification results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Higher-Order Factorization Machines\nAbstract: Factorization machines (FMs) are a supervised learning approach that can use<lb>second-order feature combinations even when the data is very high-dimensional.<lb>Unfortunately, despite increasing interest in FMs, there exists to date no efficient<lb>training algorithm for higher-order FMs (HOFMs). In this paper, we present<lb>the first generic yet efficient algorithms for training arbitrary-order HOFMs. We<lb>also present new variants of HOFMs with shared parameters, which greatly re-<lb>duce model size and prediction times while maintaining similar accuracy. We<lb>demonstrate the proposed approaches on four different link prediction tasks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DEEPLY SUPERVISED SIAMESE NETWORK\nAbstract: In this paper, we propose a new text recognition model based on measuring the visual similarity of text and predicting the content of the unlabeled texts. First a Siamese network is trained with deep supervision on a labeled training dataset. This network projects texts into a similarity manifold. The Deeply Supervised Siamese network learns visual similarity of texts. Then a K-nearest neighbor classifier is used to predict unlabeled text based on similarity distance to labeled texts. The performance of the model is evaluated on three datasets of machine-print and hand-written text combined. We demonstrate that the model reduces the cost of human estimation by 50%\u2212 85%. The error of the system is less than 0.1%. The results also demonstrate that the predicted labels are sometimes better than human labels e.g. spelling correction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Streaming Algorithms for Pattern Discovery over Dynamically Changing Event Sequences\nAbstract: Discovering frequent episodes over event sequences is an important data mining task. In many applications, events constituting the data sequence arrive as a stream, at furious rates, and recent trends (or frequent episodes) can change and drift due to the dynamical nature of the underlying event generation process. The ability to detect and track such the changing sets of frequent episodes can be valuable in many application scenarios. Current methods for frequent episode discovery are typically multipass algorithms, making them unsuitable in the streaming context. In this paper, we propose a new streaming algorithm for discovering frequent episodes over a window of recent events in the stream. Our algorithm processes events as they arrive, one batch at a time, while discovering the top frequent episodes over a window consisting of several batches in the immediate past. We derive approximation guarantees for our algorithm under the condition that frequent episodes are approximately well-separated from infrequent ones in every batch of the window. We present extensive experimental evaluations of our algorithm on both real and synthetic data. We also present empirical comparisons with baselines and adaptations of streaming algorithms from itemset mining literature.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Kernelized Multi-armed Bandits\nAbstract: We consider the stochastic bandit problem with a continuous set of arms, with the expected reward function over the arms assumed to be fixed but unknown. We provide two new Gaussian process-based algorithms for continuous bandit optimization \u2013 Improved GP-UCB (IGP-UCB) and GP-Thomson sampling (GP-TS), and derive corresponding regret bounds. Specifically, the bounds hold when the expected reward function belongs to the reproducing kernel Hilbert space (RKHS) that naturally corresponds to a Gaussian process kernel used as input by the algorithms. Along the way, we derive a new self-normalized concentration inequality for vectorvalued martingales of arbitrary, possibly infinite, dimension. Finally, experimental evaluation and comparisons to existing algorithms on synthetic and real-world environments are carried out that highlight the favorable gains of the proposed strategies in many cases.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Clustering Signed Networks with the Geometric Mean of Laplacians\nAbstract: Signed networks allow to model positive and negative relationships. We analyze existing extensions of spectral clustering to signed networks. It turns out that existing approaches do not recover the ground truth clustering in several situations where either the positive or the negative network structures contain no noise. Our analysis shows that these problems arise as existing approaches take some form of arithmetic mean of the Laplacians of the positive and negative part. As a solution we propose to use the geometric mean of the Laplacians of positive and negative part and show that it outperforms the existing approaches. While the geometric mean of matrices is computationally expensive, we show that eigenvectors of the geometric mean can be computed efficiently, leading to a numerical scheme for sparse matrices which is of independent interest.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting Singleton Review Spammers Using Semantic Similarity\nAbstract: Online reviews have increasingly become a very important resource for consumers when making purchases. Though it is becoming more and more difficult for people to make wellinformed buying decisions without being deceived by fake reviews. Prior works on the opinion spam problem mostly considered classifying fake reviews using behavioral user patterns. They focused on prolific users who write more than a couple of reviews, discarding one-time reviewers. The number of singleton reviewers however is expected to be high for many review websites. While behavioral patterns are effective when dealing with elite users, for one-time reviewers, the review text needs to be exploited. In this paper we tackle the problem of detecting fake reviews written by the same person using multiple names, posting each review under a different name. We propose two methods to detect similar reviews and show the results generally outperform the vectorial similarity measures used in prior works. The first method extends the semantic similarity between words to the reviews level. The second method is based on topic modeling and exploits the similarity of the reviews topic distributions using two models: bag-of-words and bag-of-opinionphrases. The experiments were conducted on reviews from three different datasets: Yelp (57K reviews), Trustpilot (9K reviews) and Ott dataset (800 reviews).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Exploration: Incentivizing Exploration in Bayesian Games\nAbstract: We consider a ubiquitous scenario in the Internet economywhen individual decision-makers (henceforth, agents) both produce and consume information as they make strategic choices in an uncertain environment. This creates a three-way tradeoff between exploration (trying out insufficiently explored alternatives to help others in the future), exploitation (making optimal decisions given the information discovered by other agents), and incentives of the agents (who are myopically interested in exploitation, while preferring the others to explore). We posit a principal who controls the flow of information from agents that came before to the ones that arrive later, and strives to coordinate the agents towards a socially optimal balance between exploration and exploitation, not using any monetary transfers. The goal is to design a recommendation policy for the principal which respects agents\u2019 incentives and minimizes a suitable notion of regret. We extend prior work in this direction to allow the agents to interact with one another in a shared environment: at each time step, multiple agents arrive to play a Bayesian game, receive recommendations, choose their actions, receive their payoffs, and then leave the game forever. The agents now face two sources of uncertainty: the actions of the other agents and the parameters of the uncertain game environment. Our main contribution is to show that the principal can achieve constant regret when the utilities are deterministic (where the constant depends on the prior distribution, but not on the time horizon), and logarithmic regret when the utilities are stochastic. As a key technical tool, we introduce the concept of explorable actions, the actions which some incentive-compatible policy can recommend with non-zero probability. We show how the principal can identify (and explore) all explorable actions, and use the revealed information to perform optimally. In particular, our results significantly improve over the prior work on the special case of a single agent per round, which relies on assumptions to guarantee that all actions are explorable. Interestingly, we do not require the principal\u2019s utility to be aligned with the cumulative utility of the agents; instead, the principal can optimize an arbitrary notion of per-round reward. \u2217Microsoft Research and Tel Aviv University. mansour@microsoft.com \u2020Microsoft Research, New York, NY, USA. slivkins@microsoft.com \u2021Microsoft Research, New York, NY, USA. vasy@microsoft.com \u00a7University of Pennsylvania, Philadelphia, PA, USA. wuzhiwei@cis.upenn.edu\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper introduces a principled approach for the design of a scalable general reinforcement learning agent. This approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general reinforcement learning agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a Monte Carlo Tree Search algorithm along with an agent-specific extension of the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a number of stochastic, unknown, and partially observable domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating News Headlines with Recurrent Neural Networks\nAbstract: We describe an application of an encoder-decoder recurrent neural network with LSTM units and attention to generating headlines from the text of news articles. We find that the model is quite effective at concisely paraphrasing news articles. Furthermore, we study how the neural network decides which input words to pay attention to, and specifically we identify the function of the different neurons in a simplified attention mechanism. Interestingly, our simplified attention mechanism performs better that the more complex attention mechanism on a held out set of articles.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Variational Inference in Non-negative Factorial Hidden Markov Models for Efficient Audio Source Separation\nAbstract: The past decade has seen substantial work on the use of non-negative matrix factorization and its probabilistic counterparts for audio source separation. Although able to capture audio spectral structure well, these models neglect the non-stationarity and temporal dynamics that are important properties of audio. The recently proposed non-negative factorial hidden Markov model (N-FHMM) introduces a temporal dimension and improves source separation performance. However, the factorial nature of this model makes the complexity of inference exponential in the number of sound sources. Here, we present a Bayesian variant of the N-FHMM suited to an efficient variational inference algorithm, whose complexity is linear in the number of sound sources. Our algorithm performs comparably to exact inference in the original NFHMM but is significantly faster. In typical configurations of the N-FHMM, our method achieves around a 30x increase in speed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extractive Summarization using Deep Learning\nAbstract: This paper proposes a text summarization approach for factual reports using a deep learning model. This approach consists of three phases: feature extraction, feature enhancement, and summary generation, which work together to assimilate core information and generate a coherent, understandable summary. We are exploring various features to improve the set of sentences selected for the summary, and are using a Restricted Boltzmann Machine to enhance and abstract those features to improve resultant accuracy without losing any important information. The sentences are scored based on those enhanced features and an extractive summary is constructed. Experimentation carried out on several articles demonstrates the effectiveness of the proposed approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Graph Regularized Low Rank Representation for Aerosol Optical Depth Retrieval\nAbstract: In this paper, we propose a novel data-driven regression model for aerosol optical depth (AOD) retrieval. First, we adopt a low rank representation (LRR) model to learn a powerful representation of the spectral response. Then, graph regularization is incorporated into the LRR model to capture the local structure information and the nonlinear property of the remote-sensing data. Since it is easy to acquire the rich satellite-retrieval results, we use them as a baseline to construct the graph. Finally, the learned feature representation is feeded into support vector machine (SVM) to retrieve AOD. Experiments are conducted on two widely used data sets acquired by different sensors, and the experimental results show that the proposed method can achieve superior performance compared to the physical models and other state-of-the-art empirical models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Relative Exponential Weighing Algorithm for Adversarial Utility-based Dueling Bandits (extended version)\nAbstract: We study the K-armed dueling bandit problem which is a variation of the classical Multi-Armed Bandit (MAB) problem in which the learner receives only relative feedback about the selected pairs of arms. We propose an efficient algorithm called Relative Exponential-weight algorithm for Exploration and Exploitation (REX3) to handle the adversarial utility-based formulation of this problem. We prove a finite time expected regret upper bound of order O( \u221a K ln(K)T ) for this algorithm and a general lower bound of order \u03a9( \u221a KT ). At the end, we provide experimental results using real data from information retrieval applications.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Yeah, Right, Uh-Huh: A Deep Learning Backchannel Predictor\nAbstract: Using supporting backchannel (BC) cues can make human-computer interaction more social. BCs provide a feedback from the listener to the speaker indicating to the speaker that he is still listened to. BCs can be expressed in different ways, depending on the modality of the interaction, for example as gestures or acoustic cues. In this work, we only considered acoustic cues. We are proposing an approach towards detecting BC opportunities based on acoustic input features like power and pitch. While other works in the field rely on the use of a hand-written rule set or specialized features, we made use of artificial neural networks. They are capable of deriving higher order features from input features themselves. In our setup, we first used a fully connected feed-forward network to establish an updated baseline in comparison to our previously proposed setup. We also extended this setup by the use of Long Short-Term Memory (LSTM) networks which have shown to outperform feed-forward based setups on various tasks. Our best system achieved an F1-Score of 0.37 using power and pitch features. Adding linguistic information using word2vec, the score increased to 0.39.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Layer-Specific Adaptive Learning Rates for Deep Networks\nAbstract: The increasing complexity of deep learning architectures is resulting in training time requiring weeks or even months. This slow training is due in part to \u201cvanishing gradients,\u201d in which the gradients used by back-propagation are extremely large for weights connecting deep layers (layers near the output layer), and extremely small for shallow layers (near the input layer); this results in slow learning in the shallow layers. Additionally, it has also been shown that in highly non-convex problems, such as deep neural networks, there is a proliferation of high-error low curvature saddle points, which slows down learning dramatically [1]. In this paper, we attempt to overcome the two above problems by proposing an optimization method for training deep neural networks which uses learning rates which are both specific to each layer in the network and adaptive to the curvature of the function, increasing the learning rate at low curvature points. This enables us to speed up learning in the shallow layers of the network and quickly escape high-error low curvature saddle points. We test our method on standard image classification datasets such as MNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracy as well as reduces the required training time over standard algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sparse projections onto the simplex\nAbstract: The past decade has seen the rise of `1-relaxation methods to promote sparsity for better interpretability and generalization of learning results. However, there are several important learning applications, such as Markowitz portolio selection and sparse mixture density estimation, that feature simplex constraints, which disallow the application of the standard `1-penalty. In this setting, we show how to efficiently obtain sparse projections onto the positive and general simplex with sparsity constraints. We provide an exact sparse projector for the positive simplex constraints, and derive a novel approach with online optimality and approximation guarantees for sparse projections onto the general simplex constraints. Even for small sized problems, this new approach is three orders of magnitude faster than the alternative, state-of-the-art branch-and-bound based CPLEX solver with no sacrifice in solution quality. We also empirically demonstrate that our projectors provide substantial benefits in portfolio selection and density estimation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LPQP for MAP: Putting LP Solvers to Better Use\nAbstract: MAP inference for general energy functions remains a challenging problem. While most efforts are channeled towards improving the linear programming (LP) based relaxation, this work is motivated by the quadratic programming (QP) relaxation. We propose a novel MAP relaxation that penalizes the Kullback-Leibler divergence between the LP pairwise auxiliary variables, and QP equivalent terms given by the product of the unaries. We develop two efficient algorithms based on variants of this relaxation. The algorithms minimize the non-convex objective using belief propagation and dual decomposition as building blocks. Experiments on synthetic and real-world data show that the solutions returned by our algorithms substantially improve over the LP relaxation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Infinite-Label Learning with Semantic Output Codes\nAbstract: We develop a new statistical machine learning paradigm, named infinite-label learning, to annotate a data point with more than one relevant labels from a candidate set, which pools both the finite labels observed at training and a potentially infinite number of previously unseen labels. The infinite-label learning fundamentally expands the scope of conventional multi-label learning, and better models the practical requirements in various real-world applications, such as image tagging, ads-query association, and article categorization. However, how can we learn a labeling function that is capable of assigning to a data point the labels omitted from the training set? To answer the question, we seek some clues from the recent work on zero-shot learning, where the key is to represent a class/label by a vector of semantic codes, as opposed to treating them as atomic labels. We validate the infinite-label learning by a PAC bound in theory and some empirical studies on both synthetic and real data. 1 ar X iv :1 60 8. 06 60 8v 1 [ cs .L G ] 2 3 A ug 2 01 6\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This work explores hypernetworks: an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype \u2013 the hypernetwork \u2013 and a phenotype \u2013 the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-art results on a variety of language modeling tasks with Character-Level Penn Treebank and Hutter Prize Wikipedia datasets, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Integrating Deep Features for Material Recognition\nAbstract: This paper considers the problem of material recognition. Motivated by an observation that there is close interconnection between material recognition and object recognition, we study how to select and integrate multiple features obtained by different models of Convolutional Neural Networks (CNNs) trained in a transfer learning setting. To be specific, we first compute activations of features using representations on images to select a set of samples which are best represented by the features. Then, we measure uncertainty of the features by computing entropy of class distributions for each sample set. Finally, we compute contribution of each feature to representation of classes for feature selection and integration. Experimental results show that the proposed method achieves state-of-the-art performance on two benchmark datasets for material recognition. Additionally, we introduce a new material dataset, named EFMD, which extends Flickr Material Database (FMD). By the employment of the EFMD for transfer learning, we achieve 84.0%\u00b1 1.8% accuracy on the FMD dataset, which is close to reported human performance 84.9%.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Cost-Sensitive Tree of Classifiers\nAbstract: Recently, machine learning algorithms have successfully entered large-scale real-world industrial applications (e.g. search engines and email spam filters). Here, the CPU cost during test-time must be budgeted and accounted for. In this paper, we address the challenge of balancing the test-time cost and the classifier accuracy in a principled fashion. The test-time cost of a classifier is often dominated by the computation required for feature extraction\u2014which can vary drastically across features. We decrease this extraction time by constructing a tree of classifiers, through which test inputs traverse along individual paths. Each path extracts different features and is optimized for a specific subpartition of the input space. By only computing features for inputs that benefit from them the most, our cost-sensitive tree of classifiers can match the high accuracies of the current state-of-the-art at a small fraction of the computational cost.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Zero-Shot Learning and Clustering for Semantic Utterance Classification\nAbstract: We propose two novel zero-shot learning methods for semantic utterance classification (SUC) using deep learning. Both approaches rely on learning deep semantic embeddings from a large amount of Query Click Log data obtained from a search engine. Traditional semantic utterance classification systems require large amounts of labelled data, whereas our proposed methods make use of the structure of the task to allow classification without labeled data. We also develop a zero-shot semantic clustering algorithm for extracting discriminative features for supervised semantic utterance classification systems. We demonstrate the effectiveness of the zero-shot semantic learning algorithm on the SUC dataset collected by [1]. Furthermore, we show that extracting features using zero-shot semantic clustering for a linear SVM reaches state-of-the-art result on that dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Experimental Study of LSTM Encoder-Decoder Model for Text Simplification\nAbstract: Text simplification (TS) aims to reduce the lexical and structural complexity of a text, while still retaining the semantic meaning. Current automatic TS techniques are limited to either lexical-level applications or manually defining a large amount of rules. Since deep neural networks are powerful models that have achieved excellent performance over many difficult tasks, in this paper, we propose to use the Long Short-Term Memory (LSTM) Encoder-Decoder model for sentence level TS, which makes minimal assumptions about word sequence. We conduct preliminary experiments to find that the model is able to learn operation rules such as reversing, sorting and replacing from sequence pairs, which shows that the model may potentially discover and apply rules such as modifying sentence structure, substituting words, and removing words for TS.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Interpretable Structure-Evolving LSTM\nAbstract: This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Modelling Student Behavior using Granular Large Scale Action Data from a MOOC\nAbstract: Digital learning environments generate a precise record of the actions learners take as they interact with learning materials and complete exercises towards comprehension. With this high quantity of sequential data comes the potential to apply time series models to learn about underlying behavioral patterns and trends that characterize successful learning based on the granular record of student actions. There exist several methods for looking at longitudinal, sequential data like those recorded from learning environments. In the field of language modelling, traditional n-gram techniques and modern recurrent neural network (RNN) approaches have been applied to algorithmically find structure in language and predict the next word given the previous words in the sentence or paragraph as input. In this paper, we draw an analogy to this work by treating student sequences of resource views and interactions in a MOOC as the inputs and predicting students\u2019 next interaction as outputs. In this study, we train only on students who received a certificate of completion. In doing so, the model could potentially be used for recommendation of sequences eventually leading to success, as opposed to perpetuating unproductive behavior. Given that the MOOC used in our study had over 3,500 unique resources, predicting the exact resource that a student will interact with next might appear to be a difficult classification problem. We find that simply following the syllabus (built-in structure of the course) gives on average 23% accuracy in making this prediction, followed by the n-gram method with 70.4%, and RNN based methods with 72.2%. This research lays the ground work for recommendation in a MOOC and other digital learning environments where high volumes of sequential data exist. 1 ar X iv :1 60 8. 04 78 9v 1 [ cs .C Y ] 1 6 A ug 2 01 6\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Parallel and Distributed Approaches for Graph Based Semi-supervised Learning\nAbstract: Two approaches for graph based semi-supervised learning are proposed. The first approach is based on iteration of an affine map. A key element of the affine map iteration is sparse matrix-vector multiplication, which has several very efficient parallel implementations. The second approach belongs to the class of Markov Chain Monte Carlo (MCMC) algorithms. It is based on sampling of nodes by performing a random walk on the graph. The latter approach is distributed by its nature and can be easily implemented on several processors or over the network. Both theoretical and practical evaluations are provided. It is found that the nodes are classified into their class with very small error. The sampling algorithm\u2019s ability to track new incoming nodes and to classify them is also demonstrated. Key-words: Semi-supervised learning, Graph-based learning, Distributed algorithms, Parallel algorithms \u2217 K. Avrachenkov is with Inria Sophia Antipolis, France, k.avrachenkov@inria.fr \u2020 V.S. Borkar is with Department of Electrical Engineering, IIT Bombay, India, borkar.vs@gmail.com \u2021 K. Saboo is with Department of Electrical Engineering, IIT Bombay, India, kvsaboo.2004@ee.iitb.ac.in \u00a7 The work of KA and VSB was supported in part by grant no. 5100-ITA from the Indo-French Centre for the Promotion of Advanced Research (IFCPAR) and Alcatel-Lucent Inria Joint Lab. Les Approches Parall\u00e8les et Distribu\u00e9s pour l\u2019Apprentissage Semi-supervis\u00e9 R\u00e9sum\u00e9 : Deux approches pour l\u2019apprentissage semi-supervis\u00e9 bas\u00e9 sur le graphe de similarit\u00e9 sont propos\u00e9s. La premi\u00e8re approche est bas\u00e9e sur l\u2019it\u00e9ration d\u2019un op\u00e9rateur affine. Un \u00e9l\u00e9ment cl\u00e9 de l\u2019it\u00e9ration de l\u2019op\u00e9rateur affine est la multiplication vecteur par matrice de type sparse, qui a plusieurs impl\u00e9mentations parall\u00e8les tr\u00e8s efficaces. La seconde approche appartient \u00e0 la classe des algorithmes de Monte-Carlo par cha\u00eenes de Markov (MCMC). Elle est bas\u00e9 sur un \u00e9chantillonnage de noeuds en effectuant une marche al\u00e9atoire sur le graphe de similarit\u00e9. Cette derni\u00e8re approche est distribu\u00e9 par sa nature et peut \u00eatre facilement mis en oeuvre sur plusieurs processeurs ou sur un r\u00e9seau. \u00c9valuations th\u00e9oriques ainsi que pratiques sont fournis. On constate que les noeuds sont class\u00e9s dans leurs classes avec tr\u00e8s petite erreur. La capacit\u00e9 de l\u2019algorithme MCMC de suivre les nouveaux noeuds arrivants online et de les classer est \u00e9galement d\u00e9montr\u00e9. Mots-cl\u00e9s : Apprentissage semi-supervis\u00e9, Apprentissage bas\u00e9 sur le graphe de similarit\u00e9, Algorithmes distribu\u00e9s, Algorithmes parall\u00e8les Distributed Semi-supervised Learning 3\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A hybrid solution to improve iteration efficiency in the distributed learning\nAbstract: Currently, many machine learning algorithms contain lots of iterations. When it comes to existing large-scale distributed systems, some slave nodes may break down or have lower efficiency. Therefore traditional machine learning algorithm may fail because of the instability of distributed system.We presents a hybrid approach which not only own a high fault-tolerant but also achieve a balance of performance and efficiency.For each iteration, the result of slow machines will be abandoned. First, we discuss the relationship between accuracy and abandon rate. Then we debate the convergence speed of this process. Finally, our experiments demonstrate our idea can dramatically reduce calculation time and be used in many platforms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Models of Data Streams with Hierarchical Power Priors\nAbstract: Making inferences from data streams is a pervasive problem in many modern data analysis applications. But it requires to address the problem of continuous model updating, and adapt to changes or drifts in the underlying data generating distribution. In this paper, we approach these problems from a Bayesian perspective covering general conjugate exponential models. Our proposal makes use of non-conjugate hierarchical priors to explicitly model temporal changes of the model parameters. We also derive a novel variational inference scheme which overcomes the use of non-conjugate priors while maintaining the computational efficiency of variational methods over conjugate models. The approach is validated on three real data sets over three latent variable models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Structural Kernels for Natural Language Processing\nAbstract: Structural kernels are a flexible learning paradigm that has been widely used in Natural Language Processing. However, the problem of model selection in kernel-based methods is usually overlooked. Previous approaches mostly rely on setting default values for kernel hyperparameters or using grid search, which is slow and coarse-grained. In contrast, Bayesian methods allow efficient model selection by maximizing the evidence on the training data through gradient-based methods. In this paper we show how to perform this in the context of structural kernels by using Gaussian Processes. Experimental results on tree kernels show that this procedure results in better prediction performance compared to hyperparameter optimization via grid search. The framework proposed in this paper can be adapted to other structures besides trees, e.g., strings and graphs, thereby extending the utility of kernel-based methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Parallel SVM using Data Augmentation\nAbstract: As one of the most popular classifiers, linear SVMs still have challenges in dealing with very large-scale problems, even though linear or sub-linear algorithms have been developed recently on single machines. Parallel computing methods have been developed for learning large-scale SVMs. However, existing methods rely on solving local sub-optimization problems. In this paper, we develop a novel parallel algorithm for learning large-scale linear SVM. Our approach is based on a data augmentation equivalent formulation, which casts the problem of learning SVM as a Bayesian inference problem, for which we can develop very efficient parallel sampling methods. We provide empirical results for this parallel sampling SVM, and provide extensions for SVR, nonlinear kernels, and provide a parallel implementation of the Crammer and Singer model. This approach is very promising in its own right, and further is a very useful technique to parallelize a broader family of general maximum-margin models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Secure Multi-Party Computation Based Privacy Preserving Extreme Learning Machine Algorithm Over Vertically Distributed Data\nAbstract: Especially in the Big Data era, the usage of different classification methods is increasing day by day. The success of these classification methods depends on the effectiveness of learning methods. Extreme learning machine (ELM) classification algorithm is a relatively new learning method built on feed-forward neural-network. ELM classification algorithm is a simple and fast method that can create a model from high-dimensional data sets. Traditional ELM learning algorithm implicitly assumes complete access to whole data set. This is a major privacy concern in most of cases. Sharing of private data (i.e. medical records) is prevented because of security concerns. In this research, we propose an efficient and secure privacy-preserving learning algorithm for ELM classification over data that is vertically partitioned among several parties. The new learning method preserves the privacy on numerical attributes, builds a classification model without sharing private data without disclosing the data of each party to others.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Given a multi-armed bandit problem it may be desirable to achieve a smaller-than-usual worst-case regret for some special actions. I show that the price for such unbalanced worst-case regret guarantees is rather high. Specifically, if an algorithm enjoys a worst-case regret of B with respect to some action, then there must exist another action for which the worst-case regret is at least \u03a9(nK/B), where n is the horizon and K the number of actions. I also give upper bounds in both the stochastic and adversarial settings showing that this result cannot be improved. For the stochastic case the pareto regret frontier is characterised exactly up to constant factors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Multiplicative Integration with Recurrent Neural Networks\nAbstract: We introduce a general and simple structural design called \u201cMultiplicative Integration\u201d (MI) to improve recurrent neural networks (RNNs). MI changes the way in which information from difference sources flows and is integrated in the computational building block of an RNN, while introducing almost no extra parameters. The new structure can be easily embedded into many popular RNN models, including LSTMs and GRUs. We empirically analyze its learning behaviour and conduct evaluations on several tasks using different RNN models. Our experimental results demonstrate that Multiplicative Integration can provide a substantial performance boost over many of the existing RNN models.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning computationally efficient dictionaries and their implementation as fast transforms\nAbstract: Dictionary learning is a branch of signal processing and machine learning that aims at finding a frame (called dictionary) in which some training data admits a sparse representation. The sparser the representation, the better the dictionary. The resulting dictionary is in general a dense matrix, and its manipulation can be computationally costly both at the learning stage and later in the usage of this dictionary, for tasks such as sparse coding. Dictionary learning is thus limited to relatively small-scale problems. In this paper, inspired by usual fast transforms, we consider a general dictionary structure that allows cheaper manipulation, and propose an algorithm to learn such dictionaries \u2013and their fast implementation\u2013 over training data. The approach is demonstrated experimentally with the factorization of the Hadamard matrix and with synthetic dictionary learning experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Content Modeling Using Latent Permutations\nAbstract: We present a novel Bayesian topic model for learning discourse-level document structure. Our model leverages insights from discourse theory to constrain latent topic assignments in a way that reflects the underlying organization of document topics. We propose a global model in which both topic selection and ordering are biased to be similar across a collection of related documents. We show that this space of orderings can be effectively represented using a distribution over permutations called the Generalized Mallows Model. We apply our method to three complementary discourse-level tasks: cross-document alignment, document segmentation, and information ordering. Our experiments show that incorporating our permutation-based model in these applications yields substantial improvements in performance over previously proposed methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Spectral Theory of Unsigned and Signed Graphs Applications to Graph Clustering: a Survey\nAbstract: This is a survey of the method of graph cuts and its applications to graph clustering of weighted unsigned and signed graphs. I provide a fairly thorough treatment of the method of normalized graph cuts, a deeply original method due to Shi and Malik, including complete proofs. I also cover briefly the method of ratio cuts, and show how it can be viewed as a special case of normalized cuts. I include the necessary background on graphs and graph Laplacians. I then explain in detail how the eigenvectors of the graph Laplacian can be used to draw a graph. This is an attractive application of graph Laplacians. The main thrust of this paper is the method of normalized cuts. I give a detailed account for K = 2 clusters, and also for K > 2 clusters, based on the work of Yu and Shi. I also show how both graph drawing and normalized cut K-clustering can be easily generalized to handle signed graphs, which are weighted graphs in which the weight matrix W may have negative coefficients. Intuitively, negative coefficients indicate distance or dissimilarity. The solution is to replace the degree matrix D by the matrix D in which absolute values of the weights are used, and to replace the Laplacian L = D \u2212W by the signed Laplacian L = D \u2212W . The signed Laplacian L is always positive semidefinite, and it may be positive definite (for unbalanced graphs, see Chapter 5). As far as I know, the generalization of K-way normalized clustering to signed graphs is new. Finally, I show how the method of ratio cuts, in which a cut is normalized by the size of the cluster rather than its volume, is just a special case of normalized cuts. All that needs to be done is to replace the normalized Laplacian Lsym by the unormalized Laplacian L. This is also true for signed graphs (where we replace Lsym by L). Three points that do not appear to have been clearly articulated before are elaborated: 1. The solutions of the main optimization problem should be viewed as tuples in the K-fold cartesian product of projective space RPN\u22121. 2. When K > 2, the solutions of the relaxed problem should be viewed as elements of the Grassmannian G(K,N). 3. Two possible Riemannian distances are available to compare the closeness of solutions: (a) The distance on (RPN\u22121)K . (b) The distance on the Grassmannian. I also clarify what should be the necessary and sufficient conditions for a matrix to represent a partition of the vertices of a graph to be clustered.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: PixelNet: Representation of the pixels, by the pixels, and for the pixels\nAbstract: We explore design principles for general pixel-level prediction problems, from low-level edge detection to midlevel surface normal estimation to high-level semantic segmentation. Convolutional predictors, such as the fullyconvolutional network (FCN), have achieved remarkable success by exploiting the spatial redundancy of neighboring pixels through convolutional processing. Though computationally efficient, we point out that such approaches are not statistically efficient during learning precisely because spatial redundancy limits the information learned from neighboring pixels. We demonstrate that stratified sampling of pixels allows one to (1) add diversity during batch updates, speeding up learning; (2) explore complex nonlinear predictors, improving accuracy; and (3) efficiently train state-of-the-art models tabula rasa (i.e., \u201cfrom scratch\u201d) for diverse pixel-labeling tasks. Our single architecture produces state-of-the-art results for semantic segmentation on PASCAL-Context dataset, surface normal estimation on NYUDv2 depth dataset, and edge detection on BSDS.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We present a new algorithm for general reinforcement learning where the true environment is known to belong to a finite class of N arbitrary models. The algorithm is shown to be near-optimal for all but O(N log N) time-steps with high probability. Infinite classes are also considered where we show that compactness is a key criterion for determining the existence of uniform sample-complexity bounds. A matching lower bound is given for the finite case.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Lean From Thy Neighbor: Stochastic & Adversarial Bandits in a Network\nAbstract: An individual\u2019s decisions are often guided by those of his or her peers, i.e., neighbors in a social network. Presumably, being privy to the experiences of others aids in learning and decision making, but how much advantage does an individual gain by observing her neighbors? Such problems make appearances in sociology and economics and, in this paper, we present a novel model to capture such decision-making processes and appeal to the classical multi-armed bandit framework to analyze it. Each individual, in addition to her own actions, can observe the actions and rewards obtained by her neighbors, and can use all of this information in order to minimize her own regret. We provide algorithms for this setting, both for stochastic and adversarial bandits, and show that their regret smoothly interpolates between the regret in the classical bandit setting and that of the full-information setting as a function of the neighbors\u2019 exploration. In the stochastic setting the additional information must simply be incorporated into the usual estimation of the rewards, while in the adversarial setting this is attained by constructing a new unbiased estimator for the rewards and appropriately bounding the amount of additional information provided by the neighbors. These algorithms are optimal up to log factors; despite the fact that the agents act independently and selfishly, this implies that it is an approximate Nash equilibria for all agents to use our algorithms. Further, we show via empirical simulations that our algorithms, often significantly, outperform existing algorithms that one could apply to this setting.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning For Smile Recognition\nAbstract: Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition. A smile recognition test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches based on hand-crafted features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of the architecture parameters, allowing to find an appropriate architecture for each expression such as smile. This is feasible because all experiments were run on a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations on a CPU.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning\nAbstract: This paper presents an end-to-end framework for task-oriented dialog systems using a variant of Deep Recurrent QNetworks (DRQN). The model is able to interface with a relational database and jointly learn policies for both language understanding and dialog strategy. Moreover, we propose a hybrid algorithm that combines the strength of reinforcement learning and supervised learning to achieve faster learning speed. We evaluated the proposed model on a 20 Question Game conversational game simulator. Results show that the proposed method outperforms the modular-based baseline and learns a distributed representation of the latent dialog state.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple\u2019s iOS, OS X and tvOS developed in Metal and Swift\nAbstract: In this paper we present DeepLearningKit an open source framework that supports using pretrained deep learning models (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to utilize the GPU efficiently and Swift for integration with applications, e.g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using deep learning models trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time required to train Deep Learning models we suggest an App Store like model to distribute and download pretrained and reusable Deep Learning models. 1 GPU Accelerated Deep Learning Library The Metal programming language is most the efficient way of utilizing the GPU on Apple\u2019s iOS since 2014 [1, 2, 3, 4] and OSX since 2015 [5, 6, 7]. This paper gives a brief overview of a Metal and Swift based Deep Learning library named DeepLearningKit, in particular parts of Metal convolutional neural network operators for the GPU. DeepLearningKit supports on-device Deep Learning on Apple\u2019s iOS, OS X and tvOS. DeepLearningKit currently has shader functions for convolutional neural networks implemented in Metal and parallelized for the GPU, operators include: convolution, pooling, rectifier layer and softmax. In terms of deep learning model supported it has support for Min Lin\u2019s Caffe-trained Network In Network[8] (NIN trained on CIFAR-10, CIFAR-100 and ImageNet data sets). We also have preliminary support running Theano[9] trained LeNet (trained on MNIST digit classification dataset). The reason we have chosen NIN is that the network is small compared to other deep convolutional neural networks, but at the same time provide very high classification accuracy on images, e.g. better than AlexNet. GoogleLeNet (winner of Imagenet 2014) uses a similar approach as NIN[?]. NIN can perhaps also be used in non-image domains, e.g speech recognition[10] or natural language processing[11]. In particular one could attempt to adapt Zhang and Lecun\u2019s encoding and 1D convolutional operators in \u201cText Understanding from Scratch\u201d[12] and use it with NIN. 1.1 Experiences with PowerVR G6430/GT7600 on iPhone 5S/6S The performance of DeepLearningKit Deep Learning going from iPhone 5S (with PowerVR G6430 according to The iPhone 5S Review (AnandTech)) to iPhone 6S (with PowerVR GT7600 according to Apple iPhone 6S Plus vs. Samsung Galaxy S6 Edge+) we got 1 order of magnitude in improved performance. Calculation time to run through a 20 layer deep convolutional neural network model \u2217http://DeepLearningKit.org 1 ar X iv :1 60 5. 04 61 4v 1 [ cs .L G ] 1 5 M ay 2 01 6\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hybrid Batch Bayesian Optimization\nAbstract: Bayesian Optimization (BO) aims at optimizing an unknown function that is costly to evaluate. We focus on applications where concurrent function evaluations are possible. In such cases, BO could choose to either sequentially evaluate the function (sequential mode) or evaluate the function at a batch of multiple inputs at once (batch mode). The sequential mode generally leads to better optimization performance as each function evaluation is selected with more information, whereas the batch mode is more time efficient (smaller number of iterations). Our goal is to combine the strength of both settings. We systematically analyze BO using a Gaussian Process as the posterior estimator and provide a hybrid algorithm that dynamically switches between sequential and batch with variable batch sizes. We theoretically justify our algorithm and present experimental results on eight benchmark BO problems. The results show that our method achieves substantial speedup (up to 78%) compared to sequential, without suffering any significant performance loss.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-View Kernels for Low-Dimensional Modeling of Seismic Events\nAbstract: The problem of learning from seismic recordings has been studied for years. There is a growing interest of developing automatic mechanisms for identifying the properties of a seismic event. One main motivation is the ability have a reliable identification of manmade explosions. The availability of multiple high dimensional observations has increased the use of machine learning techniques in a variety of fields. In this work, we propose to use a kernel-fusion based dimensionality reduction framework for generating meaningful seismic representations from raw data. The proposed method is tested on 2023 events that were recorded in Israel and in Jordan. The method achieves promising results in classification of event type as well as in estimating the location of the event. The proposed fusion and dimensionality reduction tools may be applied to other types of geophysical data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast ALS-based tensor factorizat ion for context-aware recommendat ion from implicit feedback\nAbstract: Albeit , t he implicit feedback based recommendat ion problem\u2014when only t he user hist ory is available but t here are no rat ings\u2014is t he most typical set t ing in real-world applicat ions, it is much less researched than the explicit feedback case. St at e-of-t he-art algorit hms that are efficient on the explicit case cannot be st raight forwardly t ransformed to t he implicit case if scalability should be maint ained. There are few if any implicit feedback benchmark dat aset s, t herefore new ideas are usually experiment ed on explicit benchmarks. In t his paper, we propose a generic cont ext -aware implicit feedback recommender algorit hm, coined iTALS. iTALS apply a fast , ALS-based t ensor fact orizat ion learning method that scales linearly wit h t he number of non-zero element s in t he t ensor. T he method also allows us t o incorporat e diverse cont ext informat ion int o t he model while maint aining it s comput at ional efficiency. In part icular, we present two such cont ext -aware implement at ion variant s of iTALS. The first incorporat es seasonality and enables t o dist inguish user behavior in different t ime int ervals. T he other views the user hist ory as sequent ial informat ion and has t he ability t o recognize usage pat t ern typical t o cert ain group of it ems, e.g. t o automat ically t ell apart product types or cat egories t hat are typically purchased repet it ively (collect ibles, grocery goods) or once (household appliances). Experiment s performed on three implicit dat aset s (two propriet ary ones and an implicit variant of t he Netflix dat aset ) show that by int egrat ing cont ext -aware informat ion wit h our fact orizat ion framework int o t he st at e-of-t he-art implicit recommender algorit hm the recommendat ion quality improves significant ly. K eywor d s: recommender syst ems, t ensor fact orizat ion, cont extual informat ion, implicit feedback\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Contextual Dueling Bandits\nAbstract: We consider the problem of learning to choose actions using contextual information when provided with limited feedback in the form of relative pairwise comparisons. We study this problem in the dueling-bandits framework of Yue et al. (2009), which we extend to incorporate context. Roughly, the learner\u2019s goal is to find the best policy, or way of behaving, in some space of policies, although \u201cbest\u201d is not always so clearly defined. Here, we propose a new and natural solution concept, rooted in game theory, called a von Neumann winner, a randomized policy that beats or ties every other policy. We show that this notion overcomes important limitations of existing solutions, particularly the Condorcet winner which has typically been used in the past, but which requires strong and often unrealistic assumptions. We then present three efficient algorithms for online learning in our setting, and for approximating a von Neumann winner from batch-like data. The first of these algorithms achieves particularly low regret, even when data is adversarial, although its time and space requirements are linear in the size of the policy space. The other two algorithms require time and space only logarithmic in the size of the policy space when provided access to an oracle for solving classification problems on the space.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting Spammers via Aggregated Historical Data Set\nAbstract: The battle between email service providers and senders of mass unsolicited emails (Spam) continues to gain traction. Vast numbers of Spam emails are sent mainly from automatic botnets distributed over the world. One method for mitigating Spam in a computationally efficient manner is fast and accurate blacklisting of the senders. In this work we propose a new sender reputation mechanism that is based on an aggregated historical data-set which encodes the behavior of mail transfer agents over time. A historical data-set is created from labeled logs of received emails. We use machine learning algorithms to build a model that predicts the spammingness of mail transfer agents in the near future. The proposed mechanism is targeted mainly at large enterprises and email service providers and can be used for updating both the black and the white lists. We evaluate the proposed mechanism using 9.5M anonymized log entries obtained from the biggest Internet service provider in Europe. Experiments show that proposed method detects more than 94% of the Spam emails that escaped the blacklist (i.e., TPR), while having less than 0.5% false-alarms. Therefore, the effectiveness of the proposed method is much higher than of previously reported reputation mechanisms, which rely on emails logs. In addition, the proposed method, when used for updating both the black and white lists, eliminated the need in automatic content inspection of 4 out of 5 incoming emails, which resulted in dramatic reduction in the filtering computational load.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Marginal Structured SVM with Hidden Variables\nAbstract: In this work, we propose the marginal structured SVM (MSSVM) for structured prediction with hidden variables. MSSVM properly accounts for the uncertainty of hidden variables, and can significantly outperform the previously proposed latent structured SVM (LSSVM; Yu & Joachims (2009)) and other state-of-art methods, especially when that uncertainty is large. Our method also results in a smoother objective function, making gradient-based optimization of MSSVMs converge significantly faster than for LSSVMs. We also show that our method consistently outperforms hidden conditional random fields (HCRFs; Quattoni et al. (2007)) on both simulated and real-world datasets. Furthermore, we propose a unified framework that includes both our and several other existing methods as special cases, and provides insights into the comparison of different models in practice.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to detect video events from zero or very few video examples\nAbstract: In this work we deal with the problem of high-level event detection in video. Specifically, we study the challenging problems of i) learning to detect video events from solely a textual description of the event, without using any positive video examples, and ii) additionally exploiting very few positive training samples together with a small number of \u201crelated\u201d videos. For learning only from an event\u2019s textual description, we first identify a general learning framework and then study the impact of different design choices for various stages of this framework. For additionally learning from example videos, when true positive training samples are scarce, we employ an extension of the Support Vector Machine that allows us to exploit \u201crelated\u201d event videos by automatically introducing different weights for subsets of the videos in the overall training set. Experimental evaluations performed on the large-scale TRECVID MED 2014 video dataset provide insight on the effectiveness of the proposed methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Compressing Neural Language Models by Sparse Word Representations\nAbstract: Neural networks are among the state-ofthe-art techniques for language modeling. Existing neural language models typically map discrete words to distributed, dense vector representations. After information processing of the preceding context words by hidden layers, an output layer estimates the probability of the next word. Such approaches are timeand memory-intensive because of the large numbers of parameters for word embeddings and the output layer. In this paper, we propose to compress neural language models by sparse word representations. In the experiments, the number of parameters in our model increases very slowly with the growth of the vocabulary size, which is almost imperceptible. Moreover, our approach not only reduces the parameter space to a large extent, but also improves the performance in terms of the perplexity measure.1\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequential Nonparametric Regression\nAbstract: We present algorithms for nonparametric regression in settings where the data are obtained sequentially. While traditional estimators select bandwidths that depend upon the sample size, for sequential data the effective sample size is dynamically changing. We propose a linear time algorithm that adjusts the bandwidth for each new data point, and show that the estimator achieves the optimal minimax rate of convergence. We also propose the use of online expert mixing algorithms to adapt to unknown smoothness of the regression function. We provide simulations that confirm the theoretical results, and demonstrate the effectiveness of the methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On a Topic Model for Sentences\nAbstract: Probabilistic topic models are generative models that describe the content of documents by discovering the latent topics underlying them. However, the structure of the textual input, and for instance the grouping of words in coherent text spans such as sentences, contains much information which is generally lost with these models. In this paper, we propose sentenceLDA, an extension of LDA whose goal is to overcome this limitation by incorporating the structure of the text in the generative and inference processes. We illustrate the advantages of sentenceLDA by comparing it with LDA using both intrinsic (perplexity) and extrinsic (text classification) evaluation tasks on different text collections.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Learning for Classification of Low-rank Representation Features and Its Applications in Audio Segment Classification\nAbstract: In this paper, a novel framework based on trace norm minimization for audio segment is proposed. In this framework, both the feature extraction and classification are obtained by solving corresponding convex optimization problem with trace norm regularization. For feature extraction, robust principle component analysis (robust PCA) via minimization a combination of the nuclear norm and the l1-norm is used to extract low-rank features which are robust to white noise and gross corruption for audio segments. These low-rank features are fed to a linear classifier where the weight and bias are learned by solving similar trace norm constrained problems. For this classifier, most methods find the weight and bias in batch-mode learning, which makes them inefficient for large-scale problems. In this paper, we propose an online framework using accelerated proximal gradient method. This framework has a main advantage in memory cost. In addition, as a result of the regularization formulation of matrix classification, the Lipschitz constant was given explicitly, and hence the step size estimation of general proximal gradient method was omitted in our approach. Experiments on real data sets for laugh/non-laugh and applause/non-applause classification indicate that this novel framework is effective and noise robust.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Nonparametric Online Regression while Learning the Metric\nAbstract: <lb>We study algorithms for online nonparametric regression that learn the directions along which the<lb>regression function is smoother. Our algorithm learns the Mahalanobis metric based on the gradient<lb>outer product matrix G of the regression function (automatically adapting to the effective rank of this<lb>matrix), while simultaneously bounding the regret \u2014on the same data sequence\u2014 in terms of the<lb>spectrum of G. As a preliminary step in our analysis, we generalize a nonparametric online learning<lb>algorithm by Hazan and Megiddo by enabling it to compete against functions whose Lipschitzness is<lb>measured with respect to an arbitrary Mahalanobis metric.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dense Prediction on Sequences with Time-Dilated Convolutions for Speech Recognition\nAbstract: In computer vision pixelwise dense prediction is the task of predicting a label for each pixel in the image. Convolutional neural networks achieve good performance on this task, while being computationally efficient. In this paper we carry these ideas over to the problem of assigning a sequence of labels to a set of speech frames, a task commonly known as framewise classification. We show that dense prediction view of framewise classification offers several advantages and insights, including computational efficiency and the ability to apply batch normalization. When doing dense prediction we pay specific attention to strided pooling in time and introduce an asymmetric dilated convolution, called time-dilated convolution, that allows for efficient and elegant implementation of pooling in time. We show results using time-dilated convolutions in a very deep VGG-style CNN with batch normalization on the Hub5 Switchboard-2000 benchmark task. With a big n-gram language model, we achieve 7.7% WER which is the best single model single-pass performance reported so far.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Correction for Syntax Errors in Programming Assignments using Recurrent Neural Networks\nAbstract: We present a method for automatically generating repair feedback for syntax errors for introductory programming problems. Syntax errors constitute one of the largest classes of errors (34%) in our dataset of student submissions obtained from a MOOC course on edX. The previous techniques for generating automated feedback on programming assignments have focused on functional correctness and style considerations of student programs. These techniques analyze the program AST of the program and then perform some dynamic and symbolic analyses to compute repair feedback. Unfortunately, it is not possible to generate ASTs for student programs with syntax errors and therefore the previous feedback techniques are not applicable in repairing syntax errors. We present a technique for providing feedback on syntax errors that uses Recurrent neural networks (RNNs) to model syntactically valid token sequences. Our approach is inspired from the recent work on learning language models from Big Code (large code corpus). For a given programming assignment, we first learn an RNN to model all valid token sequences using the set of syntactically correct student submissions. Then, for a student submission with syntax errors, we query the learnt RNN model with the prefix token sequence to predict token sequences that can fix the error by either replacing or inserting the predicted token sequence at the error location. We evaluate our technique on over 14, 000 student submissions with syntax errors. Our technique can completely repair 31.69% (4501/14203) of submissions with syntax errors and in addition partially correct 6.39% (908/14203) of the submissions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Optimal Recommendation to Users that React: Online Learning for a Class of POMDPs\nAbstract: We describe and study a model for an Automated Online Recommendation System (AORS) in which a user\u2019s preferences can be time-dependent and can also depend on the history of past recommendations and play-outs. The three key features of the model that makes it more realistic compared to existing models for recommendation systems are (1) user preference is inherently latent, (2) current recommendations can affect future preferences, and (3) it allows for the development of learning algorithms with provable performance guarantees. The problem is cast as an average-cost restless multi-armed bandit for a given user, with an independent partially observable Markov decision process (POMDP) for each item of content. We analyze the POMDP for a single arm, describe its structural properties, and characterize its optimal policy. We then develop a Thompson sampling-based online reinforcement learning algorithm to learn the parameters of the model and optimize utility from the binary responses of the users to continuous recommendations. We then analyze the performance of the learning algorithm and characterize the regret. Illustrative numerical results and directions for extension to the restless hidden Markov multiarmed bandit problem are also presented.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Measuring Neural Net Robustness with Constraints\nAbstract: Despite having high accuracy, neural nets have been shown to be susceptible to adversarial examples, where a small perturbation to an input can cause it to become mislabeled. We propose metrics for measuring the robustness of a neural net and devise a novel algorithm for approximating these metrics based on an encoding of robustness as a linear program. We show how our metrics can be used to evaluate the robustness of deep neural nets with experiments on the MNIST and CIFAR-10 datasets. Our algorithm generates more informative estimates of robustness metrics compared to estimates based on existing algorithms. Furthermore, we show how existing approaches to improving robustness \u201coverfit\u201d to adversarial examples generated using a specific algorithm. Finally, we show that our techniques can be used to additionally improve neural net robustness both according to the metrics that we propose, but also according to previously proposed metrics.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Monte Carlo Bayesian Reinforcement Learning\nAbstract: Bayesian reinforcement learning (BRL) encodes prior knowledge of the world in a model and represents uncertainty in model parameters by maintaining a probability distribution over them. This paper presents Monte Carlo BRL (MC-BRL), a simple and general approach to BRL. MC-BRL samples a priori a finite set of hypotheses for the model parameter values and forms a discrete partially observable Markov decision process (POMDP) whose state space is a cross product of the state space for the reinforcement learning task and the sampled model parameter space. The POMDP does not require conjugate distributions for belief representation, as earlier works do, and can be solved relatively easily with pointbased approximation algorithms. MC-BRL naturally handles both fully and partially observable worlds. Theoretical and experimental results show that the discrete POMDP approximates the underlying BRL task well with guaranteed performance.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Internal Guidance for Satallax\nAbstract: We propose a new internal guidance method for automated theorem provers based on the given-clause algorithm. Our method influences the choice of unprocessed clauses using positive and negative examples from previous proofs. To this end, we present an efficient scheme for Naive Bayesian classification by generalising label occurrences to types with monoid structure. This makes it possible to extend existing fast classifiers, which consider only positive examples, with negative ones. We implement the method in the higher-order logic prover Satallax, where we modify the delay with which propositions are processed. We evaluated our method on a simply-typed higher-order logic version of the Flyspeck project, where it solves 26% more problems than Satallax without internal\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stay on path: PCA along graph paths\nAbstract: We introduce a variant of (sparse) PCA in which the set of feasible support sets is determined by a graph. In particular, we consider the following setting: given a directed acyclic graph G on p vertices corresponding to variables, the non-zero entries of the extracted principal component must coincide with vertices lying along a path in G. From a statistical perspective, information on the underlying network may potentially reduce the number of observations required to recover the population principal component. We consider the canonical estimator which optimally exploits the prior knowledge by solving a non-convex quadratic maximization on the empirical covariance. We introduce a simple network and analyze the estimator under the spiked covariance model. We show that side information potentially improves the statistical complexity. We propose two algorithms to approximate the solution of the constrained quadratic maximization, and recover a component with the desired properties. We empirically evaluate our schemes on synthetic and real datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Learning with Feedback Graphs: Beyond Bandits\nAbstract: We study a general class of online learning problems where the feedback is specified by a graph. This class includes online prediction with expert advice and the multiarmed bandit problem, but also several learning problems where the online player does not necessarily observe his own loss. We analyze how the structure of the feedback graph controls the inherent difficulty of the induced T -round learning problem. Specifically, we show that any feedback graph belongs to one of three classes: strongly observable graphs, weakly observable graphs, and unobservable graphs. We prove that the first class induces learning problems with \u0398\u0303(\u03b11/2T 1/2) minimax regret, where \u03b1 is the independence number of the underlying graph; the second class induces problems with \u0398\u0303(\u03b41/3T 2/3) minimax regret, where \u03b4 is the domination number of a certain portion of the graph; and the third class induces problems with linear minimax regret. Our results subsume much of the previous work on learning with feedback graphs and reveal new connections to partial monitoring games. We also show how the regret is affected if the graphs are allowed to vary with time. Tel Aviv University, Tel Aviv, Israel, and Microsoft Research, Herzliya, Israel, nogaa@post.tau.ac.il. Dipartimento di Informatica, Universit\u00e0 degli Studi di Milano, Milan, Italy, nicolo.cesabianchi@unimi.it. Parts of this work were done while the author was at Microsoft Research, Redmond. Microsoft Research, Redmond, Washington; oferd@microsoft.com. Technion\u2014Israel Institute of Technology, Haifa, Israel, and Microsoft Research, Herzliya, Israel, tomerk@technion.ac.il. Parts of this work were done while the author was at Microsoft Research, Redmond.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting\nAbstract: Oriental ink painting, called Sumi-e, is one of the most appealing painting styles that has attracted artists around the world. Major challenges in computer-based Sumi-e simulation are to abstract complex scene information and draw smooth and natural brush strokes. To automatically generate such strokes, we propose to model a brush as a reinforcement learning agent, and learn desired brush-trajectories by maximizing the sum of rewards in the policy search framework. We also elaborate on the design of actions, states, and rewards tailored for a Sumi-e agent. The effectiveness of our proposed approach is demonstrated through simulated Sumi-e experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Structurally Smoothed Graphlet Kernel\nAbstract: A commonly used paradigm for representing graphs is to use a vector that contains normalized frequencies of occurrence of certain motifs or sub-graphs. This vector representation can be used in a variety of applications, such as, for computing similarity between graphs. The graphlet kernel of Shervashidze et al. [32] uses induced sub-graphs of k nodes (christened as graphlets by Przulj [28]) as motifs in the vector representation, and computes the kernel via a dot product between these vectors. One can easily show that this is a valid kernel between graphs. However, such a vector representation suffers from a few drawbacks. As k becomes larger we encounter the sparsity problem; most higher order graphlets will not occur in a given graph. This leads to diagonal dominance, that is, a given graph is similar to itself but not to any other graph in the dataset. On the other hand, since lower order graphlets tend to be more numerous, using lower values of k does not provide enough discrimination ability. We propose a smoothing technique to tackle the above problems. Our method is based on a novel extension of Kneser-Ney and Pitman-Yor smoothing techniques from natural language processing to graphs. We use the relationships between lower order and higher order graphlets in order to derive our method. Consequently, our smoothing algorithm not only respects the dependency between sub-graphs but also tackles the diagonal dominance problem by distributing the probability mass across graphlets. In our experiments, the smoothed graphlet kernel outperforms graph kernels based on raw frequency counts.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating images with recurrent adversarial networks\nAbstract: Gatys et al. (2015) showed that optimizing pixels to match features in a convolutional network with respect reference image features is a way to render images of high visual quality. We show that unrolling this gradient-based optimization yields a recurrent computation that creates images by incrementally adding onto a visual \u201ccanvas\u201d. We propose a recurrent generative model inspired by this view, and show that it can be trained using adversarial training to generate very good image samples. We also propose a way to quantitatively compare adversarial networks by having the generators and discriminators of these networks compete against each other.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning From An Optimization Viewpoint\nAbstract: Optimization has always played a central role in machine learning and advances in the field of optimization and mathematical programming have greatly influenced machine learning models. However the connection between optimization and learning is much deeper : one can phrase statistical and online learning problems directly as corresponding optimization problems. In this dissertation I take this viewpoint and analyze learning problems in both the statistical and online learning frameworks from an optimization perspective. In doing so we develop a deeper understanding of the connections between statistical and online learning and between learning and optimization. The dissertation can roughly be divided into two parts. In the first part we consider the question of learnability and possible learning rates for general statistical and online learning problems without regard to tractability issues. In the second part we restrict ourselves to convex learning problems and address the issue of tractability for both online and statistical learning problems by considering the oracle complexity of these learning problems. I. We first consider the question of learnability and possible learning rates for statistical learning problems under the general learning setting. The notion of learnability was first introduced by Valiant (1984) for the problem of binary classification in the realizable case. Vapnik (1995) introduced the general learning setting as a unifying framework for the general problem of statistical learning from empirical data. In this framework the learner is provided with a sample of instances drawn i.i.d. from some distribution unknown to the learner. The goal of the learner is to pick a hypothesis with low expected loss based on the sample received. The question of learnability is well studied and fully characterized for binary classification using the Vapnik Chervonenkis (VC) theory and for real valued supervised learning problems using the theory of uniform convergence with tools like Rademacher complexity, covering numbers and fat-shattering dimension etc. However we show that for the general learning setting the traditional approach of using uniform convergence theory to characterize learnability fails. Specifically we phrase the learning problem as a stochastic optimization problem and construct an example of a convex problem where Stochastic Approximation (SA) approach provides successful learning guarantee but Empirical Risk Minimization (ERM) (or equivalently Sample Average Approximation (SAA) approach) fails to give any meaningful learning guarantee. This example establishes that for general learning problems the concept of uniform convergence fails to capture learnability and ERM/SAA ap-\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Pursuit of Exploitable Bugs in Machine Learning\nAbstract: Governments and businesses increasingly rely on data analytics and machine learning (ML) for improving their competitive edge in areas such as consumer satisfaction, threat intelligence, decision making, and product efficiency. However, by cleverly corrupting a subset of data used as input to a target\u2019s ML algorithms, an adversary can perturb outcomes and compromise the effectiveness of ML technology. While prior work in the field of adversarial machine learning has studied the impact of input manipulation on correct ML algorithms, we consider the exploitation of bugs in ML implementations. In this paper, we characterize the attack surface of ML programs, and we show that malicious inputs exploiting implementation bugs enable strictly more powerful attacks than the classic adversarial machine learning techniques. We propose a semi-automated technique, called steered fuzzing, for exploring this attack surface and for discovering exploitable bugs in machine learning programs, in order to demonstrate the magnitude of this threat. As a result of our work, we responsibly disclosed five vulnerabilities, established three new CVE-IDs, and illuminated a common insecure practice across many machine learning systems. Finally, we outline several research directions for further understanding and mitigating this threat.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing\nAbstract: Digital crowdsourcing (CS) is a modern approach to perform certain large projects<lb>using small contributions of a large crowd. In CS, a taskmaster typically breaks<lb>down the project into small batches of tasks and assigns them to so-called workers<lb>with imperfect skill levels. The crowdsourcer then collects and analyzes the results<lb>for inference and serving the purpose of the project. In this work, the CS problem,<lb>as a human-in-the-loop computation problem, is modeled and analyzed in an<lb>information theoretic rate-distortion framework. The purpose is to identify the<lb>ultimate fidelity that one can achieve by any form of query from the crowd and any<lb>decoding (inference) algorithm with a given budget. The results are established<lb>by a joint source channel (de)coding scheme, which represent the query scheme<lb>and inference, over parallel noisy channels, which model workers with imperfect<lb>skill levels. We also present and analyze a query scheme dubbed k-ary incidence<lb>coding and study optimized query pricing in this setting.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: b-Bit Minwise Hashing in Practice: Large-Scale Batch and Online Learning and Using GPUs for Fast Preprocessing with Simple Hash Functions\nAbstract: ABSTRACT Minwise hashing is a standard technique in the context of search for approximating set similarities. The recent work [27] demonstrated a potential use of b-bit minwise hashing [26] for batch learning on large data. However, several critical issues must be tackled before one can apply b-bit minwise hashing to the volumes of data often used industrial applications, especially in the context of search.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-velocity neural networks for gesture recognition in videos\nAbstract: We present a new action recognition deep neural network which adaptively learns the best action velocities in addition to the classification. While deep neural networks have reached maturity for image understanding tasks, we are still exploring network topologies and features to handle the richer environment of video clips. Here, we tackle the problem of multiple velocities in action recognition, and provide state-of-the-art results for gesture recognition, on known and new collected datasets. We further provide the training steps for our semi-supervised network, suited to learn from huge unlabeled datasets with only a fraction of labeled examples.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Auto-JacoBin: Auto-encoder Jacobian Binary Hashing\nAbstract: Binary codes can be used to speed up nearest neighbor search tasks in large scale data sets as they are efficient for both storage and retrieval. In this paper, we propose a robust auto-encoder model that preserves the geometric relationships of high-dimensional data sets in Hamming space. This is done by considering a noise-removing function in a region surrounding the manifold where the training data points lie. This function is defined with the property that it projects the data points near the manifold into the manifold wisely, and we approximate this function by its first order approximation. Experimental results show that the proposed method achieves better than state-of-the-art results on three large scale high dimensional data sets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Minimal Gated Unit for Recurrent Neural Networks\nAbstract: Recently recurrent neural networks (RNN) has been very successful in handling sequence data. However, understanding RNN and finding the best practices for RNN is a difficult task, partly because there are many competing and complex hidden units (such as LSTM and GRU). We propose a gated unit for RNN, named as Minimal Gated Unit (MGU), since it only contains one gate, which is a minimal design among all gated hidden units. The design of MGU benefits from evaluation results on LSTM and GRU in the literature. Experiments on various sequence data show that MGU has comparable accuracy with GRU, but has a simpler structure, fewer parameters, and faster training. Hence, MGU is suitable in RNN\u2019s applications. Its simple architecture also means that it is easier to evaluate and tune, and in principle it is easier to study MGU\u2019s properties theoretically and empirically.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification\nAbstract: Unsupervised learning and supervised learning are key research topics in deep learning. However, as high-capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks, the availability of large-scale labeled images reduced the significance of unsupervised learning. Inspired by the recent trend toward revisiting the importance of unsupervised learning, we investigate joint supervised and unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction. First, we demonstrate that the intermediate activations of pretrained large-scale classification networks preserve almost all the information of input images except a portion of local spatial details. Then, by end-to-end training of the entire augmented architecture with the reconstructive objective, we show improvement of the network performance for supervised tasks. We evaluate several variants of autoencoders, including the recently proposed \u201cwhat-where\" autoencoder that uses the encoder pooling switches, to study the importance of the architecture design. Taking the 16-layer VGGNet trained under the ImageNet ILSVRC 2012 protocol as a strong baseline for image classification, our methods improve the validation-set accuracy by a noticeable margin.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Finding interesting symmetrical topological structures in high-dimensional systems is an important problem in statistical machine learning. Limited amount of available high-dimensional data and its sensitivity to noise pose computational challenges to find symmetry. Our paper presents a new method to find local symmetries in a low-dimensional 2-D grid structure which is embedded in high-dimensional structure. To compute the symmetry in a grid structure, we introduce three legal grid moves (i) Commutation (ii) Cyclic Permutation (iii) Stabilization on sets of local grid squares, grid blocks. The three grid moves are legal transformations as they preserve the statistical distribution of hamming distances in each grid block. We propose and coin the term of grid symmetry of data on the 2-D data grid as the invariance of statistical distributions of hamming distance are preserved after a sequence of grid moves. We have computed and analyzed the grid symmetry of data on multivariate Gaussian distributions and Gamma distributions with noise.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Improving a Credit Scoring Model by Incorporating Bank Statement Derived Features\nAbstract: In this paper, we investigate the extent to which features derived from bank statements provided by loan applicants, and which are not declared on an application form, can enhance a credit scoring model for a New Zealand lending company. Exploring the potential of such information to improve credit scoring models in this manner has not been studied previously. We construct a baseline model based solely on the existing scoring features obtained from the loan application form, and a second baseline model based solely on the new bank statement derived features. A combined feature model is then created by augmenting the application form features with the new bank statement derived features. Our experimental results show that a combined feature model performs better than both of the two baseline models, and that a number of the bank statement derived features have value in improving the credit scoring model. As is often the case in credit scoring, our target data was highly imbalanced, and Naive Bayes was found to be the best performing classifier, outperforming a number of other classifiers commonly used in credit scoring. Future experimentation with Naive Bayes on other highly imbalanced credit scoring data sets will help to confirm whether the classifier should be more commonly used in the credit scoring context.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hierarchical Variational Models\nAbstract: Black box inference allows researchers to easily prototype and evaluate an array of models. Recent advances in variational inference allow such algorithms to scale to high dimensions. However, a central question remains: How to specify an expressive variational distribution which maintains efficient computation? To address this, we develop hierarchical variational models. In a HIERARCHICAL VM, the variational approximation is augmented with a prior on its parameters, such that the latent variables are conditionally independent given this shared structure. This preserves the computational efficiency of the original approximation, while admitting hierarchically complex distributions for both discrete and continuous latent variables. We study HIERARCHICAL VM on a variety of deep discrete latent variable models. HIERARCHICAL VM generalizes other expressive variational distributions and maintains higher fidelity to the posterior.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Guaranteed Non-convex Optimization: Submodular Maximization over Continuous Domains\u2217\nAbstract: Submodular continuous functions are a category of (generally) non-convex/non-concave functions with a wide spectrum of applications. We characterize these functions and demonstrate that they can be maximized efficiently with approximation guarantees. Specifically, i) We introduce the weak DR property that gives a unified characterization of submodularity for all set, integer-lattice and continuous functions; ii) for maximizing monotone DR-submodular continuous functions under general down-closed convex constraints, we propose a Frank-Wolfe variant with (1\u22121/e) approximation guarantee, and sub-linear convergence rate; iii) for maximizing general non-monotone submodular continuous functions subject to box constraints, we propose a DoubleGreedy algorithm with 1/3 approximation guarantee. Submodular continuous functions naturally find applications in various real-world settings, including influence and revenue maximization with continuous assignments, sensor energy management, multi-resolution data summarization, facility location, etc. Experimental results show that the proposed algorithms efficiently generate superior solutions compared to baseline algorithms. \u2217Appears in the 20 International Conference on Artificial Intelligence and Statistics (AISTATS) 2017, Fort Lauderdale, Florida, USA. ar X iv :1 60 6. 05 61 5v 4 [ cs .L G ] 1 M ar 2 01 7\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: IMPROVED TEXT ANALYTICS TRANSFER LEARNING\nAbstract: Although neural networks are well suited for sequential transfer learning tasks, the catastrophic forgetting problem hinders proper integration of prior knowledge. In this work, we propose a solution to this problem by using a multi-task objective based on the idea of distillation and a mechanism that directly penalizes forgetting at the shared representation layer during the knowledge integration phase of training. We demonstrate our approach on a Twitter domain sentiment analysis task with sequential knowledge transfer from four related tasks. We show that our technique outperforms networks fine-tuned to the target task. Additionally, we show both through empirical evidence and examples that it does not forget useful knowledge from the source task that is forgotten during standard fine-tuning. Surprisingly, we find that first distilling a human made rule based sentiment engine into a recurrent neural network and then integrating the knowledge with the target task data leads to a substantial gain in generalization performance. Our experiments demonstrate the power of multi-source transfer techniques in practical text analytics problems when paired with distillation. In particular, for the SemEval 2016 Task 4 Subtask A (Nakov et al., 2016) dataset we surpass the state of the art established during the competition with a comparatively simple model architecture that is not even competitive when trained on only the labeled task specific data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Personalized Course Sequence Recommendations\nAbstract: Given the variability in student learning it is becoming increasingly important to tailor courses as well as course sequences to student needs. This paper presents a systematic methodology for offering personalized course sequence recommendations to students. First, a forward-search backwardinduction algorithm is developed that can optimally select course sequences to decrease the time required for a student to graduate. The algorithm accounts for prerequisite requirements (typically present in higher level education) and course availability. Second, using the tools of multi-armed bandits, an algorithm is developed that can optimally recommend a course sequence that both reduces the time to graduate while also increasing the overall GPA of the student. The algorithm dynamically learns how students with different contextual backgrounds perform for given course sequences and then recommends an optimal course sequence for new students. Using real-world student data from the UCLA Mechanical and Aerospace Engineering department, we illustrate how the proposed algorithms outperform other methods that do not include student contextual information when making course sequence recommendations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: by physician knowledge and attitude, with a relatively low agreement in different clinicians\u2019 decision. Diagnosis using these behavioral observations has been often unreliable and is highly dependent on the clinicians\u2019 intuition. Early and accurate diagnosis of different mental disorders is important for proper treatment approach selection and prevention of mortality and morbidity. EEG-based CAD as a quantitative method for diagnosis, which relies on analysis of electrical activity of the brain, can help clinicians to increase the confidence of diagnosis\nAbstract: Abstract\u2014The generalization and robustness of an electroencephalogram (EEG)-based computer aided diagnostic system are crucial requirements in actual clinical practice. To reach these goals, we propose a new EEG representation that provides a more realistic view of brain functionality by applying multi-instance (MI) framework to consider the nonstationarity of the EEG signal. The non-stationary characteristic of EEG is considered by describing the signal as a bag of relevant and irrelevant concepts. The concepts are provided by a robust representation of homogenous segments of EEG signal using spatial covariance matrices. Due to the nonlinear geometry of the space of covariance matrices, we determine the boundaries of the homogeneous segments based on adaptive segmentation of the signal in a Riemannian framework. Each subject is described as a bag of covariance matrices of homogenous segments and the bag-level discriminative information is used for classification. To evaluate the performance of the proposed approach, we examine it in attention deficit hyperactivity/bipolar mood disorder detection and depression/normal diagnosis applications. Experimental results confirm the superiority of the proposed approach, which is gained due to the robustness of covariance descriptor, the effectiveness of Riemannian geometry, and the benefits of considering the inherent non-stationary nature of the brain.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Query Learning with Wikipedia and Genetic Programming\nAbstract: Most of the existing information retrieval systems are based on bag of words model and are not equipped with common world knowledge. Work has been done towards improving the efficiency of such systems by using intelligent algorithms to generate search queries, however, not much research has been done in the direction of incorporating human-and-society level knowledge in the queries. This paper is one of the first attempts where such information is incorporated into the search queries using Wikipedia semantics. The paper presents an essential shift from conventional token based queries to concept based queries, leading to an enhanced efficiency of information retrieval systems. To efficiently handle the automated query learning problem, we propose Wikipedia-based Evolutionary Semantics (Wiki-ES) framework where concept based queries are learnt using a co-evolving evolutionary procedure. Learning concept based queries using an intelligent evolutionary procedure yields significant improvement in performance which is shown through an extensive study using Reuters newswire documents. Comparison of the proposed framework is performed with other information retrieval systems. Concept based approach has also been implemented on other information retrieval systems to justify the effectiveness of a transition from token based queries to concept based queries.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MULTI-CORE MACHINES\nAbstract: AdaBoost is an important algorithm in machine learning and is being widely used in object detection. AdaBoost works by iteratively selecting the best amongst weak classifiers, and then combines several weak classifiers to obtain a strong classifier. Even though AdaBoost has proven to be very effective, its learning execution time can be quite large depending upon the application e.g., in face detection, the learning time can be several days. Due to its increasing use in computer vision applications, the learning time needs to be drastically reduced so that an adaptive near real time object detection system can be incorporated. In this paper, we develop a hybrid parallel and distributed AdaBoost algorithm that exploits the multiple cores in a CPU via light weight threads, and also uses multiple machines via a web service software architecture to achieve high scalability. We present a novel hierarchical web services based distributed architecture and achieve nearly linear speedup up to the number of processors available to us. In comparison with the previously published work, which used a single level master-slave parallel and distributed implementation [1] and only achieved a speedup of 2.66 on four nodes, we achieve a speedup of 95.1 on 31 workstations each having a quad-core processor, resulting in a learning time of only 4.8 seconds per feature.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From Kernel Machines to Ensemble Learning\nAbstract: Ensemble methods such as boosting combine multiple learners to obtain better prediction than could be obtained from any individual learner. Here we propose a principled framework for directly constructing ensemble learning methods from kernel methods. Unlike previous studies showing the equivalence between boosting and support vector machines (SVMs), which needs a translation procedure, we show that it is possible to design boosting-like procedure to solve the SVM optimization problems. In other words, it is possible to design ensemble methods directly from SVM without any middle procedure. This finding not only enables us to design new ensemble learning methods directly from kernel methods, but also makes it possible to take advantage of those highlyoptimized fast linear SVM solvers for ensemble learning. We exemplify this framework for designing binary ensemble learning as well as a new multi-class ensemble learning methods. Experimental results demonstrate the flexibility and usefulness of the proposed framework.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning\nAbstract: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning. In order to achieve a high object detection performance, we propose a new approach to extract low-level visual features based on spatial pooling. Incorporating spatial pooling improves the translational invariance and thus the robustness of the detection process. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the proposed structured ensemble learning method with spatially pooled features. The result is the current best reported performance on the Caltech-USA pedestrian detection dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Local Information with Feedback Perturbation Suffices for Dictionary Learning in Neural Circuits\nAbstract: While the sparse coding principle can successfully model information processing in sensory neural systems, it remains unclear how learning can be accomplished under neural architectural constraints. Feasible learning rules must rely solely on synaptically local information in order to be implemented on spatially distributed neurons. We describe a neural network with spiking neurons that can address the aforementioned fundamental challenge and solve the `1-minimizing dictionary learning problem, representing the first model able to do so. Our major innovation is to introduce feedback synapses to create a pathway to turn the seemingly non-local information into local ones. The resulting network encodes the error signal needed for learning as the change of network steady states caused by feedback, and operates akin to the classical stochastic gradient descent method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adversarial Perturbations Against Deep Neural Networks for Malware Classification\nAbstract: Deep neural networks have recently been shown to lack robustness against adversarially crafted inputs. These inputs are derived from regular inputs by minor yet carefully selected perturbations that deceive the neural network into desired misclassifications. Existing work in this emerging field was largely specific to the domain of image classification, since images with their high-entropy can be conveniently manipulated without changing the images\u2019 overall visual appearance. Yet, it remains unclear how such attacks translate to more security-sensitive applications such as malware detection\u2013which may pose significant challenges in sample generation and arguably grave consequences for failure. In this paper, we show how to construct highly-effective adversarial sample crafting attacks for neural networks used as malware classifiers. Here, we face severely constrained limits on crafting suitable samples when the problem of image classification is replaced by malware classification: (i) continuous, differentiable input domains are replaced by discrete, often binary inputs; and (ii) the loose condition of leaving visual appearance unchanged is replaced by requiring equivalent functional behavior. We demonstrate the feasibility of these attacks on many different instances of malware classifiers that we trained using the DREBIN Android malware data set. We furthermore evaluate to which extent potential defensive mechanisms against adversarial crafting can be leveraged to the setting of malware classification. While feature reduction did not prove to have a positive impact, distillation and re-training on adversarially crafted samples show promising results.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discriminating Traces with Time\nAbstract: What properties about the internals of a program explain the possible differences in its overall running time for different inputs? In this paper, we propose a formal framework for considering this question we dub trace-set discrimination. We show that even though the algorithmic problem of computing maximum likelihood discriminants is NP-hard, approaches based on integer linear programming (ILP) and decision tree learning can be useful in zeroing-in on the program internals. On a set of Java benchmarks, we find that compactly-represented decision trees scalably discriminate with high accuracy\u2014more scalably than maximum likelihood discriminants and with comparable accuracy. We demonstrate on three larger case studies how decision-tree discriminants produced by our tool are useful for debugging timing side-channel vulnerabilities (i.e., where a malicious observer infers secrets simply from passively watching execution times) and availability vulnerabilities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed Cooperative Q-learning for Power Allocation in Cognitive Femtocell Networks\nAbstract: In this paper, we propose a distributed reinforcement learning (RL) technique called distributed power control using Q-learning (DPC-Q) to manage the interference caused by the femtocells on macro-users in the downlink. The DPC-Q leverages Q-Learning to identify the sub-optimal pattern of power allocation, which strives to maximize femtocell capacity, while guaranteeing macrocell capacity level in an underlay cognitive setting. We propose two different approaches for the DPC-Q algorithm: namely, independent, and cooperative. In the former, femtocells learn independently from each other while in the latter, femtocells share some information during learning in order to enhance their performance. Simulation results show that the independent approach is capable of mitigating the interference generated by the femtocells on macro-users. Moreover, the results show that cooperation enhances the performance of the femtocells in terms of speed of convergence, fairness and aggregate femtocell capacity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Privacy Loss in Apple\u2019s Implementation of Differential Privacy on MacOS 10.12\nAbstract: In June 2016, Apple made a bold announcement that it will deploy local differential privacy for some of their user data collection in order to ensure privacy of user data, even from Apple [21, 23]. The details of Apple\u2019s approach remained sparse. Although several patents [17\u201319] have since appeared hinting at the algorithms that may be used to achieve differential privacy, they did not include a precise explanation of the approach taken to privacy parameter choice. Such choice and the overall approach to privacy budget use and management are key questions for understanding the privacy protections provided by any deployment of differential privacy. In this work, through a combination of experiments, static and dynamic code analysis of macOS Sierra (Version 10.12) implementation, we shed light on the choices Apple made for privacy budget management. We discover and describe Apple\u2019s set-up for differentially private data processing, including the overall data pipeline, the parameters used for differentially private perturbation of each piece of data, and the frequency with which such data is sent to Apple\u2019s servers. We find that although Apple\u2019s deployment ensures that the (differential) privacy loss per each datum submitted to its servers is 1 or 2, the overall privacy loss permitted by the system is significantly higher, as high as 16 per day for the four initially announced applications of Emojis, New words, Deeplinks and Lookup Hints [21]. Furthermore, Apple renews the privacy budget available every day, which leads to a possible privacy loss of 16 times the number of days since user opt-in to differentially private data collection for those four applications. We applaud Apple\u2019s deployment of differential privacy for its bold demonstration of feasibility of innovation while guaranteeing rigorous privacy. However, we argue that in order to claim the benefits of differentially private data collection, Apple must give full transparency of its implementation, enable user choice in areas related to privacy loss, and set meaningful defaults on the daily, weekly, and device lifetime privacy loss permitted. ACM Reference Format: Jun Tang, Aleksandra Korolova, Xiaolong Bai, XueqiangWang, and Xiaofeng Wang. 2017. Privacy Loss in Apple\u2019s Implementation of Differential Privacy\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks\nAbstract: Access to electronic health records (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk. In this paper, we propose a new approach, medical Generative Adversarial Network (medGAN), to generate realistic synthetic EHRs. Based on an input EHR dataset, medGAN can generate high-dimensional discrete variables (e.g., binary and count features) via a combination of an autoencoder and generative adversarial networks. We also propose minibatch averaging to efficiently avoid mode collapse, and increase the learning efficiency with batch normalization and shortcut connections. To demonstrate feasibility, we showed that medGAN generates synthetic EHR datasets that achieve comparable performance to real data on many experiments including distribution statistics, predictive modeling tasks and medical expert review.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LASS: a simple assignment model with Laplacian smoothing\nAbstract: We consider the problem of learning soft assignments of N items to K categories given two sources of information: an item-category similarity matrix, which encourages items to be assigned to categories they are similar to (and to not be assigned to categories they are dissimilar to), and an item-item similarity matrix, which encourages similar items to have similar assignments. We propose a simple quadratic programming model that captures this intuition. We give necessary conditions for its solution to be unique, define an out-of-sample mapping, and derive a simple, effective training algorithm based on the alternating direction method of multipliers. The model predicts reasonable assignments from even a few similarity values, and can be seen as a generalization of semisupervised learning. It is particularly useful when items naturally belong to multiple categories, as for example when annotating documents with keywords or pictures with tags, with partially tagged items, or when the categories have complex interrelations (e.g. hierarchical) that are unknown.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning from Clinical Judgments: Semi-Markov-Modulated Marked  Hawkes Processes for Risk Prognosis\nAbstract: Critically ill patients in regular wards are vulnerable to unanticipated adverse events which require prompt transfer to the intensive care unit (ICU). To allow for accurate prognosis of deteriorating patients, we develop a novel continuoustime probabilistic model for a monitored patient\u2019s temporal sequence of physiological data. Our model captures \u201cinformatively sampled\u201d patient episodes: the clinicians\u2019 decisions on when to observe a hospitalized patient\u2019s vital signs and lab tests over time are represented by a marked Hawkes process, with intensity parameters that are modulated by the patient\u2019s latent clinical states, and with observable physiological data (mark process) modeled as a switching multi-task Gaussian process. In addition, our model captures \u201cinformatively censored\u201d patient episodes by representing the patient\u2019s latent clinical states as an absorbing semi-Markov jump process. The model parameters are learned from offline patient episodes in the electronic health records via an EM-based algorithm. Experiments conducted on a cohort of patients admitted to a major medical center over a 3-year period show that risk prognosis based on our model significantly outperforms the currently deployed medical risk scores and other baseline machine learning algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Mixed Observability Markov Decision Process Model for Musical Pitch\nAbstract: Partially observable Markov decision processes have been widely used to provide models for real-world decision making problems. In this paper, we will provide a method in which a slightly different version of them called Mixed observability Markov decision process, MOMDP, is going to join with our problem. Basically, we aim at offering a behavioural model for interaction of intelligent agents with musical pitch environment and we will show that how MOMDP can shed some light on building up a decision making model for musical pitch conveniently.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Constant-Factor Bi-Criteria Approximation Guarantee for k-means++\nAbstract: This paper studies the k-means++ algorithm for clustering as well as the class of D sampling algorithms to which k-means++ belongs. It is shown that for any constant factor \u03b2 > 1, selecting \u03b2k cluster centers by D sampling yields a constant-factor approximation to the optimal clustering with k centers, in expectation and without conditions on the dataset. This result extends the previously known O(log k) guarantee for the case \u03b2 = 1 to the constant-factor bi-criteria regime. It also improves upon an existing constant-factor bi-criteria result that holds only with constant probability.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Uniform Convergence of Consistent Confidence Measures\nAbstract: Many classification algorithms produce confidence measures in the form of conditional probability of labels given the features of the target instance. It is desirable to be make these confidence measures calibrated or consistent, in the sense that they correctly capture the belief of the algorithm in the label output. For instance, if the algorithm outputs a label with confidence measure p for n times, then the output label should be correct approximately np times overall. Calibrated confidence measures lead to higher interpretability by humans and computers and enable downstream analysis or processing. In this paper, we formally characterize the consistency of confidence measures and prove a PAC-style uniform convergence result for the consistency of confidence measures. We show that finite VCdimension is sufficient for guaranteeing the consistency of confidence measures produced by empirically consistent classifiers. Our result also implies that we can calibrate confidence measures produced by any existing algorithms with monotonic functions, and still get the same generalization guarantee on consistency.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Why do linear SVMs trained on HOG features perform so well?\nAbstract: Linear Support Vector Machines trained on HOG features are now a de facto standard across many visual perception tasks. Their popularisation can largely be attributed to the step-change in performance they brought to pedestrian detection, and their subsequent successes in deformable parts models. This paper explores the interactions that make the HOG-SVM symbiosis perform so well. By connecting the feature extraction and learning processes rather than treating them as disparate plugins, we show that HOG features can be viewed as doing two things: (i) inducing capacity in, and (ii) adding prior to a linear SVM trained on pixels. From this perspective, preserving second-order statistics and locality of interactions are key to good performance. We demonstrate surprising accuracy on expression recognition and pedestrian detection tasks, by assuming only the importance of preserving such local second-order interactions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: HSR: \u2044 Regularized Sparse Representation for Fast Face Recognition using Hierarchical Feature Selection\nAbstract: In this paper, we propose a novel method for fast face recognition called \u2044 Regularized Sparse Representation using Hierarchical Feature Selection (HSR). By employing hierarchical feature selection, we can compress the scale and dimension of global dictionary, which directly contributes to the decrease of computational cost in sparse representation that our approach is strongly rooted in. It consists of Gabor wavelets and Extreme Learning Machine Auto-Encoder (ELM-AE) hierarchically. For Gabor wavelets part, local features can be extracted at multiple scales and orientations to form Gabor-feature based image, which in turn improves the recognition rate. Besides, in the presence of occluded face image, the scale of Gabor-feature based global dictionary can be compressed accordingly because redundancies exist in Gabor-feature based occlusion dictionary. For ELM-AE part, the dimension of Gabor-feature based global dictionary can be compressed because high-dimensional face images can be rapidly represented by low-dimensional feature. By introducing \u2044 regularization, our approach can produce sparser and more robust representation compared to regularized Sparse Representation based Classification (SRC), which also contributes to the decrease of the computational cost in sparse representation. In comparison with related work such as SRC and Gaborfeature based SRC (GSRC), experimental results on a variety of face databases demonstrate the great advantage of our method for computational cost. Moreover, we also achieve approximate or even better recognition rate.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood\nAbstract: Our goal is to learn a semantic parser that maps natural language utterances into executable programs when only indirect supervision is available: examples are labeled with the correct execution result, but not the program itself. Consequently, we must search the space of programs for those that output the correct result, while not being misled by spurious programs: incorrect programs that coincidentally output the correct result. We connect two common learning paradigms, reinforcement learning (RL) and maximum marginal likelihood (MML), and then present a new learning algorithm that combines the strengths of both. The new algorithm guards against spurious programs by combining the systematic search traditionally employed in MML with the randomized exploration of RL, and by updating parameters such that probability is spread more evenly across consistent programs. We apply our learning algorithm to a new neural semantic parser and show significant gains over existing state-of-theart results on a recent context-dependent semantic parsing task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: What do We Learn by Semantic Scene Understanding for Remote Sensing imagery in CNN framework?\nAbstract: Recently, deep convolutional neural network (DCNN) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition. Compared with the natural image, the scale of remote sensing image is larger and the scene and the object it represents are more macroscopic. This study inquires whether remote sensing scene and natural scene recognitions differ and raises the following questions: What are the key factors in remote sensing scene recognition? Is the DCNN recognition mechanism centered on object recognition still applicable to the scenarios of remote sensing scene understanding? We performed several experiments to explore the influence of the DCNN structure and the scale of remote sensing scene understanding from the perspective of scene complexity. Our experiment shows that understanding a complex scene depends on an in-depth network and multiple-scale perception. Using a visualization method, we qualitatively and quantitatively analyze the recognition mechanism in a complex remote sensing scene and demonstrate the importance of multi-objective joint semantic support.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Non-adaptive Group Testing on Graphs\nAbstract: Grebinski and Kucherov (1998) and Alon et al. (2004-2005) studied the problem of learning a hidden graph for some especial cases, such as hamiltonian cycle, cliques, stars, and matchings, which was motivated by some problems in chemical reactions, molecular biology and genome sequencing. The present study aimed to present a generalization of this problem. Graphs G and H were considered, by assuming that G includes exactly one defective subgraph isomorphic to H . The purpose is to find the defective subgraph by performing the minimum non-adaptive tests, where each test is an induced subgraph of the graph G and the test is positive in the case of involving at least one edge of the defective subgraph H . We present an upper bound for the number of non-adaptive tests to find the defective subgraph by using the symmetric and high probability variation of Lov\u00e1sz Local Lemma. Finally, we present a nonadaptive randomized algorithm to find defective subgraph by at most 3 2 times of this upper bound with high probability.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: PARTICIPATION ANTICIPATING INELECTIONS USINGDATAMININGMETHODS\nAbstract: Anticipating the political behavior of people will be considerable help for election candidates to assess the possibility of their success and to be acknowledged about the public motivations to select them. In this paper, we provide a general schematic of the architecture of participation anticipating system in presidential election by using KNN, Classification Tree and Na\u00efve Bayes and tools orange based on crisp which had hopeful output. To test and assess the proposed model, we begin to use the case study by selecting 100 qualified persons who attend in 11th presidential election of Islamic republic of Iran and anticipate their participation in Kohkiloye & Boyerahmad. We indicate that KNN can perform anticipation and classification processes with high accuracy in compared with two other algorithms to anticipate participation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\nAbstract: Visual question answering (QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (i.e. the correct one) and the decoys (i.e. the incorrect ones). Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets. In particular, the resulting learner can ignore the visual information, the question, or the both while still doing well on the task. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular visual QA datasets as well as to create a new visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via http://www.teds.usc.edu/website_vqa/.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Embedding Deep Metric for Person Re-identification: A Study Against Large Variations\nAbstract: Person re-identification is challenging due to the large variations of pose, illumination, occlusion and camera view. Owing to these variations, the pedestrian data is distributed as highly-curved manifolds in the feature space, despite the current convolutional neural networks (CNN)\u2019s capability of feature extraction. However, the distribution is unknown, so it is difficult to use the geodesic distance when comparing two samples. In practice, the current deep embedding methods use the Euclidean distance for the training and test. On the other hand, the manifold learning methods suggest to use the Euclidean distance in the local range, combining with the graphical relationship between samples, for approximating the geodesic distance. From this point of view, selecting suitable positive (i.e. intra-class) training samples within a local range is critical for training the CNN embedding, especially when the data has large intra-class variations. In this paper, we propose a novel moderate positive sample mining method to train robust CNN for person re-identification, dealing with the problem of large variation. In addition, we improve the learning by a metric weight constraint, so that the learned metric has a better generalization ability. Experiments show that these two strategies are effective in learning robust deep metrics for person re-identification, and accordingly our deep model significantly outperforms the state-of-the-art methods on several benchmarks of person re-identification. Therefore, the study presented in this paper may be useful in inspiring new designs of deep models for person re-identification.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Robobarista: Learning to Manipulate Novel Objects via Deep Multimodal Embedding\nAbstract: There is a large variety of objects and appliances in human environments, such as stoves, coffee dispensers, juice extractors, and so on. It is challenging for a roboticist to program a robot for each of these object types and for each of their instantiations. In this work, we present a novel approach to manipulation planning based on the idea that many household objects share similarly-operated object parts. We formulate the manipulation planning as a structured prediction problem and learn to transfer manipulation strategy across different objects by embedding point-cloud, natural language, and manipulation trajectory data into a shared embedding space using a deep neural network. In order to learn semantically meaningful spaces throughout our network, we introduce a method for pre-training its lower layers for multimodal feature embedding and a method for fine-tuning this embedding space using a loss-based margin. In order to collect a large number of manipulation demonstrations for different objects, we develop a new crowd-sourcing platform called Robobarista. We test our model on our dataset consisting of 116 objects and appliances with 249 parts along with 250 language instructions, for which there are 1225 crowd-sourced manipulation demonstrations. We further show that our robot with our model can even prepare a cup of a latte with appliances it has never seen before.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bolasso: Model Consistent Lasso Estimation through the Bootstrap\nAbstract: We consider the least-square linear regression problem with regularization by the l1-norm, a problem usually referred to as the Lasso. In this paper, we present a detailed asymptotic analysis of model consistency of the Lasso. For various decays of the regularization parameter, we compute asymptotic equivalents of the probability of correct model selection (i.e., variable selection). For a specific rate decay, we show that the Lasso selects all the variables that should enter the model with probability tending to one exponentially fast, while it selects all other variables with strictly positive probability. We show that this property implies that if we run the Lasso for several bootstrapped replications of a given sample, then intersecting the supports of the Lasso bootstrap estimates leads to consistent model selection. This novel variable selection algorithm, referred to as the Bolasso, is compared favorably to other linear regression methods on synthetic data and datasets from the UCI machine learning repository.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Abstract This paper addresses the problem of non-Bayesian learning over multi-agent networks, where agents repeatedly collect partially informative observations about an unknown state of the world, and try to collaboratively learn the true state. We focus on the impact of the adversarial agents on the performance of consensus-based non-Bayesian learning, where non-faulty agents combine local learning updates with consensus primitives. In particular, we consider the scenario where an unknown subset of agents suffer Byzantine faults \u2013 agents suffering Byzantine faults behave arbitrarily.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Past, Present, Future: A Computational Investigation of the Typology of Tense in 1000 Languages\nAbstract: We present SuperPivot, an analysis<lb>method for low-resource languages that<lb>occur in a superparallel corpus, i.e., in a<lb>corpus that contains an order of magni-<lb>tude more languages than parallel corpora<lb>currently in use. We show that SuperPivot<lb>performs well for the crosslingual analysis<lb>of the linguistic phenomenon of tense.<lb>We produce analysis results for more than<lb>1000 languages, conducting \u2013 to the best<lb>of our knowledge \u2013 the largest crosslin-<lb>gual computational study performed to<lb>date. We extend existing methodology for<lb>leveraging parallel corpora for typological<lb>analysis by overcoming a limiting as-<lb>sumption of earlier work: We only require<lb>that a linguistic feature is overtly marked<lb>in a few of thousands of languages as<lb>opposed to requiring that it be marked in<lb>all languages under investigation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: GEOMETRIC TIGHT FRAME BASED STYLOMETRY FOR ART AUTHENTICATION OF VAN GOGH PAINTINGS\nAbstract: This paper is about authenticating genuine van Gogh paintings from forgeries. The authentication process depends on two key steps: feature extraction and outlier detection. In this paper, a geometric tight frame and some simple statistics of the tight frame coefficients are used to extract features from the paintings. Then a forward stage-wise rank boosting is used to select a small set of features for more accurate classification so that van Gogh paintings are highly concentrated towards some center point while forgeries are spread out as outliers. Numerical results show that our method can achieve 86.08% classification accuracy under the leave-one-out cross-validation procedure. Our method also identifies five features that are much more predominant than other features. Using just these five features for classification, our method can give 88.61% classification accuracy which is the highest so far reported in literature. Evaluation of the five features is also performed on two hundred datasets generated by bootstrap sampling with replacement. The median and the mean are 88.61% and 87.77% respectively. Our results show that a small set of statistics of the tight frame coefficients along certain orientations can serve as discriminative features for van Gogh paintings. It is more important to look at the tail distributions of such directional coefficients than mean values and standard deviations. It reflects a highly consistent style in van Gogh\u2019s brushstroke movements, where many forgeries demonstrate a more diverse spread in these features.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Robust Semi-Supervised Graph Classifier Learning with Negative Edge Weights\nAbstract: In a semi-supervised learning scenario, (possibly noisy) partially observed labels are used as input to train a classifier, in order to assign labels to unclassified samples. In this paper, we study this classifier learning problem from a graph signal processing (GSP) perspective. Specifically, by viewing a binary classifier as a piecewise constant graph-signal in a highdimensional feature space, we cast classifier learning as a signal restoration problem via a classical maximum a posteriori (MAP) formulation. Unlike previous graph-signal restoration works, we consider in addition edges with negative weights that signify anti-correlation between samples. One unfortunate consequence is that the graph Laplacian matrix L can be indefinite, and previously proposed graph-signal smoothness prior xLx for candidate signal x can lead to pathological solutions. In response, we derive an optimal perturbation matrix \u2206\u2014based on a fast lower-bound computation of the minimum eigenvalue of L via a novel application of the Haynsworth inertia additivity formula\u2014 so that L + \u2206 is positive semi-definite, resulting in a stable signal prior. Further, instead of forcing a hard binary decision for each sample, we define the notion of generalized smoothness on graph that promotes ambiguity in the classifier signal. Finally, we propose an algorithm based on iterative reweighted least squares (IRLS) that solves the posed MAP problem efficiently. Extensive simulation results show that our proposed algorithm outperforms both SVM variants and graph-based classifiers using positiveedge graphs noticeably.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adversarial and Clean Data Are Not Twins\nAbstract: Adversarial attack has cast a shadow on the massive success of deep neural networks. Despite being almost visually identical to the clean data, the adversarial images can fool deep neural networks into wrong predictions with very high confidence. In this paper, however, we show that we can build a simple binary classifier separating the adversarial apart from the clean data with accuracy over 99%. We also empirically show that the binary classifier is robust to a secondround adversarial attack. In other words, it is difficult to disguise adversarial samples to bypass the binary classifier. Further more, we empirically investigate the generalization limitation which lingers on all current defensive methods, including the binary classifier approach. And we hypothesize that this is the result of intrinsic property of adversarial crafting algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Ternary Neural Networks with Fine-Grained Quantization\nAbstract: We propose a novel fine-grained quantization (FGQ) method to ternarize pretrained full precision models, while also constraining activations to 8 and 4-bits. Using this method, we demonstrate minimal loss in classification accuracy on state-of-the-art topologies without additional training. We provide an improved theoretical formulation that forms the basis for a higher quality solution using FGQ. Our method involves ternarizing the original weight tensor in groups of N weights. Using N = 4, we achieve Top-1 accuracy within 3.7% and 4.2% of the baseline full precision result for Resnet-101 and Resnet-50 respectively, while eliminating 75% of all multiplications. These results enable a full 8/4-bit inference pipeline, with best reported accuracy using ternary weights on ImageNet dataset, with a potential of 9\u00d7 improvement in performance. Also, for smaller networks like AlexNet, FGQ achieves state-of-the-art results. We further study the impact of group size on both performance and accuracy. With a group size of N = 64, we eliminate \u2248 99% of the multiplications; however, this introduces a noticeable drop in accuracy, which necessitates fine tuning the parameters at lower precision. We address this by fine-tuning Resnet-50 with 8-bit activations and ternary weights at N = 64, improving the Top-1 accuracy to within 4% of the full precision result with < 30% additional training overhead. Our final quantized model can run on a full 8-bit compute pipeline using 2-bit weights and has the potential of up to 15\u00d7 improvement in performance compared to baseline full-precision models.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EXPLORING LOSS FUNCTION TOPOLOGY WITH CYCLICAL LEARNING RATES\nAbstract: We present observations and discussion of previously unreported phenomena discovered while training residual networks. The goal of this work is to better understand the nature of neural networks through the examination of these new empirical results.1 These behaviors were identified through the application of Cyclical Learning Rates (CLR) and linear network interpolation. Among these behaviors are counterintuitive increases and decreases in training loss and instances of rapid training. For example, we demonstrate how CLR can produce greater testing accuracy than traditional training despite using large learning rates.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bandit Structured Prediction for Learning from Partial Feedback in Statistical Machine Translation\nAbstract: We present an approach to structured prediction from bandit feedback, called Bandit Structured Prediction, where only the value of a task loss function at a single predicted point, instead of a correct structure, is observed in learning. We present an application to discriminative reranking in Statistical Machine Translation (SMT) where the learning algorithm only has access to a 1 \u2212 BLEU loss evaluation of a predicted translation instead of obtaining a gold standard reference translation. In our experiment bandit feedback is obtained by evaluating BLEU on reference translations without revealing them to the algorithm. This can be thought of as a simulation of interactive machine translation where an SMT system is personalized by a user who provides single point feedback to predicted translations. Our experiments show that our approach improves translation quality and is comparable to approaches that employ more informative feedback in learning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We review the task of Sentence Pair Scoring, popular in the literature in various forms \u2014 slanted as Answer Sentence Selection, Paraphrasing, Semantic Text Scoring, Next Utterance Ranking, Recognizing Textual Entailment or e.g. a component of Memory Networks. We argue that such tasks are similar from the model perspective (especially in the context of high-capacity deep neural models) and propose new baselines by comparing the performance of popular convolutional, recurrent and attentionbased neural models across many Sentence Pair Scoring tasks and datasets. We discuss the problem of evaluating randomized models, propose a statistically grounded methodology, and attempt to improve comparisons by releasing new datasets that are much harder than some of the currently used well explored benchmarks. To address the current research fragmentation in a future-proof way, we introduce a unified open source software framework with easily pluggable models, allowing easy evaluation on a wide range of semantic natural language tasks. This allows us to outline a path towards a universal machine learned semantic model for machine reading tasks. We support this plan by experiments that demonstrate reusability of models trained on different tasks, even across corpora of very different nature.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Infinite Restricted Boltzmann Machine\nAbstract: We present a mathematical construction for the restricted Boltzmann machine (RBM) in which the hidden layer size is adaptive and can grow during training. This is obtained by first extending the RBM to be sensitive to the ordering of its hidden units. Then, thanks to a carefully chosen definition of the energy function, we show that the limit of infinitely many hidden units is well defined. As in a regular RBM, approximate maximum likelihood training can be performed, resulting in an algorithm that naturally and adaptively adds trained hidden units during learning. We empirically study the behaviour of this infinite RBM, showing that its performance is competitive to that of the RBM.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Incorporating Causal Prior Knowledge as Path-Constraints in Bayesian Networks and Maximal Ancestral Graphs\nAbstract: We consider the incorporation of causal knowledge about the presence or absence of (possibly indirect) causal relations into a causal model. Such causal relations correspond to directed paths in a causal model. This type of knowledge naturally arises from experimental data, among others. Specifically, we consider the formalisms of Causal Bayesian Networks and Maximal Ancestral Graphs and their Markov equivalence classes: Partially Directed Acyclic Graphs and Partially Oriented Ancestral Graphs. We introduce sound and complete procedures which are able to incorporate causal prior knowledge in such models. In simulated experiments, we show that often considering even a few causal facts leads to a significant number of new inferences. In a case study, we also show how to use real experimental data to infer causal knowledge and incorporate it into a real biological causal network. The code is available at mensxmachina.org.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Robust PCA via Outlier Pursuit\nAbstract: Singular Value Decomposition (and Principal Component Analysis) is one of the most widely used techniques<lb>for dimensionality reduction: successful and efficiently computable, it is nevertheless plagued by a well-known,<lb>well-documented sensitivity to outliers. Recent work has considered the setting where each point has a few arbitrarily<lb>corrupted components. Yet, in applications of SVD or PCA such as robust collaborative filtering or bioinformatics,<lb>malicious agents, defective genes, or simply corrupted or contaminated experiments may effectively yield entire<lb>points that are completely corrupted.<lb>We present an efficient convex optimization-based algorithm we call Outlier Pursuit, that under some mild<lb>assumptions on the uncorrupted points (satisfied, e.g., by the standard generative assumption in PCA problems)<lb>recovers the exact optimal low-dimensional subspace, and identifies the corrupted points. Such identification of<lb>corrupted points that do not conform to the low-dimensional approximation, is of paramount interest in bioinfor-<lb>matics and financial applications, and beyond. Our techniques involve matrix decomposition using nuclear norm<lb>minimization, however, our results, setup, and approach, necessarily differ considerably from the existing line of<lb>work in matrix completion and matrix decomposition, since we develop an approach to recover the correct column<lb>space of the uncorrupted matrix, rather than the exact matrix itself.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Estimating Mixture Models via Mixtures of Polynomials\nAbstract: Mixture modeling is a general technique for making any simple model more expressive<lb>through weighted combination. This generality and simplicity in part explains the<lb>success of the Expectation Maximization (EM) algorithm, in which updates are easy<lb>to derive for a wide class of mixture models. However, the likelihood of a mixture<lb>model is non-convex, so EM has no known global convergence guarantees. Recently,<lb>method of moments approaches offer global guarantees for some mixture models, but<lb>they do not extend easily to the range of mixture models that exist. In this work, we<lb>present Polymom, an unifying framework based on method of moments in which es-<lb>timation procedures are easily derivable, just as in EM. Polymom is applicable when<lb>the moments of a single mixture component are polynomials of the parameters. Our<lb>key observation is that the moments of the mixture model are a mixture of these<lb>polynomials, which allows us to cast estimation as a Generalized Moment Problem.<lb>We solve its relaxations using semidefinite optimization, and then extract parame-<lb>ters using ideas from computer algebra. This framework allows us to draw insights<lb>and apply tools from convex optimization, computer algebra and the theory of mo-<lb>ments to study problems in statistical estimation. Simulations show good empirical<lb>performance on several models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Motivated by e-commerce, we study the online assortment optimization problem. The seller offers an assortment, i.e. a subset of products, to each arriving customer, who then purchases one or no product from her offered assortment. A customer\u2019s purchase decision is governed by the underlyingMultiNomial Logit (MNL) choice model. The seller aims to maximize the total revenue in a finite sales horizon, subject to resource constraints and uncertainty in the MNL choice model. We first propose an efficient online policy which incurs a regret \u00d5(T ), where T is the number of customers in the sales horizon. Then, we propose a UCB policy that achieves a regret \u00d5(T ). Both regret bounds are sublinear in the number of assortments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient PAC Learning from the Crowd\nAbstract: In recent years crowdsourcing has become the method of choice for gathering labeled training data for learning algorithms. Standard approaches to crowdsourcing view the process of acquiring labeled data separately from the process of learning a classifier from the gathered data. This can give rise to computational and statistical challenges. For example, in most cases there are no known computationally efficient learning algorithms that are robust to the high level of noise that exists in crowdsourced data, and efforts to eliminate noise through voting often require a large number of queries per example. In this paper, we show how by interleaving the process of labeling and learning, we can attain computational efficiency with much less overhead in the labeling cost. In particular, we consider the realizable setting where there exists a true target function in F and consider a pool of labelers. When a noticeable fraction of the labelers are perfect, and the rest behave arbitrarily, we show that any F that can be efficiently learned in the traditional realizable PAC model can be learned in a computationally efficient manner by querying the crowd, despite high amounts of noise in the responses. Moreover, we show that this can be done while each labeler only labels a constant number of examples and the number of labels requested per example, on average, is a constant. When no perfect labelers exist, a related task is to find a set of the labelers which are good but not perfect. We show that we can identify all good labelers, when at least the majority of labelers are good.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Variational Inference in the Conjugate Exponential Family\nAbstract: We present a general method for deriving collapsed variational inference algorithms for probabilistic models in the conjugate exponential family. Our method unifies many existing approaches to collapsed variational inference. Our collapsed variational inference leads to a new lower bound on the marginal likelihood. We exploit the information geometry of the bound to derive much faster optimization methods based on conjugate gradients for these models. Our approach is very general and is easily applied to any model where the mean field update equations have been derived. Empirically we show significant speed-ups for probabilistic inference using our bound.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: REINFORCEMENT LEARNING WITH UNSUPERVISED AUXILIARY TASKS\nAbstract: Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-theart on Atari, averaging 880% expert human performance, and a challenging suite of first-person, three-dimensional Labyrinth tasks leading to a mean speedup in learning of 10\u00d7 and averaging 87% expert human performance on Labyrinth. Natural and artificial agents live in a stream of sensorimotor data. At each time step t, the agent receives observations ot and executes actions at. These actions influence the future course of the sensorimotor stream. In this paper we develop agents that learn to predict and control this stream, by solving a host of reinforcement learning problems, each focusing on a distinct feature of the sensorimotor stream. Our hypothesis is that an agent that can flexibly control its future experiences will also be able to achieve any goal with which it is presented, such as maximising its future rewards. The classic reinforcement learning paradigm focuses on the maximisation of extrinsic reward. However, in many interesting domains, extrinsic rewards are only rarely observed. This raises questions of what and how to learn in their absence. Even if extrinsic rewards are frequent, the sensorimotor stream contains an abundance of other possible learning targets. Traditionally, unsupervised learning attempts to reconstruct these targets, such as the pixels in the current or subsequent frame. It is typically used to accelerate the acquisition of a useful representation. In contrast, our learning objective is to predict and control features of the sensorimotor stream, by treating them as pseudorewards for reinforcement learning. Intuitively, this set of tasks is more closely matched with the agent\u2019s long-term goals, potentially leading to more useful representations. Consider a baby that learns to maximise the cumulative amount of red that it observes. To correctly predict the optimal value, the baby must understand how to increase \u201credness\u201d by various means, including manipulation (bringing a red object closer to the eyes); locomotion (moving in front of a red object); and communication (crying until the parents bring a red object). These behaviours are likely to recur for many other goals that the baby may subsequently encounter. No understanding of these behaviours is required to simply reconstruct the redness of current or subsequent images. Our architecture uses reinforcement learning to approximate both the optimal policy and optimal value function for many different pseudo-rewards. It also makes other auxiliary predictions that serve to focus the agent on important aspects of the task. These include the long-term goal of predicting cumulative extrinsic reward as well as short-term predictions of extrinsic reward. To learn more efficiently, our agents use an experience replay mechanism to provide additional updates \u2217Joint first authors. Ordered alphabetically by first name. 1 ar X iv :1 61 1. 05 39 7v 1 [ cs .L G ] 1 6 N ov 2 01 6\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online and Stochastic Gradient Methods for Non-decomposable Loss Functions\nAbstract: Modern applications in sensitive domains such as biometrics and medicine frequently require the use of non-decomposable loss functions such as precision@k, F-measure etc. Compared to point loss functions such as hinge-loss, these offer much more fine grained control over prediction, but at the same time present novel challenges in terms of algorithm design and analysis. In this work we initiate a study of online learning techniques for such non-decomposable loss functions with an aim to enable incremental learning as well as design scalable solvers for batch problems. To this end, we propose an online learning framework for such loss functions. Our model enjoys several nice properties, chief amongst them being the existence of efficient online learning algorithms with sublinear regret and online to batch conversion bounds. Our model is a provable extension of existing online learning models for point loss functions. We instantiate two popular losses, Prec@k and pAUC, in our model and prove sublinear regret bounds for both of them. Our proofs require a novel structural lemma over ranked lists which may be of independent interest. We then develop scalable stochastic gradient descent solvers for non-decomposable loss functions. We show that for a large family of loss functions satisfying a certain uniform convergence property (that includes Prec@k, pAUC, and F-measure), our methods provably converge to the empirical risk minimizer. Such uniform convergence results were not known for these losses and we establish these using novel proof techniques. We then use extensive experimentation on real life and benchmark datasets to establish that our method can be orders of magnitude faster than a recently proposed cutting plane method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Removing systematic errors for exoplanet search via latent causes\nAbstract: We describe a method for removing the effect of confounders in order to reconstruct a latent quantity of interest. The method, referred to as halfsibling regression, is inspired by recent work in causal inference using additive noise models. We provide a theoretical justification and illustrate the potential of the method in a challenging astronomy application.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Simple Bayesian Algorithms for Best-Arm Identification\nAbstract: This paper considers the optimal adaptive allocation of measurement effort for identifying the best among a finite set of options or designs. An experimenter sequentially chooses designs to measure and observes noisy signals of their quality with the goal of confidently identifying the best design after a small number of measurements. This paper proposes three simple and intuitive Bayesian algorithms for adaptively allocating measurement effort, and formalizes a sense in which these seemingly naive rules are the best possible. One proposal is top-two probability sampling, which computes the two designs with the highest posterior probability of being optimal, and then randomizes to select among these two. One is a variant of top-two sampling which considers not only the probability a design is optimal, but the expected amount by which its quality exceeds that of other designs. The final algorithm is a modified version of Thompson sampling that is tailored for identifying the best design. We prove that these simple algorithms satisfy a sharp optimality property. In a frequentist setting where the true quality of the designs is fixed, one hopes the posterior definitively identifies the optimal design, in the sense that that the posterior probability assigned to the event that some other design is optimal converges to zero as measurements are collected. We show that under the proposed algorithms this convergence occurs at an exponential rate, and the corresponding exponent is the best possible among all allocation rules.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recent Advances in Convolutional Neural Networks\nAbstract: In the last few years, deep learning has lead to very good performance on a variety of problems, such as object recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Due to the lack of training data and computing power in early days, it is hard to train a large high-capacity convolutional neural network without overfitting. Recently, with the rapid growth of data size and the increasing power of graphics processor unit, many researchers have improved the convolutional neural networks and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. Besides, we also introduce some applications of convolutional neural networks in computer vision.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MEC: Memory-efficient Convolution for Deep Neural Network\nAbstract: Convolution is a critical component in modern deep neural networks, thus several algorithms for convolution have been developed. Direct convolution is simple but suffers from poor performance. As an alternative, multiple indirect methods have been proposed including im2colbased convolution, FFT-based convolution, or Winograd-based algorithm. However, all these indirect methods have high memory-overhead, which creates performance degradation and offers a poor trade-off between performance and memory consumption. In this work, we propose a memory-efficient convolution or MEC with compact lowering, which reduces memoryoverhead substantially and accelerates convolution process. MEC lowers the input matrix in a simple yet efficient/compact way (i.e., much less memory-overhead), and then executes multiple small matrix multiplications in parallel to get convolution completed. Additionally, the reduced memory footprint improves memory subsystem efficiency, improving performance. Our experimental results show that MEC reduces memory consumption significantly with good speedup on both mobile and server platforms, compared with other indirect convolution algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: K-Means Clustering using Tabu Search with Quantized Means\nAbstract: The Tabu Search (TS) metaheuristic has been proposed for K-Means clustering as an alternative to Lloyd\u2019s algorithm, which for all its ease of implementation and fast runtime, has the major drawback of being trapped at local optima. While the TS approach can yield superior performance, it involves a high computational complexity. Moreover, the difficulty in parameter selection in the existing TS approach does not make it any more attractive. This paper presents an alternative, low-complexity formulation of the TS optimization procedure for K-Means clustering. This approach does not require many parameter settings. We initially constrain the centers to points in the dataset. We then aim at evolving these centers using a unique neighborhood structure that makes use of gradient information of the objective function. This results in an efficient exploration of the search space, after which the means are refined. The proposed scheme is implemented in MATLAB and tested on four real-world datasets, and it achieves a significant improvement over the existing TS approach in terms of the intra cluster sum of squares and computational time.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Proliferation of advanced metering devices with high sampling rates in distribution grids, e.g., micro-phasor measurement units (\u03bcPMU), provides unprecedented potentials for wide-area monitoring and diagnostic applications, e.g., situational awareness, health monitoring of distribution assets. Unexpected disruptive events interrupting the normal operation of assets in distribution grids can eventually lead to permanent failure with expensive replacement cost over time. Therefore, disruptive event classification provides useful information for preventive maintenance of the assets in distribution networks. Preventive maintenance provides wide range of benefits in terms of time, avoiding unexpected outages, maintenance crew utilization, and equipment replacement cost. In this paper, a PMUdata-driven framework is proposed for classification of disruptive events in distribution networks. The two disruptive events, i.e., malfunctioned capacitor bank switching and malfunctioned regulator on-load tap changer (OLTC) switching are considered and distinguished from the normal abrupt load change in distribution grids. The performance of the proposed framework is verified using the simulation of the events in the IEEE 13-bus distribution network. The event classification is formulated using two different algorithms as; i) principle component analysis (PCA) together with multi-class support vector machine (SVM), and ii) autoencoder along with softmax classifier. The results demonstrate the effectiveness of the proposed algorithms and satisfactory classification accuracies.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Deep neural networks with millions of parameters are at the heart of many state of the art machine learning models today. However, recent works have shown that models with much smaller number of parameters can also perform just as well. In this work, we introduce the problem of architecture-learning, i.e; learning the architecture of a neural network along with weights. We introduce a new trainable parameter called tri-state ReLU, which helps in eliminating unnecessary neurons. We also propose a smooth regularizer which encourages the total number of neurons after elimination to be small. The resulting objective is differentiable and simple to optimize. We experimentally validate our method on both small and large networks, and show that it can learn models with a considerably small number of parameters without affecting prediction accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SEMI-SUPERVISED LEARNING WITH ENCODER- DECODER RECURRENT NEURAL NETWORKS: EX-\nAbstract: Recent work on sequence to sequence translation using Recurrent Neural Networks (RNNs) based on Long Short Term Memory (LSTM) architectures has shown great potential for learning useful representations of sequential data. These architectures, using one recurrent neural network to encode sequences into fixedlength representations, and one or more network(s) to decode representations into new sequences have the advantages of being modular, while also allowing modules to be jointly trained. A one-to-many encoder-decoder(s) scheme allows for a single encoder to provide representations serving multiple purposes. In our case, we present an LSTM encoder network able to produce representations used by two decoders: one that reconstructs, and one that classifies if the training sequence has a labelling. This allows the network to learn representations that are useful for both discriminative and generative tasks at the same time. We show how this paradigm is very well suited for semi-supervised learning with sequences. We test our proposed approach on an action recognition task using motion capture (MOCAP) sequences and show that semi-supervised feature learning can improve movement classification.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Addressing the Rare Word Problem in Neural Machine Translation\nAbstract: Neural Machine Translation (NMT) has recently attracted a lot of attention due to the very high performance achieved by deep neural networks in other domains. An inherent weakness in existing NMT systems is their inability to correctly translate rare words: end-to-end NMTs tend to have relatively small vocabularies with a single \u201cunknown-word\u201d symbol representing every possible out-of-vocabulary (OOV) word. In this paper, we propose and implement a simple technique to address this problem. We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to output, for each OOV word in the target sentence, its corresponding word in the source sentence. This information is later utilized in a post-processing step that translates every OOV word using a dictionary. Our experiments on the WMT\u201914 English to French translation task show that this simple method provides a substantial improvement over an equivalent NMT system that does not use this technique. The performance of our system achieves a BLEU score of 36.9, which improves the previous best end-to-end NMT by 2.1 points. Our model matches the performance of the state-of-the-art system while using three times less data.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: One-Shot Imitation Learning\nAbstract: Imitation learning has been commonly applied to solve different tasks in isolation. This usually requires either careful feature engineering, or a significant number of samples. This is far from what we desire: ideally, robots should be able to learn from very few demonstrations of any given task, and instantly generalize to new situations of the same task, without requiring task-specific engineering. In this paper, we propose a metalearning framework for achieving such capability, which we call one-shot imitation learning. Specifically, we consider the setting where there is a very large (maybe infinite) set of tasks, and each task has many instantiations. For example, a task could be to stack all blocks on a table into a single tower, another task could be to place all blocks on a table into two-block towers, etc. In each case, different instances of the task would consist of different sets of blocks with different initial states. At training time, our algorithm is presented with pairs of demonstrations for a subset of all tasks. A neural net is trained that takes as input one demonstration and the current state (which initially is the initial state of the other demonstration of the pair), and outputs an action with the goal that the resulting sequence of states and actions matches as closely as possible with the second demonstration. At test time, a demonstration of a single instance of a new task is presented, and the neural net is expected to perform well on new instances of this new task. Our experiments show that the use of soft attention allows the model to generalize to conditions and tasks unseen in the training data. We anticipate that by training this model on a much greater variety of tasks and settings, we will obtain a general system that can turn any demonstrations into robust policies that can accomplish an overwhelming variety of tasks. OpenAI University of California, Berkeley. Correspondence to: Yan Duan <rocky@openai.com>. Copyright 2017 by the author(s). One-shot policy. A single policy trained to solve many tasks. (left) Task-specific policy. This policy is trained to stack blocks into two towers, each of height 3. (right) A separate task-specific policy. This policy is trained to stack blocks into three towers, each of height 2. Figure 1. Traditionally, policies are task-specific. For example, a policy might have been trained (through imitation or reinforcement learning) to stack blocks into towers of height 3, and then another policy would be trained to stack blocks into towers of height 2, etc. In this paper, we are interested in policies that are not specific to one task, but rather can be told (through a single demonstration) what the current new task is, and be successful at this new task. As illustrative examples, we would want to be able to provide a single demonstration of each task, and from that the one-shot policy would know what to do when faced with a new situation of the task, where the blocks are randomly rearranged. Videos of the illustrated tasks are available at http://bit.ly/one-shot-imitation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A COMPARISON ON AUDIO SIGNAL PREPROCESSING METHODS FOR DEEP NEURAL NETWORKS ON MUSIC TAGGING\nAbstract: Deep neural networks (DNN) have been successfully applied for music classification tasks including music tagging. In this paper, we investigate the effect of audio preprocessing on music tagging with neural networks. We perform comprehensive experiments involving audio preprocessing using different time-frequency representations, logarithmic magnitude compression, frequency weighting and scaling. We show that many commonly used input preprocessing techniques are redundant except magnitude compression.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Consensus-Based Modelling using Distributed Feature Construction\nAbstract: A particularly successful role for Inductive Logic Programming (ILP) is as a tool for discovering useful relational features for subsequent use in a predictive model. Conceptually, the case for using ILP to construct relational features rests on treating these features as functions, the automated discovery of which necessarily requires some form of first-order learning. Practically, there are now several reports in the literature that suggest that augmenting any existing features with ILPdiscovered relational features can substantially improve the predictive power of a model. While the approach is straightforward enough, much still needs to be done to scale it up to explore more fully the space of possible features that can be constructed by an ILP system. This is in principle, infinite and in practice, extremely large. Applications have been confined to heuristic or random selections from this space. In this paper, we address this computational difficulty by allowing features to be constructed in a distributed manner. That is, there is a network of computational units, each of which employs an ILP engine to construct some small number of features and then builds a (local) model. We then employ a consensus-based algorithm, in which neighbouring nodes share information to update local models. For a category of models (those with convex loss functions), it can be shown that the algorithm will result in all nodes converging to a consensus model. In practice, it may be slow to achieve this convergence. Nevertheless, our results on synthetic and real datasets that suggests that in relatively short time the \u201cbest\u201d node in the network reaches a model whose predictive accuracy is comparable to that obtained using more computational effort in a non-distributed setting (the best node is identified as the one whose weights converge first). ? A short 6-page version of this paper was presented at the 24th International Conference on Inductive Logic Programming, held in conjunction with ECML PKDD, France. Furthermore, a significant part of the work in this paper was done when the first author was an Associate Research Scientist at the Center for Computational Learning Systems (CCLS), Columbia University, NY. ar X iv :1 40 9. 34 46 v1 [ cs .L G ] 1 1 Se p 20 14 2 Haimonti Dutta and Ashwin Srinivasan\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to Generate with Memory\nAbstract: Memory units have been widely used to enrich the capabilities of deep networks on capturing long-term dependencies in reasoning and prediction tasks, but little investigation exists on deep generative models (DGMs) which are good at inferring high-level invariant representations from unlabeled data. This paper presents a deep generative model with a possibly large external memory and an attention mechanism to capture the local detail information that is often lost in the bottom-up abstraction process in representation learning. By adopting a smooth attention model, the whole network is trained end-to-end by optimizing a variational bound of data likelihood via auto-encoding variational Bayesian methods, where an asymmetric recognition network is learnt jointly to infer high-level invariant representations. The asymmetric architecture can reduce the competition between bottom-up invariant feature extraction and top-down generation of instance details. Our experiments on several datasets demonstrate that memory can significantly boost the performance of DGMs on various tasks, including density estimation, image generation, and missing value imputation, and DGMs with memory can achieve state-ofthe-art quantitative results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Kernel-Based Halfspaces with the Zero-One Loss\nAbstract: <lb>We describe and analyze a new algorithm for agnostically learning kernel-based halfspaces<lb>with respect to the zero-one loss function. Unlike most previous formulations which rely on<lb>surrogate convex loss functions (e.g. hinge-loss in SVM and log-loss in logistic regression),<lb>we provide finite time/sample guarantees with respect to the more natural zero-one loss<lb>function. The proposed algorithm can learn kernel-based halfspaces in worst-case time<lb>poly(exp(L log(L/\u01eb))), for any distribution, where L is a Lipschitz constant (which can be<lb>thought of as the reciprocal of the margin), and the learned classifier is worse than the<lb>optimal halfspace by at most \u01eb. We also prove a hardness result, showing that under a<lb>certain cryptographic assumption, no algorithm can learn kernel-based halfspaces in time<lb>polynomial in L.<lb>\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Visualization Regularizers for Neural Network based Image Recognition\nAbstract: The success of deep neural networks is mostly due their ability to learn meaningful features from the data. Features learned in the hidden layers of deep neural networks trained in computer vision tasks have been shown to be similar to midlevel vision features. We leverage this fact in this work and propose the visualization regularizer for image tasks. The proposed regularization technique enforces smoothness of the features learned by hidden nodes and turns out to be a special case of Tikhonov regularization. We achieve higher classification accuracy as compared to existing regularizers such as the L2 norm regularizer and dropout, on benchmark datasets with no change in the training computational complexity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Provable Alternating Gradient Descent for Non-negative Matrix Factorization with Strong Correlations\nAbstract: Non-negative matrix factorization is a basic tool for decomposing data into the feature and weight matrices under non-negativity constraints, and in practice is often solved in the alternating minimization framework. However, it is unclear whether such algorithms can recover the groundtruth feature matrix when the weights for different features are highly correlated, which is common in applications. This paper proposes a simple and natural alternating gradient descent based algorithm, and shows that with a mild initialization it provably recovers the ground-truth in the presence of strong correlations. In most interesting cases, the correlation can be in the same order as the highest possible. Our analysis also reveals its several favorable features including robustness to noise. We complement our theoretical results with empirical studies on semi-synthetic datasets, demonstrating its advantage over several popular methods in recovering the groundtruth.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Error-Correcting Factorization\nAbstract: Error Correcting Output Codes (ECOC) is a successful technique in multi-class classification, which is a core problem in Pattern Recognition and Machine Learning. A major advantage of ECOC over other methods is that the multi-class problem is decoupled into a set of binary problems that are solved independently. However, literature defines a general error-correcting capability for ECOCs without analyzing how it distributes among classes, hindering a deeper analysis of pairwise error-correction. To address these limitations this paper proposes an Error-Correcting Factorization (ECF) method, our contribution is three fold: (I) We propose a novel representation of the error-correction capability, called the design matrix, that enables us to build an ECOC on the basis of allocating correction to pairs of classes. (II) We derive the optimal code length of an ECOC using rank properties of the design matrix. (III) ECF is formulated as a discrete optimization problem, and a relaxed solution is found using an efficient constrained block coordinate descent approach. (IV) Enabled by the flexibility introduced with the design matrix we propose to allocate the error-correction on classes that are prone to confusion. Experimental results in several databases show that when allocating the error-correction to confusable classes ECF outperforms state-of-the-art approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Functional magnetic resonance imaging produces high dimensional data, with a less then ideal number of labelled samples for brain decoding tasks (predicting brain states). In this study, we propose a new deep temporal convolutional neural network architecture with spatial pooling for brain decoding which aims to reduce dimensionality of feature space along with improved classification performance. Temporal representations (filters) for each layer of the convolutional model are learned by leveraging unlabelled fMRI data in an unsupervised fashion with regularized autoencoders. Learned temporal representations in multiple levels capture the regularities in the temporal domain and are observed to be a rich bank of activation patterns which also exhibit similarities to the actual hemodynamic responses. Further, spatial pooling layers in the convolutional architecture reduce the dimensionality without losing excessive information. By employing the proposed temporal convolutional architecture with spatial pooling, raw input fMRI data is mapped to a non-linear, highly-expressive and low-dimensional feature space where the final classification is conducted. In addition, we propose a simple heuristic approach for hyper-parameter tuning when no validation data is available. Proposed method is tested on a ten class recognition memory experiment with nine subjects. The results support the efficiency and potential of the proposed model, compared to the baseline multi-voxel pattern analysis techniques.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Provable Efficient Online Matrix Completion via Non-convex Stochastic Gradient Descent\nAbstract: Matrix completion, where we wish to recover a low rank matrix by observing a few entries from it, is a widely studied problem in both theory and practice with wide applications. Most of the provable algorithms so far on this problem have been restricted to the offline setting where they provide an estimate of the unknown matrix using all observations simultaneously. However, in many applications, the online version, where we observe one entry at a time and dynamically update our estimate, is more appealing. While existing algorithms are efficient for the offline setting, they could be highly inefficient for the online setting. In this paper, we propose the first provable, efficient online algorithm for matrix completion. Our algorithm starts from an initial estimate of the matrix and then performs non-convex stochastic gradient descent (SGD). After every observation, it performs a fast update involving only one row of two tall matrices, giving near linear total runtime. Our algorithm can be naturally used in the offline setting as well, where it gives competitive sample complexity and runtime to state of the art algorithms. Our proofs introduce a general framework to show that SGD updates tend to stay away from saddle surfaces and could be of broader interests for other non-convex problems to prove tight rates.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Aspect-based Opinion Summarization with Convolutional Neural Networks\nAbstract: This paper considers Aspect-based Opinion Summarization (AOS) of reviews on particular products. To enable real applications, an AOS system needs to address two core subtasks, aspect extraction and sentiment classification. Most existing approaches to aspect extraction, which use linguistic analysis or topic modelling, are general across different products but not precise enough or suitable for particular products. Instead we take a less general but more precise scheme, directly mapping each review sentence into pre-defined aspects. To tackle aspect mapping and sentiment classification, we propose two Convolutional Neural Network (CNN) based methods, cascaded CNN and multitask CNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNs at level 1 deal with aspect mapping task, and a single CNN at level 2 deals with sentiment classification. Multitask CNN also contains multiple aspect CNNs and a sentiment CNN, but different networks share the same word embeddings. Experimental results indicate that both cascaded and multitask CNNs outperform SVM-based methods by large margins. Multitask CNN generally performs better than cascaded CNN.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sparse hierarchical interaction learning with epigraphical projection\nAbstract: This work focus on regression optimization problem with hierarchical interactions between variables, which is beyond the additive models in the traditional linear regression. We investigate more specifically two different fashions encountered in the literature to deal with this problem: \u201chierNet\u201d and structural-sparsity regularization, and study their connections. We propose a primal-dual proximal algorithm based on epigraphical projection to optimize a general formulation of this learning problem. The experimental setting first highlights the improvement of the proposed procedure compared to state-of-the-art methods based on fast iterative shrinkage-thresholding algorithm (i.e. FISTA) or alternating direction method of multipliers (i.e. ADMM) and second we provide fair comparisons between the different hierarchical penalizations. The experiments are conducted both on the synthetic and real data, and they clearly show that the proposed primal-dual proximal algorithm based on epigraphical projection is efficient and effective to solve and investigate the question of the hierarchical interaction learning problem.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dynamic ad allocation: bandits with budgets\nAbstract: We consider an application of multi-armed bandits to internet advertising (specifically, to dynamic ad allocation in the pay-per-click model, with uncertainty on the click probabilities). We focus on an important practical issue that advertisers are constrained in how much money they can spend on their ad campaigns. This issue has not been considered in the prior work on bandit-based approaches for ad allocation, to the best of our knowledge. We define a simple, stylized model where an algorithm picks one ad to display in each round, and each ad has a budget: the maximal amount of money that can be spent on this ad. This model admits a natural variant of UCB1, a well-known algorithm for multi-armed bandits with stochastic rewards. We derive strong provable guarantees for this algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Policy Invariance under Reward Transformations for General-Sum Stochastic Games\nAbstract: We extend the potential-based shaping method from Markov decision processes to multi-player general-sum stochastic games. We prove that the Nash equilibria in a stochastic game remains unchanged after potential-based shaping is applied to the environment. The property of policy invariance provides a possible way of speeding convergence when learning to play a stochastic game.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exponential Family Matrix Completion under Structural Constraints\nAbstract: We consider the matrix completion problem of recovering a structured matrix from noisy and partial measurements. Recent works have proposed tractable estimators with strong statistical guarantees for the case where the underlying matrix is low\u2013rank, and the measurements consist of a subset, either of the exact individual entries, or of the entries perturbed by additive Gaussian noise, which is thus implicitly suited for thin\u2013tailed continuous data. Arguably, common applications of matrix completion require estimators for (a) heterogeneous data\u2013types, such as skewed\u2013continuous, count, binary, etc., (b) for heterogeneous noise models (beyond Gaussian), which capture varied uncertainty in the measurements, and (c) heterogeneous structural constraints beyond low\u2013rank, such as block\u2013sparsity, or a superposition structure of low\u2013rank plus elementwise sparseness, among others. In this paper, we provide a vastly unified framework for generalized matrix completion by considering a matrix completion setting wherein the matrix entries are sampled from any member of the rich family of exponential family distributions; and impose general structural constraints on the underlying matrix, as captured by a decomposable norm regularizer R(.). We propose a simple convex regularized M\u2013estimator for this generalized framework, and provide a unified and novel statistical analysis for this class of estimators. We finally corroborate our theoretical results on simulated datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In recent years, attention has been focused on the relationship between black box optimization and reinforcement learning. Black box optimization is a framework for the problem of finding the input that optimizes the output represented by an unknown function. Reinforcement learning, by contrast, is a framework for finding a policy to optimize the expected cumulative reward from trial and error. In this research, we propose a reinforcement learning algorithm based on the mirror descent method, which is general optimization algorithm. The proposed method is called Mirror Descent Search. The contribution of this research is roughly twofold. First, an extension method for mirror descent can be applied to reinforcement learning and such a method is here considered. Second, the relationship between existing reinforcement learning algorithms is clarified. Based on these, we propose Mirror Descent Search and derivative methods. The experimental results show that learning with the proposed method progresses faster.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A 128 channel Extreme Learning Machine based Neural Decoder for Brain Machine Interfaces\nAbstract: Currently, state-of-the-art motor intention decoding algorithms in brain-machine interfaces are mostly implemented on a PC and consume significant amount of power. A machine learning co-processor in 0.35\u03bcm CMOS for motor intention decoding in brain-machine interfaces is presented in this paper. Using Extreme Learning Machine algorithm and low-power analog processing, it achieves an energy efficiency of 3.45 pJ/MAC at a classification rate of 50 Hz. The learning in second stage and corresponding digitally stored coefficients are used to increase robustness of the core analog processor. The chip is verified with neural data recorded in monkey finger movements experiment, achieving a decoding accuracy of 99.3% for movement type. The same co-processor is also used to decode time of movement from asynchronous neural spikes. With time-delayed feature dimension enhancement, the classification accuracy can be increased by 5% with limited number of input channels. Further, a sparsity promoting training scheme enables reduction of number of programmable weights by \u2248 2X .\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards a continuous modeling of natural language domains\nAbstract: Humans continuously adapt their style and language to a variety of domains. However, a reliable definition of \u2018domain\u2019 has eluded researchers thus far. Additionally, the notion of discrete domains stands in contrast to the multiplicity of heterogeneous domains that humans navigate, many of which overlap. In order to better understand the change and variation of human language, we draw on research in domain adaptation and extend the notion of discrete domains to the continuous spectrum. We propose representation learningbased models that can adapt to continuous domains and detail how these can be used to investigate variation in language. To this end, we propose to use dialogue modeling as a test bed due to its proximity to language modeling and its social component.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Counter-fitting Word Vectors to Linguistic Constraints\nAbstract: In this work, we present a novel counter-fitting method which injects antonymy and synonymy constraints into vector space representations in order to improve the vectors\u2019 capability for judging semantic similarity. Applying this method to publicly available pre-trained word vectors leads to a new state of the art performance on the SimLex-999 dataset. We also show how the method can be used to tailor the word vector space for the downstream task of dialogue state tracking, resulting in robust improvements across different dialogue domains.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network\nAbstract: We present a neural network architecture and training method designed to enable very rapid training and low implementation complexity. Due to its training speed and very few tunable parameters, the method has strong potential for embedded hardware applications requiring frequent retraining or online training. The approach is characterized by (a) convolutional filters based on biologically inspired visual processing filters, (b) randomly-valued classifier-stage input weights, (c) use of least squares regression to train the classifier output weights in a single batch, and (d) linear classifier-stage output units. We demonstrate the efficacy of the method as an image classifier, obtaining state-of-the-art results on the MNIST (0.37% error) and NORB-small (2.2%) image classification databases, with very fast training times compared to standard deep network approaches. The network\u2019s performance on the Google Street View House Number (SVHN) (4%) database is also competitive with state-ofthe art methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Comment on \u201cClustering by fast search and find of density peaks\u201d\nAbstract: In [1], a clustering algorithm was given to find the centers of clusters quickly. However, the accuracy of this algorithm heavily depend on the threshold value of dc. Furthermore, [1] has not provided any efficient way to select the threshold value of dc, that is, one can have to estimate the value of dc depend on one\u2019s subjective experience. In this paper, based on the data field [2], we propose a new way to automatically extract the threshold value of dc from the original dataset by using the potential entropy of data field. For any dataset to be clustered, the most reasonable value of dc can be objectively calculated from the dataset by using our proposed method. The same experiments in [1] are redone with our proposed method on the same experimental datasets used in [1], the results of which shows that the problem to calculate the threshold value of dc in [1] has been solved by using our method. Key word: data field; potential entropy; dc; clustering; density peaks\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We provide a simple and efficient algorithm for computing the Euclidean projection of a point onto the capped simplex, formally defined as min x\u2208RD 1 2 \u2016x\u2212 y\u20162 s.t. x1 = s, 0 \u2264 x \u2264 1, together with an elementary proof. Both the MATLAB and C++ implementations of the proposed algorithm can be downloaded at https://eng.ucmerced.edu/people/wwang5.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Splash: User-friendly Programming Interface for Parallelizing Stochastic Algorithms\nAbstract: Stochastic algorithms are efficient approaches to solving machine learning and optimization problems. In this paper, we propose a general framework called Splash for parallelizing stochastic algorithms on multi-node distributed systems. Splash consists of a programming interface and an execution engine. Using the programming interface, the user develops sequential stochastic algorithms without concerning any detail about distributed computing. The algorithm is then automatically parallelized by a communication-efficient execution engine. We provide theoretical justifications on the optimal rate of convergence for parallelizing stochastic gradient descent. The real-data experiments with stochastic gradient descent, collapsed Gibbs sampling, stochastic variational inference and stochastic collaborative filtering verify that Splash yields order-of-magnitude speedup over single-thread stochastic algorithms and over parallelized batch algorithms. Besides its efficiency, Splash provides a rich collection of interfaces for algorithm implementation. It is built on Apache Spark and is closely integrated with the Spark ecosystem.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget\nAbstract: Can we make Bayesian posterior MCMC sampling more efficient when faced with very large datasets? We argue that computing the likelihood for N datapoints in the Metropolis-Hastings (MH) test to reach a single binary decision is computationally inefficient. We introduce an approximate MH rule based on a sequential hypothesis test that allows us to accept or reject samples with high confidence using only a fraction of the data required for the exact MH rule. While this method introduces an asymptotic bias, we show that this bias can be controlled and is more than offset by a decrease in variance due to our ability to draw more samples per unit of time.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Face Deblurring\nAbstract: Even though the problem of blind deblurring is a long studied vision task, the outcomes of generic methods are not effective in real world blurred images. Exploiting domain knowledge for specific object deblurring, e.g. text or faces, has attracted recently an increasing amount of attention. Faces are among the most well studied objects in computer vision and despite the significant progress made, the deblurring of faces does not yield yet satisfying results in an arbitrary image. We study the problem of face deblurring by inserting weak supervision in the form of alignment in a deep network. We introduce an efficient framework, used to generate a dataset of over two million frames. The dataset, which we call 2MF , was used during the networks training process. We conduct experiments with real world blurred facial images and report that our method returns a result close to the sharp natural latent image.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Formalizing Neurath\u2019s Ship: Approximate Algorithms for Online Causal Learning\nAbstract: Author note: Neil R. Bramley, Department of Experimental Psychology, University College London; Peter Dayan, Gatsby Computational Neuroscience Unit, University College London; Thomas L. Griffiths, Department of Psychology, University of California Berkeley; David A. Lagnado, Department of Experimental Psychology, University College London. This research was supported in part by an Economic and Social Research Council UK grant (RES 062330004). Correspondence concerning this article should be addressed to: 201, 26 Bedford Way, University College London, London, UK,WC1H 0DS, Email: neil.bramley@ucl.ac.uk . Experiment 2 previously appeared in a conference paper presented at The 37th Annual Conference of The Cognitive Science Society (Bramley, Dayan, & Lagnado, 2015). A preprint of the current manuscript was made available on arXiv on September 17th 2016 here: https://arxiv .org/abs/1609.04212.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Pointing the Unknown Words\nAbstract: The problem of rare and unknown words is an important issue that can potentially effect the performance of many NLP systems, including both the traditional countbased and the deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models using attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one predicts the location of a word in the source sentence, and the other predicts a word in the shortlist vocabulary. At each time-step, the decision of which softmax layer to use choose adaptively made by an MLP which is conditioned on the context. We motivate our work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known. We observe improvements on two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset using our proposed model.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: No Free Lunch Theorem and Bayesian probability theory: two sides of the same coin. Some implications for black-box optimization and metaheuristics\u2217\nAbstract: Challenging optimization problems, which elude acceptable solution via conventional calculus methods, arise commonly in different areas of industrial design and practice. Hard optimization problems are those who manifest the following behavior: a) high number of independent input variables; b) very complex or irregular multi-modal fitness; c) computational expensive fitness evaluation. This paper will focus on some theoretical issues that have strong implications for practice. I will stress how an interpretation of the No Free Lunch theorem leads naturally to a general Bayesian optimization framework. The choice of a prior over the space of functions is a critical and inevitable step in every black-box optimization. key words: No free lunch theorem, Metaheuristics, Bayesian optimization\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Why and When Can Deep \u2013 but Not Shallow \u2013 Networks Avoid the Curse of Dimensionality\nAbstract: The paper reviews an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning. Deep convolutional networks represent an important special case of these conditions, though weight sharing is not the main reason for their exponential advantage. Explanation of a few key theorems is provided together with new results, open problems and conjectures. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216. H.M. is supported in part by ARO Grant W911NF-15-10385. 1 ar X iv :1 61 1. 00 74 0v 1 [ cs .L G ] 2 N ov 2 01 6 Why and When Can Deep \u2013 but Not Shallow \u2013 Networks Avoid the Curse of Dimensionality Tomaso Poggio Hrushikesh Mhaskar Lorenzo Rosasco Brando Miranda Qianli Liao Center for Brains, Minds, and Machines, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA, 02139. Department of Mathematics, California Institute of Technology, Pasadena, CA 91125; Institute of Mathematical Sciences, Claremont Graduate University, Claremont, CA 91711 Abstract: The paper reviews an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning. Deep convolutional networks represent an important special case of these conditions, though weight sharing is not the main reason for their exponential advantage. Explanation of a few key theorems is provided together with new results, open problems and conjectures. The paper reviews an emerging body of theoretical results on deep learning including the conditions under which it can be exponentially better than shallow learning. Deep convolutional networks represent an important special case of these conditions, though weight sharing is not the main reason for their exponential advantage. Explanation of a few key theorems is provided together with new results, open problems and conjectures.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Sample Complexity of Reinforcement Learning with a Generative Model \nAbstract: We consider the problem of learning the optimal action-value function in the discountedreward Markov decision processes (MDPs). We prove a new PAC bound on the samplecomplexity of model-based value iteration algorithm in the presence of the generative model, which indicates that for an MDP with N state-action pairs and the discount factor \u03b3 \u2208 [0, 1) only O ( N log(N/\u03b4)/ ( (1 \u2212 \u03b3)\u03b5 )) samples are required to find an \u03b5-optimal estimation of the action-value function with the probability 1 \u2212 \u03b4. We also prove a matching lower bound of \u0398 ( N log(N/\u03b4)/ ( (1 \u2212 \u03b3)\u03b5 )) on the sample complexity of estimating the optimal action-value function by every RL algorithm. To the best of our knowledge, this is the first matching result on the sample complexity of estimating the optimal (action) value function in which the upper bound matches the lower bound of RL in terms ofN , \u03b5, \u03b4 and 1/(1\u2212\u03b3). Also, both our lower bound and our upper bound significantly improve on the state-of-the-art in terms of 1/(1\u2212 \u03b3).\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Utility of Text: The Case of Amicus Briefs and the Supreme Court\nAbstract: We explore the idea that authoring a piece of text is an act of maximizing one\u2019s expected utility. To make this idea concrete, we consider the societally important decisions of the Supreme Court of the United States. Extensive past work in quantitative political science provides a framework for empirically modeling the decisions of justices and how they relate to text. We incorporate into such a model texts authored by amici curiae (\u201cfriends of the court\u201d separate from the litigants) who seek to weigh in on the decision, then explicitly model their goals in a random utility model. We demonstrate the benefits of this approach in improved vote prediction and the ability to perform counterfactual analysis.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Loss-Proportional Subsampling for Subsequent ERM\nAbstract: We propose a sampling scheme suitable for reducing a data set prior to selecting a hypothesis with minimum empirical risk. The sampling only considers a subset of the ultimate (unknown) hypothesis set, but can nonetheless guarantee that the final excess risk will compare favorably with utilizing the entire original data set. We demonstrate the practical benefits of our approach on a large dataset which we subsample and subsequently fit with boosted trees.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scalable Twin Neural Networks for Classification of Unbalanced Data\nAbstract: Learning from large datasets has been a challenge irrespective of the Machine Learning approach used. Twin Support Vector Machines (TWSVMs) have proved to be an efficient alternative to Support Vector Machine (SVM) for learning from imbalanced datasets. However, the TWSVM is unsuitable for large datasets due to the matrix inversion operations required. In this paper, we discuss a Twin Neural Network for learning from large datasets that are unbalanced, while optimizing the feature map at the same time. Our results clearly demonstrate the generalization ability and scalability obtained by the Twin Neural Network on large unbalanced datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Block Regression Model for Short-Term Mobile Traffic Forecasting\nAbstract: Accurate mobile traffic forecast is important for efficient network planning and operations. However, existing traffic forecasting models have high complexity, making the forecasting process slow and costly. In this paper, we analyze some characteristics of mobile traffic such as periodicity, spatial similarity and short term relativity. Based on these characteristics, we propose a Block Regression (BR) model for mobile traffic forecasting. This model employs seasonal differentiation so as to take into account of the temporally repetitive nature of mobile traffic. One of the key features of our BR model lies in its low complexity since it constructs a single model for all base stations. We evaluate the accuracy of BR model based on real traffic data and compare it with the existing models. Results show that our BR model offers equal accuracy to the existing models but has much less complexity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning from Data with Heterogeneous Noise using SGD\nAbstract: We consider learning from data of variable quality that may be obtained from different heterogeneous sources. Addressing learning from heterogenous data in its full generality is a challenging problem. In this paper, we adopt instead a model in which data is observed through heterogeneous noise, where the noise level reflects the quality of the data source. We study how to use stochastic gradient algorithms to learn in this model. Our study is motivated by two concrete examples where this problem arises naturally: learning with local differential privacy based on data from multiple sources with different privacy requirements, and learning from data with labels of variable quality. The main contribution of this paper is to identify how heterogeneous noise impacts performance. We show that given two datasets with heterogeneous noise, the order in which to use them in standard SGD depends on the learning rate. We propose a method for changing the learning rate as a function of the heterogeneity, and prove new regret bounds for our method in two cases of interest. Experiments on real data show that our method performs better than using a single learning rate and using only the less noisy of the two datasets when the noise level is low to moderate.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We consider regression under the \u201cextremely small n large p\u201d condition. In particular, we focus on problems with so small sample sizes n compared to the dimensionality p, even n \u2192 1, that predictors cannot be estimated without prior knowledge. Furthermore, we assume all prior knowledge that can be automatically extracted from databases has already been taken into account. This setup occurs in personalized medicine, for instance, when predicting treatment outcomes for an individual patient based on noisy high-dimensional genomics data. A remaining source of information is expert knowledge which has received relatively little attention in recent years. We formulate the inference problem of asking expert feedback on features on a budget, present experimental results for two setups: \u201csmall n\u201d and \u201cn=1 with similar data available\u201d, and derive conditions under which the elicitation strategy is optimal. Experiments on simulated experts, both on simulated and genomics data, demonstrate that the proposed strategy can drastically improve prediction accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Transfer Learning for Content-Based Recommender Systems using Tree Matching\nAbstract: In this paper we present a new approach to content-based transfer learning for solving the data sparsity problem in cases when the users\u2019 preferences in the target domain are either scarce or unavailable, but the necessary information on the preferences exists in another domain. We show that training a system to use such information across domains can produce better performance. Specifically, we represent users\u2019 behavior patterns based on topological graph structures. Each behavior pattern represents the behavior of a set of users, when the users\u2019 behavior is defined as the items they rated and the items\u2019 rating values. In the next step we find a correlation between behavior patterns in the source domain and behavior patterns in the target domain. This mapping is considered a bridge between the two domains. Based on the correlation and content-attributes of the items, we train a machine learning model to predict users\u2019 ratings in the target domain. When we compare our approach to the popularity approach and KNN-cross-domain on a real world dataset, the results show that on an average of 83% of the cases our approach outperforms both methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: TRAINING DEEP NEURAL NETWORKS ON NOISY LABELS WITH BOOTSTRAPPING\nAbstract: Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-theart results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We propose a novel approach for designing kernels for support vector machines (SVMs) when the class label is linked to the observation through a latent state and the likelihood function of the observation given the state (the sensing model) is available. We show that the Bayes-optimum decision boundary is a hyperplane under a mapping defined by the likelihood function. Combining this with the maximum margin principle yields kernels for SVMs that leverage knowledge of the sensing model in an optimal way. We derive the optimum kernel for the bag-of-words (BoWs) sensing model and demonstrate its superior performance over other kernels in document and image classification tasks. These results indicate that such optimum sensing-aware kernel SVMs can match the performance of rather sophisticated state-of-the-art approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Utilities as Random Variables: Density Estimation and Structure Discovery\nAbstract: Decision theory does not traditionally include uncer\u00ad tainty over utility functions. We argue that the a per\u00ad son's utility value for a given outcome can be treated as we treat other domain attributes: as a random vari\u00ad able with a density function over its possible values. We show that we can apply statistical density estima\u00ad tion techniques to learn such a density function from a database of partially elicited utility functions. In par\u00ad ticular, we define a Bayesian learning framework for this problem, assuming the distribution over utilities is a mixture of Gaussians, where the mixture compo\u00ad nents represent statistically coherent subpopulations. We can also extend our techniques to the problem of discovering generalized additivity structure in the util\u00ad ity functions in the population. We define a Bayesian model selection criterion for utility function structure and a search procedure over structures. The factoriza\u00ad tion of the utilities in the learned model, and the gen\u00ad eralization obtained from density estimation, allows us to provide robust estimates of utilities using a signif\u00ad icantly smaller number of utility elicitation questions. We experiment with our technique on synthetic utility data and on a real database of utility functions in the domain of prenatal diagnosis.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Many modern multiclass and multilabel problems are characterized by increasingly large output spaces. For these problems, label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency. In this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings. The result is a randomized algorithm for partial least squares, whose running time is exponentially faster than naive algorithms. We demonstrate our techniques on two large-scale public datasets, from the Large Scale Hierarchical Text Challenge and the Open Directory Project, where we obtain state of the art results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Near-Optimally Teaching the Crowd to Classify\nAbstract: How should we present training examples to learners to teach them classification rules? This is a natural problem when training workers for crowdsourcing labeling tasks, and is also motivated by challenges in data-driven online education. We propose a natural stochastic model of the learners, modeling them as randomly switching among hypotheses based on observed feedback. We then develop STRICT, an efficient algorithm for selecting examples to teach to workers. Our solution greedily maximizes a submodular surrogate objective function in order to select examples to show to the learners. We prove that our strategy is competitive with the optimal teaching policy. Moreover, for the special case of linear separators, we prove that an exponential reduction in error probability can be achieved. Our experiments on simulated workers as well as three real image annotation tasks on Amazon Mechanical Turk show the effectiveness of our teaching algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A survey of sparse representation: algorithms and applications\nAbstract: Sparse representation has attracted much attention from researchers in fields of signal processing, image processing, computer vision and pattern recognition. Sparse representation also has a good reputation in both theoretical research and practical applications. Many different algorithms have been proposed for sparse representation. The main purpose of this article is to provide a comprehensive study and an updated review on sparse representation and to supply a guidance for researchers. The taxonomy of sparse representation methods can be studied from various viewpoints. For example, in terms of different norm minimizations used in sparsity constraints, the methods can be roughly categorized into five groups: sparse representation with l0-norm minimization, sparse representation with lp-norm (0<p<1) minimization, sparse representation with l1-norm minimization and sparse representation with l2,1-norm minimization. In this paper, a comprehensive overview of sparse representation is provided. The available sparse representation algorithms can also be empirically categorized into four groups: greedy strategy approximation, constrained optimization, proximity algorithmbased optimization, and homotopy algorithm-based sparse representation. The rationales of different algorithms in each category are analyzed and a wide range of sparse representation applications are summarized, which could sufficiently reveal the potential nature of the sparse representation theory. Specifically, an experimentally comparative study of these sparse representation algorithms was presented. The Matlab code used in this paper can be available at: http://www.yongxu.org/lunwen.html.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification\nAbstract: This paper describes the participation of the team \u201cTwiSE\u201d in the SemEval 2016 challenge. Specifically, we participated in Task 4, namely \u201cSentiment Analysis in Twitter\u201d for which we implemented sentiment classification systems for subtasks A, B, C and D. Our approach consists of two steps. In the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. In the second step, we focus on the optimization of the evaluation measures of the different subtasks. To this end, we examine different learning strategies by validating them on the data provided by the task organisers. For our final submissions we used an ensemble learning approach (stacked generalization) for Subtask A and single linear models for the rest of the subtasks. In the official leaderboard we were ranked 9/35, 8/19, 1/11 and 2/14 for subtasks A, B, C and D respectively.1\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Output-Space Distance Metric Learning for k-NN Classification\nAbstract: In this paper we present two related, kernel-based Distance Metric Learning (DML) methods. Their respective models non-linearly map data from their original space to an output space, and subsequent distance measurements are performed in the output space via a Mahalanobis metric. The dimensionality of the output space can be directly controlled to facilitate the learning of a low-rank metric. Both methods allow for simultaneous inference of the associated metric and the mapping to the output space, which can be used to visualize the data, when the output space is 2or 3-dimensional. Experimental results for a collection of classification tasks illustrate the advantages of the proposed methods over other traditional and kernel-based DML approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Calibration of Modern Neural Networks\nAbstract: Confidence calibration \u2013 the problem of predicting probability estimates representative of the true correctness likelihood \u2013 is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-ofthe-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling \u2013 a singleparameter variant of Platt Scaling \u2013 is surprisingly effective at calibrating predictions.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adaptive Bound Optimization for Online Convex Optimization\nAbstract: We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm\u2019s regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalized Gradient Learning on Time Series under Elastic Transformations\nAbstract: The majority of machine learning algorithms assumes that objects are represented as vectors. But often the objects we want to learn on are more naturally represented by other data structures such as sequences and time series. For these representations many standard learning algorithms are unavailable. We generalize gradient-based learning algorithms to time series under dynamic time warping. To this end, we introduce elastic functions, which extend functions on time series to matrix spaces. Necessary conditions are presented under which generalized gradient learning on time series is consistent. We indicate how results carry over to arbitrary elastic distance functions and to sequences consisting of symbolic elements. Specifically, four linear classifiers are extended to time series under dynamic time warping and applied to benchmark datasets. Results indicate that generalized gradient learning via elastic functions have the potential to complement the state-of-the-art in statistical pattern recognition on time series.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This document should serve as a quick reference for and guide to the implementation of linear GQ(\u03bb), a gradient-based off-policy temporal-difference learning algorithm. Explanation of the intuition and theory behind the algorithm are provided elsewhere (e.g., Maei & Sutton 2010, Maei 2011). If you questions or concerns about the content in this document or the attached java code please email Adam White (adam.white@ualberta.ca).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper presents a new similarity measure to be used for general tasks including supervised learning, which is represented by the K-nearest neighbor classifier (KNN). The proposed similarity measure is invariant to large differences in some dimensions in the feature space. The proposed metric is proved mathematically to be a metric. To test its viability for different applications, the KNN used the proposed metric for classifying test examples chosen from a number of real datasets. Compared to some other well known metrics, the experimental results show that the proposed metric is a promising distance measure for the KNN classifier with strong potential for a wide range of applications. [Hassanat B. A. Dimensionality Invariant Similarity Measure. J Am Sci 2014;10(8):221-226]. (ISSN: 15451003). http://www.jofamericanscience.org. 31\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Context-Aware Hierarchical Online Learning for Performance Maximization in Mobile Crowdsourcing\nAbstract: In mobile crowdsourcing, mobile users accomplish outsourced human intelligence tasks. Mobile crowdsourcing requires an appropriate task assignment strategy, since different workers may have different performance in terms of acceptance rate and quality. Task assignment is challenging, since a worker\u2019s performance (i) may fluctuate, depending on both the worker\u2019s current context and the task context, (ii) is not known a priori, but has to be learned over time. However, learning context-specific worker performance requires access to context information, which workers may not grant to a central entity. Moreover, evaluating worker performance might require costly quality assessments. In this paper, we propose a context-aware hierarchical online learning algorithm addressing the problem of performance maximization in mobile crowdsourcing. In our algorithm, a local controller (LC) in the mobile device of a worker regularly observes its worker\u2019s context, his decisions to accept or decline tasks and the quality in completing tasks. Based on these observations, the LC regularly estimates its worker\u2019s context-specific performance. The mobile crowdsourcing platform (MCSP) then selects workers based on performance estimates received from the LCs. This hierarchical approach enables the LCs to learn context-specific worker performance and it enables the MCSP to select suitable workers. In addition, our algorithm preserves worker context locally, and it keeps the number of required quality assessments low. We prove that our algorithm converges to the optimal task assignment strategy. Moreover, the algorithm outperforms simpler task assignment strategies in experiments based on synthetic and real data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Correcting Inputs: Inverse Optimization for Online Structured Prediction\nAbstract: Algorithm designers typically assume that the input data is correct, and then proceed to find \u201coptimal\u201d or \u201csub-optimal\u201d solutions using this input data. However this assumption of correct data does not always hold in practice, especially in the context of online learning systems where the objective is to learn appropriate feature weights given some training samples. Such scenarios necessitate the study of inverse optimization problems where one is given an input instance as well as a desired output and the task is to adjust the input data so that the given output is indeed optimal. Motivated by learning structured prediction models, in this paper we consider inverse optimization with a margin, i.e., we require the given output to be better than all other feasible outputs by a desired margin. We consider such inverse optimization problems for maximum weight matroid basis, matroid intersection, perfect matchings, minimum cost maximum flows, and shortest paths and derive the first known results for such problems with a non-zero margin. The effectiveness of these algorithmic approaches to online learning for structured prediction is also discussed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Breast Mass Classification from Mammograms using Deep Convolutional Neural Networks\nAbstract: Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Inference in Sparse Graphs with Pairwise Measurements and Side Information\nAbstract: We consider the statistical problem of recovering a hidden \u201cground truth\u201d binary labeling for the vertices of a graph G up to low Hamming error from noisy edge and vertex measurements. We present new algorithms and a sharp finite-sample analysis for this problem on trees and sparse graphs with poor expansion properties such as hypergrids and ring lattices. Our method generalizes and improves over (Globerson et al., 2015), who introduced the problem for twodimensional grid lattices. For trees we provide a simple, efficient, algorithm that infers the ground truth with optimal Hamming error and implies recovery results for all connected graphs. Here, the presence of side information is critical to obtain a non-trivial recovery rate. We then show how to adapt this algorithm to tree decompositions of edge-subgraphs of certain graph families such as lattices, resulting in optimal recovery error rates that can be obtained in a highly efficient manner. The thrust of our analysis is to 1) use the tree decomposition along with edge measurements to produce a small class of viable vertex labelings and 2) apply fast rate results from statistical learning theory to show that we can infer the ground truth from this class using vertex measurements. We show the power of our method by providing several examples including hypergrids, ring lattices, and the Newman-Watts model for small world graphs. For two-dimensional grids, our results improve over Globerson et al. (2015) by obtaining optimal recovery in the constant-height regime.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Latent Variable Gaussian Graphical Models\nAbstract: Gaussian graphical models (GGM) have been widely used in many highdimensional applications ranging from biological and financial data to recommender systems. Sparsity in GGM plays a central role both statistically and computationally. Unfortunately, real-world data often does not fit well to sparse graphical models. In this paper, we focus on a family of latent variable Gaussian graphical models (LVGGM), where the model is conditionally sparse given latent variables, but marginally non-sparse. In LVGGM, the inverse covariance matrix has a low-rank plus sparse structure, and can be learned in a regularized maximum likelihood framework. We derive novel parameter estimation error bounds for LVGGM under mild conditions in the high-dimensional setting. These results complement the existing theory on the structural learning, and open up new possibilities of using LVGGM for statistical inference.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Origami: A Convolutional Network Accelerator\nAbstract: Today advanced computer vision (CV) systems of ever increasing complexity are being deployed in a growing number of application scenarios with strong real-time and power constraints. Current trends in CV clearly show a rise of neural network-based algorithms, which have recently broken many object detection and localization records. These approaches are very flexible and can be used to tackle many different challenges by only changing their parameters. In this paper, we present the first convolutional network accelerator which is scalable to network sizes that are currently only handled by workstation GPUs, but remains within the power envelope of embedded systems. The architecture has been implemented on 3.09 mm core area in UMC 65 nm technology, capable of a throughput of 274 GOp/s at 369 GOp/s/W with an external memory bandwidth of just 525 MB/s full-duplex \u2013 a decrease of more than 90% from previous work.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Actor-critic versus direct policy search: a comparison based on sample complexity\nAbstract: Sample efficiency is a critical property when optimizing policy parameters for the controller of a robot. In this paper, we evaluate two state-of-the-art policy optimization algorithms. One is a recent deep reinforcement learning method based on an actor-critic algorithm, Deep Deterministic Policy Gradient (DDPG), that has been shown to perform well on various control benchmarks. The other one is a direct policy search method, Covariance Matrix Adaptation Evolution Strategy (CMA-ES), a black-box optimization method that is widely used for robot learning. The algorithms are evaluated on a continuous version of the mountain car benchmark problem, so as to compare their sample complexity. From a preliminary analysis, we expect DDPG to be more sample efficient than CMA-ES, which is confirmed by our experimental results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Repeated Inverse Reinforcement Learning\nAbstract: How detailed should we make the goals we prescribe to AI agents acting on our behalf in complex environments? Detailed & low-level specification of goals can be tedious and expensive to create, and abstract & high-level goals could lead to negative surprises as the agent may find behaviors that we would not want it to do, i.e., lead to unsafe AI. One approach to addressing this dilemma is for the agent to infer human goals by observing human behavior. This is the Inverse Reinforcement Learning (IRL) problem. However, IRL is generally ill-posed for there are typically many reward functions for which the observed behavior is optimal. While the use of heuristics to select from among the set of feasible reward functions has led to successful applications of IRL to learning from demonstration, such heuristics do not address AI safety. In this paper we introduce a novel repeated IRL problem that captures an aspect of AI safety as follows. The agent has to act on behalf of a human in a sequence of tasks and wishes to minimize the number of tasks that it surprises the human. Each time the human is surprised the agent is provided a demonstration of the desired behavior by the human. We formalize this problem, including how the sequence of tasks is chosen, in a few different ways and provide some foundational results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions\nAbstract: We study the problem of learning Markov decision processes with finite state and action spaces when the transition probability distributions and loss functions are chosen adversarially and are allowed to change with time. We introduce an algorithm whose regret with respect to any policy in a comparison class grows as the square root of the number of rounds of the game, provided the transition probabilities satisfy a uniform mixing condition. Our approach is efficient as long as the comparison class is polynomial and we can compute expectations over sample paths for each policy. Designing an efficient algorithm with small regret for the general case remains an open problem.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Dropout Training for Convolutional Neural Networks\nAbstract: Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in convolutional and pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also empirically show that the effect of convolutional dropout is not trivial, despite the dramatically reduced possibility of over-fitting due to the convolutional architecture. Elaborately designing dropout training simultaneously in max-pooling and fully-connected layers, we achieve state-of-the-art performance on MNIST, and very competitive results on CIFAR-10 and CIFAR-100, relative to other approaches without data augmentation. Finally, we compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stochastic Behavior of the Nonnegative Least Mean Fourth Algorithm for Stationary Gaussian Inputs and Slow Learning\nAbstract: Some system identification problems impose nonnegativity constraints on the parameters to estimate due to inherent physical characteristics of the unknown system. The nonnegative least-mean-square (NNLMS) algorithm and its variants allow to address this problem in an online manner. A nonnegative least mean fourth (NNLMF) algorithm has been recently proposed to improve the performance of these algorithms in cases where the measurement noise is not Gaussian. This paper provides a first theoretical analysis of the stochastic behavior of the NNLMF algorithm for stationary Gaussian inputs and slow learning. Simulation results illustrate the accuracy of the proposed analysis.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Identifying Dynamic Sequential Plans\nAbstract: We address the problem of identifying dynamic sequential plans in the framework of causal Bayesian networks, and show that the problem is reduced to identifying causal effects, for which there are complete identification algorithms available in the literature.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Moving Beyond the Turing Test with the Allen AI Science Challenge\nAbstract: The famous Turing test developed by Alan Turing in 1950 proposes that if a system can exhibit question-answering behavior that is indistinguishable from that of a human during a conversation, that system could be considered intelligent. As the field of artificial intelligence grows, this approach to evaluating a system has become less and less appropriate or meaningful. Current systems have revealed just how gameable this assessment of AI can be, as some chatbots have improved in recent years to the point where one could argue a few of them could pass the Turing test [1][2]. As The New York Times\u2019 John Markoff puts it, \u201cthe Turing test is a test of human gullibility.\u201d\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: User Clustering in Online Advertising via Topic Models\nAbstract: In the domain of online advertising, our aim is to serve the best ad to a user who visits a certain webpage, to maximize the chance of a desired action to be performed by this user after seeing the ad. While it is possible to generate a different prediction model for each user to tell if he/she will act on a given ad, the prediction result typically will be quite unreliable with huge variance, since the desired actions are extremely sparse, and the set of users is huge (hundreds of millions) and extremely volatile, i.e., a lot of new users are introduced everyday, or are no longer valid. In this paper we aim to improve the accuracy in finding users who will perform the desired action, by assigning each user to a cluster, where the number of clusters is much smaller than the number of users (in the order of hundreds). Each user will fall into the same cluster with another user if their event history are similar. For this purpose, we modify the probabilistic latent semantic analysis (pLSA) model by assuming the independence of the user and the cluster id, given the history of events. This assumption helps us to identify a cluster of a new user without re-clustering all the users. We present the details of the algorithm we employed as well as the distributed implementation on Hadoop, and some initial results on the clusters that were generated by the algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A message-passing algorithm for multi-agent trajectory planning\nAbstract: We describe a novel approach for computing collision-free global trajectories for p agents with specified initial and final configurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Parameterized Complexity of Global Constraints\nAbstract: We argue that parameterized complexity is a useful tool with which to study global constraints. In particular, we show that many global constraints which are intractable to propagate completely have natural parameters which make them fixedparameter tractable and which are easy to compute. This tractability tends either to be the result of a simple dynamic program or of a decomposition which has a strong backdoor of bounded size. This strong backdoor is often a cycle cutset. We also show that parameterized complexity can be used to study other aspects of constraint programming like symmetry breaking. For instance, we prove that value symmetry is fixed-parameter tractable to break in the number of symmetries. Finally, we argue that parameterized complexity can be used to derive results about the approximability of constraint\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hybrid Algorithm for Multi-Objective Optimization by Greedy Hypervolume Maximization\nAbstract: This paper introduces a high-performance hybrid algorithm, called Hybrid Hypervolume Maximization Algorithm (H2MA), for multi-objective optimization that alternates between exploring the decision space and exploiting the already obtained non-dominated solutions. The proposal is centered on maximizing the hypervolume indicator, thus converting the multi-objective problem into a single-objective one. The exploitation employs gradient-based methods, but considering a single candidate efficient solution at a time, to overcome limitations associated with population-based approaches and also to allow an easy control of the number of solutions provided. There is an interchange between two steps. The first step is a deterministic local exploration, endowed with an automatic procedure to detect stagnation. When stagnation is detected, the search is switched to a second step characterized by a stochastic global exploration using an evolutionary algorithm. Using five ZDT benchmarks with 30 variables, the performance of the new algorithm is compared to state-of-the-art algorithms for multi-objective optimization, more specifically NSGA-II, SPEA2, and SMS-EMOA. The solutions found by the H2MA guide to higher hypervolume and smaller distance to the true Pareto frontier with significantly less function evaluations, even when the gradient is estimated numerically. Furthermore, although only continuous decision spaces have been considered here, discrete decision spaces could also have been treated, replacing gradient-based search by hill-climbing. Finally, a thorough explanation is provided to support the expressive gain in performance that was achieved.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scene Text Eraser\nAbstract: The character information in natural scene images contains various personal information, such as telephone numbers, home addresses, etc. It is a high risk of leakage the information if they are published. In this paper, we proposed a scene text erasing method to properly hide the information via an inpainting convolutional neural network (CNN) model. The input is a scene text image, and the output is expected to be text erased image with all the character regions filled up the colors of the surrounding background pixels. This work is accomplished by a CNN model through convolution to deconvolution with interconnection process. The training samples and the corresponding inpainting images are considered as teaching signals for training. To evaluate the text erasing performance, the output images are detected by a novel scene text detection method. Subsequently, the same measurement on text detection is utilized for testing the images in benchmark dataset ICDAR2013. Compared with direct text detection way, the scene text erasing process demonstrates a drastically decrease on the precision, recall and f-score. That proves the effectiveness of proposed method for erasing the text in natural scene images.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Prioritized Planning Algorithms for Trajectory Coordination of Multiple Mobile Robots\nAbstract: An important capability of autonomous multi-robot systems is to prevent collision among the individual robots. One approach to this problem is to plan conflict-free trajectories and let each of the robots follow its pre-planned trajectory. A widely used practical method for multi-robot trajectory planning is prioritized planning, which has been shown to be effective in practice, but is in general incomplete. Formal analysis of instances that are provably solvable by prioritized planning is still missing. Moreover, prioritized planning is a centralized algorithm, which may be in many situations undesirable. In this paper we a) propose a revised version of prioritized planning and characterize the class of instances that are provably solvable by the algorithm and b) propose an asynchronous decentralized variant of prioritized planning, which maintains the desirable properties of the centralized version and in the same time exploits the distributed computational power of the individual robots, which in most situations allows to find the joint trajectories faster. The experimental evaluation performed on real-world indoor maps shows that a) the revised version of prioritized planning reliably solves a wide class of instances on which both classical prioritized planning and popular reactive technique ORCA fail and b) the asynchronous decentralized algorithm provides solution faster than the previously proposed synchronized decentralized algorithm. Note to Practitioners\u2014Consider a large warehouse in which the goods are stored and retrieved by autonomous transport robots. One option is to ignore interaction between the vehicles during the route planning for each robot and handle the conflicts only during the route execution. However, such approach is prone to deadlocks, i.e. to a situations during which some of the robots mutually block each other, cannot proceed and fail to complete their transportation task. An alternative approach would involve planning collision-free routes for each robot before the robots start executing them. However, the general methods for this problem that guarantee a solution are impractical due to their high computational complexity. In this paper, we show that a simple prioritized approach in which robots plan their routes one after another is guaranteed to find collision-free trajectories for a welldefined class of practical problems. In particular, if the systems resembles human-made transport infrastructures by requiring that the start and destination position of each vehicle must never obstruct other vehicles from moving, then the proposed approach is guaranteed to provide a solution. E.g., in such a warehouse application, the collision-free routes can efficiently computed by the prioritized approach. The paper contains formal condition that characterizes the problem instances for which is the method guaranteed to work. Further, we propose a new decentralized adaptation of the prioritized algorithm that can be used in multi-robot systems without a central solver. This technique can be used to find coordinate trajectories just by running simple negotiation protocol between the individual robots. The paper contains analysis showing that the decentralized algorithm exhibits desirable theoretical properties and experimental comparison of performance of different variations of centralized and decentralized algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Formal Characterization of the Local Search Topology of the Gap Heuristic\nAbstract: The pancake puzzle is a classic optimization problem that has become a standard benchmark for heuristic search algorithms. In this paper, we provide full proofs regarding the local search topology of the gap heuristic for the pancake puzzle. First, we show that in any non-goal state in which there is no move that will decrease the number of gaps, there is a move that will keep the number of gaps constant. We then classify any state in which the number of gaps cannot be decreased in a single action into two groups: those requiring 2 actions to decrease the number of gaps, and those which require 3 actions to decrease the number of gaps.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Belief Networks used on High Resolution Multichannel Electroencephalography Data for Seizure Detection\nAbstract: Ubiquitous bio-sensing for personalized health monitoring is slowly becoming a reality with the increasing availability of small, diverse, robust, high fidelity sensors. This oncoming flood of data begs the question of how we will extract useful information from it. In this paper we explore the use of a variety of representations and machine learning algorithms applied to the task of seizure detection in high resolution, multichannel EEG data. We explore classification accuracy, computational complexity and memory requirements with a view toward understanding which approaches are most suitable for such tasks as the number of people involved and the amount of data they produce grows to be quite large. In particular, we show that layered learning approaches such as Deep Belief Networks excel along these dimensions.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Review of 40 Years of Cognitive Architecture Research: Focus on Perception, Attention, Learning and Applications\nAbstract: In this paper we present a broad overview of the last 40 years of research on cognitive architectures. Although the number of<lb>existing architectures is nearing several hundred, most of the existing surveys do not reflect this growth and focus on a handful of<lb>well-established architectures. While their contributions are undeniable, they represent only a part of the research in the field. Thus, in this survey we wanted to shift the focus towards a more inclusive and high-level overview of the research in cognitive<lb>architectures. Our final set of 86 architectures includes 55 that are still actively developed, and borrow from a diverse set of<lb>disciplines, spanning areas from psychoanalysis to neuroscience. To keep the length of this paper within reasonable limits we<lb>discuss only the core cognitive abilities, such as perception, attention mechanisms, learning and memory structure. To assess the breadth of practical applications of cognitive architectures we gathered information on over 700 practical projects implemented<lb>using the cognitive architectures in our list.<lb>We use various visualization techniques to highlight overall trends in the development of the field. For instance, our data<lb>confirms that the hybrid approach to cognitive modeling already dominates the field and will likely continue to do so in the future. Our analysis of practical applications shows that most architectures are very narrowly focused on a particular application domain.<lb>Furthermore, there is an apparent gap between general research in robotics and computer vision and research in these areas within<lb>the cognitive architectures field. It is very clear that biologically inspired models do not have the same range and efficiency<lb>compared to the systems based on engineering principles and heuristics. Another observation is related to a general lack of collaboration, which is surprising to see in the inherently interdisciplinary area of cognitive architectures. Several factors hinder<lb>communication, among which are the closed nature of the individual projects (only one-third of the reviewed here architectures are<lb>open-source) and terminological differences.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Constraint Propagation with Imprecise Conditional Probabilities\nAbstract: An approach to reasoning with default rules where the proportion of exceptions, or more generally the probability of encountering an exception, can be at least roughly assessed is presented. It is based on local uncertainty propagation rules which provide the best bracketing of a conditional probability of interest from the knowledge of the bracketing of some other conditional probabilities. A procedure that uses two such propagation rules repeatedly is proposed in order to estimate any simple conditional probability of interest from the available knowledge. The iterative procedure, that does not require independence assumptions, looks promising with respect to the linear programming method. Improved bounds for conditional probabilities are given when independence assumptions hold.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Laplacian Framework for Option Discovery in Reinforcement Learning\nAbstract: Representation learning and option discovery are two of the biggest challenges in reinforcement learning (RL). Proto-value functions (PVFs) are a well-known approach for representation learning in MDPs. In this paper we address the option discovery problem by showing how PVFs implicitly define options. We do it by introducing eigenpurposes, intrinsic reward functions derived from the learned representations. The options discovered from eigenpurposes traverse the principal directions of the state space. They are useful for multiple tasks because they are discovered without taking the environment\u2019s rewards into consideration. Moreover, different options act at different time scales, making them helpful for exploration. We demonstrate features of eigenpurposes in traditional tabular domains as well as in Atari 2600 games.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Support and Plausibility Degrees in Generalized Functional Models\nAbstract: By discussing several examples, the theory of generalized functional models is shown to be very natural for modeling some situations of reasoning under uncertainty. A general\u00ad ized functional model is a pair (f, P) where f is a function describing the interactions between a parameter variable, an observa\u00ad tion variable and a random source, and P is a probability distribution for the random source. Unlike traditional functional mod\u00ad els, generalized functional models do not re\u00ad quire that there is only one value of the pa\u00ad rameter variable that is compatible with an observation and a realization of the random source. As a consequence, the results of the analysis of a generalized functional model are not expressed in terms of probability distri\u00ad butions but rather by support and plausi\u00ad bility functions. The analysis of a general\u00ad ized functional model is very logical and is inspired from ideas already put forward by R.A. Fisher in his theory of fiducial proba\u00ad bility. 1 The Theories of Bayes and Fisher Jessica is a young woman suspecting that she might be pregnant. To find out about her status she decides to go to the local pharmacy and buys a pregnancy test. The test result indicates that she is not pregnant, but she knows that such tests are not fully trustworthy. The question is then how to evaluate the chance that she is pregnant in spite of the negative test result. Of course, one possibility is to use the Bayesian the\u00ad ory to analyze the situation. The Bayesian model is as follows. Let 8 denote the variable indicating her true pregnancy status. The set of possible values of B is e = { -1, +1} where -1 means that she is not pregnant and +1 means that she is pregnant. Simi\u00ad larly, Jet \ufffd denote the variable indicating a test result. The set of possible values of\ufffd is X = { 1 , + 1} where -1 represents a negative test result and + 1 a positive test result. The reliability of the test can be expressed by two numbers, namely the chance p that the test will indicate a negative result when a woman in not pregnant, and the chance p' that the test will indi\u00ad cate a positive result when a woman is pregnant. It is reasonable to assume that both p and p' are rather high. This information is represented by the condi\u00ad tional probabilities P(\ufffd =liB = -1) = p, P(\ufffd = liB = 1} = p'. (1) Suppose that Jessica's prior about her status is given by the probabilities P(B = -1) = y, P(B = +1) = 1y. (2) Then by Bayes theorem the posterior probability that Jessica is not pregnant is P'(B = -1) = yp . (3) yp+ (1y)(lp') According to the Bayesian theory, this represents Jes\u00ad sica's degree of confidence in the fact that she is not pregnant. Now assume that the probability of getting a correct negative result is the same as getting a correct positive result, i.e. p = p'. This means that the test reveals the true pregnancy status with probability p. This probability is an indicator of the confidence in the test result. Then by formula (3) the posterior probability that .Jessica is not pregnant is P'(B = 1) = yp (4) yp+ (1 y)( l p) This is the Bayesian solution to Jessica's pregnancy test problem. However, .Jessica is unable to give the prior probability of her being pregnant because she is not comfortable with the idea of giving a precise number to estimate this chance. As can be seen in for\u00ad mula ( 4), without a prior it is impossible to find the posterior probability of her not being pregnant. The Bayesian theory requires prior probabilities to com\u00ad pute posterior probabilities. But Jessica is still in\u00ad terested in finding a numerical value expressing the chance of her not being pregnant considering the neg\u00ad ative test result. How can we find such a numerical value? In 1930, R.A. Fisher identified a class of prob\u00ad lems in which it appeared to him that inductive prob\u00ad ability statements could legitimately be made without prior probabilities being used. It turns out that Jes\u00ad sica's problem when p = p' is one of them. In this example, Fisher's reasoning would go as follows. First define the variable\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Truthful Feedback for Sanctioning Reputation Mechanisms\nAbstract: For product rating environments, similar to that of Amazon Reviews, it has been shown that the truthful elicitation of feedback is possible through mechanisms which pay buyer reports contingent on the reports of other buyers. We study whether similar mechanisms can be designed for reputation mechanisms at online auction sites where the buyers\u2019 experiences are partially determined by a strategic seller. We show that this is impossible for the basic setting. However, introducing a small prior belief that the seller is a cooperative commitment player leads to a payment scheme with a truthful perfect Bayesian equilibrium.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: FUNCTION-DESCRIBED GRAPHS FOR STRUCTURAL PATTERN RECOGNITION\nAbstract: A fundamental problem in pattern recognition is selecting suitable representations for objects and classes. In the decision-theoretic approach to pattern recognition, a pattern is represented by a set of numerical values, which forms a feature vector. Although, in many tasks, objects can be recognised successfully using only global features such as size and compactness, in some applications it is helpful to describe an object in terms of its basic parts and the relations between them. Nevertheless, there are two major problems that practical applications using structural pattern recognition are confronted with. The first problem is the computational complexity of comparing two structures. The time required by any of the optimal algorithms may in the worst case become exponential in the size of the graphs. The approximate algorithms, on the other hand, have only polynomial time complexity, but do not guarantee to find the optimal solution. For some of the applications, this may not be acceptable. The second problem is the fact that there is more than one model graph that must be matched with an input graph, then the conventional graph matching algorithms must be applied to each model-input pair sequentially. As a consequence, the performance is linearly dependent on the size of the database of model graphs. For applications dealing with large database, this may be prohibitive. Function-described graphs (FDGs) are a compact representation of a set of attributed graphs. They have borrowed from \u201crandom graphs\u201d proposed by Wong et al. the ability to probabilistically model structural attribute information, while improving the capacity to record structural relationships that consistently appear throughout the data. They do this by incorporating qualitative knowledge of the second-order probabilities of the elements that are expressed as relations (Boolean functions) between pairs of vertices and pairs of arcs in the FDGs. Four approaches and algorithms for building FDGs from an ensemble of attributed graphs are presented. The first synthesises an FDG in a supervised manner. The other three use the supervised clustering algorithms: dynamic, complete and single clustering. The problem of matching attributed graphs (AGs) to FDGs for recognition or classification purposes is studied from a Bayesian perspective. A distance measure between AGs and FDGs is derived from the principle of maximum likelihood, but robustness is enforced by considering only locally the effects of extraneous and missing elements. A second measure is also given in which the second-order constraints are incorporated as additional costs. A branch-and-bound algorithm is proposed to compute these distance measures together with their corresponding optimal labelling. Because of the exponential cost of this algorithm, three efficient algorithms are also proposed and compared to compute sub-optimal distances between AGs and FDGs. Two of them are based on a probabilistic relaxation approach, and the other does not have an iterative technique. Some experimental tests are presented in random graphs and a 3D-object recognition problem. In the 3D-object recognition application, an FDG model is synthesised (in a supervised and an unsupervised method) for each object from a set of views (AGs). The second-order information in FDGs is shown so that the recognition ration is better than when the first-order probability distributions are only used. Results of efficient algorithms show that there is an important decrease in the run time although there is only a slight decrease in effectiveness.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Relating Knowledge and Coordinated Action: The Knowledge of Preconditions Principle\nAbstract: The Knowledge of Preconditions principle (KoP) is proposed as a widely applicable connection between knowledge and action in multi-agent systems. Roughly speaking, it asserts that if some condition \u03c6 is a necessary condition for performing a given action \u03b1 , then knowing \u03c6 is also a necessary condition for performing \u03b1 . Since the specifications of tasks often involve necessary conditions for actions, the KoP principle shows that such specifications induce knowledge preconditions for the actions. Distributed protocols or multi-agent plans that satisfy the specifications must ensure that this knowledge be attained, and that it is detected by the agents as a condition for action. The knowledge of preconditions principle is formalised in the runs and systems framework, and is proven to hold in a wide class of settings. Well-known connections between knowledge and coordinated action are extended and shown to derive directly from the KoP principle: a common knowledge of preconditions principle is established showing that common knowledge is a necessary condition for performing simultaneous actions, and a nested knowledge of preconditions principle is proven, showing that coordinating actions to be performed in linear temporal order requires a corresponding form of nested knowledge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: IfcWoD,Semantically Adapting IFC Model Relations into OWL Properties\nAbstract: In the context of Building Information Modelling, ontologies have been identified as interesting in achieving information interoperability. Regarding the construction and facility management domains, several IFC (Industry Foundation Classes) based ontologies have been developed, such as IfcOWL. In the context of ontology modelling, the constraint of optimizing the size of IFC STEP-based files can be leveraged. In this paper, we propose an adaptation of the IFC model into OWL which leverages from all modelling constraints required by theobject-oriented structure of the IFC schema. Therefore, we do not only present a syntactic but also a semantic adaptation of the IFC model. Our model takes into consideration the meaning of entities, relationships, properties and attributes defined by the IFC standard. Our approach presents several advantages compared to other initiatives such asthe optimization of query execution time. Every advantage is defended by means of practical examples and benchmarks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Predicting Clinical Events by Combining Static and Dynamic Information Using Recurrent Neural Networks\nAbstract: In clinical data sets we often find static information (e.g. gender of the patients, blood type, etc.) combined with sequences of data that are recorded during multiple hospital visits (e.g. medications prescribed, tests performed, etc.). Recurrent Neural Networks (RNNs) have proven to be very successful for modelling sequences of data in many areas of Machine Learning. In this work we present an approach based on RNNs that is specifically designed for the clinical domain and that combines static and dynamic information in order to predict future events. We work with a database collected in the Charit\u00e9 Hospital in Berlin that contains all the information concerning patients that underwent a kidney transplantation. After the transplantation three main endpoints can occur: rejection of the kidney, loss of the kidney and death of the patient. Our goal is to predict, given the Electronic Health Record of each patient, whether any of those endpoints will occur within the next six or twelve months after each visit to the clinic. We compared different types of RNNs that we developed for this work, a model based on a Feedforward Neural Network and a Logistic Regression model. We found that the RNN that we developed based on Gated Recurrent Units provides the best performance for this task. We also performed an additional experiment using these models to predict next actions and found that for such use case the model based on a Feedforward Neural Network outperformed the other models. Our hypothesis is that long-term dependencies are not as relevant in this task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Application of Data Mining to Network Intrusion Detection: Classifier Selection Model\nAbstract: As network attacks have increased in number and severity over the past few years, intrusion detection system (IDS) is increasingly becoming a critical component to secure the network. Due to large volumes of security audit data as well as complex and dynamic properties of intrusion behaviors, optimizing performance of IDS becomes an important open problem that is receiving more and more attention from the research community. The uncertainty to explore if certain algorithms perform better for certain attack classes constitutes the motivation for the reported herein. In this paper, we evaluate performance of a comprehensive set of classifier algorithms using KDD99 dataset. Based on evaluation results, best algorithms for each attack category is chosen and two classifier algorithm selection models are proposed. The simulation result comparison indicates that noticeable performance improvement and real-time intrusion detection can be achieved as we apply the proposed models to detect different kinds of network attacks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dimension Reduction in Singularly Perturbed Continuous-Time Bayesian Networks\nAbstract: Continuous-time Bayesian networks (CTBNs) are graphical representations of multi-component continuous-time Markov processes as directed graphs. The edges in the network represent direct influences among components. The joint rate matrix of the multi-component process is specified by means of conditional rate matrices for each component separately. This paper addresses the situation where some of the components evolve on a time scale that is much shorter compared to the time scale of the other components. We prove that in the limit where the separation of scales is infinite, the Markov process converges (in distribution, or weakly) to a reduced, or effective Markov process that only involves the slow components. We also demonstrate that for a reasonable separation of scales (an order of magnitude) the reduced process is a good approximation of the marginal process over the slow components. We provide a simple procedure for building a reduced CTBN for this effective process, with conditional rate matrices that can be directly calculated from the original CTBN, and discuss the implications for approximate reasoning in large systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Polymetric Rhythmic Feel for a Cognitive Drum Computer\nAbstract: This paper addresses a question about music cognition: how do we derive polymetric structures. A preference rule system is presented which is implemented into a drum computer. The preference rule system allows inferring local polymetric structures, like two-over-three and three-over-two. By analyzing the micro-timing of West African percussion music a timing pattern consisting of six pulses was discovered. It integrates binary and ternary rhythmic feels. The presented drum computer integrates the discovered superimposed polymetric swing (timing and velocity) appropriate to the rhythmic sequence the user inputs. For binary sequences, the amount of binary swing is increased and for ternary sequences, the ternary swing is increased.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Q-learning optimization in a multi-agents system for image segmentation\nAbstract: -To know which operators to apply and in which order, as well as attributing good values to their parameters is a challenge for users of computer vision. This paper proposes a solution to this problem as a multi-agent system modeled according to the Vowel approach and using the Q-learning algorithm to optimize its choice. An implementation is given to test and validate this method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An ordinal view of independence with application to plausible reasoning\nAbstract: An ordinal view of independence is studied in the framework of possibility theory. We investigate three possible definitions of dependence, of increasing strength. One of them is the counterpart to the multiplication law in probability theory, and the two others are based on the notion of conditional possibility. These two have enough expressive power to support the whole possibility theory, and a complete axiomatization is provided for the strongest one. Moreover we show that weak independence is well-suited to the problems of belief change and plausible reasoning, especially to address the problem of blocking of property inheritance in exception-tolerant taxonomic reasoning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: RDF Translator: A RESTful Multi-Format Data Converter for the Semantic Web\nAbstract: The interdisciplinary nature of the Semantic Web and the many projects put forward by the community led to a large number of widely accepted serialization formats for RDF. Most of these RDF syntaxes have been developed out of a necessity to serve specific purposes better than existing ones, e.g. RDFa was proposed as an extension to HTML for embedding non-intrusive RDF statements in human-readable documents. Nonetheless, the RDF serialization formats are generally transducible among themselves given that they are commonly based on the RDF model. In this paper, we present (1) a RESTful Web service based on the HTTP protocol that translates between different serializations. In addition to its core functionality, our proposed solution provides (2) features to accommodate frequent needs of Semantic Web developers, namely a straightforward user interface with copy-to-clipboard functionality, syntax highlighting, persistent URI links for easy sharing, cool URI patterns, and content negotiation using respective HTTP headers. We demonstrate the benefit of our converter by presenting two use cases.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In recent years prominent intellectuals have raised ethical concerns about the consequences of artificial intelligence. One concern is that an autonomous agent might modify itself to become \u201dsuperintelligent\u201d and, in supremely effective pursuit of poorly specified goals, destroy all of humanity. This paper considers and rejects the possibility of this outcome. We argue that this scenario depends on an agent\u2019s ability to rapidly improve its ability to predict its environment through self-modification. Using a Bayesian model of a reasoning agent, we show that there are important limitations to how an agent may improve its predictive ability through self-modification alone. We conclude that concern about this artificial intelligence outcome is misplaced and better directed at policy questions around data access and storage. The appetite of the public and prominent intellectuals for the study of the ethical implications of artificial intelligence has increased in recent years. One captivating possibility is that artificial intelligence research might result in a \u2018superintelligence\u2019 that puts humanity at risk. (Russell 2014) has called for AI researchers to consider this possibility seriously because, however unlikely, its mere possibility is grave. (Bostrom 2014) argues for the importance of considering the risks of artificial intelligence as a research agenda. For Bostrom, the potential risks of artificial intelligence are not just at the scale of industrial mishaps or weapons of mass destruction. Rather, Bostrom argues that artificial intelligence has the potential to threaten humanity as a whole and determine the fate of the universe. We approach this grand thesis with a measure of skepticism. Nevertheless, we hope that by elucidating the argument and considering potential objections in good faith, we can get a better grip on the realistic ethical implications of artificial intelligence. This paper is in that spirit. We consider the argument for this AI doomsday scenario proposed by Bostrom (Bostrom 2014). Section 1 summarizes Bostrom\u2019s argument and motivates the work of the rest of the paper. In focuses on the conditions of an \u201cintelligence explosion\u201d that would lead to a dominant machine intelligence averse to humanity. Section 2 argues that rather than speculating broadly about general artificial intelligence, we can predict outcomes of Copyright c \u00a9 2015, Sebastian Benthall. artificial intelligence by considering more narrowly a few tasks that are essential to instrumental reasoning. Section 3 considers recalcitrance, the resistance of a system to improvements to its own intelligence, and the ways it can limit intelligence explosion. Section 4 contains an analysis of the recalcitrance of prediction, using a Bayesian model of a predictive agent. We conclude that prediction is not something an agent can easily improve upon autonomously. Section 5 discusses the implication of these findings for further investigation into AI risk. 1 Bostrom\u2019s core argument and definitions Bostrom makes a number of claims in the course of his argument which I will outline here as distinct propositions. Proposition 1. A system with sufficient intelligence relative to other intelligent systems will have a \u2018decisive strategic advantage\u2019 and will determine the fate of the world and uni-\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automatic Liver and Tumor Segmentation of CT and MRI Volumes using Cascaded Fully Convolutional Neural Networks\nAbstract: Automatic segmentation of the liver and hepatic lesion is an important step towards deriving quantitative biomarkers for accurate clinical diagnosis and computer-aided decision support systems. This paper presents a method to automatically segment liver and lesions in CT and MRI abdomen images using cascaded fully convolutional neural networks (CFCNs) enabling the segmentation of a large-scale medical trial or quantitative image analysis. We train and cascade two FCNs for a combined segmentation of the liver and its lesions. In the first step, we train a FCN to segment the liver as ROI input for a second FCN. The second FCN solely segments lesions within the predicted liver ROIs of step 1. CFCN models were trained on an abdominal CT dataset comprising 100 hepatic tumor volumes. Validations on further datasets show that CFCN-based semantic liver and lesion segmentation achieves Dice scores over 94% for liver with computation times below 100s per volume. We further experimentally demonstrate the robustness of the proposed method on an 38 MRI liver tumor volumes and the public 3DIRCAD dataset.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Toward Case-Based Preference Elicitation: Similarity Measures on Preference Structures\nAbstract: While decision theory provides an appealing normative framework for representing rich preference structures, eliciting utility or value functions typically incurs a large cost. For many applications involving interactive sys\u00ad tems this overhead precludes the use of for\u00ad mal decision-theoretic models of preference. Instead of performing elicitation in a vacuum, it would be useful if we could augment di\u00ad rectly elicited preferences with some appro\u00ad priate default information. In this paper we propose a case-based approach to alleviat\u00ad ing the preference elicitation bottleneck. As\u00ad suming the existence of a population of users from whom we have elicited complete or in\u00ad complete preference structures, we propose eliciting the preferences of a new user inter\u00ad actively and incrementally, using the closest existing preference structures as potential de\u00ad faults. Since a notion of closeness demands a measure of distance among preference struc\u00ad tures, this paper takes the first step of study\u00ad ing various distance measures over fully and partially specified preference structures. We explore the use of Euclidean distance, Spear\u00ad man's footrule, and define a new measure, the probabilistic distance. We provide computa\u00ad tional techniques for all three measures.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: FFECTIVE recognition of objects for tracking in real-time video stream and processing of data involve integration of background modelling, shadow removal, foreground modelling\nAbstract: In this paper, we address the basic problem of recognizing moving objects in video images using Visual Vocabulary model and Bag of Words and track our object of interest in the subsequent video frames using species inspired PSO. Initially, the shadow free images are obtained by background modelling followed by foreground modeling to extract the blobs of our object of interest. Subsequently, we train a cubic SVM with human body datasets in accordance with our domain of interest for recognition and tracking. During training, using the principle of Bag of Words we extract necessary features of certain domains and objects for classification. Subsequently, matching these feature sets with those of the extracted object blobs that are obtained by subtracting the shadow free background from the foreground, we detect successfully our object of interest from the test domain. The performance of the classification by cubic SVM is satisfactorily represented by confusion matrix and ROC curve reflecting the accuracy of each module. After classification, our object of interest is tracked in the test domain using species inspired PSO. By combining the adaptive learning tools with the efficient classification of description, we achieve optimum accuracy in recognition of the moving objects. We evaluate our algorithm benchmark datasets: iLIDS, VIVID, Walking2, Woman. Comparative analysis of our algorithm against the existing state-of-the-art trackers shows very satisfactory and competitive results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EXAMPLES AS INTERACTION: ON HUMANS TEACHING A COMPUTER TO PLAY A GAME\nAbstract: This paper reviews an experiment in human-computer interaction, where interaction takes place when humans attempt to teach a computer to play a strategy board game. We show that while individually learned models can be shown to improve the playing performance of the computer, their straightforward composition results in diluting what was earlier learned. This observation suggests that interaction cannot be easily distributed when one hopes to harness multiple human experts to develop a quality computer player. This is related to similar approaches in robot task learning and to classic approaches to human learning and reinforces the need to develop tools that facilitate the mix of human-based tuition and computer self-learning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A note on the uniqueness of models in social abstract argumentation\nAbstract: Social abstract argumentation is a principled way to assign values to conflicting (weighted) arguments. In this note we discuss the important property of the uniqueness of the model.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: U-Sem: Semantic Enrichment, User Modeling and Mining of Usage Data on the Social Web\nAbstract: With the growing popularity of Social Web applications, more and more user data is published on the Web everyday. Our research focuses on investigating ways of mining data from such platforms that can be used for modeling users and for semantically augmenting user profiles. This process can enhance adaptation and personalization in various adaptive Web-based systems. In this paper, we present the U-Sem people modeling service, a framework for the semantic enrichment and mining of people\u2019s profiles from usage data on the Social Web. We explain the architecture of our people modeling service and describe its application in an adult e-learning context as an example.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Selecting the Best Player Formation for Corner-Kick Situations Based on Bayes\u2019 Estimation\nAbstract: In the domain of RoboCup 2D soccer simulation league, appropriate player positioning against a given opponent team is an important factor of soccer team performance. This work proposes a model which decides the strategy that should be applied regarding a particular opponent team. This task can be realized by applying preliminary a learning phase where the model determines the most effective strategies against clusters of opponent teams. The model determines the best strategies by using sequential Bayes\u2019 estimators. As a first trial of the system, the proposed model is used to determine the association of player formations against opponent teams in the particular situation of cornerkick. The implemented model shows satisfying abilities to compare player formations that are similar to each other in terms of performance and determines the right ranking even by running a decent number of simulation games.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Bayesian Networks: A Unification for Discrete and Gaussian Domains\nAbstract: We examine Bayesian methods for learn\u00ad ing Bayesian networks from a combination of prior knowledge and statistical data. In particular, we unify the approaches we pre\u00ad sented at last year's conference for discrete and Gaussian domains. We derive a gen\u00ad eral Bayesian scoring metric, appropriate for both domains. We then use this metric in combination with well-known statistical facts about the Dirichlet and normal-Wishart dis\u00ad tributions to derive our metrics for discrete and Gaussian domains.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Model Based Framework for Estimating Mutation Rate of Hepatitis C Virus in Egypt\nAbstract: Hepatitis C virus (HCV) is a widely spread disease all over the world. HCV has very high mutation rate that makes it resistant to antibodies. Modeling HCV to identify the virus mutation process is essential to its detection and predicting its evolution. This paper presents a model based framework for estimating mutation rate of HCV in two steps. Firstly profile hidden Markov model (PHMM) architecture was builder to select the sequences which represents sequence per year. Secondly mutation rate was calculated by using pair-wise distance method between sequences. A pilot study is conducted on NS5B zone of HCV dataset of genotype 4 subtype a (HCV4a) in Egypt.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Latent Attention Networks\nAbstract: Deep neural networks are able to solve tasks across a variety of domains and modalities of data. Despite many empirical successes, we lack the ability to clearly understand and interpret the learned internal mechanisms that contribute to such effective behaviors or, more critically, failure modes. In this work, we present a general method for visualizing an arbitrary neural network\u2019s inner mechanisms and their power and limitations. Our dataset-centric method produces visualizations of how a trained network attends to components of its inputs. The computed \u201cattention masks\u201d support improved interpretability by highlighting which input attributes are critical in determining output. We demonstrate the effectiveness of our framework on a variety of deep neural network architectures in domains from computer vision, natural language processing, and reinforcement learning. The primary contribution of our approach is an interpretable visualization of attention that provides unique insights into the network\u2019s underlying decision-making process irrespective of the data modality.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mixture Approximations to Bayesian Networks\nAbstract: Structure and parameters in a Bayesian net\u00ad work uniquely specify the probability distri\u00ad bution of the modeled domain. The locality of both structure and probabilistic informa\u00ad tion are the great benefits of Bayesian net\u00ad works and require the modeler to only spec\u00ad ify local information. On the other hand this locality of information might prevent the modeler -and even more any other person\u00ad from obtaining a general overview of the im\u00ad portant relationships within the domain. The goal of the work presented in this paper is to provide an \"alternative\" view on the knowl\u00ad edge encoded in a Bayesian network which might sometimes be very helpful for pro\u00ad viding insights into the underlying domain. The basic idea is to calculate a mixture ap\u00ad proximation to the probability distribution represented by the Bayesian network. The mixture component densities can be thought of as representing typical scenarios implied by the Bayesian model, providing intuition about the basic relationships. As an addi\u00ad tional benefit, performing inference in the approximate model is very simple and intu\u00ad itive and can provide additional insights. The computational complexity for the calculation of the mixture approximations critically de\u00ad pends on the measure which defines the dis\u00ad tance between the probability distribution represented by the Bayesian network and the approximate distribution. Both the KL\u00ad divergence and the backward KL-divergence lead to inefficient algorithms. Incidentally, the latter is used in recent work on mixtures of mean field solutions to which the work pre\u00ad sented here is closely related. We show, how\u00ad ever, that using a mean squared error cost function leads to update equations which can be solved using the junction tree algorithm. We conclude that the mean squared error cost function can be used for Bayesian net\u00ad works in which inference based on the junc\u00ad tion tree is tractable. For large networks, however, one may have to rely on mean field approximations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Support Vector Machine Classification with Indefinite Kernels\nAbstract: We propose a method for support vector machine classification using indefinite kernels. Instead of directly minimizing or stabilizing a nonconvex loss function, our algorithm simultaneously computes support vectors and a proxy kernel matrix used in forming the loss. This can be interpreted as a penalized kernel learning problem where indefinite kernel matrices are treated as noisy observations of a true Mercer kernel. Our formulation keeps the problem convex and relatively large problems can be solved efficiently using the projected gradient or analytic center cutting plane methods. We compare the performance of our technique with other methods on several standard data sets.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reinforcement learning based local search for grouping problems: A case study on graph coloring\nAbstract: Grouping problems aim to partition a set of items into multiple mutually disjoint subsets according to some specific criterion and constraints. Grouping problems cover a large class of important combinatorial optimization problems that are generally computationally difficult. In this paper, we propose a general solution approach for grouping problems, i.e., reinforcement learning based local search (RLS), which combines reinforcement learning techniques with descent-based local search. The viability of the proposed approach is verified on a well-known representative grouping problem (graph coloring) where a very simple descent-based coloring algorithm is applied. Experimental studies on popular DIMACS and COLOR02 benchmark graphs indicate that RLS achieves competitive performances compared to a number of well-known coloring algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: There is a significant lack of unified approaches to building generally intelligent machines. The majority of current artificial intelligence research operates within a very narrow field of focus, frequently without considering the importance of the \u2019big picture\u2019. In this document, we seek to describe and unify principles that guide the basis of our development of general artificial intelligence. These principles revolve around the idea that intelligence is a tool for searching for general solutions to problems. We define intelligence as the ability to acquire skills that narrow this search, diversify it and help steer it to more promising areas. We also provide suggestions for studying, measuring, and testing the various skills and abilities that a human-level1 1 Despite its vagueness, and the lack of a universal definition, the term provides a notion of an ability of a machine to solve as many tasks to at least the same level of accuracy as most humans. intelligent machine needs to acquire. The document aims to be both implementation agnostic, and to provide an analytic, systematic, and scalable way to generate hypotheses that we believe are needed to meet the necessary conditions in the search for general artificial intelligence. We believe that such a framework is an important stepping stone for bringing together definitions, highlighting open problems, connecting researchers willing to collaborate, and for unifying the arguably most significant search of this century.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multiobjective Optimization of Solar Powered Irrigation System with Fuzzy Type-2 Noise Modelling\nAbstract: Optimization is becoming a crucial element in industrial applications involving sustainable alternative energy systems. During the design of such systems, the engineer/decision maker would often encounter noise factors (e.g. solar insolation and ambient temperature fluctuations) when their system interacts with the environment. In this chapter, the sizing and design optimization of the solar powered irrigation system was considered. This problem is multivariate, noisy, nonlinear and multiobjective. This design problem was tackled by first using the Fuzzy Type II approach to model the noise factors. Consequently, the Bacterial Foraging Algorithm (BFA) (in the context of a weighted sum framework) was employed to solve this multiobjective fuzzy design problem. This method was then used to construct the approximate Pareto frontier as well as to identify the best solution option in a fuzzy setting. Comprehensive analyses and discussions were performed on the generated numerical results with respect to the implemented solution methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Lowering the learning curve for declarative programming: a Python API for the IDP system\nAbstract: Programmers may be hesitant to use declarative systems, because of the associated learning curve. In this paper, we present an API that integrates the IDP Knowledge Base system into the Python programming language. IDP is a state-of-the-art logical system, which uses SAT, SMT, Logic Programming and Answer Set Programming technology. Python is currently one of the most widely used (teaching) languages for programming. The first goal of our API is to allow a Python programmer to use the declarative power of IDP, without needing to learn any new syntax or semantics. The second goal is allow IDP to be added to/removed from an existing code base with minimal changes.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.84, which is only 0.1 percent worse and 1.2x faster than the current state-of-the-art model. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-ofthe-art.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-agent Reinforcement Learning with Sparse Interactions by Negotiation and Knowledge Transfer\nAbstract: Reinforcement learning has significant applications for multi-agent systems, especially in unknown dynamic environments. However, most multi-agent reinforcement learning (MARL) algorithms suffer from such problems as exponential computation complexity in the joint state-action space, which makes it difficult to scale up to realistic multi-agent problems. In this paper, a novel algorithm named negotiation-based MARL with sparse interactions (NegoSI) is presented. In contrast to traditional sparse-interaction based MARL algorithms, NegoSI adopts the equilibrium concept and makes it possible for agents to select the non-strict Equilibrium Dominating Strategy Profile (non-strict EDSP) or Meta equilibrium for their joint actions. The presented NegoSI algorithm consists of four parts: the equilibrium-based framework for sparse interactions, the negotiation for the equilibrium set, the minimum variance method for selecting one joint action and the knowledge transfer of local Q-values. In this integrated algorithm, three techniques, i.e., unshared value functions, equilibrium solutions and sparse interactions are adopted to achieve privacy protection, better coordination and lower computational complexity, respectively. To evaluate the performance of the presented NegoSI algorithm, two groups of experiments are carried out regarding three criteria: steps of each episode (SEE), rewards of each episode (REE) and average runtime (AR). The first group of experiments is conducted using six grid world games and shows fast convergence and high scalability of the presented algorithm. Then in the second group of experiments NegoSI is applied to an intelligent warehouse problem and simulated results demonstrate the effectiveness of the presented NegoSI algorithm compared with other state-of-the-art MARL algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Multi-Gene Genetic Programming Application for Predicting Students Failure at School\nAbstract: Several efforts to predict student failure rate (SFR) at school accurately still remains a core problem area faced by many in the educational sector. The procedure for forecasting SFR are rigid and most often times require data scaling or conversion into binary form such as is the case of the logistic model which may lead to lose of information and effect size attenuation. Also, the high number of factors, incomplete and unbalanced dataset, and black boxing issues as in Artificial Neural Networks and Fuzzy logic systems exposes the need for more efficient tools. Currently the application of Genetic Programming (GP) holds great promises and has produced tremendous positive results in different sectors. In this regard, this study developed GPSFARPS, a software application to provide a robust solution to the prediction of SFR using an evolutionary algorithm known as multi-gene genetic programming. The approach is validated by feeding a testing data set to the evolved GP models. Result obtained from GPSFARPS simulations show its unique ability to evolve a suitable failure rate expression with a fast convergence at 30 generations from a maximum specified generation of 500. The multigene system was also able to minimize the evolved model expression and accurately predict student failure rate using a subset of the original expression.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Injury risk prediction for traffic accidents in Porto Alegre/RS, Brazil (draft)\nAbstract: This study describes the experimental application of Machine Learning techniques to build prediction models that can assess the injury risk associated with traffic accidents. This work uses an freely available data set of traffic accident records that took place in the city of Porto Alegre/RS (Brazil) during the year of 2013. This study also provides an analysis of the most important attributes of a traffic accident that could produce an outcome of injury to the people involved in the accident.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Regret-based Reward Elicitation for Markov Decision Processes\nAbstract: The specification of a Markov decision process (MDP) can be difficult. Reward function specification is especially problematic; in practice, it is often cognitively complex and time-consuming for users to precisely specify rewards. This work casts the problem of specifying rewards as one of preference elicitation and aims to minimize the degree of precision with which a reward function must be specified while still allowing optimal or near-optimal policies to be produced. We first discuss how robust policies can be computed for MDPs given only partial reward information using the minimax regret criterion. We then demonstrate how regret can be reduced by efficiently eliciting reward information using bound queries, using regret-reduction as a means for choosing suitable queries. Empirical results demonstrate that regret-based reward elicitation offers an effective way to produce near-optimal policies without resorting to the precise specification of the entire reward function.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: As the practical use of answer set programming (ASP) has grown with the development of efficient solvers, we expect a growing interest in extensions of ASP as their semantics stabilize and solvers supporting them mature. Epistemic Specifications, which adds modal operators K and M to the language of ASP, is one such extension. We call a program in this language an epistemic logic program (ELP). Solvers have thus far been practical for only the simplest ELPs due to exponential growth of the search space. We describe a solver that is able to solve harder problems better (e.g., without exponentially-growing memory needs w.r.t. K and M occurrences) and faster than any other known ELP solver.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Data-Intensive Supercomputing in the Cloud\nAbstract: We present our experiences using cloud computing to support data-intensive analytics on satellite imagery for commercial applications. Drawing from our background in highperformance computing, we draw parallels between the early days of clustered computing systems and the current state of cloud computing and its potential to disrupt the HPC market. Using our own virtual file system layer on top of cloud remote object storage, we demonstrate aggregate read bandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE) nodes accessing a USA multi-region standard storage bucket. This figure is comparable to the best HPC storage systems in existence. We also present several of our application results, including the identification of field boundaries in Ukraine, and the generation of a global cloud-free base layer from Landsat imagery.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unsupervised Learning for Physical Interaction through Video Prediction\nAbstract: A core challenge for an agent learning to interact with the world is to predict how its actions affect objects in its environment. Many existing methods for learning the dynamics of physical interactions require labeled object information. However, to scale real-world interaction learning to a variety of scenes and objects, acquiring labeled data becomes increasingly impractical. To learn about physical object motion without labels, we develop an action-conditioned video prediction model that explicitly models pixel motion, by predicting a distribution over pixel motion from previous frames. Because our model explicitly predicts motion, it is partially invariant to object appearance, enabling it to generalize to previously unseen objects. To explore video prediction for real-world interactive agents, we also introduce a dataset of 50, 000 robot interactions involving pushing motions, including a test set with novel objects. In this dataset, accurate prediction of videos conditioned on the robot\u2019s future actions amounts to learning a \u201cvisual imagination\u201d of different futures based on different courses of action. Our experiments show that our proposed method not only produces more accurate video predictions, but also more accurately predicts object motion, when compared to prior methods.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Acquiring Word-Meaning Mappings for Natural Language Interfaces\nAbstract: This paper focuses on a system, Wolfie (WOrd Learning From Interpreted Examples), that acquires a semantic lexicon from a corpus of sentences paired with semantic representations. The lexicon learned consists of phrases paired with meaning representations. Wolfie is part of an integrated system that learns to transform sentences into representations such as logical database queries. Experimental results are presented demonstrating Wolfie\u2019s ability to learn useful lexicons for a database interface in four different natural languages. The usefulness of the lexicons learned by Wolfie are compared to those acquired by a similar system, with results favorable to Wolfie. A second set of experiments demonstrates Wolfie\u2019s ability to scale to larger and more difficult, albeit artificially generated, corpora. In natural language acquisition, it is difficult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, most results to date for active learning have only considered standard classification tasks. To reduce annotation effort while maintaining accuracy, we apply active learning to semantic lexicons. We show that active learning can significantly reduce the number of annotated examples required to achieve a given level of performance.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unified vector space mapping for knowledge representation systems\nAbstract: One of the most significant problems which inhibits further developments in the areas of Knowledge Representation and Artificial Intelligence is a problem of semantic alignment or knowledge mapping. The progress in its solution will be greatly beneficial for further advances of information retrieval, ontology alignment, relevance calculation, text mining, natural language processing etc. In the paper the concept of multidimensional global knowledge map, elaborated through unsupervised extraction of dependencies from large documents corpus, is proposed. In addition, the problem of direct Human \u2013 Knowledge Representation System interface is addressed and a concept of adaptive decoder proposed for the purpose of interaction with previously described unified mapping model. In combination these two approaches are suggested as basis for a development of a new generation of knowledge representation systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MAP Estimation, Message Passing, and Perfect Graphs\nAbstract: Efficiently finding the maximum a posteriori (MAP) configuration of a graphical model is an important problem which is often implemented using message passing algorithms. The optimality of such algorithms is only well established for singly-connected graphs and other limited settings. This article extends the set of graphs where MAP estimation is in P and where message passing recovers the exact solution to so-called perfect graphs. This result leverages recent progress in defining perfect graphs (the strong perfect graph theorem), linear programming relaxations of MAP estimation and recent convergent message passing schemes. The article converts graphical models into nand Markov random fields which are straightforward to relax into linear programs. Therein, integrality can be established in general by testing for graph perfection. This perfection test is performed efficiently using a polynomial time algorithm. Alternatively, known decomposition tools from perfect graph theory may be used to prove perfection for certain families of graphs. Thus, a general graph framework is provided for determining when MAP estimation in any graphical model is in P, has an integral linear programming relaxation and is exactly recoverable by message passing.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Effects of Coupling in Human-virtual Agent Body Interaction\nAbstract: This paper presents a study of the dynamic coupling between a user and a virtual character during body interaction. Coupling is directly linked with other dimensions, such as co-presence, engagement, and believability, and was measured in an experiment that allowed users to describe their subjective feelings about those dimensions of interest. The experiment was based on a theatrical game involving the imitation of slow upper-body movements and the proposal of new movements by the user and virtual agent. The agent\u2019s behaviour varied in autonomy: the agent could limit itself to imitating the user\u2019s movements only, initiate new movements, or combine both behaviours. After the game, each participant completed a questionnaire regarding their engagement in the interaction, their subjective feeling about the co-presence of the agent, etc. Based on four main dimensions of interest, we tested several hypotheses against our experimental results, which are discussed here.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Different machine learning techniques have been proposed and used for modeling individual and group user needs, interests and preferences. In the traditional predictive modeling instances are described by observable variables, called attributes. The goal is to learn a model for predicting the target variable for unseen instances. For example, for marketing purposes a company consider profiling a new user based on her observed web browsing behavior, referral keywords or other relevant information. In many real world applications the values of some attributes are not only observable, but can be actively decided by a decision maker. Furthermore, in some of such applications the decision maker is interested not only to generate accurate predictions, but to maximize the probability of the desired outcome. For example, a direct marketing manager can choose which type of a special offer to send to a client (actionable attribute), hoping that the right choice will result in a positive response with a higher probability. We study how to learn to choose the value of an actionable attribute in order to maximize the probability of a desired outcome in predictive modeling. We emphasize that not all instances are equally sensitive to changes in actions. Accurate choice of an action is critical for those instances, which are on the borderline (e.g. users who do not have a strong opinion one way or the other). We formulate three supervised learning approaches for learning to select the value of an actionable attribute at an instance level. We also introduce a focused training procedure which puts more emphasis on the situations where varying the action is the most likely to take the effect. The proof of concept experimental validation on two real-world case studies in web analytics and e-learning domains highlights the potential of the proposed approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: GeomRDF: A Geodata Converter with a Fine-Grained Structured Representation of Geometry in the Web\nAbstract: In recent years, with the advent of the web of data, a growing number of national mapping agencies tend to publish their geospatial data as Linked Data. However, differences between traditional GIS data models and Linked Data model can make the publication process more complicated. Besides, it may require, to be done, the setting of several parameters and some expertise in the semantic web technologies. In addition, the use of standards like GeoSPARQL (or ad hoc predicates) is mandatory to perform spatial queries on published geospatial data. In this paper, we present GeomRDF, a tool that helps users to convert spatial data from traditional GIS formats to RDF model easily. It generates geometries represented as GeoSPARQL WKT literal but also as structured geometries that can be exploited by using only the RDF query language, SPARQL. GeomRDF was implemented as a module in the RDF publication platform Datalift. A validation of GeomRDF has been realized against the French administrative units dataset (provided by IGN France).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Semantic Parsing of Mathematics by Context-based Learning from Aligned Corpora and Theorem Proving\nAbstract: We study methods for automated parsing of informal mathematical expressions into formal ones, a main prerequisite for deep computer understanding of informal mathematical texts. We propose a context-based parsing approach that combines efficient statistical learning of deep parse trees with their semantic pruning by type checking and large-theory automated theorem proving. We show that the methods very significantly improve on previous results in parsing theorems from the Flyspeck corpus.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Semantics of Gringo\nAbstract: Input languages of answer set solvers are based on the mathematically simple concept of a stable model. But many useful constructs available in these languages, including local variables, conditional literals, and aggregates, cannot be easily explained in terms of stable models in the sense of the original definition of this concept and its straightforward generalizations. Manuals written by designers of answer set solvers usually explain such constructs using examples and informal comments that appeal to the user\u2019s intuition, without references to any precise semantics. We propose to approach the problem of defining the semantics of gringo programs by translating them into the language of infinitary propositional formulas. This semantics allows us to study equivalent transformations of gringo programs using natural deduction in infinitary propositional logic.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\nAbstract: Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. The primary difficulty arises due to insufficient exploration, resulting in an agent being unable to learn robust value functions. Intrinsically motivated agents can explore new behavior for its own sake rather than to directly solve problems. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical value functions, operating at different temporal scales, with intrinsically motivated deep reinforcement learning. A top-level value function learns a policy over intrinsic goals, and a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse, delayed feedback: (1) a complex discrete MDP with stochastic transitions, and (2) the classic ATARI game \u2018Montezuma\u2019s Revenge\u2019.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tackling Dynamic Vehicle Routing Problem with Time Windows by means of Ant Colony System\nAbstract: The Dynamic Vehicle Routing Problem with Time Windows (DVRPTW) is an extension of the well-known Vehicle Routing Problem (VRP), which takes into account the dynamic nature of the problem. This aspect requires the vehicle routes to be updated in an ongoing manner as new customer requests arrive in the system and must be incorporated into an evolving schedule during the working day. Besides the vehicle capacity constraint involved in the classical VRP, DVRPTW considers in addition time windows, which are able to better capture realworld situations. Despite this, so far, few studies have focused on tackling this problem of greater practical importance. To this end, this study devises for the resolution of DVRPTW, an ant colony optimization based algorithm, which resorts to a joint solution construction mechanism, able to construct in parallel the vehicle routes. This method is coupled with a local search procedure, aimed to further improve the solutions built by ants, and with an insertion heuristics, which tries to reduce the number of vehicles used to service the available customers. The experiments indicate that the proposed algorithm is competitive and effective, and on DVRPTW instances with a higher dynamicity level, it is able to yield better results compared to existing ant-based approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Case-Based Merging Techniques in OAKPLAN\nAbstract: Case-based planning can take advantage of former problem-solving experiences by storing in a plan library previously generated plans that can be reused to solve similar planning problems in the future. Although comparative worst-case complexity analyses of plan generation and reuse techniques reveal that it is not possible to achieve provable efficiency gain of reuse over generation, we show that the case-based planning approach can be an effective alternative to plan generation when similar reuse candidates can be chosen.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Digital Synaptic Neural Substrate: Size and Quality Matters\nAbstract: We investigate the \u2018Digital Synaptic Neural Substrate\u2019 (DSNS) computational creativity approach further with respect to the size and quality of images that can be used to seed the process. In previous work we demonstrated how combining photographs of people and sequences taken from chess games between weak players can be used to generate chess problems or puzzles of higher aesthetic quality, on average, compared to alternative approaches. In this work we show experimentally that using larger images as opposed to smaller ones improves the output quality even further. The same is also true for using clearer or less corrupted images. The reasons why these things influence the DSNS process is presently not well-understood and debatable but the findings are nevertheless immediately applicable for obtaining better results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tractable Triangles and Cross-Free Convexity in Discrete Optimisation\nAbstract: The minimisation problem of a sum of unary and pairwise functions of discrete variables is a general NP-hard problem with wide applications such as computing MAP configurations in Markov Random Fields (MRF), minimising Gibbs energy, or solving binary Valued Constraint Satisfaction Problems (VCSPs). We study the computational complexity of classes of discrete optimisation problems given by allowing only certain types of costs in every triangle of variable-value assignments to three distinct variables. We show that for several computational problems, the only nontrivial tractable classes are the well known maximum matching problem and the recently discovered joint-winner property. Our results, apart from giving complete classifications in the studied cases, provide guidance in the search for hybrid tractable classes; that is, classes of problems that are not captured by restrictions on the functions (such as submodularity) or the structure of the problem graph (such as bounded treewidth). Furthermore, we introduce a class of problems with convex cardinality functions on cross-free sets of assignments. We prove that while imposing only one of the two conditions renders the problem NP-hard, the conjunction of the two gives rise to a novel tractable class satisfying the cross-free convexity property, which generalises the joint-winner property to problems of unbounded arity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Non-Minimal Triangulations for Mixed Stochastic/Deterministic Graphical Models\nAbstract: We observe that certain large-clique graph triangulations can be useful for reducing computational requirements when making queries on mixed stochastic/deterministic graphical models. We demonstrate that many of these largeclique triangulations are non-minimal and are thus unattainable via the elimination algorithm. We introduce ancestral pairs as the basis for novel triangulation heuristics and prove that no more than the addition of edges between ancestral pairs need be considered when searching for state space optimal triangulations in such graphs. Empirical results on random and real world graphs are given. We also present an algorithm and correctness proof for determining if a triangulation can be obtained via elimination, and we show that the decision problem associated with finding optimal state space triangulations in this mixed setting is NP-complete.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: E\u0301tude de Proble\u0300mes d\u2019Optimisation Combinatoire a\u0300 Multiples Composantes Interde\u0301pendantes\nAbstract: This extended abstract presents an overview on NP-hard optimization problems with multiple interdependent components. These problems occur in many real-world applications: industrial applications, engineering, and logistics. The fact that these problems are composed of many sub-problems that are NP-hard makes them even more challenging to solve using exact algorithms. This is mainly due to the high complexity of this class of algorithms and the hardness of the problems themselves. The main source of difficulty of these problems is the presence of internal dependencies between sub-problems. This aspect of interdependence of components is presented, and some outlines on solving approaches are briefly introduced from a (meta)heuristics and evolutionary computation perspective.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: BEEM : Bucket Elimination with External Memory\nAbstract: A major limitation of exact inference algorithms for probabilistic graphical models is their extensive memory usage, which often puts real-world problems out of their reach. In this paper we show how we can extend inference algorithms, particularly Bucket Elimination, a special case of cluster (join) tree decomposition, to utilize disk memory. We provide the underlying ideas and show promising empirical results of exactly solving large problems not solvable before.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Top Rank Optimization in Linear Time\nAbstract: Bipartite ranking aims to learn a real-valued ranking function that orders positive instances before<lb>negative instances. Recent efforts of bipartite ranking are focused on optimizing ranking accuracy<lb>at the top of the ranked list. Most existing approaches are either to optimize task specific metrics<lb>or to extend the ranking loss by emphasizing more on the error associated with the top ranked<lb>instances, leading to a high computational cost that is super-linear in the number of training<lb>instances. We propose a highly efficient approach, titled TopPush, for optimizing accuracy at the<lb>top that has computational complexity linear in the number of training instances. We present a<lb>novel analysis that bounds the generalization error for the top ranked instances for the proposed<lb>approach. Empirical study shows that the proposed approach is highly competitive to the state-<lb>of-the-art approaches and is 10-100 times faster.<lb>\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extending Modern SAT Solvers for Enumerating All Models\nAbstract: In this paper, we address the problem of enumerating all models of a Boolean formula in conjunctive normal form (CNF). We propose an extension of CDCL-based SAT solvers to deal with this fundamental problem. Then, we provide an experimental evaluation of our proposed SAT model enumeration algorithms on both satisfiable SAT instances taken from the last SAT challenge and on instances from the SAT-based encoding of sequence mining problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Principles and Examples of Plausible Reasoning and Propositional Plausible Logic\nAbstract: Plausible reasoning concerns situations whose inherent lack of precision is not quantified; that is, there are no degrees or levels of precision, and hence no use of numbers like probabilities. A hopefully comprehensive set of principles that clarifies what it means for a formal logic to do plausible reasoning is presented. A new propositional logic, called Propositional Plausible Logic (PPL), is defined and applied to some important examples. PPL is the only non-numeric non-monotonic logic we know of that satisfies all the principles and correctly reasons with all the examples. Some important results about PPL are proved.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Search for Impossibility Theorems in Social Choice Theory: Ranking Sets of Objects\nAbstract: We present a method for using standard techniques from satisfiability checking to automatically verify and discover theorems in an area of economic theory known as ranking sets of objects. The key question in this area, which has important applications in social choice theory and decision making under uncertainty, is how to extend an agent\u2019s preferences over a number of objects to a preference relation over nonempty sets of such objects. Certain combinations of seemingly natural principles for this kind of preference extension can result in logical inconsistencies, which has led to a number of important impossibility theorems. We first prove a general result that shows that for a wide range of such principles, characterised by their syntactic form when expressed in a many-sorted first-order logic, any impossibility exhibited at a fixed (small) domain size will necessarily extend to the general case. We then show how to formulate candidates for impossibility theorems at a fixed domain size in propositional logic, which in turn enables us to automatically search for (general) impossibility theorems using a SAT solver. When applied to a space of 20 principles for preference extension familiar from the literature, this method yields a total of 84 impossibility theorems, including both known and nontrivial new results.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Development of knowledge Base Expert System for Natural treatment of Diabetes disease\nAbstract: The development of expert system for treatment of Diabetes disease by using natural methods is new information technology derived from Artificial Intelligent research using ESTA (Expert System Text Animation) System. The proposed expert system contains knowledge about various methods of natural treatment methods (Massage, Herbal/Proper Nutrition, Acupuncture, Gems) for Diabetes diseases of Human Beings. The system is developed in the ESTA (Expert System shell for Text Animation) which is Visual Prolog 7.3 Application. The knowledge for the said system will be acquired from domain experts, texts and other related sources. KeywordsExpert System; ESTA; Natural treatment; Diabetes.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition\nAbstract: In this paper, a novel architecture for a deep recurrent neural network, residual LSTM is introduced.<lb>A plain LSTM has an internal memory cell that can learn long term dependencies of sequential data. It<lb>also provides a temporal shortcut path to avoid vanishing or exploding gradients in the temporal domain.<lb>The proposed residual LSTM architecture provides an additional spatial shortcut path from lower layers<lb>for efficient training of deep networks with multiple LSTM layers. Compared with the previous work,<lb>highway LSTM, residual LSTM reuses the output projection matrix and the output gate of LSTM to<lb>control the spatial information flow instead of additional gate networks, which effectively reduces more<lb>than 10% of network parameters. An experiment for distant speech recognition on the AMI SDM corpus<lb>indicates that the performance of plain and highway LSTM networks degrades with increasing network<lb>depth. For example, 10-layer plain and highway LSTM networks showed 13.7% and 6.2% increase in<lb>WER over 3-layer baselines, respectively. On the contrary, 10-layer residual LSTM networks provided<lb>the lowest WER 41.0%, which corresponds to 3.3% and 2.8% WER reduction over 3-layer plain and<lb>highway LSTM networks, respectively. Training with both the IHM and SDM corpora, the residual<lb>LSTM architecture provided larger gain from increasing depth: a 10-layer residual LSTM showed 3.0%<lb>WER reduction over the corresponding 5-layer one.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)\nAbstract: Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Social Networks to Aid Homeless Shelters: Dynamic Influence Maximization under Uncertainty - An Extended Version\nAbstract: This paper presents HEALER, a software agent that recommends sequential intervention plans for use by homeless shelters, who organize these interventions to raise awareness about HIV among homeless youth. HEALER\u2019s sequential plans (built using knowledge of social networks of homeless youth) choose intervention participants strategically to maximize influence spread, while reasoning about uncertainties in the network. While previous work presents influence maximizing techniques to choose intervention participants, they do not address three real-world issues: (i) they completely fail to scale up to real-world sizes; (ii) they do not handle deviations in execution of intervention plans; (iii) constructing real-world social networks is an expensive process. HEALER handles these issues via four major contributions: (i) HEALER casts this influence maximization problem as a POMDP and solves it using a novel planner which scales up to previously unsolvable realworld sizes; (ii) HEALER allows shelter officials to modify its recommendations, and updates its future plans in a deviation-tolerant manner; (iii) HEALER constructs social networks of homeless youth at low cost, using a Facebook application. Finally, (iv) we show hardness results for the problem that HEALER solves. HEALER will be deployed in the real world in early Spring 2016 and is currently undergoing testing at a homeless shelter.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Propositional Knowledge Representation in Restricted Boltzmann Machines\nAbstract: Representing symbolic knowledge into a connectionist network is the key element for the integration of scalable learning and sound reasoning. Most of the previous studies focus on discriminative neural networks which unnecessarily require a separation of input/output variables. Recent development of generative neural networks such as restricted Boltzmann machines (RBMs) has shown a capability of learning semantic abstractions directly from data, posing a promise for general symbolic learning and reasoning. Previous work on Penalty logic show a link between propositional logic and symmetric connectionist networks, however it is not applicable to RBMs. This paper proposes a novel method to represent propositional formulas into RBMs/stack of RBMs where Gibbs sampling can be seen as MaxSAT. It also shows a promising use of RBMs to learn symbolic knowledge through maximum likelihood estimation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Incremental Clustering and Expansion for Faster Optimal Planning in Decentralized POMDPs\nAbstract: This article presents the state-of-the-art in optimal solution methods for decentralized partially observable Markov decision processes (Dec-POMDPs), which are general models for collaborative multiagent planning under uncertainty. Building off the generalized multiagent A* (GMAA*) algorithm, which reduces the problem to a tree of one-shot collaborative Bayesian games (CBGs), we describe several advances that greatly expand the range of DecPOMDPs that can be solved optimally. First, we introduce lossless incremental clustering of the CBGs solved by GMAA*, which achieves exponential speedups without sacrificing optimality. Second, we introduce incremental expansion of nodes in the GMAA* search tree, which avoids the need to expand all children, the number of which is in the worst case doubly exponential in the node\u2019s depth. This is particularly beneficial when little clustering is possible. In addition, we introduce new hybrid heuristic representations that are more compact and thereby enable the solution of larger Dec-POMDPs. We provide theoretical guarantees that, when a suitable heuristic is used, both incremental clustering and incremental expansion yield algorithms that are both complete and search equivalent. Finally, we present extensive empirical results demonstrating that GMAA*-ICE, an algorithm that synthesizes these advances, can optimally solve Dec-POMDPs of unprecedented size.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Quantifying Mental Health from Social Media with Neural User Embeddings Quantifying Mental Health from Social Media with Neural User Embeddings\nAbstract: Mental illnesses adversely affect a significant proportion of the population worldwide. However, the methods traditionally used for estimating and characterizing the prevalence of mental health conditions are time-consuming and expensive. Consequently, best-available estimates concerning the prevalence of mental health conditions are often years out of date. Automated approaches to supplement these survey methods with broad, aggregated information derived from social media content provides a potential means for near realtime estimates at scale. These may, in turn, provide grist for supporting, evaluating and iteratively improving upon public health programs and interventions. We propose a novel model for automated mental health status quantification that incorporates user embeddings. This builds upon recent work exploring representation learning methods that induce embeddings by leveraging social media post histories. Such embeddings capture latent characteristics of individuals (e.g., political leanings) and encode a soft notion of homophily. In this paper, we investigate whether user embeddings learned from twitter post histories encode information that correlates with mental health statuses. To this end, we estimated user embeddings for a set of users known to be affected by depression and post-traumatic stress disorder (PTSD), and for a set of demographically matched \u2018control\u2019 users. We then evaluated these embeddings with respect to: (i) their ability to capture homophilic relations with respect to mental health status; and (ii) the performance of downstream mental health prediction models based on these features. Our experimental results demonstrate that the user embeddings capture similarities between users with respect to mental conditions, and are predictive of mental health.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-way Monte Carlo Method for Linear Systems\nAbstract: We study the Monte Carlo method for solving a linear system of the form x = Hx + b. A sufficient condition for the method to work is \u2016H\u2016 < 1, which greatly limits the usability of this method. We improve this condition by proposing a new multi-way Markov random walk, which is a generalization of the standard Markov random walk. Under our new framework we prove that the necessary and sufficient condition for our method to work is the spectral radius \u03c1(H) < 1, which is a weaker requirement than \u2016H\u2016 < 1. In addition to solving more problems, our new method can work faster than the standard algorithm. In numerical experiments on both synthetic and real world matrices, we demonstrate the effectiveness of our new method. ar X iv :1 60 8. 04 36 1v 1 [ cs .N A ] 1 5 A ug 2 01 6\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Axiomatic Approach to Routing\nAbstract: Information delivery in a network of agents is a key issue for large, complex systems that need to do so in a predictable, efficient manner. The delivery of information in such multi-agent systems is typically implemented through routing protocols that determine how information flows through the network. Different routing protocols exist each with its own benefits, but it is generally unclear which properties can be successfully combined within a given algorithm. We approach this problem from the axiomatic point of view, i.e., we try to establish what are the properties we would seek to see in such a system, and examine the different properties which uniquely define common routing algorithms used today. We examine several desirable properties, such as robustness, which ensures adding nodes and edges does not change the routing in a radical, unpredictable ways; and properties that depend on the operating environment, such as an \u201ceconomic model\u201d, where nodes choose their paths based on the cost they are charged to pass information to the next node. We proceed to fully characterize minimal spanning tree, shortest path, and weakest link routing algorithms, showing a tight set of axioms for each.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We propose a new approach to the theoretical analysis of Loopy Belief Propagation (LBP) and the Bethe free energy (BFE) by establishing a formula to connect LBP and BFE with a graph zeta function. The proposed approach is applicable to a wide class of models including multinomial and Gaussian types. The connection derives a number of new theoretical results on LBP and BFE. This paper focuses two of such topics. One is the analysis of the region where the Hessian of the Bethe free energy is positive definite, which derives the non-convexity of BFE for graphs with multiple cycles, and a condition of convexity on a restricted set. This analysis also gives a new condition for the uniqueness of the LBP fixed point. The other result is to clarify the relation between the local stability of a fixed point of LBP and local minima of the BFE, which implies, for example, that a locally stable fixed point of the Gaussian LBP is a local minimum of the Gaussian Bethe free energy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: STransE: a novel embedding model of entities and relationships in knowledge bases\u2217\nAbstract: Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform link prediction or knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This paper combines insights from several previous link prediction models into a new embedding model STransE that represents each entity as a low-dimensional vector, and each relation by two matrices and a translation vector. STransE is a simple combination of the SE and TransE models, but it obtains better link prediction performance on two benchmark datasets than previous embedding models. Thus, STransE can serve as a new baseline for the more complex models in the link prediction task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles\nAbstract: Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A New Penta-valued Logic Based Knowledge Representation\nAbstract: In this paper a knowledge representation model are proposed, FP5, which combine the ideas from fuzzy sets and penta-valued logic. FP5 represents imprecise properties whose accomplished degree is undefined, contradictory or indeterminate for some objects. Basic operations of conjunction, disjunction and negation are introduced. Relations to other representation models like fuzzy sets, intuitionistic, paraconsistent and bipolar fuzzy sets are discussed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Teraflop-scale Incremental Machine Learning\nAbstract: We propose a long-term memory design for artificial general intelligence based on Solomonoff\u2019s incremental machine learning methods. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on stochastic Context Free Grammar together with four synergistic update algorithms that use the same grammar as a guiding probability distribution of programs. The update algorithms include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. Experiments with two training sequences demonstrate that our approach to incremental learning is ef-\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: OpenTripPlanner, OpenStreetMap, General Transit Feed Specification: Tools for Disaster Relief and Recovery\nAbstract: OpenTripPlanner was identified as the most promising open source multimodal trip planning software. OpenStreetMap, which provides mapping data to OpenTripPlanner, is one of the most well-known open source international repository of geographic data. General Transit Feed Specification, which provides transportation data to OpenTripPlanner, has been the standard for describing transit systems and platform for numerous applications. Together, when used to implement an instance of OpenTripPlanner, these software has been helping in traffic decongestion all over the world by assisting commuters to shift from using private transportation modes to public ones. Their potential however goes beyond providing multimodal public transportation routes. This paper aims to first discuss the researchers\u2019 experience in implementing a public transportation route planner for the purpose of traffic decongestion. After, the researchers would examine the prospective of using the system for disaster preparedness and recovery and concrete ways on how to realize them.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Shared reference is an essential aspect of meaning. It is also indispensable for the semantic web, since it enables to weave the global graph, i.e., it allows different users to contribute to an identical referent. For example, an essential kind of referent is a geographic place, to which users may contribute observations. We argue for a human-centric, operational approach towards reference, based on respective human competences. These competences encompass perceptual, cognitive as well as technical ones, and together they allow humans to inter-subjectively refer to a phenomenon in their environment. The technology stack of the semantic web should be extended by such operations. This would allow establishing new kinds of observation-based reference systems that help constrain and integrate the semantic web bottom-up. 1 Meaning and Reference In the tradition of sciences such as philosophy and linguistics, semantics is the study of meaning, whereas syntax is the study of symbol manipulation. The classical distinction reflects that the realm of meaning is different and should not be confounded with the realm of syntax. The things symbols stand for are called referents. The notion of meaning involves such essential problems as how humans come to share language referents, and how we can refer to them in an inter-subjective way. This problem is what we call the problem of reference. In many respects, it can be considered a practical manifestation of the symbol grounding problem [1], the problem of how to get out of the realm of syntax into any determinable contact with referents in the world. The problem of reference has been an ongoing issue in the semantic web [2], and symbol grounding recently was recognized as an untackled problem [3]. Like symbol grounding, the problem of reference is not solved by formal semantics of a Tarskian flavour, because formal theories can neither distinguish a particular domain nor a particular interpretation [4]. Furthermore, natural language descriptions cannot account for reference, too, because they are context dependent, in particular since they rely on polysemy and synonymy [4]. The semantic web was proposed to make the meaning of information on the web explicit. Reference is an essential part of meaning that is also indispensable for the semantic web, especially for linked data. In particular, it is shared reference which allows to establish identity, and, thus, allows different users to contribute information to the same information item, e.g., different tags to the same place in Linked Geo Data. This so called network effect is critical to the semantic web [5]. However, often, semantic web research is driven by syntax and technology stacks in the first place. \u22c6 Dagstuhl Seminar 12221: Cognitive Approaches for the Semantic Web, 28.05.12 \u2013 01.06.12, Dedre Gentner, Pascal Hitzler, Kai-Uwe K\u00fchnberger, Frank van Harmelen We argue for enlarging the breadth of semantic web research by focusing on the problem of reference. This requires us to learn from existing grounded symbol systems and to notice how humans cognize [6] and disambiguate referents in language. 2 An operational view on the roots of reference We argue for an operational view on the problem of reference and take up on the ongoing debate in the semantic web. Meaning and referencing cannot be reduced to symbols. Some authors have tried to account for reference in terms of URIs [7], formal semantics [8,9], and appropriate descriptions [5]. Such approaches rely on the assumption that while meaning is external to the web, it can be regarded as internal to the semantic web; see also [8,7]. However, it is important to note that while the language of the semantic web is machine readable, meanings are not. Hayes points out that it is not possible to solve the problem of reference within language constructs [2]. The tendency seems therefore to surrender and start praising the benefits of ambiguity in language instead [2,8]. The existence of ontological disagreement [8], however, does not mean that we can dispense with intended meaning, as Ginsberg argued [10]. Intended meanings provide reference, and shared reference is critically indispensable in order to prevent data isolation. Referencing is something human observers do. We argue that there is no need to surrender but a need to shift perspective on the problem. Hayes and Halpin hint at the right direction when they state that \u201creference is part of a communicative act between cognitive agents\u201d that involves conventions [2]. We argue that referencing (and meaning as well) is not an object or some abstract mapping, but something that humans do [11], namely a kind of speech act that draws human attention to some reproducible phenomenon [12]. However, one should be aware that understanding this act draws on almost the full range of human cognitive capabilities, including Gestalt perception, joint attention [13], conventionally established predications and imagination. Technical language reference is based on human operations. The problem of where to begin the construction of a concise technical language [14], i.e., where to ground terms [12], is decisive for its meaningfulness, and is much too often disregarded in information ontology. [14] have argued that in order to prevent talking at cross purposes, it is necessary to begin with a language level whose interpretation is internalized, embodied in practice, and therefore shared among speakers, and on which a more concise technical language can be constructed. Paul Lorenzen argued that in order to understand the method of thought, we need to comprehend the extra-linguistic actions that are needed to build a language [14]. Does this mean that the current semantic web technology stack is useless? No, since ontologies are useful to constrain the interpretation and to infer implicit knowledge. However, they constrain interpretation only top-down, while shared references are based on human capabilities that constrain interpretation bottom-up [11]. We argue that the technology stack of the semantic web needs to draw on these cognitive capabilities in order to allow bottom-up semantic constraints [16, c.f.]. Based on this argumentation, we have shown in previous work how to reconstruct geospatial concepts based on perceptual operations and constructions instead of describing them top-down [12,17]. For example, geographic places [18], water bodies and environmental media [19], environmental qualities [20], road networks and 1 See the discussion in [12]. 2 See [14]. Quine\u2019s observation sentences [15] reflect a similar idea. junctions can be reconstructed based on observing action potentials (affordances) [21]. Reference systems. Solutions to the problem of reference should transgress syntax as well as technology. They cannot solely rely on computers but must also rely on human referential competences. This requirement is met by reference systems [22]. Reference systems are different from ontologies in that they constrain meaning bottom-up [11]. Most importantly, they are not \"yet another chimaera\" invented by ontology engineers, but already exist in various successful variants. A prominent example are spatial (geodetic) reference system, which provide a language about points on a mathematical ellipsoid anchored relative to the earth surface by reference observations of places and directions. It is responsible for the success of geographic information systems (GIS), navigation systems, and serves as an integration layer for the semantic web [23]. Another example are measurement scales, whose units of measurement are likewise established by conventional observations. Address systems are (geo-)reference systems for certain kinds of observable places, namely buildings. Calendars are temporal reference systems anchored in the observation of day and night, as well as celestial bodies. New kinds of reference systems as semantic integration layer. A reference system can be seen as a theory in which abstract or vague concepts are reconstructed based on conventionally established and, therefore, reproducible observation procedures [12]. This makes it useful as a semantic plane for linking heterogeneous conceptualizations that still divide the semantic web. A comparable idea is Peter G\u00e4rdenfors\u2019 notion of a conceptual space [24]. This is a geometric, topological space whose dimensions are anchored in human cognition, and in which concepts are expressed as convex regions. For example, local conceptualizations of a term like \u201chigh mountain\u201d can be compared in terms of different convex regions in this space [17]. New kinds of reference systems would allow us to negotiate or translate between heterogeneous views on the world [23]. For example, places are essential concepts for spatial referencing of user generated content on the social web, such as points of interest (POI), geo-tagged pictures, blog posts or tweets. But they are highly vague both regarding their boundaries as well as regarding category labels [12]. A place reference system would allow us to disambiguate place concepts beyond spatial footprints, taking into account the different types of afforded actions that constitutes them as well as their spatio-temporal distribution [18].\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: KR3: An Architecture for Knowledge Representation and Reasoning in Robotics\nAbstract: This paper describes an architecture that combines the complementary strengths of declarative programming and probabilistic graphical models to enable robots to represent, reason with, and learn from, qualitative and quantitative descriptions of uncertainty and knowledge. An action language is used for the low-level (LL) and high-level (HL) system descriptions in the architecture, and the definition of recorded histories in the HL is expanded to allow prioritized defaults. For any given goal, tentative plans created in the HL using default knowledge and commonsense reasoning are implemented in the LL using probabilistic algorithms, with the corresponding observations used to update the HL history. Tight coupling between the two levels enables automatic selection of relevant variables and generation of suitable action policies in the LL for each HL action, and supports reasoning with violation of defaults, noisy observations and unreliable actions in large and complex domains. The architecture is evaluated in simulation and on physical robots transporting objects in indoor domains; the benefit on robots is a reduction in task execution time of 39% compared with a purely probabilistic, but still hierarchical, approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Causal Mechanism-based Model Constructions\nAbstract: We propose a framework for building graph\u00ad ical causal model that is based on the con\u00ad cept of causal mechanisms. Causal models are intuitive for human users and, more im\u00ad portantly, support the prediction of the ef\u00ad fect of manipulation. We describe an imple\u00ad mentation of the proposed framework as an interactive model construction module, Ima\u00ad GeNie, in SMILE (Structural Modeling, In\u00ad ference, and Learning Engine) and in GeNie (SMILE's Windows user interface).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Optimistic Concurrency Control for Distributed Unsupervised Learning\nAbstract: Research on distributed machine learning algorithms has focused pri-<lb>marily on one of two extremes\u2014algorithms that obey strict concurrency<lb>constraints or algorithms that obey few or no such constraints. We consider<lb>an intermediate alternative in which algorithms optimistically assume that<lb>conflicts are unlikely and if conflicts do arise a conflict-resolution protocol<lb>is invoked. We view this \u201coptimistic concurrency control\u201d paradigm as<lb>particularly appropriate for large-scale machine learning algorithms, partic-<lb>ularly in the unsupervised setting. We demonstrate our approach in three<lb>problem areas: clustering, feature learning and online facility location. We<lb>evaluate our methods via large-scale experiments in a cluster computing<lb>environment. The desire to apply machine learning to increasingly larger datasets has<lb>pushed the machine learning community to address the challenges of distributed<lb>algorithm design: partitioning and coordinating computation across the pro-<lb>cessing resources. In many cases, when computing statistics of iid data or<lb>transforming features, the computation factors according to the data and coor-<lb>dination is only required during aggregation. For these embarrassingly parallel<lb>tasks, the machine learning community has embraced the map-reduce paradigm,<lb>which provides a template for constructing distributed algorithms that are fault<lb>tolerant, scalable, and easy to study.<lb>However, in pursuit of richer models, we often introduce statistical dependen-<lb>cies that require more sophisticated algorithms (e.g., collapsed Gibbs sampling<lb>or coordinate ascent) which were developed and studied in the serial setting.<lb>Because these algorithms iteratively transform a global state, parallelization can<lb>be challenging and often requires frequent and complex coordination.<lb>Recent efforts to distribute these algorithms can be divided into two pri-<lb>mary approaches. The mutual exclusion approach, adopted by [12] and [16], 1<lb>ar<lb>X<lb>iv<lb>:1<lb>30<lb>7.<lb>80<lb>49<lb>v1<lb>[<lb>cs<lb>.L<lb>G<lb>]<lb>3<lb>0<lb>Ju<lb>l<lb>2<lb>01<lb>3 guarantees a serializable execution preserving the theoretical properties of the<lb>serial algorithm but at the expense of parallelism and costly locking overhead.<lb>Alternatively, in the coordination-free approach, proposed by [21] and [1],<lb>processors communicate frequently without coordination minimizing the cost of<lb>contention but leading to stochasticity, data-corruption, and requiring potentially<lb>complex analysis to prove algorithm correctness.<lb>In this paper we explore a third approach, optimistic concurrency control<lb>(OCC) [14] which offers the performance gains of the coordination-free approach<lb>while at the same time ensuring a serializable execution and preserving the<lb>theoretical properties of the serial algorithm. Like the coordination-free approach,<lb>OCC exploits the infrequency of data-corrupting operations. However, instead<lb>of allowing occasional data-corruption, OCC detects data-corrupting operations<lb>and applies correcting computation. As a consequence, OCC automatically<lb>ensures correctness, and the analysis is only necessary to guarantee optimal<lb>scaling performance.<lb>We apply OCC to distributed nonparametric unsupervised learning\u2014<lb>including but not limited to clustering\u2014and implement distributed versions of<lb>the DP-Means [13], BP-Means [4], and online facility location (OFL) algorithms.<lb>We demonstrate how to analyze OCC in the context of the DP-Means algorithm<lb>and evaluate the empirical scalability of the OCC approach on all three of the<lb>proposed algorithms. The primary contributions of this paper are: 1. Concurrency control approach to distributing unsupervised learning algo-<lb>rithms. 2. Reinterpretation of online nonparametric clustering in the form of facility<lb>location with approximation guarantees. 3. Analysis of optimistic concurrency control for unsupervised learning. 4. Application to feature modeling and clustering. 1 Optimistic Concurrency Control Many machine learning algorithms iteratively transform some global state (e.g.,<lb>model parameters or variable assignment) giving the illusion of serial dependencies<lb>between each operation. However, due to sparsity, exchangeability, and other<lb>symmetries, it is often the case that many, but not all, of the state-transforming<lb>operations can be computed concurrently while still preserving serializability:<lb>the equivalence to some serial execution where individual operations have been<lb>reordered.<lb>This opportunity for serializable concurrency forms the foundation of dis-<lb>tributed database systems. For example, two customers may concurrently make<lb>purchases exhausting the inventory of unrelated products, but if they try to<lb>purchase the same product then we may need to serialize their purchases to<lb>ensure sufficient inventory. One solution (mutual exclusion) associates locks<lb>with each product type and forces each purchase of the same product to be<lb>processed serially. This might work for an unpopular, rare product but if we are\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Game-Theoretic Approach for Non-Cooperative Planning\nAbstract: When two or more self-interested agents put their plans to execution in the same environment, conflicts may arise as a consequence, for instance, of a common utilization of resources. In this case, an agent can postpone the execution of a particular action, if this punctually solves the conflict, or it can resort to execute a different plan if the agent\u2019s payoff significantly diminishes due to the action deferral. In this paper, we present a game-theoretic approach to non-cooperative planning that helps predict before execution what plan schedules agents will adopt so that the set of strategies of all agents constitute a Nash equilibrium. We perform some experiments and discuss the solutions obtained with our game-theoretical approach, analyzing how the conflicts between the plans determine the strategic behavior of the agents.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bipolar Weighted Argumentation Graphs\nAbstract: This paper discusses the semantics of weighted argumentation graphs that are biplor, i.e. contain both attacks and support graphs. The work builds on previous work by Amgoud, Ben-Naim et. al. [1, 2], which presents and compares several semantics for argumentation graphs that contain only supports or only attacks relationships, respectively.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Provable Optimal Algorithms for Generalized Linear Contextual Bandits\nAbstract: Contextual bandits are widely used in Internet services from news recommendation to advertising. Generalized linear models (logistical regression in particular) have demonstrated stronger performance than linear models in many applications. However, most theoretical analyses on contextual bandits so far are on linear bandits. In this work, we propose an upper confidence bound based algorithm for generalized linear contextual bandits, which achieves an \u00d5( \u221a dT ) regret over T rounds with d dimensional feature vectors. This regret matches the minimax lower bound, up to logarithmic terms, and improves on the best previous result by a \u221a d factor, assuming the number of arms is fixed. A key component in our analysis is to establish a new, sharp finite-sample confidence bound for maximumlikelihood estimates in generalized linear models, which may be of independent interest. We also analyze a simpler upper confidence bound algorithm, which is useful in practice, and prove it to have optimal regret for the certain cases.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Bayesian Method for Causal Modeling and Discovery Under Selection\nAbstract: This paper describes a Bayesian method for learning causal networks using samples that were selected in a non-random manner from a population of interest. Examples of data obtained by non-random sampling include convenience samples and case-control data in which a fixed number of samples with and without some condition is collected; such data are not uncommon. The paper describes a method for combining data under selection with prior beliefs in order to derive a posterior probability for a model of the causal processes that are generating the data in the population of interest. The priors include beliefs about the nature of the non-random sampling procedure. Although exact application of the method would be computationally intractable for most realistic datasets, efficient special-case and approximation methods are discussed. Finally, the paper describes how to combine learning under selection with previous methods for learning from observational and experimental data that are obtained on random samples of the population of interest. The net result is a Bayesian methodology that supports causal modeling and discovery from a rich mixture of different types of data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Irrelevance and Independence Relations in Quasi-Bayesian Networks\nAbstract: This paper analyzes irrelevance and independence re\u00ad lations in graphical models associated with convex sets of probability distributions (called Quasi-Bayesian networks) . The basic question in Quasi-Bayesian networks is, How can irrelevance/independence rela\u00ad tions in Quasi-Bayesian networks be detected, enforced and exploited? This paper addresses these questions through Walley's definitions of irrelevance and inde\u00ad pendence. Novel algorithms and results are presented for inferences with the so-called natural extensions us\u00ad ing fractional linear programming, and the properties of the so-called type-1 extensions are clarified through a new generalization of d-separation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Probabilistic Similarity Logic\nAbstract: Many machine learning applications require the ability to learn from and reason about noisy multi-relational data. To address this, several effective representations have been developed that provide both a language for expressing the structural regularities of a domain, and principled support for probabilistic inference. In addition to these two aspects, however, many applications also involve a third aspect\u2013the need to reason about similarities\u2013which has not been directly supported in existing frameworks. This paper introduces probabilistic similarity logic (PSL), a general-purpose framework for joint reasoning about similarity in relational domains that incorporates probabilistic reasoning about similarities and relational structure in a principled way. PSL can integrate any existing domainspecific similarity measures and also supports reasoning about similarities between sets of entities. We provide efficient inference and learning techniques for PSL and demonstrate its effectiveness both in common relational tasks and in settings that require reasoning about similarity.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Device Placement Optimization with Reinforcement Learning\nAbstract: The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-tosequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A COUNTEREXAMPLE TO THE FORWARD RECURSION IN FUZZY CRITICAL PATH ANALYSIS UNDER DISCRETE FUZZY SETS\nAbstract: Fuzzy logic is an alternate approach for quantifying uncertainty relating to activity duration. The fuzzy version of the backward recursion has been shown to produce results that incorrectly amplify the level of uncertainty. However, the fuzzy version of the forward recursion has been widely proposed as an approach for determining the fuzzy set of critical path lengths. In this paper, the direct application of the extension principle leads to a proposition that must be satisfied in fuzzy critical path analysis. Using a counterexample it is demonstrated that the fuzzy forward recursion when discrete fuzzy sets are used to represent activity durations produces results that are not consistent with the theory presented. The problem is shown to be the application of the fuzzy maximum. Several methods presented in the literature are described and shown to provide results that are consistent with the extension principle.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: HATP: An HTN Planner for Robotics\nAbstract: Hierarchical Task Network (HTN) planning is a popular approach that cuts down on the classical planning search space by relying on a given hierarchical library of domain control knowledge. This provides an intuitive methodology for specifying high-level instructions on how robots and agents should perform tasks, while also giving the planner enough flexibility to choose the lower-level steps and their ordering. In this paper we present the HATP (Hierarchical Agentbased Task Planner) planning framework which extends the traditional HTN planning domain representation and semantics by making them more suitable for roboticists, and treating agents as \u201cfirst class\u201d entities in the language. The former is achieved by allowing \u201csocial rules\u201d to be defined which specify what behaviour is acceptable/unacceptable by the agents/robots in the domain, and interleaving planning with geometric reasoning in order to validate online\u2013with respect to a detailed geometric 3D world\u2013the human/robot actions currently being pursued by HATP.1\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequential Diagnosis by Abstraction\nAbstract: When a system behaves abnormally, sequential diagnosis takes a sequence of measurements of the system until the faults causing the abnormality are identified, and the goal is to reduce the diagnostic cost, defined here as the number of measurements. To propose measurement points, previous work employs a heuristic based on reducing the entropy over a computed set of diagnoses. This approach generally has good performance in terms of diagnostic cost, but can fail to diagnose large systems when the set of diagnoses is too large. Focusing on a smaller set of probable diagnoses scales the approach but generally leads to increased average diagnostic costs. In this paper, we propose a new diagnostic framework employing four new techniques, which scales to much larger systems with good performance in terms of diagnostic cost. First, we propose a new heuristic for measurement point selection that can be computed efficiently, without requiring the set of diagnoses, once the system is modeled as a Bayesian network and compiled into a logical form known as d-DNNF. Second, we extend hierarchical diagnosis, a technique based on system abstraction from our previous work, to handle probabilities so that it can be applied to sequential diagnosis to allow larger systems to be diagnosed. Third, for the largest systems where even hierarchical diagnosis fails, we propose a novel method that converts the system into one that has a smaller abstraction and whose diagnoses form a superset of those of the original system; the new system can then be diagnosed and the result mapped back to the original system. Finally, we propose a novel cost estimation function which can be used to choose an abstraction of the system that is more likely to provide optimal average cost. Experiments with ISCAS-85 benchmark circuits indicate that our approach scales to all circuits in the suite except one that has a flat structure not susceptible to useful abstraction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Probabilistic Relational Dynamics for Multiple Tasks\nAbstract: The ways in which an agent\u2019s actions affect the world can often be modeled compactly using a set of relational probabilistic planning rules. This paper addresses the problem of learning such rule sets for multiple related tasks. We take a hierarchical Bayesian approach, in which the system learns a prior distribution over rule sets. We present a class of prior distributions parameterized by a rule set prototype that is stochastically modified to produce a task-specific rule set. We also describe a coordinate ascent algorithm that iteratively optimizes the task-specific rule sets and the prior distribution. Experiments using this algorithm show that transferring information from related tasks significantly reduces the amount of training data required to predict action effects in blocks-world domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A distance-based decision in the credal level\nAbstract: Belief function theory provides a flexible way to combine information provided by different sources. This combination is usually followed by a decision making which can be handled by a range of decision rules. Some rules help to choose the most likely hypothesis. Others allow that a decision is made on a set of hypotheses. In [6], we proposed a decision rule based on a distance measure. First, in this paper, we aim to demonstrate that our proposed decision rule is a particular case of the rule proposed in [4]. Second, we give experiments showing that our rule is able to decide on a set of hypotheses. Some experiments are handled on a set of mass functions generated randomly, others on real databases.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: No-Regret Learning in Extensive-Form Games with Imperfect Recall\nAbstract: Counterfactual Regret Minimization (CFR) is an efficient no-regret learning algorithm for decision problems modeled as extensive games. CFR\u2019s regret bounds depend on the requirement of perfect recall: players always remember information that was revealed to them and the order in which it was revealed. In games without perfect recall, however, CFR\u2019s guarantees do not apply. In this paper, we present the first regret bound for CFR when applied to a general class of games with imperfect recall. In addition, we show that CFR applied to any abstraction belonging to our general class results in a regret bound not just for the abstract game, but for the full game as well. We verify our theory and show how imperfect recall can be used to trade a small increase in regret for a significant reduction in memory in three domains: die-roll poker, phantom tic-tac-toe, and Bluff.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hardness of the Pricing Problem for Chains in Barter Exchanges\nAbstract: Kidney exchange is a barter market where patients trade willing but medically incompatible donors. These trades occur via cycles, where each patient-donor pair both gives and receives a kidney, and via chains, which begin with an altruistic donor who does not require a kidney in return. For logistical reasons, the maximum length of a cycle is typically limited to a small constant, while chains can be much longer. Given a compatibility graph of patient-donor pairs, altruists, and feasible potential transplants between them, finding even a maximumcardinality set of vertex-disjoint cycles and chains is NP-hard. There has been much work on developing provably optimal solvers that are efficient in practice. One of the leading techniques has been branch and price, where column generation is used to incrementally bring cycles and chains into the optimization model on an as-needed basis. In particular, only positive-price columns need to be brought into the model. We prove that finding a positive-price chain is NP-complete. This shows incorrectness of two leading branch-andprice solvers that suggested polynomial-time chain pricing algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Minimax Optimal Offline Policy Evaluation\nAbstract: This paper studies the off-policy evaluation problem, where one aims to estimate the value of a target policy based on a sample of observations collected by another policy. We first consider the multi-armed bandit case, establish a minimax risk lower bound, and analyze the risk of two standard estimators. It is shown, and verified in simulation, that one is minimax optimal up to a constant, while another can be arbitrarily worse, despite its empirical success and popularity. The results are applied to related problems in contextual bandits and fixed-horizon Markov decision processes, and are also related to semi-supervised learning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Structural-Model Approach\nAbstract: A definition of causality introduced by Halpern and Pearl [2005a], which uses structural equations, is reviewed. A more refined definition is then considered, which takes into account issues of normality and typicality, which are well known to affect causal ascriptions. Causality is typically an all-or-nothing notion: either A is a cause of B or it is not. An extension of the definition of causality to capture notions of degree of responsibility and degree of blame, due to Chockler and Halpern [2004], is reviewed. For example, if someone wins an election 11\u20130, then each person who votes for him is less responsible for the victory than if he had won 6\u20135, and another extension that considers the degree of blame, which takes into account an agent\u2019s epistemic state. Roughly speaking, the degree of blame of A for B is the expected degree of responsibility of A for B, taken over the epistemic state of an agent. Finally, the structural-equations definition of causality is compared to Wright\u2019s [1985, 1988, 2001] NESS test. Supported in part by NSF under under grants ITR-0325453, IIS-0534064, and IIS-0911036, and by AFOSR under grant FA9550-05-1-0055. Cause, Responsibility, and Blame: A Structural-Model Approach\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Contribution to the Formal Specification and Verification of a Multi-Agent Robotic System\nAbstract: It is important to have multi-agent robotic system specifications that ensure correctness properties of safety and liveness. As these systems have concurrency, and often have dynamic environment, the formal specification and verification of these systems along with step-wise refinement from abstract to concrete concepts play a major role in system correctness. Formal verification is used for exhaustive investigation of the system space thus ensuring that undetected failures in the behavior are excluded. We construct the system incrementally from subcomponents, based on software architecture. The challenge is to develop a safe multi-agent robotic system, more specifically to ensure the correctness properties of safety and liveness. Formal specifications based on model-checking are flexible, have a concrete syntax, and play vital role in correctness of a multi-agent robotic system. To formally verify safety and liveness of such systems is important because they have high concurrency and in most of the cases have dynamic environment. We have considered a case-study of a multi-agent robotic system for the transport of stock between storehouses to exemplify our formal approach. Our proposed development approach allows for formal verification during specification definition. The development process has been classified in to four major phases of requirement specifications, verification specifications, architecture specifications and implementation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Value-Directed Sampling Methods for Monitoring POMDPs\nAbstract: We consider the problem of approximate belief-state monitoring using particle filtering for the purposes of implementing a policy for a partially observable Markov decision process (POMDP). While particle fil\u00ad tering has become a widely used tool in AI for monitor\u00ad ing dynamical systems, rather scant attention has been paid to their use in the context of decision making. As\u00ad suming the existence of a value function, we derive er\u00ad ror bounds on decision quality associated with filtering using importance sampling. We also describe an adap\u00ad tive procedure that can be used to dynamically deter\u00ad mine the number of samples required to meet specific error bounds. Empirical evidence is offered supporting this technique as a profitable means of directing sam\u00ad pling effort where it is needed to distinguish policies.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Instance Segmentation with Object Priority: Prominent Object Detection and Recognition\nAbstract: This manuscript introduces the problem of prominent object detection and recognition inspired by the fact that human seems to priorities perception of scene elements. The problem deals with finding the most important region of interest, segmenting the relevant item/object in that area, and assigning it an object class label. In other words, we are solving the three problems of saliency modeling, saliency detection, and object recognition under one umbrella. The motivation behind such a problem formulation is (1) the benefits to the knowledge representation-based vision pipelines, and (2) the potential improvements in emulating bio-inspired vision systems by solving these three problems together. We are foreseeing extending this problem formulation to fully semantically segmented scenes with instance object priority for high-level inferences in various applications including assistive vision. Along with a new problem definition, we also propose a method to achieve such a task. The proposed model predicts the most important area in the image, segments the associated objects, and labels them. The proposed problem and method are evaluated against human fixations, annotated segmentation masks, and object class categories. We define a chance level for each of the evaluation criterion to compare the proposed algorithm with. Despite the good performance of the proposed baseline, the overall evaluations indicate that the problem of prominent object detection and recognition is a challenging task that is still worth investigating further.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Qsmodels: ASP Planning in Interactive Gaming Environment\u22c6\nAbstract: Qsmodels is a novel application of Answer Set Programming to interactive gaming environment. We describe a software architecture by which the behavior of a bot acting inside the Quake 3 Arena can be controlled by a planner. The planner is written as an Answer Set Program and is interpreted by the Smodels solver. This article describes the Qsmodels project, which grew out of a graduation project [3] is currently under development. The aim of this project is twofold. First, we want to demonstrate the viability of using Answer Set Programming [1] (ASP) in an interactive environment. The chosen environment is the Quake 3 Arena (Q3A) game from id Software; recently most of the source codes have been released to the public. Q3A is a first person shooter : the player\u2019s goal is to kill enemies using weapons and upgrades found inside the game field (normally a labyrinth). The human-like enemies found within Q3A are called BOTs. Like in the most computer games, Q3A bots behave according to the rules of a finite-state automaton (FSM) defined by expert game programmers. The second objective is to implement and experiment with the high-level agent architecture described by Baral, Gelfond and Provetti [2]. Such schema consists in the following loop: Observe\u2013 Select Goal\u2013Plan\u2013Execute. The Qsmodels architecture consists of two layers: a high level, responsible for midand longterm planning, and a (low level) in charge of plan execution and emergency state reactions. The high level has been developed mainly in ASP on the Smodels platform. I.e., smodels computes the answer sets of a logic program which characterizes all successful plans of a given length, following the more or less standard encoding found in [1]. The computed answer set is passed to the low-level layer that inspects it, extracts relevant syntactic informations and executes the required actions. The high-level layer of our project realizes a Q3A agent which, starting with the knowledge about the game field similar to that of an intermediate-level human player, tries to beat his opponents by facing them only when in a better condition for the attack. To achieve this result, we have added to the planner a very simple learning system which keeps track of opponent\u2019s behavior in order to better guess future moves. Even though we are still in the experimental phase, we submit that our architecture has several advantages over the traditional schema for the AI part of games. Namely, our solution is \u22c6 Work supported by the Information Society Technologies programme of the European Commission, Future and Emerging Technologies under the IST-2001-37004 WASP project.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Qualitative Comparison of Decisions Having Positive and Negative Features\nAbstract: Making a decision is often a matter of listing and comparing positive and negative arguments. In such cases, the evaluation scale for decisions should be considered bipolar, that is, negative and positive values should be explicitly distinguished. That is what is done, for example, in Cumulative Prospect Theory. However, contrary to the latter framework that presupposes genuine numerical assessments, human agents often decide on the basis of an ordinal ranking of the pros and the cons, and by focusing on the most salient arguments. In other terms, the decision process is qualitative as well as bipolar. In this article, based on a bipolar extension of possibility theory, we define and axiomatically characterize several decision rules tailored for the joint handling of positive and negative arguments in an ordinal setting. The simplest rules can be viewed as extensions of the maximin and maximax criteria to the bipolar case, and consequently suffer from poor decisive power. More decisive rules that refine the former are also proposed. These refinements agree both with principles of efficiency and with the spirit of order-of-magnitude reasoning, that prevails in qualitative decision theory. The most refined decision rule uses leximin rankings of the pros and the cons, and the ideas of counting arguments of equal strength and cancelling pros by cons. It is shown to come down to a special case of Cumulative Prospect Theory, and to subsume the \u201cTake the Best\u201d heuristic studied by cognitive psychologists.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Identifying Independence in Relational Models\nAbstract: The rules of d -separation provide a framework for deriving conditional independence facts from model structure. However, this theory only applies to simple directed graphical models. We introduce relational d -separation, a theory for deriving conditional independence in relational models. We provide a sound, complete, and computationally efficient method for relational d -separation, and we present empirical results that demonstrate effectiveness.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recognition Networks for Approximate Inference in BN20 Networks\nAbstract: A recognition network is a multilayer per\u00ad ception (MLP) trained to predict posterior marginals given observed evidence in a par\u00ad ticular Bayesian network. The input to the MLP is a vector of the states of the eviden\u00ad tial nodes. The activity of an output unit is interpreted as a prediction of the posterior marginal of the corresponding variable. The MLP is trained using samples generated from the corresponding Bayesian network. We evaluate a recognition network that was trained to do inference in a large Bayesian network, similar in structure and complex\u00ad ity to the Quick Medical Reference, Decision Theoretic (QMR-DT) network. Our network is a binary, two-layer, noisy-OR (BN20) net\u00ad work containing over 4000 potentially observ\u00ad able nodes and over 600 unobservable, hidden nodes. In real medical diagnosis, most ob\u00ad servables are unavailable, and there is a com\u00ad plex and unknown process that selects which ones are provided. We incorporate a very ba\u00ad sic type of selection bias in our network: a known preference that available observables are positive rather than negative. Even this simple bias has a significant effect on the pos\u00ad terior. We compare the performance of our recogni\u00ad tion network to state-of-the-art approximate inference algorithms on a large set of test cases. In order to evaluate the effect of our simplistic model of the selection bias, we eval\u00ad uate algorithms using a variety of incorrectly modelled selection biases. Recognition net\u00ad works perform well using both correct and incorrect selection biases. \u2022 also affiliated with Department of Brain and Cogni\u00ad tive Sciences at MIT\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Feature Based Fuzzy Rule Base Design for Image Extraction\nAbstract: In the recent advancement of multimedia technologies, it becomes a major concern of detecting visual attention regions in the field of image processing. The popularity of the terminal devices in a heterogeneous environment of the multimedia technology gives us enough scope for the betterment of image visualization. Although there exist numerous methods, feature based image extraction becomes a popular one in the field of image processing. The objective of image segmentation is the domain-independent partition of the image into a set of regions, which are visually distinct and uniform with respect to some property, such as grey level, texture or colour. Segmentation and subsequent extraction can be considered the first step and key issue in object recognition, scene understanding and image analysis. Its application area encompasses mobile devices, industrial quality control, medical appliances, robot navigation, geophysical exploration, military applications, etc. In all these areas, the quality of the final results depends largely on the quality of the preprocessing work. Most of the times, acquiring spurious-free preprocessing data requires a lot of application cum mathematical intensive background works. We propose a feature based fuzzy rule guided novel technique that is functionally devoid of any external intervention during execution. Experimental results suggest that this approach is an efficient one in comparison to different other techniques extensively addressed in literature. In order to justify the supremacy of performance of our proposed technique in respect of its competitors, we take recourse to effective metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE) and Peak Signal to Noise Ratio (PSNR).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Data Centroid Based Multi-Level Fuzzy Min-Max Neural Network\nAbstract: Recently, a multi-level fuzzy min max neural network (MLF) was proposed, which improves the classification accuracy by handling an overlapped region (area of confusion) with the help of a tree structure. In this brief, an extension of MLF is proposed which defines a new boundary region, where the previously proposed methods mark decisions with less confidence and hence misclassification is more frequent. A methodology to classify patterns more accurately is presented. Our work enhances the testing procedure by means of data centroids. We exhibit an illustrative example, clearly highlighting the advantage of our approach. Results on standard datasets are also presented to evidentially prove a consistent improvement in the classification rate.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The combined approach of the Qualitative Reasoning and Probabilistic Functions for the knowledge representation is proposed. The method aims at represent uncertain, qualitative knowledge that is essential for the moving blocks task\u2019s execution. The attempt to formalize the commonsense knowledge is performed with the Situation Calculus language for reasoning and robot\u2019s beliefs representation. The method is implemented in the Prolog programming language and tested for a specific simulated scenario. In most cases the implementation enables us to solve a given task, i.e., move blocks to desired positions. The example of robot\u2019s reasoning and main parts of the implemented program\u2019s code are presented.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Multi-view Context-aware Approach to Android Malware Detection and Malicious Code Localization\nAbstract: Existing Android malware detection approaches use a variety of features such as securitysensitive APIs, system calls, control-flow structures and information flows in conjunction with Machine Learning classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps\u2019 behaviors with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterize several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevents them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localization. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDroid uses a graph kernel to capture structural and contextual information from apps\u2019 dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid\u2019s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Graying the black box: Understanding DQNs\nAbstract: In recent years there is a growing interest in using deep representations for reinforcement learning. In this paper, we present a methodology and tools to analyze Deep Q-networks (DQNs) in a non-blind matter. Using our tools we reveal that the features learned by DQNs aggregate the state space in a hierarchical fashion, explaining its success. Moreover we are able to understand and describe the policies learned by DQNs for three different Atari2600 games and suggest ways to interpret, debug and optimize of deep neural networks in Reinforcement Learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Low-rank Shared Dictionary Learning for Image Classification\nAbstract: Despite the fact that different objects possess distinct class-specific features, they also usually share common patterns. This observation has been exploited partially in a recently proposed dictionary learning framework by separating the particularity and the commonality (COPAR). Inspired by this, we propose a novel method to explicitly and simultaneously learn a set of common patterns as well as class-specific features for classification with more intuitive constraints. Our dictionary learning framework is hence characterized by both a shared dictionary and particular (class-specific) dictionaries. For the shared dictionary, we enforce a low-rank constraint, i.e. claim that its spanning subspace should have low dimension and the coefficients corresponding to this dictionary should be similar. For the particular dictionaries, we impose on them the well-known constraints stated in the Fisher discrimination dictionary learning (FDDL). Further, we develop new fast and accurate algorithms to solve the subproblems in the learning step, accelerating its convergence. The said algorithms could also be applied to FDDL and its extensions. The efficiencies of these algorithms are theoretically and experimentally verified by comparing their complexities and running time with those of other well-known dictionary learning methods. Experimental results on widely used image datasets establish the advantages of our method over state-of-the-art dictionary learning methods.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Incremental Learning of Event Definitions with Inductive Logic Programming\nAbstract: Event recognition systems rely on properly engineered knowledge bases of event definitions to infer occurrences of events in time. The manual development of such knowledge is a tedious and error-prone task, thus event-based applications may benefit from automated knowledge construction techniques, such as Inductive Logic Programming (ILP), which combines machine learning with the declarative and formal semantics of First-Order Logic. However, learning temporal logical formalisms, which are typically utilized by logic-based Event Recognition systems is a challenging task, which most ILP systems cannot fully undertake. In addition, event-based data is usually massive and collected at different times and under various circumstances. Ideally, systems that learn from temporal data should be able to operate in an incremental mode, that is, revise prior constructed knowledge in the face of new evidence. Most ILP systems are batch learners, in the sense that in order to account for new evidence they have no alternative but to forget past knowledge and learn from scratch. Given the increased inherent complexity of ILP and the volumes of real-life temporal data, this results to algorithms that scale poorly. In this work we present an incremental method for learning and revising event-based knowledge, in the form of Event Calculus programs. The proposed algorithm relies on abductive-inductive learning and comprises a scalable clause refinement methodology, based on a compressive summarization of clause coverage in a stream of examples. We present an empirical evaluation of our approach on real and synthetic data from activity recognition and city transport applications. Nikos Katzouris National Center for Scientific Research \u201cDemokritos\u201d and National University of Athens E-mail: nkatz@iit.demokritos.gr Alexander Artikis University of Piraeus and National Center for Scientific Research \u201cDemokritos\u201d E-mail: E-mail: a.artikis@iit.demokritos.gr George Paliouras National Center for Scientific Research \u201cDemokritos\u201d E-mail: paliourg@iit.demokritos.gr ar X iv :1 40 2. 59 88 v2 [ cs .L G ] 2 2 N ov 2 01 4 2 Nikos Katzouris et al.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stochastic simulation algorithms for dynamic probabilistic networks\nAbstract: Stochastic simulation algorithms such as like\u00ad lihood weighting often give fast, accurate approximations to posterior probabilities in probabilistic networks, and are the methods of choice for very large networks. Unfor\u00ad tunately, the special characteristics of dy\u00ad namic probabilistic networks (DPNs), which are used to represent stochastic temporal pro\u00ad cesses, mean that standard simulation algo\u00ad rithms perform very poorly. In essence, the simulation trials diverge further and further from reality as the process is observed over time. In this paper, we present simulation algorithms that use the evidence observed at each time step to push the set of trials back towards reality. The first algorithm, \"evi\u00ad dence reversal\" (ER) restructures each time slice of the DPN so that the evidence nodes for the slice become ancestors of the state variables. The second algorithm, called \"sur\u00ad vival of the fittest\" sampling (SOF), \"repop\u00ad ulates\" the set of trials at each time step us\u00ad ing a stochastic reproduction rate weighted by the likelihood of the evidence according to each trial. We compare the performance of each algorithm with likelihood weighting on the original network, and also investigate the benefits of combining the ER and SOF methods. The ER/SOF combination appears to maintain bounded error independent of the number of time steps in the simulation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Infinite-Horizon Policy-Gradient Estimation\nAbstract: Gradient-based approaches to direct policy search in reinforcement learning have received much recent attention as a means to solve problems of partial observability and to avoid some of the problems associated with policy degradation in value-function methods. In this paper we introduce GPOMDP, a simulation-based algorithm for generating a biased estimate of the gradient of the average reward in Partially Observable Markov Decision Processes (POMDPs) controlled by parameterized stochastic policies. A similar algorithm was proposed by Kimura, Yamamura, and Kobayashi (1995). The algorithm\u2019s chief advantages are that it requires storage of only twice the number of policy parameters, uses one free parameter 2 [0; 1) (which has a natural interpretation in terms of bias-variance trade-off), and requires no knowledge of the underlying state. We prove convergence of GPOMDP, and show how the correct choice of the parameter is related to the mixing time of the controlledPOMDP. We briefly describe extensions ofGPOMDP to controlled Markov chains, continuous state, observation and control spaces, multiple-agents, higher-order derivatives, and a version for training stochastic policies with internal states. In a companion paper (Baxter, Bartlett, & Weaver, 2001) we show how the gradient estimates generated by GPOMDP can be used in both a traditional stochastic gradient algorithm and a conjugate-gradient procedure to find local optima of the average reward.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DYNAMIC NETWORK UPDATING TECHNIQUES FOR DIAGNOSTIC REASONING\nAbstract: A new probabilistic network construction system, DYNASTY, is proposed for diagnos\u00ad tic reasoning given variables whose probabil\u00ad ities change over time. Diagnostic reason\u00ad ing is formulated as a sequential stochastic process, and is modeled using influence dia\u00ad grams. Given a set 0 of observations, DY\u00ad NASTY creates an influence diagram in or\u00ad der to devise the best action given 0. Sensi\u00ad tivity analyses are conducted to determine if the best network has been created, given the uncertainty in network parameters and topol\u00ad ogy. DYNASTY uses an equivalence class ap\u00ad proach to provide decision thresholds for the sensitivity analysis. This equivalence-class approach to diagnostic reasoning differenti\u00ad ates diagnoses only if the required actions are different. A set of network-topology updat\u00ad ing algorithms are proposed for dynamically updating the network when necessary.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Answer Set Programming for Non-Stationary Markov Decision Processes\nAbstract: Non-stationary domains, where unforeseen changes happen, present a challenge for agents to find an optimal policy for a sequential decision making problem. This work investigates a solution to this problem that combines Markov Decision Processes (MDP) and Reinforcement Learning (RL) with Answer Set Programming (ASP) in a method we call ASP(RL). In this method, Answer Set Programming is used to find the possible trajectories of an MDP, from where Reinforcement Learning is applied to learn the optimal policy of the problem. Results show that ASP(RL) is capable of efficiently finding the optimal solution of an MDP representing non-stationary domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Proposal for the creation of a research facility for the development of the SP machine\u2217\nAbstract: This is a proposal to create a research facility for the development of a high-parallel version of the SP machine, based on the SP theory of intelligence. We envisage that the new version of the SP machine will be an open-source software virtual machine, derived from the existing SP computer model, and hosted on an existing high-performance computer. It is intended as a means for researchers everywhere to explore what can be done with the system and to create new versions of it. The SP system is a unique attempt to simplify and integrate observations and concepts across artificial intelligence, mainstream computing, mathematics, and human perception and cognition, with information compression via the matching and unification of patterns as a unifying theme. Many potential benefits and applications flow from this simplification and integration. These include potential with problems associated with big data; potential to facilitate the development of autonomous robots; and potential in other areas including: unsupervised learning, natural language processing, several kinds of reasoning, fuzzy pattern recognition and recognition at multiple levels of abstraction, computer vision, best-match and semantic forms of information retrieval, software engineering, medical diagnosis, simplification of computing systems, and the seamless integration of diverse kinds of knowledge and diverse aspects of intelligence. Additional motivations for creating the proposed facility include \u2217An electronic copy of this document may be downloaded via bit.ly/1zZjjIs. \u2020Dr Gerry Wolff, BA (Cantab), PhD (Wales), CEng, MIEEE, MBCS (CITP); CognitionResearch.org, Menai Bridge, UK; jgw@cognitionresearch.org; +44 (0) 1248 712962; +44 (0) 7746 290775; Skype: gerry.wolff; Web: www.cognitionresearch.org. \u2021Dr Vasile Palade, MEng (Tech. Univ. of Bucharest), PhD (University of Gala\u0163i), IEEE Senior Member; Reader in Pervasive Computing, Department of Computing, Coventry University, UK; vasile.palade@coventry.ac.uk; +44 (0) 2477 659190; +44 (0) 7912 043982; Skype: v palade; Web: bit.ly/1xNM5xr, bit.ly/1Buyk9E. 1 ar X iv :1 50 8. 04 57 0v 1 [ cs .A I] 1 9 A ug 2 01 5 the potential of the SP system to help solve problems in defence, security, and the detection and prevention of crime; the potential impact of the development in terms of economic, social, environmental, and academic criteria, and in terms of publicity; and the potential for international influence in research. The main elements of the proposed facility are described, including support for the development of SP-neural, a neural version of the SP machine. The facility should be permanent in the sense that it should be available for the foreseeable future, and it should be designed to facilitate its use by researchers anywhere in the world.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Understanding and Harnessing the Potential of Clause Learning\nAbstract: Efficient implementations of DPLL with the addition of clause learning are the fastest complete Boolean satisfiability solvers and can handle many significant real-world problems, such as verification, planning and design. Despite its importance, little is known of the ultimate strengths and limitations of the technique. This paper presents the first precise characterization of clause learning as a proof system (CL), and begins the task of understanding its power by relating it to the well-studied resolution proof system. In particular, we show that with a new learning scheme, CL can provide exponentially shorter proofs than many proper refinements of general resolution (RES) satisfying a natural property. These include regular and Davis-Putnam resolution, which are already known to be much stronger than ordinary DPLL. We also show that a slight variant of CL with unlimited restarts is as powerful as RES itself. Translating these analytical results to practice, however, presents a challenge because of the nondeterministic nature of clause learning algorithms. We propose a novel way of exploiting the underlying problem structure, in the form of a high level problem description such as a graph or PDDL specification, to guide clause learning algorithms toward faster solutions. We show that this leads to exponential speed-ups on grid and randomized pebbling problems, as well as substantial improvements on certain ordering formulas.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Improving DPLL Solver Performance with Domain-Specific Heuristics: the ASP Case\nAbstract: In spite of the recent improvements in the performance of the solvers based on the DPLL procedure, it is still possible for the search algorithm to focus on the wrong areas of the search space, preventing the solver from returning a solution in an acceptable amount of time. This prospect is a real concern e.g. in an industrial setting, where users typically expect consistent performance. To overcome this problem, we propose a framework that allows learning and using domain-specific heuristics in solvers based on the DPLL procedure. The learning is done off-line, on representative instances from the target domain, and the learned heuristics are then used for choice-point selection. In this paper we focus on Answer Set Programming (ASP) solvers. In our experiments, the introduction of domain-specific heuristics improved performance on hard instances by up to 3 orders of magnitude (and 2 on average), nearly completely eliminating the cases in which the solver had to be terminated because the wait for an answer had become unacceptable.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards a theory of good SAT representations\nAbstract: We consider the fundamental task of representing a boolean function f by a conjunctive normal form (clause-set) F for the purpose of SAT solving. The boolean function f here acts as a kind of constraint, like a cardinality constraint or an S-box in a cryptosystem, while F is a subset of the whole SAT problem to be solved. The traditional approach towards \u201cgood\u201d properties of F considers \u201carc consistency\u201d, which demands that for every partial instantiation of f , all forced assignments can be recovered from the corresponding partial assignment to F via unit-clause propagation (UCP). We propose to consider a more refined framework: First, instead of considering the above relative condition, a relation between f and F , we consider an absolute condition, namely that goodness of F is guaranteed by F being element of a suitable target class. And second, instead of just considering UCP, we consider hierarchies of target classes, which allow for different mechanisms than UCP and allow for size/complexity trade-offs. The hierarchy UCk of unit-refutation complete clause-sets of level k, introduced in [36, 37, 38], provides the most basic target classes, that is, F \u2208 UCk is to be achieved for k as small as feasible. Here UC1 = UC has been introduced in [26] for the purpose of knowledge compilation. In general, UCk is the set of clause-sets F such that unsatisfiable instantiations (by partial assignments) are recognisable by k-times nested unit-clause propagation. We also touch upon the hierarchy PCk of propagation complete clause-sets of level k, where PC1 = PC has been introduced in [15]. The hierarchy PCk refines the hierarchy UCk by providing intermediate layers. In order to make use of full resolution, we consider the hierarchy WCk of width-refutation complete clauses-sets of level k, employing an improved notion of width (so that we always have UCk \u2286 WCk). Via the absolute condition, the quality of the representation F is fully captured by the target class, and the only relation between f and F is that F must \u201crepresent\u201d f . If F does not contain new variables, then this means that F is equivalent to f , while with new variables the satisfying assignments of F projected to the variables of f must be precisely the satisfying assignments of f . Without new variables, the relative and absolute condition coincide, but with new variables, the absolute condition is stronger. As we remark in this article, for the relative condition and new variables at least the hierarchies UCk and PCk collapse, and we also conjecture that the WCk hierarchy collapses. The main result of this article is that without new variables, none of these hierarchies collapses. That means that there are boolean functions with only exponential-size equivalent clause-sets at level k, but with poly-size equivalent clause-sets at level k + 1.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Gesture recognition is mainly apprehensive on analyzing the functionality of human wits. The main goal of gesture recognition is to create a system which can recognize specific human gestures and use them to convey information or for device control. Hand gestures provide a separate complementary modality to speech for expressing ones ideas. Information associated with hand gestures in a conversation is degree, discourse structure, spatial and temporal structure. The approaches present can be mainly divided into Data-Glove Based and Vision Based approaches. An important face feature point is the nose tip. Since nose is the highest protruding point from the face. Besides that, it is not affected by facial expressions. Another important function of the nose is that it is able to indicate the head pose. Knowledge of the nose location will enable us to align an unknown 3D face with those in a face database. Eye detection is divided into eye position detection and eye contour detection. Existing works in eye detection can be classified into two major categories: traditional image-based passive approaches and the active IR based approaches. The former uses intensity and shape of eyes for detection and the latter works on the assumption that eyes have a reflection under near IR illumination and produce bright/dark pupil effect. The traditional methods can be broadly classified into three categories: template based methods, appearance based methods and feature based methods. The purpose of this paper is to compare various human Gesture recognition systems for interfacing machines directly to human wits without any corporeal media in an ambient environment.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Maximum Likelihood-based Online Adaptation of Hyper-parameters in CMA-ES\nAbstract: The Covariance Matrix Adaptation Evolution Strategy (CMAES) is widely accepted as a robust derivative-free continuous optimization algorithm for non-linear and non-convex optimization problems. CMA-ES is well known to be almost parameterless, meaning that only one hyper-parameter, the population size, is proposed to be tuned by the user. In this paper, we propose a principled approach called selfCMA-ES to achieve the online adaptation of CMA-ES hyper-parameters in order to improve its overall performance. Experimental results show that for larger-than-default population size, the default settings of hyperparameters of CMA-ES are far from being optimal, and that self-CMAES allows for dynamically approaching optimal settings.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Reinforcement Learning-based Image Captioning with Embedding Reward\nAbstract: Image captioning is a challenging problem owing to the complexity in understanding the image content and diverse ways of describing it in natural language. Recent advances in deep neural networks have substantially improved the performance of this task. Most state-of-the-art approaches follow an encoder-decoder framework, which generates captions using a sequential recurrent prediction model. However, in this paper, we introduce a novel decision-making framework for image captioning. We utilize a \u201cpolicy network\u201d and a \u201cvalue network\u201d to collaboratively generate captions. The policy network serves as a local guidance by providing the confidence of predicting the next word according to the current state. Additionally, the value network serves as a global and lookahead guidance by evaluating all possible extensions of the current state. In essence, it adjusts the goal of predicting the correct words towards the goal of generating captions similar to the ground truth captions. We train both networks using an actor-critic reinforcement learning model, with a novel reward defined by visual-semantic embedding. Extensive experiments and analyses on the Microsoft COCO dataset show that the proposed framework outperforms state-ofthe-art approaches across different evaluation metrics.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A la croise\u0301e de l\u2019informatique et du the\u0301a\u0302tre : similarite\u0301 en intension versus similarite\u0301 en extension\nAbstract: La mise en sc\u00e8ne de th\u00e9\u00e2tre traditionnelle repose sur une approche formelle de la similarit\u00e9 s\u2019appuyant sur des ontologies dramaturgiques et des variations d\u2019instanciation. Inspir\u00e9s par la fouille de donn\u00e9es num\u00e9riques interactive, qui sugg\u00e8re des approches diff\u00e9rentes, nous rendons compte de recherches th\u00e9\u00e2trales utilisant l\u2019ordinateur comme partenaire de l\u2019acteur pour \u00e9chapper \u00e0 la sp\u00e9cification a priori des r\u00f4les.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi\u2013resource defensive strategies for patrolling games with alarm systems\nAbstract: Security Games employ game theoretical tools to derive resource allocation strategies in security domains. Recent works considered the presence of alarm systems, even suffering various forms of uncertainty, and showed that disregarding alarm signals may lead to arbitrarily bad strategies. The central problem with an alarm system, unexplored in other Security Games, is finding the best strategy to respond to alarm signals for each mobile defensive resource. The literature provides results for the basic single\u2013resource case, showing that even in that case the problem is computationally hard. In this paper, we focus on the challenging problem of designing algorithms scaling with multiple resources. First, we focus on finding the minimum number of resources assuring non\u2013null protection to every target. Then, we deal with the computation of multi\u2013resource strategies with different degrees of coordination among resources. For each considered problem, we provide a computational analysis and propose algorithmic methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Even more generic solution construction in Valuation-Based Systems\nAbstract: Valuation algebras abstract a large number of formalisms for automated reasoning and enable the definition of generic inference procedures. Many of these formalisms provide some notions of solutions. Typical examples are satisfying assignments in constraint systems, models in logics or solutions to linear equation systems. Recently, formal requirements for the presence of solutions and a generic algorithm for solution construction based on the results of a previously executed inference scheme have been proposed [9, 8]. Unfortunately, the formalization of Pouly and Kohlas relies on a theorem for which we provide a counter example. In spite of that, the mainline of the theory described is correct, although some of the necessary conditions to apply some of the algorithms have to be revised. To fix the theory, we generalize some of their definitions and provide correct sufficient conditions for the algorithms. As a result, we get a more general and corrected version of the theory presented at [9, 8].\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Reward Function for Survival\nAbstract: Obtaining a survival strategy (policy) is one of the fundamental problems of biological agents. In this paper, we generalize the formulation of previous research related to the survival of an agent and we formulate the survival problem as a maximization of the multi-step survival probability in future time steps. We introduce a method for converting the maximization of multi-step survival probability into a classical reinforcement learning problem. Using this conversion, the reward function (negative temporal cost function) is expressed as the log of the temporal survival probability. And we show that the objective function of the reinforcement learning in this sense is proportional to the variational lower bound of the original problem. Finally, We empirically demonstrate that the agent learns survival behavior by using the reward function introduced in this paper.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analyzing Games with Ambiguous Player Types Using the MINthenMAX Decision Model\nAbstract: In many common interactive scenarios, participants lack information about other participants, and specifically about the preferences of other participants. In this work, we model an extreme case of incomplete information, which we term games with type ambiguity, where a participant lacks even information enabling him to form a belief on the preferences of others. Under type ambiguity, one cannot analyze the scenario using the commonly used Bayesian framework, and therefore one needs to model the participants using a different decision model. To this end, we present the MINthenMAX decision model under ambiguity. This model is a refinement of Wald\u2019s MiniMax principle, which we show to be too coarse for games with type ambiguity. We characterize MINthenMAX as the finest refinement of the MiniMax principle that satisfies three properties we claim are necessary for games with type ambiguity. This prior-less approach we present here also follows the common practice in computer science of worst-case analysis. Finally, we define and analyze the corresponding equilibrium concept, when all players follow MINthenMAX. We demonstrate this equilibrium by applying it to two common economic scenarios: coordination games and bilateral trade. We show that in both scenarios, an equilibrium in pure strategies always exists, and we analyze\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extracting Lifted Mutual Exclusion Invariants from Temporal Planning Domains\nAbstract: We present a technique for automatically extracting mutual exclusion invariants from temporal planning instances. It first identifies a set of invariant templates by inspecting the lifted representation of the domain and then checks these templates against properties that assure invariance. Our technique builds on other approaches to invariant synthesis presented in the literature, but departs from their limited focus on instantaneous actions by addressing temporal domains. To deal with time, we formulate invariance conditions that account for the entire structure of the actions and the possible concurrent interactions between them. As a result, we construct a significantly more comprehensive technique than previous methods, which is able to find not only invariants for temporal domains, but also a broader set of invariants for non-temporal domains. The experimental results reported in this paper provide evidence that identifying a broader set of invariants results in the generation of fewer multi-valued state variables with larger domains. We show that, in turn, this reduction in the number of variables reflects positively on the performance of a number of temporal planners that use a variable/value representation by significantly reducing their running time.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dealing with uncertainty on the initial state of a Petri net\nAbstract: give a reminder on the Petri net theory. This paper proposes a method to find the ac\u00ad tual state of a complex dynamic system from information coming from the sensors on the system himself, or on its environment. The nominal evolution of the system is a pri\u00ad ori known and can be modeled (by an expert, for example) , by different methods. In this paper, the Petri nets have been chosen. Con\u00ad trary to the usual use of the Petri nets, the initial state of the system is unknown. So a degree of belief is bound to each places, or set of places. The theory used to model this un\u00ad certainty is the Dempster-Shafer's one which is well adapted to this type of problems. From the given Petri net characterizing the nominal evolution of the dynamic system, and from the observation inputs, the pro\u00ad posed method allows to determine according to the reliability of the model and the inputs, the state of the system at any time.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Log-based Evaluation of Label Splits for Process Models\nAbstract: Process mining techniques aim to extract insights in processes from event logs. One of the challenges in process mining is identifying interesting and meaningful event labels that contribute to a better understanding of the process. Our application area is mining data from smart homes for elderly, where the ultimate goal is to signal deviations from usual behavior and provide timely recommendations in order to extend the period of independent living. Extracting individual process models showing user behavior is an important instrument in achieving this goal. However, the interpretation of sensor data at an appropriate abstraction level is not straightforward. For example, a motion sensor in a bedroom can be triggered by tossing and turning in bed or by getting up. We try to derive the actual activity depending on the context (time, previous events, etc.). In this paper we introduce the notion of label refinements, which links more abstract event descriptions with their more refined counterparts. We present a statistical evaluation method to determine the usefulness of a label refinement for a given event log from a process perspective. Based on data from smart homes, we show how our statistical evaluation method for label refinements can be used in practice. Our method was able to select two label refinements out of a set of candidate label refinements that both had a positive effect on model precision.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Pseudo Fuzzy Set\nAbstract: Here a novel idea to handle imprecise or vague set viz. Pseudo fuzzy set has been proposed. Pseudo fuzzy set is a triplet of element and its two membership functions. Both the membership functions may or may not be dependent. The hypothesis is that every positive sense has some negative sense. So, one membership function has been considered as positive and another as negative. Considering this concept, here the development of Pseudo fuzzy set and its property along with Pseudo fuzzy numbers has been discussed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: STEX+ \u2013 a System for Flexible Formalization of Linked Data\nAbstract: We present the STEX+ system, a user-driven advancement of STEX \u2014 a semantic extension of LTEX that allows for producing high-quality PDF documents for (proof)reading and printing, as well as semantic XML/OMDoc documents for the Web or further processing. Originally STEX had been created as an invasive, semantic frontend for authoring XML documents. Here, we used STEX in a Software Engineering case study as a formalization tool. In order to deal with modular pre-semantic vocabularies and relations, we upgraded it to STEX+ in a participatory design process. We present a tool chain that starts with an STEX+ editor and ultimately serves the generated documents as XHTML+RDFa Linked Data via an OMDoc-enabled, versioned XML database. In the final output, all structural annotations are preserved in order to enable semantic information retrieval services.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Note on Information-Directed Sampling and Thompson Sampling\nAbstract: This note introduce three Bayesian style Multi-armed bandit algorithms: Information-directed sampling, Thompson Sampling and Generalized Thompson Sampling. The goal is to give an intuitive explanation for these three algorithms and their regret bounds, and provide some derivations that are omitted in the original papers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Composition of Probability Measures on Finite Spaces\nAbstract: Decomposable models and Bayesian net\u00ad works can be defined as sequences of oligo\u00ad dimensional probability measures connected with opemtors of composition. The prelim\u00ad inary results suggest that the probabilistic models allowing for effective computational procedures are represented by sequences pos\u00ad sessing a special property; we shall call them perfect sequences. The present paper lays down the elementary foundation necessary for further study of it\u00ad erative application of operators of composi\u00ad tion. We believe to develop a technique de\u00ad scribing several graph models in a unifying way. We are convinced that practically all theoretical results and procedures connected with decomposable models and Bayesian net\u00ad works can be translated into the terminology introduced in this paper. For example, com\u00ad plexity of computational procedures in these models is closely dependent on possibility to change the ordering of oligo-dimensional mea\u00ad sures defining the model. Therefore, in this paper, lot of attention is paid to possibility to change ordering of the operators of composi\u00ad tion. 1 NOTATION Let {Xi};EV be a finite system of finite sets. We shall deal with probability measures on the Cartesian prod\u00ad uct space\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Approach For Transforming of Relational Databases to OWL Ontology\nAbstract: Rapid growth of documents, web pages, and other types of text content is a huge challenge for the modern content management systems. One of the problems in the areas of information storage and retrieval is the lacking of semantic data. Ontologies can present knowledge in sharable and repeatedly usable manner and provide an effective way to reduce the data volume overhead by encoding the structure of a particular domain. Metadata in relational databases can be used to extract ontology from database in a special domain. According to solve the problem of sharing and reusing of data, approaches based on transforming relational database to ontology are proposed. In this paper we propose a method for automatic ontology construction based on relational database. Mining and obtaining further components from relational database leads to obtain knowledge with high semantic power and more expressiveness. Triggers are one of the database components which could be transformed to the ontology model and increase the amount of power and expressiveness of knowledge by presenting part of the knowledge dynamically.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reasoning in Infinitely Valued G-IALCQ\nAbstract: Fuzzy Description Logics (FDLs) are logic-based formalisms used to represent and reason with vague or imprecise knowledge. It has been recently shown that reasoning in most FDLs using truth values from the interval [0, 1] becomes undecidable in the presence of a negation constructor and general concept inclusion axioms. One exception to this negative result are FDLs whose semantics is based on the infinitely valued G\u00f6del t-norm (G). In this paper, we extend previous decidability results for G-IALC to deal also with qualified number restrictions. Our novel approach is based on a combination of the known crispification technique for finitely valued FDLs and the automatabased procedure originally developed for reasoning in G-IALC . The proposed approach combines the advantages of these two methods, while removing their respective drawbacks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Convergence in Navigational Reinforcement Learning\nAbstract: Reinforcement learning is a formal framework for modeling agents that learn to solve tasks. For example, one important task for animals is to navigate in an environment to find food or to return to their nest. In such tasks, the agent has to learn a path through the environment from start states to goal states, by visiting a sequence of intermediate states. The agent receives reward on a goal state. Concretely, we need to learn a policy that maps each encountered state to an immediate action that leads to a next state, eventually leading to a goal state. We say that a learning process has converged if eventually the policy will no longer change, i.e., the policy stabilizes. The intuition of paths and navigation policies can be applied generally. Indeed, in this article, we study navigation tasks formalized as a graph structure that, for each application of an action to a state, describes the possible successor states that could result from that application. In contrast to standard reinforcement learning, we essentially simplify numeric reward signals to boolean flags on the transitions in the graph. The resulting framework enables a clear theoretical study of how properties of the graph structure can cause convergence of the learning process. In particular, we formally study a learning process that detects revisits to states in the graph, i.e., we detect cycles, and the process keeps adjusting the policy until no more cycles are made. So, eventually, the agent goes straight to reward from each start state. We identify reducibility of the task graph as a sufficient condition for this learning process to converge. We also syntactically characterize the form of the final policy, which can be used to detect convergence in a simulation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: x Acknowledgements xii Chapter\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On The Power of Tree Projections: Structural Tractability of Enumerating CSP Solutions\nAbstract: The problem of deciding whether CSP instances admit solutions has been deeply studied in the literature, and several structural tractability results have been derived so far. However, constraint satisfaction comes in practice as a computation problem where the focus is either on finding one solution, or on enumerating all solutions, possibly projected over some given set of output variables. The paper investigates the structural tractability of the problem of enumerating (possibly projected) solutions, where tractability means here computable with polynomial delay (WPD), since in general exponentially many solutions may be computed. A general framework based on the notion of tree projection of hypergraphs is considered, which generalizes all known decomposition methods. Tractability results have been obtained both for classes of structures where output variables are part of their specification, and for classes of structures where computability WPD must be ensured for any possible set of output variables. These results are shown to be tight, by exhibiting dichotomies for classes of structures having bounded arity and where the tree decomposition method is considered.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Causal Discovery from Changes\nAbstract: We propose a new method of discovering causal structures, based on the detection of local, spontaneous changes in the un\u00ad derlying data-generating model. We ana\u00ad lyze the classes of structures that are equiv\u00ad alent relative to a stream of distributions produced by local changes, and devise algo\u00ad rithms that output graphical representations of these equivalence classes. We present ex\u00ad perimental results, using simulated data, and examine the errors associated with detection of changes and recovery of structures.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Calculus for Causal Relevance\nAbstract: We present a sound and complete calculus for causal relevance that uses Pearl's func\u00ad tional causal models as semantics. The cal\u00ad culus consists of axioms and rules of inference for reasoning about causal relevance relation\u00ad ships. We extend the set of known axioms for causal relevance with new axioms and rules of inference. The axioms are then divided into different sets for reasoning about spe\u00ad cific subclasses of models. These subclasses make up a new decomposition of the class of causal models. At the end, we show how the calculus for causal relevance can be used in the task of identifying causal structure from non-observational data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Quantifying Creativity in Art Networks\u2217\nAbstract: Can we develop a computer algorithm that assesses the creativity of a painting given its context within art history? This paper proposes a novel computational framework for assessing the creativity of creative products, such as paintings, sculptures, poetry, etc. We use the most common definition of creativity, which emphasizes the originality of the product and its influential value. The proposed computational framework is based on constructing a network between creative products and using this network to infer about the originality and influence of its nodes. Through a series of transformations, we construct a Creativity Implication Network. We show that inference about creativity in this network reduces to a variant of network centrality problems which can be solved efficiently. We apply the proposed framework to the task of quantifying creativity of paintings (and sculptures). We experimented on two datasets with over 62K paintings to illustrate the behavior of the proposed framework. We also propose a methodology for quantitatively validating the results of the proposed algorithm, which we call the \u201ctime machine experiment\u201d.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?\nAbstract: Non-technical losses (NTL) occur during the distribution of electricity in power grids and include, but are not limited to, electricity theft and faulty meters. In emerging countries, they may range up to 40% of the total electricity distributed. In order to detect NTLs, machine learning methods are used that learn irregular consumption patterns from customer data and inspection results. The Big Data paradigm followed in modern machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results are biased as well and therefore lead to unreliable predictions of whether customers cause NTL or not. In machine learning, this issue is called covariate shift and has not been addressed in the literature on NTL detection yet. In this work, we present a novel framework for quantifying and visualizing covariate shift. We apply it to a commercial data set from Brazil that consists of 3.6M customers and 820K inspection results. We show that some features have a stronger covariate shift than others, making predictions less reliable. In particular, previous inspections were focused on certain neighborhoods or customer classes and that they were not sufficiently spread among the population of customers. This framework is about to be deployed in a commercial product for NTL detection.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Limitations and Alternatives for the Evaluation of Large-scale Link Prediction\nAbstract: Link prediction, the problem of identifying missing links among a set of inter-related data entities, is a popular field of research due to its application to graph-like domains. Producing consistent evaluations of the performance of the many link prediction algorithms being proposed can be challenging due to variable graph properties, such as size and density. In this paper we first discuss traditional data mining solutions which are applicable to link prediction evaluation, arguing about their capacity for producing faithful and useful evaluations. We also introduce an innovative modification to a traditional evaluation methodology with the goal of adapting it to the problem of evaluating link prediction algorithms when applied to large graphs, by tackling the problem of class imbalance. We empirically evaluate the proposed methodology and, building on these findings, make a case for its importance on the evaluation of large-scale graph processing. Graph Mining Link Prediction Evaluation Methodology\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hierarchical Linearly-Solvable Markov Decision Problems (Extended Version with Supplementary Material)\nAbstract: We present a hierarchical reinforcement learning framework that formulates each task in the hierarchy as a special type of Markov decision process for which the Bellman equation is linear and has analytical solution. Problems of this type, called linearly-solvable MDPs (LMDPs) have interesting properties that can be exploited in a hierarchical setting, such as efficient learning of the optimal value function or task compositionality. The proposed hierarchical approach can also be seen as a novel alternative to solving LMDPs with large state spaces. We derive a hierarchical version of the socalled Z-learning algorithm that learns different tasks simultaneously and show empirically that it significantly outperforms the state-of-the-art learning methods in two classical hierarchical reinforcement learning domains: the taxi domain and an autonomous guided vehicle task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recovering Epipolar Geometry from Images of Smooth Surfaces\nAbstract: We present four methods for recovering the epipolar geometry from images of smooth surfaces. In the existing methods for recovering epipolar geometry corresponding feature points are used that cannot be found in such images. The first method is based on finding corresponding characteristic points created by illumination (ICPM illumination characteristic points method). The second method is based on correspondent tangency points created by tangents from epipoles to outline of smooth bodies (OTPM outline tangent points method). These two methods are exact and give correct results for real images, because positions of the corresponding illumination characteristic points and corresponding outline are known with small errors. But the second method is limited either to special type of scenes or to restricted camera motion. We also consider two more methods which are termed CCPM (curve characteristic points method, green curves are used for this method on Figures) and CTPM (curve tangent points method, red curves are used for this method on Figures), for searching epipolar geometry for images of smooth bodies based on a set of level curves (isophoto curves) with a constant illumination intensity. The CCPM method is based on searching correspondent points on isophoto curves with the help of correlation of curvatures between these lines. The CTPM method is based on property of the tangential to isophoto curve epipolar line to map into the tangential to correspondent isophoto curves epipolar line. The standard method termed SM (standard method, blue curves are used for this method on Figures) and based on knowledge of pairs of the almost exact correspondent points, has been used for testing of these two methods. The main technical contributions of our CCPM method are following. The first of them consists of bounding the search space for epipole locations. On the face of it, this space is infinite and unbounded. We suggest a method to partition the infinite plane into a finite number of regions. This partition is based on the desired accuracy and maintains properties that yield an efficient search over the infinite plane. The second is an efficient method for finding correspondence between points of two closed isophoto curves and finding homography, mapping between these two isophoto curves. Then this homography is corrected for all possible epipole positions with the help of evaluation function. A finite subset of solution is chosen from the full set given by all possible epipole positions. This subset includes fundamental matrices giving local minimums of evaluating function close to global minimum. Epipoles of this subset lie almost on straight line directed parallel to parallax shift. CTPM method was used to find the best solution from this subset. Our method is applicable to any pair of images of smooth objects taken under perspective projection models, as long as assumption of the constant brightness is taken for granted. The methods have\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning for Multi-label Classification\nAbstract: In multi-label classification, the main focus has been to develop ways of learning the underlying dependencies between labels, and to take advantage of this at classification time. Developing better feature-space representations has been predominantly employed to reduce complexity, e.g., by eliminating non-helpful feature attributes from the input space prior to (or during) training. This is an important task, since many multilabel methods typically create many different copies or views of the same input data as they transform it, and considerable memory can be saved by taking advantage of redundancy. In this paper, we show that a proper development of the feature space can make labels less interdependent and easier to model and predict at inference time. For this task we use a deep learning approach with restricted Boltzmann machines. We present a deep network that, in an empirical evaluation, outperforms a number of competitive methods from the literature.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Characterizing the Set of Coherent Lower Previsions with a Finite Number of Constraints or Vertices\nAbstract: The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mining Social Media for Open Innovation in Transportation Systems\nAbstract: This work proposes a novel framework for the development of new products and services in transportation through an open innovation approach based on automatic content analysis of social media data. The framework is able to extract users comments from Online Social Networks (OSN), to process and analyze text through information extraction and sentiment analysis techniques to obtain relevant information about product reception on the market. A use case was developed using the mobile application Uber, which is today one of the fastest growing technology companies in the world. We measured how a controversial, highly diffused event influences the volume of tweets about Uber and the perception of its users. While there is no change in the image of Uber, a large increase in the number of tweets mentioning the company is observed, which meant a free and important diffusion of its product.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Markov logic uses weighted formulas to com-<lb>pactly encode a probability distribution over pos-<lb>sible worlds. Despite the use of logical formu-<lb>las, Markov logic networks (MLNs) can be diffi-<lb>cult to interpret, due to the often counter-intuitive<lb>meaning of their weights. To address this issue,<lb>we propose a method to construct a possibilis-<lb>tic logic theory that exactly captures what can<lb>be derived from a given MLN using maximum<lb>a posteriori (MAP) inference. Unfortunately, the<lb>size of this theory is exponential in general. We<lb>therefore also propose two methods which can<lb>derive compact theories that still capture MAP<lb>inference, but only for specific types of evidence.<lb>These theories can be used, among others, to<lb>make explicit the hidden assumptions underlying<lb>an MLN or to explain the predictions it makes.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Convergence Property of Implicit Self-paced Objective\nAbstract: Self-paced learning (SPL) is a new methodology that simulates the learning principle of humans/animals to start learning easier aspects of a learning task, and then gradually take more complex examples into training. This new-coming learning regime has been empirically substantiated to be effective in various computer vision and pattern recognition tasks. Recently, it has been proved that the SPL regime has a close relationship to a implicit self-paced objective function. While this implicit objective could provide helpful interpretations to the effectiveness, especially the robustness, insights under the SPL paradigms, there are still no theoretical results strictly proved to verify such relationship. To this issue, in this paper, we provide some convergence results on this implicit objective of SPL. Specifically, we prove that the learning process of SPL always converges to critical points of this implicit objective under some mild conditions. This result verifies the intrinsic relationship between SPL and this implicit objective, and makes the previous robustness analysis on SPL complete and theoretically rational.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to Predict from Textual Data\nAbstract: Given a current news event, we tackle the problem of generating plausible predictions of future events it might cause. We present a new methodology for modeling and predicting such future news events using machine learning and data mining techniques. Our Pundit algorithm generalizes examples of causality pairs to infer a causality predictor. To obtain precisely labeled causality examples, we mine 150 years of news articles and apply semantic natural language modeling techniques to headlines containing certain predefined causality patterns. For generalization, the model uses a vast number of world knowledge ontologies. Empirical evaluation on real news articles shows that our Pundit algorithm performs as well as non-expert humans.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In this work, a study on Variable Neighborhood Search algorithms for multi-depot dial-a-ride problems is presented. In dial-a-ride problems patients need to be transported from pre-specified pickup locations to pre-specified delivery locations, under different considerations. The addressed problem presents several constraints and features, such as heterogeneous vehicles, distributed in different depots, and heterogeneous patients. The aim is of minimizing the total routing cost, while respecting time-window, ride-time, capacity and route duration constraints. The objective of the study is of determining the best algorithm configuration in terms of initial solution, neighborhood and local search procedures. At this aim, two different procedures for \u2217Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche, University of Siena, Via Roma, 56, 53100 Siena, Italy, e-mail detti@dii.unisi.it \u2020Dipartimento di Ingegneria dell\u2019Informazione e Scienze Matematiche, University of Siena, Via Roma, 56, 53100 Siena, Italy, e-mail garazizml@gmail.com\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Three informal lectures on physics of intelligence\nAbstract: What is the nature of curiosity? Is there any scientific way to understand the origin of this mysterious force that drives the behavior of even the \u201cstupidest\u201d naturally intelligent systems and is completely absent in their \u201csmartest\u201d artificial analogs? Can we build AI systems that could be curious about something, systems that would have an intrinsic motivation to learn? Is such a motivation quantifiable? Is it implementable? Will we ever see artificially built systems having their views, values or goals? Or maybe the only mission of AI is to imitate intelligence, fool Turing test judges and build next-generation gadgets? These are the main questions I will try to address here, in these lectures. I will discuss this problem from the standpoint of physics. Treating intelligence as a physical phenomenon will not only allow us to understand what its driving force is, but will also give us a powerful formalism capable of studying it mathematically in a systematic and unified way. The relationship between physics and intelligence is a consequence of the fact that \u201ccorrectly predicted information\u201d is nothing but an energy resource, and the process of thinking can be viewed as a process of accumulating and spending this resource through the acts of perception and, respectively, decision making. The natural motivation of any autonomous system to keep this accumulation/spending balance as high as possible allows one to treat the problem of describing the dynamics of thinking processes as a resource optimization problem. Here I will propose and discuss a simple theoretical model of such an autonomous system which I call the Autonomous Turing Machine (ATM). The potential attractiveness of ATM lies in the fact that it is the model of a self-propelled AI for which the only available energy resource is the information itself. For ATM, the problem of optimal thinking, learning, and decision-making becomes conceptually simple and mathematically well tractable. This circumstance makes the ATM an ideal playground for studying the dynamics of intelligent behavior and allows one to quantify many seemingly unquantifiable features of genuine intelligence. A closer look at this subject reveals its cross-disciplinary nature: it turns out that there are many striking parallels between diverse branches of artificial intelligence on the one hand and theoretical physics and business economics on the other hand. For this reason, I wanted to target this text to a maximally broad audience, including physicists, computer scientists, business analysts and philosophers of science. I hope that this explains its somewhat informal and not quite academic style and also a relatively high-level character of references. 1 Email: alex.ushveridze@capella.edu\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Diversified Multi-Start Algorithm for Unconstrained Binary Quadratic Problems Leveraging the Graphics Processor Unit\nAbstract: Multi-start algorithms are a common and effective tool for metaheuristic searches. In this paper we amplify multi-start capabilities by employing the parallel processing power of the graphics processer unit (GPU) to quickly generate a diverse starting set of solutions for the Unconstrained Binary Quadratic Optimization Problem which are evaluated and used to implement screening methods to select solutions for further optimization. This method is implemented as an initial high quality solution generation phase prior to a secondary steepest ascent search and a comparison of results to best known approaches on benchmark unconstrained binary quadratic problems demonstrates that GPU-enabled diversified multistart with screening quickly yields very good results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalizing the Role of Determinization in Probabilistic Planning\nAbstract: The stochastic shortest path problem (SSP) is a highly expressive model for probabilistic planning. The computational hardness of SSPs has sparked interest in determinization-based planners that can quickly solve large problems. However, existing methods employ a simplistic approach to determinization. In particular, they ignore the possibility of tailoring the determinization to the specific characteristics of the target domain. In this work we examine this question, by showing that learning a good determinization for a planning domain can be done efficiently and can improve performance. Moreover, we show how to directly incorporate probabilistic reasoning into the planning problem when a good determinization is not sufficient by itself. Based on these insights, we introduce a planner, FF-LAO*, that outperforms stateof-the-art probabilistic planners on several wellknown competition benchmarks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Elicitation of Probabilities for Belief Networks: Combining Qualitative and Quantitative Information\nAbstract: Although the usefulness of belief networks for reasoning under uncertainty is widely accepted, obtaining numerical probabilities that they require is still perceived a major obstacle. Often not enough statistical data is available to allow for reliable probability estimation. Available information may not be directly amenable for encoding in the net\u00ad work. Finally, domain experts may be reluc\u00ad tant to provide numerical probabilities. In this paper, we propose a method for elici\u00ad tation of probabilities from a domain expert that is non-invasive and accommodates what\u00ad ever probabilistic information the expert is willing to state. We express all available in\u00ad formation, whether qualitative or quantita\u00ad tive in nature, in a canonical form consisting of (in)equalities expressing constraints on the hyperspace of possible joint probability dis\u00ad tributions. We then use this canonical form to derive second-order probability distribu\u00ad tions over the desired probabilities.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Accounting for Context in Plan Recognition, with Application to Traffic Monitoring\nAbstract: Typical approaches to plan recognition start from a representation of an agent's possible plans, and reason evidentially from observations of the agent's actions to assess the plausibility of the various candidates. A more expansive view of the task (consistent with some prior work) ac\u00ad counts for the context in which the plan was gen\u00ad erated, the mental state and planning process of the agent, and consequences of the agent's ac\u00ad tions in the world. We present a general Bayesian framework encompassing this view, and focus on how context can be exploited in plan recogni\u00ad tion. We demonstrate the approach on a prob\u00ad lem in traffic monitoring, where the objective is to induce the plan of the driver from observation of vehicle movements. Starting from a model of how the driver generates plans, we show how the highway context can appropriately influence the recognizer's interpretation of observed driver be\u00ad havior.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Be Precise or Fuzzy: Learning the Meaning of Cardinals and Quantifiers from Vision\nAbstract: People can refer to quantities in a visual scene by using either exact cardinals (e.g. one, two, three) or natural language quantifiers (e.g. few, most, all). In humans, these two processes underlie fairly different cognitive and neural mechanisms. Inspired by this evidence, the present study proposes two models for learning the objective meaning of cardinals and quantifiers from visual scenes containing multiple objects. We show that a model capitalizing on a \u2018fuzzy\u2019 measure of similarity is effective for learning quantifiers, whereas the learning of exact cardinals is better accomplished when information about number is provided.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The quality of priority ratios estimation in relation to a selected prioritization procedure and consistency measure for a Pairwise Comparison Matrix\nAbstract: An overview of current debates and contemporary research devoted to the modeling of decision making processes and their facilitation directs attention to the Analytic Hierarchy Process (AHP). At the core of the AHP are various prioritization procedures (PPs) and consistency measures (CMs) for a Pairwise Comparison Matrix (PCM) which, in a sense, reflects preferences of decision makers. Certainly, when judgments about these preferences are perfectly consistent (cardinally transitive), all PPs coincide and the quality of the priority ratios (PRs) estimation is exemplary. However, human judgments are very rarely consistent, thus the quality of PRs estimation may significantly vary. The scale of these variations depends on the applied PP and utilized CM for a PCM. This is why it is important to find out which PPs and which CMs for a PCM lead directly to an improvement of the PRs estimation accuracy. The main goal of this research is realized through the properly designed, coded and executed seminal and sophisticated simulation algorithms in Wolfram Mathematica 8.0. These research results convince that the embedded in the AHP and commonly applied, both genuine PP and CM for PCM may significantly deteriorate the quality of PRs estimation; however, solutions proposed in this paper can significantly improve the methodology.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Self Organizing Maps Whose Topologies Can Be Learned With Adaptive Binary Search Trees Using Conditional Rotations\nAbstract: Numerous variants of Self-Organizing Maps (SOMs) have been proposed in the literature, including those which also possess an underlying structure, and in some cases, this structure itself can be defined by the user Although the concepts of growing the SOM and updating it have been studied, the whole issue of using a self-organizing Adaptive Data Structure (ADS) to further enhance the properties of the underlying SOM, has been unexplored. In an earlier work, we impose an arbitrary, user-defined, tree-like topology onto the codebooks, which consequently enforced a neighborhood phenomenon and the so-called tree-based Bubble of Activity (BoA). In this paper, we consider how the underlying tree itself can be rendered dynamic and adaptively transformed. To do this, we present methods by which a SOM with an underlying Binary Search Tree (BST) structure can be adaptively re-structured using Conditional Rotations (CONROT). These rotations on the nodes of the tree are local, can be done in constant time, and performed so as to decrease the Weighted Path Length (WPL) of the entire tree. In doing this, we introduce the pioneering concept referred to as Neural Promotion, where neurons gain prominence in the Neural Network (NN) as their significance increases. We are not aware of any research which deals with the issue of Neural Promotion. The advantages of such a scheme is that the user need not be aware of any of the topological peculiarities of the stochastic data distribution. Rather, the algorithm, referred to as the TTOSOM with Conditional Rotations (TTOCONROT), converges in such a manner that the neurons are ultimately placed in the input space so as to represent its stochastic distribution, and additionally, the neighborhood properties of the neurons suit the best BST that represents the data. These properties have been confirmed by our experimental results on a variety of data sets. We submit that all of these concepts are both novel and of a pioneering sort.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization\nAbstract: Large-Scale Global Optimization Iztok Fister,\u2217 Iztok Fister Jr.,\u2020 Janez Brest,\u2021 and Viljem \u017dumer\u00a7 Abstract Memetic computation (MC) has emerged recently as a new paradigm of efficient algorithms for solving the hardest optimization problems. On the other hand, artificial bees colony (ABC) algorithms demonstrate good performances when solving continuous and combinatorial optimization problems. This study tries to use these technologies under the same roof. As a result, a memetic ABC (MABC) algorithm has been developed that is hybridized with two local search heuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction exploitation (RWDE). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptation rule was employed in order to control the balancing between exploration and exploitation. This MABC algorithm was applied to a Special suite on Large Scale Continuous Global Optimization at the 2012 IEEE Congress on Evolutionary Computation. The obtained results the MABC are comparable with the results of DECC-G, DECC-G*, and MLCC. To cite paper as follows: I. Fister, I. Fister Jr., J. Brest, V. Zumer, Memetic Artificial Bee Colony Algorithm for Large-Scale Global Optimization, in Proc. IEEE Congress on Evolutionary Computation, Brisbane, Australia, 2012\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Organizing Linked Data Quality Related Methods\nAbstract: This article presents the top-level of an ontology categorizing and generalizing best practices and quality criteria or measures for Linked Data. It permits to compare these techniques and have a synthetic organized view of what can or should be done for knowledge sharing purposes. This ontology is part of a general knowledge base that can be accessed and complemented by any Web user. Thus, it can be seen as a cooperatively built library for the above cited elements. Since they permit to evaluate information objects and create better ones, these elements also permit knowledgebased tools and techniques \u2013 as well as knowledge providers \u2013 to be evaluated and categorized based on their input/output information objects. One top-level distinction permitting to organize this ontology is the one between content, medium and containers of descriptions. Various structural, ontological, syntactical and lexical distinctions are then used.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Balancing Lexicographic Fairness and a Utilitarian Objective with Application to Kidney Exchange\nAbstract: Balancing fairness and efficiency in resource allocation is a classical economic and computational problem. The price of fairness measures the worst-case loss of economic efficiency when using an inefficient but fair allocation rule; for indivisible goods in many settings, this price is unacceptably high. One such setting is kidney exchange, where needy patients swap willing but incompatible kidney donors. In this work, we close an open problem regarding the theoretical price of fairness in modern kidney exchanges. We then propose a general hybrid fairness rule that balances a strict lexicographic preference ordering over classes of agents, and a utilitarian objective that maximizes economic efficiency. We develop a utility function for this rule that favors disadvantaged groups lexicographically; but if cost to overall efficiency becomes too high, it switches to a utilitarian objective. This rule has only one parameter which is proportional to a bound on the price of fairness, and can be adjusted by policymakers. We apply this rule to real data from a large kidney exchange and show that our hybrid rule produces more reliable outcomes than other fairness rules.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Smart machines and the SP theory of intelligence\nAbstract: These notes describe how the SP theory of intelligence, and its embodiment in the SP machine, may help to realise cognitive computing, as described in the book Smart Machines. In the SP system, information compression and a concept of multiple alignment are centre stage. The system is designed to integrate such things as unsupervised learning, pattern recognition, probabilistic reasoning, and more. It may help to overcome the problem of variety in big data, it may serve in pattern recognition and in the unsupervised learning of structure in data, and it may facilitate the management and transmission of big data. There is potential, via information compression, for substantial gains in computational efficiency, especially in the use of energy. The SP system may help to realise data-centric computing, perhaps via a development of Hebb\u2019s concept of a \u2018cell assembly\u2019, or via the use of light or DNA for the processing of information. It has potential in the management of errors and uncertainty in data, in medical diagnosis, in processing streams of data, and in promoting adaptability in robots.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DAC-h3: A Proactive Robot Cognitive Architecture to Acquire and Express Knowledge About the World and the Self\nAbstract: This paper introduces a cognitive architecture for a humanoid robot to engage in a proactive, mixed-initiative exploration and manipulation of its environment, where the initiative can originate from both the human and the robot. The framework, based on a biologically-grounded theory of the brain and mind, integrates a reactive interaction engine, a number of state-of-the art perceptual and motor learning algorithms, as well as planning abilities and an autobiographical memory. The architecture as a whole drives the robot behavior to solve the symbol grounding problem, acquire language capabilities, execute goal-oriented behavior, and express a verbal narrative of its own experience in the world. We validate our approach in a human-robot interaction experiment with the iCub humanoid robot, showing that the proposed cognitive architecture can be applied in real time within a realistic scenario.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Programming with Personalized PageRank: A Locally Groundable First-Order Probabilistic Logic\nAbstract: In many probabilistic first-order representation systems, inference is performed by \u201cgrounding\u201d\u2014i.e., mapping it to a propositional representation, and then performing propositional inference. With a large database of facts, groundings can be very large, making inference and learning computationally expensive. Here we present a firstorder probabilistic language which is wellsuited to approximate \u201clocal\u201d grounding: every query Q can be approximately grounded with a small graph. The language is an extension of stochastic logic programs where inference is performed by a variant of personalized PageRank. Experimentally, we show that the approach performs well without weight learning on an entity resolution task; that supervised weight-learning improves accuracy; and that grounding time is independent of DB size. We also show that order-of-magnitude speedups are possible by parallelizing learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Indu tive logi programming, or relational learning, is a powerful paradigm for ma hine learning or data mining. However, in order for ILP to be ome pra ti ally useful, the e\u00c6 ien y of ILP systems must improve substantially. To this end, the notion of a query pa k is introdu ed: it stru tures sets of similar queries. Furthermore, a me hanism is des ribed for exe uting su h query pa ks. A omplexity analysis shows that onsiderable e\u00c6 ien y improvements an be a hieved through the use of this query pa k exe ution me hanism. This laim is supported by empiri al results obtained by in orporating support for query pa k exe ution in two existing learning systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Many different approaches for solving Constraint Satisfaction Problems (CSPs) and related Constraint Optimization Problems (COPs) exist. However, there is no single solver (nor approach) that performs well on all classes of problems and many portfolio approaches for selecting a suitable solver based on simple syntactic features of the input CSP instance have been developed. In this paper we first present a simple portfolio method for CSP based on k-nearest neighbors method. Then, we propose a new way of using portfolio systems \u2014 training them shortly in the exploitation time, specifically for the set of instances to be solved and using them on that set. Thorough evaluation has been performed and has shown that the approach yields good results. We evaluated several machine learning techniques for our portfolio. Due to its simplicity and efficiency, the selected k-nearest neighbors method is especially suited for our short training approach and it also yields the best results among the tested methods. We also confirm that our approach yields good results on SAT domain.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Theta*: Any-Angle Path Planning on Grids\nAbstract: Grids with blocked and unblocked cells are often used to represent terrain in robotics and video games. However, paths formed by grid edges can be longer than true shortest paths in the terrain since their headings are artificially constrained. We present two new correct and complete anyangle path-planning algorithms that avoid this shortcoming. Basic Theta* and Angle-Propagation Theta* are both variants of A* that propagate information along grid edges without constraining paths to grid edges. Basic Theta* is simple to understand and implement, fast and finds short paths. However, it is not guaranteed to find true shortest paths. Angle-Propagation Theta* achieves a better worst-case complexity per vertex expansion than Basic Theta* by propagating angle ranges when it expands vertices, but is more complex, not as fast and finds slightly longer paths. We refer to Basic Theta* and Angle-Propagation Theta* collectively as Theta*. Theta* has unique properties, which we analyze in detail. We show experimentally that it finds shorter paths than both A* with post-smoothed paths and Field D* (the only other version of A* we know of that propagates information along grid edges without constraining paths to grid edges) with a runtime comparable to that of A* on grids. Finally, we extend Theta* to grids that contain unblocked cells with non-uniform traversal costs and introduce variants of Theta* which provide different tradeoffs between path length and runtime.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Implicit Contextual Integrity in Online Social Networks\nAbstract: Many real incidents demonstrate that users of Online Social Networks need mechanisms that help them manage their interactions by increasing the awareness of the different contexts that coexist in Online Social Networks and preventing them from exchanging inappropriate information in those contexts or disseminating sensitive information from some contexts to others. Contextual integrity is a privacy theory that conceptualises the appropriateness of information sharing based on the contexts in which this information is to be shared. Computational models of Contextual Integrity assume the existence of well-defined contexts, in which individuals enact pre-defined roles and information sharing is governed by an explicit set of norms. However, contexts in Online Social Networks are known to be implicit, unknown a priori and ever changing; users relationships are constantly evolving; and the information sharing norms are implicit. This makes current Contextual Integrity models not suitable for Online Social Networks. In this paper, we propose the first computational model of Implicit Contextual Integrity, presenting an information model for Implicit Contextual Integrity as well as a so-called Information Assistant Agent that uses the information model to learn implicit contexts, relationships and the information sharing norms in order to help users avoid inappropriate information exchanges and undesired information disseminations. Through an experimental evaluation, we validate the properties of the model proposed. In particular, Information Assistant Agents are shown to: (i) infer the information sharing norms even if a small proportion of the users follow the norms and in presence of malicious users; (ii) help reduce the exchange of inappropriate information and the dissemination of sensitive information with only a partial view of the system and the information received and sent by their users; and (iii) minimise the burden to the users in terms of raising unnecessary alerts.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Complete framework for ambush avoidance in realistic environments\nAbstract: Operating vehicles in adversarial environments between a recurring origin-destination pair requires new planning techniques. A Ruckle-inspired game is introduced. The goal of the first player is to minimize the expected casualties undergone by a convoy. The goal of the second player is to maximize this damage. The outcome of the game is obtained via a linear program that solves the corresponding minmax optimization problem over this outcome. Different environment models are defined in order to compute routing strategies over unstructured environments. To compare these methods for increasingly accurate representations of the environment, a grid-based model is chosen to represent the environment and the existence of a sufficient network size is highlighted. A global framework for the generation of realistic routing strategies between any two points is described. This framework requires a good assessment of the potential casualties at any location, therefore the most important parameters are identified. Finally the framework is tested on real world environments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Prime Implicates and Prime Implicants: From Propositional to Modal Logic\nAbstract: Prime implicates and prime implicants have proven relevant to a number of areas of artificial intelligence, most notably abductive reasoning and knowledge compilation. The purpose of this paper is to examine how these notions might be appropriately extended from propositional logic to the modal logic K. We begin the paper by considering a number of potential definitions of clauses and terms for K. The different definitions are evaluated with respect to a set of syntactic, semantic, and complexity-theoretic properties characteristic of the propositional definition. We then compare the definitions with respect to the properties of the notions of prime implicates and prime implicants that they induce. While there is no definition that perfectly generalizes the propositional notions, we show that there does exist one definition which satisfies many of the desirable properties of the propositional case. In the second half of the paper, we consider the computational properties of the selected definition. To this end, we provide sound and complete algorithms for generating and recognizing prime implicates, and we show the prime implicate recognition task to be Pspace-complete. We also prove upper and lower bounds on the size and number of prime implicates. While the paper focuses on the logic K, all of our results hold equally well for multi-modal K and for concept expressions in the description logic ALC.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Approximation Complexity of Maximum A Posteriori Inference in Sum-Product Networks\nAbstract: We discuss the computational complexity of approximating maximum a posteriori inference in sum-product networks. We first show np-hardness in three-level tree networks by a reduction from maximum independent set; this implies non-approximability within a sublinear factor. We show that this is a tight bound, as we can find an approximation within a linear factor in any three-level networks. We then show that in four-level tree networks it is np-hard to approximate the problem within a factor 2f(n) for any sublinear function f of the size of the input n. Again, this is bound is tight, as we prove that the usual max-product algorithm finds (in any network) approximations within factor 2cn from some constant c < 1. Last, we present a simple algorithm, and show that provably produces solutions at least as good as, and potentially much better, than the max-product algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Characterization of neighborhood behaviours in a multi-neighborhood local search algorithm\nAbstract: We consider a multi-neighborhood local search algorithm with a large number of possible neighborhoods. Each neighborhood is accompanied by a weight value which represents the probability of being chosen at each iteration. These weights are fixed before the algorithm runs, and are considered as parameters of the algorithm. Given a set of instances, off-line tuning of the algorithm\u2019s parameters can be done by automated algorithm configuration tools (e.g., SMAC). However, the large number of neighborhoods can make the tuning expensive and difficult even when the number of parameters has been reduced by some intuition. In this work, we propose a systematic method to characterize each neighborhood\u2019s behaviours, representing them as a feature vector, and using cluster analysis to form similar groups of neighborhoods. The novelty of our characterization method is the ability of reflecting changes of behaviours according to hardness of different solution quality regions. We show that using neighborhood clusters instead of individual neighborhoods helps to reduce the parameter configuration space without misleading the search of the tuning procedure. Moreover, this method is problem-independent and potentially can be applied in similar contexts.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Most Relevant Explanation: Properties, Algorithms, and Evaluations\nAbstract: Most Relevant Explanation (MRE) is a method for nding multivariate explanations for given evidence in Bayesian networks [12]. This paper studies the theoretical properties of MRE and develops an algorithm for nding multiple top MRE solutions. Our study shows that MRE relies on an implicit soft relevance measure in automatically identifying the most relevant target variables and pruning less relevant variables from an explanation. The soft measure also enables MRE to capture the intuitive phenomenon of explaining away encoded in Bayesian networks. Furthermore, our study shows that the solution space of MRE has a special lattice structure which yields interesting dominance relations among the solutions. A K-MRE algorithm based on these dominance relations is developed for generating a set of top solutions that are more representative. Our empirical results show that MRE methods are promising approaches for explanation in Bayesian networks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Wind ramp event prediction with parallelized Gradient Boosted Trees\nAbstract: Classifying the wind power ramp events. Accurate prediction of wind ramp events is critical for the ensuring the reliability and stability of the power systems with high penetration of wind energy. This paper proposes a classification based approach for estimating the future class of wind ramp event based on certain thresholds. A parallelized gradient boosted regression tree based technique has been proposed to accurately classify the normal as well as rare extreme wind power ramp events. The model has been validated using wind power data from Alberta electricity market. Performance comparison with several benchmark techniques indicates that the model superiority of the proposed technique in terms of superior classification accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SR-Clustering: Semantic Regularized Clustering for Egocentric Photo Streams Segmentation\nAbstract: While wearable cameras are becoming increasingly popular, locating relevant information in large unstructured collections of egocentric images is still a tedious and time consuming process. This paper addresses the problem of organizing egocentric photo streams acquired by a wearable camera into semantically meaningful segments, hence making an important step towards the goal of automatically annotating these photos for browsing and retrieval. In the proposed method, first, contextual and semantic information is extracted for each image by employing a Convolutional Neural Networks approach. Later, a vocabulary of concepts is defined in a semantic space by relying on linguistic information. Finally, by exploiting the temporal coherence of concepts in photo streams, images which share contextual and semantic attributes are grouped together. The resulting temporal segmentation is particularly suited for further analysis, ranging from event recognition to semantic indexing and summarization. Experimental results over egocentric set of nearly 31,000 images, show the prominence of the proposed approach over state-of-the-art methods.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Abzooba Smart Health Informatics Platform (SHIP)\nAbstract: This paper describes a technology to connect patients to information in the experiences of other patients by using the power of structured big data. The approach, implemented in the Abzooba Smart Health Informatics Platform (SHIP),is to distill concepts of facts and expressions from conversations and discussions in health social media forums, and use those distilled concepts in connecting patients to experiences and insights that are highly relevant to them in particular. We envision our work, in progress, to provide new and effective tools to exploit the richness of content in social media in health for outcomes research.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: TWO-TIMESCALE LEARNING USING IDIOTYPIC BEHAVIOUR MEDIATION FOR A NAVIGATING MOBILE ROBOT\nAbstract: A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to solving mobile-robot navigation problems is presented and tested in both the real and virtual domains. The LTL phase consists of rapid simulations that use a Genetic Algorithm to derive diverse sets of behaviours, encoded as variable sets of attributes, and the STL phase is an idiotypic Artificial Immune System. Results from the LTL phase show that sets of behaviours develop very rapidly, and significantly greater diversity is obtained when multiple autonomous populations are used, rather than a single one. The architecture is assessed under various scenarios, including removal of the LTL phase and switching off the idiotypic mechanism in the STL phase. The comparisons provide substantial evidence that the best option is the inclusion of both the LTL phase and the idiotypic system. In addition, this paper shows that structurally different environments can be used for the two phases without compromising transferability.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bit-Pragmatic Deep Neural Network Computing\nAbstract: We quantify a source of ineffectual computations when processing the multiplications of the convolutional layers in Deep Neural Networks (DNNs) and propose Pragmatic (PRA), an architecture that exploits it improving performance and energy efficiency. The source of these ineffectual computations is best understood in the context of conventional multipliers which generate internally multiple terms, that is, products of the multiplicand and powers of two, which added together produce the final product [1]. At runtime, many of these terms are zero as they are generated when the multiplicand is combined with the zero-bits of the multiplicator. While conventional bit-parallel multipliers calculate all terms in parallel to reduce individual product latency, PRA calculates only the non-zero terms using a) on-thefly conversion of the multiplicator representation into an explicit list of powers of two, and b) bit-parallel multplicand/bit-serial multiplicator processing units. PRA exploits two sources of ineffectual computations: 1) the aforementioned zero product terms which are the result of the lack of explicitness in the multiplicator representation, and 2) the excess in the representation precision used for both multiplicants and multiplicators, e.g., [2]. Measurements demonstrate that for the convolutional layers, a straightforward variant of PRA improves performance by 2.6x over the DaDiaNao (DaDN) accelerator [3] and by 1.4x over STR [4]. Similarly, PRA improves energy efficiency by 28% and 10% on average compared to DaDN and STR. An improved cross lane synchronization scheme boosts performance improvements to 3.1x over DaDN. Finally, Pragmatic benefits persist even with an 8-bit quantized representation [5].\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions\nAbstract: In this paper, we present MidiNet, a deep convolutional neural network (CNN) based generative adversarial network (GAN) that is intended to provide a general, highly adaptive network structure for symbolic-domain music generation. The network takes random noise as input and generates a melody sequence one measure (bar) after another. Moreover, it has a novel reflective CNN sub-model that allows us to guide the generation process by providing not only 1D but also 2D conditions. In our implementation, we used the intended chord of the current bar as a 1D condition to provide a harmonic context, and the melody generated for the preceding bar previously as a 2D condition to provide sequential information. The output of the network is a 16 by 128 matrix each time, representing the presence of each of the 128 MIDI notes in the generated melody sequence of that bar, with the smallest temporal unit being the sixteenth note. MidiNet can generate music of arbitrary number of bars, by concatenating these 16 by 128 matrices. The melody sequence can then be played back with a synthesizer. We provide example clips showing the effectiveness of MidiNet in generating harmonic music.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Multistage Stochastic Programming Approach to the Dynamic and Stochastic VRPTW Extended version\nAbstract: We consider a dynamic vehicle routing problem with time windows and stochastic customers (DS-VRPTW), such that customers may request for services as vehicles have already started their tours. To solve this problem, the goal is to provide a decision rule for choosing, at each time step, the next action to perform in light of known requests and probabilistic knowledge on requests likelihood. We introduce a new decision rule, called Global Stochastic Assessment (GSA) rule for the DS-VRPTW, and we compare it with existing decision rules, such as MSA. In particular, we show that GSA fully integrates nonanticipativity constraints so that it leads to better decisions in our stochastic context. We describe a new heuristic approach for efficiently approximating our GSA rule. We introduce a new waiting strategy. Experiments on dynamic and stochastic benchmarks, which include instances of different degrees of dynamism, show that not only our approach is competitive with state-of-the-art methods, but also enables to compute meaningful offline solutions to fully dynamic problems where absolutely no a priori customer request is provided.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Image Processing Based Systems and Techniques for the Recognition of Ancient and Modern Coins \nAbstract: Coins are frequently used in everyday life at various places like in banks, grocery stores, supermarkets, automated weighing machines, vending machines etc. So, there is a basic need to automate the counting and sorting of coins. For this machines need to recognize the coins very fast and accurately, as further transaction processing depends on this recognition. Three types of systems are available in the market: Mechanical method based systems, Electromagnetic method based systems and Image processing based systems. This paper presents an overview of available systems and techniques based on image processing to recognize ancient and modern coins.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Factored Filtering of Continuous-Time Systems\nAbstract: We consider filtering for a continuous-time, or asynchronous, stochastic system where the full distribution over states is too large to be stored or calculated. We assume that the rate matrix of the system can be compactly represented and that the belief distribution is to be approximated as a product of marginals. The essential computation is the matrix exponential. We look at two different methods for its computation: ODE integration and uniformization of the Taylor expansion. For both we consider approximations in which only a factored belief state is maintained. For factored uniformization we demonstrate that the KL-divergence of the filtering is bounded. Our experimental results confirm our factored uniformization performs better than previously suggested uniformization methods and the mean field algorithm. 1 Continuous-Time Markov Systems We are interested in monitoring (alternatively tracking or filtering) a continuous-time finite-state homogeneous Markovian stochastic system. This implies that evidence and events can arrive at any real-valued time (asynchronously) and be either instantaneous or have real-valued time durations. The system is stationary and has discrete states which means that a sample (trajectory) for the system consists of a series of times at which the system jumped from one state to another. Such models are common in the queueing theory and verification literatures. The algorithms developed there almost exclusively focus on steady-state properties of the system. A singular exception is the work of Sutton and Jordan (2008) which applied Gibbs sampling to queueing models. By contrast, the continuous time Bayesian network (Nodelman et al., 2002) literature has focused on finite-time properties, so we compare against those algorithms. In verification, continuous-time models can be used to compute the probability a system will function by a given time, such as in continuous stochastic logic (Baier et al., 2003). Other problems of interest include state estimation in asynchronous systems, such as distributed computer systems (Xu and Shelton, 2010), robotics (Ng et al., 2005), social networks (Fan and Shelton, 2009), or phylogenetic trees (Cohn et al., 2009). 1.1 Parameterization Such a Markovian system is described by an initial distribution over the state space and an intensity (or rate) matrix, often denoted Q. The diagonal element qii = \u2212qi where qi \u2265 0 is the rate of leaving state i. This means that the density of the duration of the process remaining in state i for exactly a duration \u2206t is an exponential distribution: qiei. The non-diagonal elements, qij \u2265 0 are the rates of transitioning from state i to state j. qi = \u2211 j qij in a closed system. (The rate of leaving a state is equal to the sum of the rates of moving to any other state.) The probability of transitioning to state j immediately upon leaving state i is qij/qi. Note that the diagonal elements of Q are non-positive and the non-diagonal elements are non-negative. The sum of each row is 0. Monitoring such a system consists of keeping track of the probability distribution over the state at the current time t, given all evidence prior to t. We would like a recursive solution in which evidence before t can be discarded once the distribution (or its estimate) at t has been computed. As an initial problem, we will be interested in tracking in the absence of any evidence. We will cover how to incorporate evidence in Section 5. To simplify notation, we will assume that we have the distribution at time 0 and wish to propagate this distribution to time t. If p is the distribution at time 0, represented as a row vector, then p\u2032, the distribution at t also represented as a row vector, is\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Soft Computing Framework for Routing in Wireless Mesh Networks: An Integrated Cost Function Approach\nAbstract: Dynamic behaviour of a WMN imposes stringent constraints on the routing policy of the network. In the shortest path based routing the shortest paths needs to be evaluated within a given time frame allowed by the WMN dynamics. The exact reasoning based shortest path evaluation methods usually fail to meet this rigid requirement. Thus, requiring some soft computing based approaches which can replace \"best for sure\" solutions with \"good enough\" solutions. This paper proposes a framework for optimal routing in the WMNs; where we investigate the suitability of Big Bang-Big Crunch (BBBC), a soft computing based approach to evaluate shortest/near-shortest path. In order to make routing optimal we first propose to replace distance between the adjacent nodes with an integrated cost measure that takes into account throughput, delay, jitter and residual energy of a node. A fuzzy logic based inference mechanism evaluates this cost measure at each node. Using this distance measure we apply BB-BC optimization algorithm to evaluate shortest/near shortest path to update the routing tables periodically as dictated by network requirements. A large number of simulations were conducted and it has been observed that BB-BC algorithm appears to be a high potential candidate suitable for routing in WMNs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Intelligent Semantic Web Search Engines: A Brief Survey\nAbstract: The World Wide Web (WWW) allows the people to share the information (data) from the large database repositories globally. The amount of information grows billions of databases. We need to search the information will specialize tools known generically search engine. There are many of search engines available today, retrieving meaningful information is difficult. However to overcome this problem in search engines to retrieve meaningful information intelligently, semantic web technologies are playing a major role. In this paper we present survey on the search engine generations and the role of search engines in intelligent web and semantic search technologies.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An overview of embedding models of entities and relationships for knowledge base completion\nAbstract: Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion or link prediction, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article presents an overview of embedding models of entities and relationships for knowledge base completion.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: What Counterfactuals Can Be Tested\nAbstract: Counterfactual statements, e.g., \u201dmy headache would be gone had I taken an aspirin\u201d are central to scientific discourse, and are formally interpreted as statements derived from \u201dalternative worlds\u201d. However, since they invoke hypothetical states of affairs, often incompatible with what is actually known or observed, testing counterfactuals is fraught with conceptual and practical difficulties. In this paper, we provide a complete characterization of \u201dtestable counterfactuals,\u201d namely, counterfactual statements whose probabilities can be inferred from physical experiments. We provide complete procedures for discerning whether a given counterfactual is testable and, if so, expressing its probability in terms of experimental data.\n",
        "output": "HIGH"
    }
]