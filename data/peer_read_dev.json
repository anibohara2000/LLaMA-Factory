[
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scalable Text Mining with Sparse Generative Models\nAbstract: The information age has brought a deluge of data. Much of this is in text form, insurmountable in scope for humans and incomprehensible in structure for computers. Text mining is an expanding field of research that seeks to utilize the information contained in vast document collections. General data mining methods based on machine learning face challenges with the scale of text data, posing a need for scalable text mining methods. This thesis proposes a solution to scalable text mining: generative models combined with sparse computation. A unifying formalization for generative text models is defined, bringing together research traditions that have used formally equivalent models, but ignored parallel developments. This framework allows the use of methods developed in different processing tasks such as retrieval and classification, yielding effective solutions across different text mining tasks. Sparse computation using inverted indices is proposed for inference on probabilistic models. This reduces the computational complexity of the common text mining operations according to sparsity, yielding probabilistic models with the scalability of modern search engines. The proposed combination provides sparse generative models: a solution for text mining that is general, effective, and scalable. Extensive experimentation on text classification and ranked retrieval datasets are conducted, showing that the proposed solution matches or outperforms the leading task-specific methods in effectiveness, with a order of magnitude decrease in classification times for Wikipedia article categorization with a million classes. The developed methods were further applied in two 2014 Kaggle data mining prize competitions with over a hundred competing teams, earning first and second places.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Universal Dependencies Parsing for Colloquial Singaporean English\nAbstract: Singlish can be interesting to the ACL community both linguistically as a major creole based on English, and computationally for information extraction and sentiment analysis of regional social media. We investigate dependency parsing of Singlish by constructing a dependency treebank under the Universal Dependencies scheme, and then training a neural network model by integrating English syntactic knowledge into a state-ofthe-art parser trained on the Singlish treebank. Results show that English knowledge can lead to 25% relative error reduction, resulting in a parser of 84.47% accuracies. To the best of our knowledge, we are the first to use neural stacking to improve cross-lingual dependency parsing on low-resource languages. We make both our annotation and parser available for further research.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: One of the main challenges for building the Semantic web is Ontology Authoring. Controlled Natural Languages CNLs offer a user friendly means for non-experts to author ontologies. This paper provides a snapshot of the state-of-the-art for the core CNLs for ontology authoring and reviews their respective evaluations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Importance of Automatic Syntactic Features in Vietnamese Named Entity Recognition\nAbstract: This paper presents a state-of-the-art system for Vietnamese Named Entity Recognition (NER). By incorporating automatic syntactic features with word embeddings as input for bidirectional Long Short-Term Memory (BiLSTM), our system, although simpler than some deep learning architectures, achieves a much better result for Vietnamese NER. The proposed method achieves an overall F1 score of 92.05% on the test set of an evaluation campaign, organized in late 2016 by the Vietnamese Language and Speech Processing (VLSP) community. Our named entity recognition system outperforms the best previous systems for Vietnamese NER by a large margin.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Rule- and dictionary-based solution for variations in written Arabic names in social networks, big data, accounting systems, and large databases\nAbstract: This paper investigates the problem that some Arabic names can be written in multiple ways. When someone searches for only one form of a name, neither exact nor approximate matching is appropriate for returning the multiple variants of the name. Exact matching requires the user to enter all forms of the name for the search, and approximate matching yields names not among the variations of the one being sought.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Word Embeddings in Twitter Election Classification\nAbstract: Word embeddings and convolutional neural networks (CNN) have attracted extensive attention in various classification tasks for Twitter, e.g. sentiment classification. However, the effect of the configuration used to train and generate the word embeddings on the classification performance has not been studied in the existing literature. In this paper, using a Twitter election classification task that aims to detect election-related tweets, we investigate the impact of the background dataset used to train the embedding models, the context window size and the dimensionality of word embeddings on the classification performance. By comparing the classification results of two word embedding models, which are trained using different background corpora (e.g. Wikipedia articles and Twitter microposts), we show that the background data type should align with the Twitter classification dataset to achieve a better performance. Moreover, by evaluating the results of word embeddings models trained using various context window sizes and dimensionalities, we found that large context window and dimension sizes are preferable to improve the performance. Our experimental results also show that using word embeddings and CNN leads to statistically significant improvements over various baselines such as random, SVM with TF-IDF and SVM with word embeddings.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Trolling Hierarchy in Social Media and A Conditional Random Field For Trolling Detection\nAbstract: An-ever increasing number of social media websites, electronic newspapers and Internet forums allow visitors to leave comments for others to read and interact. This exchange is not free from participants with malicious intentions, which do not contribute with the written conversation. Among different communities users adopt strategies to handle such users. In this paper we present a comprehensive categorization of the trolling phenomena resource, inspired by politeness research and propose a model that jointly predicts four crucial aspects of trolling: intention, interpretation, intention disclosure and response strategy. Finally, we present a new annotated dataset containing excerpts of conversations involving trolls and the interactions with other users that we hope will be a useful resource for the research community.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Network-Based Abstract Generation for Opinions and Arguments\nAbstract: We study the problem of generating abstractive summaries for opinionated text. We propose an attention-based neural network model that is able to absorb information from multiple text units to construct informative, concise, and fluent summaries. An importance-based sampling method is designed to allow the encoder to integrate information from an important subset of input. Automatic evaluation indicates that our system outperforms state-ofthe-art abstractive and extractive summarization systems on two newly collected datasets of movie reviews and arguments. Our system summaries are also rated as more informative and grammatical in human evaluation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Most representation learning algorithms for language and image processing are local, in that they identify features for a data point based on surrounding points. Yet in language processing, the correct meaning of a word often depends on its global context. As a step toward incorporating global context into representation learning, we develop a representation learning algorithm that incorporates joint prediction into its technique for producing features for a word. We develop efficient variational methods for learning Factorial Hidden Markov Models from large texts, and use variational distributions to produce features for each word that are sensitive to the entire input sequence, not just to a local context window. Experiments on part-of-speech tagging and chunking indicate that the features are competitive with or better than existing state-of-the-art representation learning methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recognition of Isolated Words using Zernike and MFCC features for Audio Visual Speech Recognition\nAbstract: Automatic Speech Recognition (ASR) by machine is an attractive research topic in signal processing domain and has attracted many researchers to contribute in this area. In recent year, there have been many advances in automatic speech reading system with the inclusion of audio and visual speech features to recognize words under noisy conditions. The objective of audio-visual speech recognition system is to improve recognition accuracy. In this paper we computed visual features using Zernike moments and audio feature using Mel Frequency Cepstral Coefficients (MFCC) on \u2018vVISWa\u2019 (Visual Vocabulary of Independent Standard Words) dataset which contains collection of isolated set of city names of 10 speakers. The visual features were normalized and dimension of features set was reduced by Principal Component Analysis (PCA) in order to recognize the isolated word utterance on PCA space.The performance of recognition of isolated words based on visual only and audio only features results in 63.88% and 100% respectively.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Proof nets for the Lambek-Grishin calculus\nAbstract: Grishin\u2019s generalization of Lambek\u2019s Syntactic Calculus combines a non-commutative multiplicative conjunction and its residuals (product, left and right division) with a dual family: multiplicative disjunction, right and left difference. Interaction between these two families takes the form of linear distributivity principles. We study proof nets for LG and the correspondence between these nets and unfocused and focused versions of its sequent calculus. 1 Background, motivation In his two seminal papers (Lambek 1958; Lambek 1961), Jim Lambek introduced the \u2018parsing as deduction\u2019 method in linguistics: the traditional parts of speech (noun, verb, adverb, determiner, etc) are replaced by logical formulas \u2014 types if one takes the computational view; the judgement whether an expression is wellformed is the outcome of a process of logical deduction, or, reading formulas as types, a computation in the type calculus. np \u2297 (np\\s) \u2297 (((np\\s)\\(np\\s))/np) \u2297 (np/n) \u2297 n \u2192 s time flies like an arrow (1) What is the precise nature of grammatical composition, the \u2297 operation in the example above? The \u201958 and \u201961 papers present two views on this: in the \u201958 paper, types are assigned to strings of words, in the \u201961 paper, they are assigned to phrases, bracketed strings, with a grouping into constituents. The Syntactic Calculus, under the latter view, is extremely simple. The derivability relation between types is given by the preorder laws (2) and the residuation principles of (3). A \u2192 A ; from A \u2192 B and B \u2192 C infer A \u2192 C (2) \u22c6 Draft of a chapter in E. Grefenstette, C. Heunen, and M. Sadrzadeh (eds.) \u2018Compositional methods in Physics and Linguistics\u2019, OUP, to appear. We thank Arno Bastenhof for helpful comments on an earlier version. 2 A \u2192 C/B iff A\u2297B \u2192 C iff B \u2192 A\\C (3) To obtain the \u201958 view, one adds the non-logical axioms of (4), attributing associativity properties to the \u2297 operation. (A\u2297B)\u2297 C \u2192 A\u2297 (B \u2297 C) ; A\u2297 (B \u2297 C) \u2192 (A\u2297B)\u2297 C (4) The Syntactic Calculus in its two incarnations \u2014 the basic system NL given by (2) and (3) and the associative variant L which adds the postulates of (4) \u2014 recognizes only context-free languages. It is well known that to capture the dependencies that occur in natural languages, one needs expressivity beyond context-free. Here are some characteristic patterns from formal language theory that can be seen as suitable idealizations of phenomena that occur in the wild. copying: {w | w \u2208 {a, b}} counting dependencies: {abc | n > 0} crossed dependencies: {abcd | n,m > 0} (5) In the tradition of extended rewriting systems, there is a large group of grammar formalisms that handle these and related patterns gracefully: Tree Adjoining Grammars, Linear Indexed Grammars, Combinatory Categorial Grammars, Minimalist Grammars, Multiple Context Free Grammars, . . . (Kallmeyer 2010). Also in the Lambek tradition, extended type-logical systems have been proposed with expressive power beyond context-free: multimodal grammars (Morrill 1994; Moortgat 1996), discontinuous calculi (Morrill, Fadda, and Valentin 2007), etc. These extensions, as well as the original Lambek systems, respect an \u201cintuitionistic\u201d restriction: in a sequent presentation, derivability is seen as a relation between (a structured configuration of) hypotheses A1, . . . , An and a single conclusionB. In a paper antedating Linear Logic by a couple of years, Grishin (1983) proposes a generalization of the Lambek calculus which removes this intuitionistic restriction. Linguistic application of Grishin\u2019s ideas is fairly recent. In the present paper, we study the system presented in (Moortgat 2009), which we\u2019ll refer to as LG. 1.1 Dual residuation principles, linear distributivities In LG the inventory of type-forming operations is doubled: in addition to the familiar operators \u2297, \\, / (product, left and right division), we find a dual family \u2295,\u2298,;: coproduct, right and left difference. A,B ::= p | atoms: s, np, . . . A\u2297B | B\\A | A/B | product, left vs right division A\u2295B | A\u2298B | B ; A coproduct, right vs left difference (6) Some clarification about the notation: we follow (Lambek 1993) in writing \u2295 for the coproduct, which is a multiplicative operation, like \u2297. We read B\\A as \u2018B under A\u2019, A/B as \u2018A over B\u2019, B ; A as \u2018B from A\u2019 and A \u2298 B as \u2018A less B\u2019. 3 For the difference operations, then, the quantity that is subtracted is under the circled (back)slash, just as we have the denominator under the (back)slash in the case of left and right division types. In a formulas-as-types spirit, we will feel free to refer to the division operations as implications, and to the difference operations as co-implications. Dual residuation principles The most basic version of LG is the symmetric generalization of NL, which means that to (2) and (3) we add the dual residuation principles of (7). B ; C \u2192 A iff C \u2192 B \u2295A iff C \u2298A \u2192 B (7) To get a feeling for the consequences of the preorder laws (2) and the (dual) residuation principles (3) and (7), here are some characteristic theorems and derived rules of inference. First, the compositions of the product and division operations, and of the co-product and difference operation give rise to the expanding and contracting patterns of (8). The rows here are related by a left-right symmetry; the columns by arrow reversal. A\u2297 (A\\B) \u2192 B \u2192 A\\(A\u2297B) (B/A)\u2297A \u2192 B \u2192 (B \u2297A)/A (B \u2295A)\u2298A \u2192 B \u2192 (B \u2298A)\u2295A A ; (A\u2295B) \u2192 B \u2192 A\u2295 (A ; B) (8) Secondly, one can show that the type-forming operations have the monotonicity properties summarized in the following schema, where \u2191 (\u2193) is an isotone (antitone) position: (\u2191 \u2297 \u2191), (\u2191 / \u2193), (\u2193 \\ \u2191), (\u2191 \u2295 \u2191), (\u2191 \u2298 \u2193), (\u2193 ; \u2191) In other words, the following inference rules are valid. A \u2192 A B \u2192 B A \u2297B \u2192 A\u2297B A \u2192 A B \u2192 B A\u2295B \u2192 A \u2295B (9) A \u2192 A B \u2192 B A\\B \u2192 A\\B A \u2192 A B \u2192 B A \u2298B \u2192 A\u2298B A \u2192 A B \u2192 B B/A \u2192 B/A A \u2192 A B \u2192 B B ; A \u2192 B ; A (10) Interaction: distributivity principles As we saw above, one could extend the inferential capabilities of this minimal system by adding postulates of associativity and/or commutativity for \u2297 and \u2295. From a substructural perspective, each of these options destroys structure-sensitivity for a particular dimension of grammatical organization: word order in the case of commutativity, constituent structure in the case of associativity. In LG there is an alternative which leaves the sensitivity for linear order and phrasal structure intact: instead of considering structural options for the individual \u2297 and \u2295 families, one can consider 4 interaction principles for the communication between them. We will consider the following group. (A ; B)\u2297 C \u2192 A ; (B \u2297 C) C \u2297 (B \u2298A) \u2192 (C \u2297B)\u2298A C \u2297 (A ; B) \u2192 A ; (C \u2297B) (B \u2298A)\u2297 C \u2192 (B \u2297 C)\u2298A (11) These postulates have come to be called linear distributivity principles (e.g. (Cockett and Seely 1996)): linear, because they respect resources (no material gets copied). Moot (2007) models the adjunction operation of Tree Adjoining Grammars using the interaction principles of (11) and shows how through this modeling the mildly context-sensitive patterns of (5) can be obtained within LG. 1.2 Arrows: LG as a deductive system In his (Lambek 1988), Lambek studies the Syntactic Calculus from a categorical perspective. Types are seen as the objects of a category and one studies morphisms between these objects, arrows f : A \u2212\u2192 B. For each A, there is an identity arrow 1A. Then there are inference rules to produce new arrows from arrows already obtained. Among these is the composition g \u25e6 f , defined when dom(g) = cod(f). Composition is associative, i.e. one has the equation f \u25e6 (g \u25e6 h) = (f \u25e6 g) \u25e6 h. Also, f \u25e6 1A = f = 1B \u25e6 f , where f : A \u2212\u2192 B. 1A : A \u2212\u2192 A f : A \u2212\u2192 B g : B \u2212\u2192 C g \u25e6 f : A \u2212\u2192 C (12) In this paper, we will not pursue the categorical interpretation of LG: our emphasis in the following sections is on the sequent calculus for this logic, the term language coding sequent proofs, and the correspondence between these proofs and proof nets. Our aim in this section is simply to have a handy language for naming proofs in the deductive presentation, and to use this in \u00a72.1 to establish the equivalence between the deductive and the sequent presentations. To obtain aLG, one adds to (12) further rules of inference for the residuation principles and their duals. (Omitting type subscripts \u22b2A,B,Cf for legibility. . . ) f : A\u2297B \u2212\u2192 C \u22b2f : A \u2212\u2192 C/B f : A\u2297 B \u2212\u2192 C \u22b3f : B \u2212\u2192 A\\C (13) g : A \u2212\u2192 C/B \u22b2g : A\u2297B \u2212\u2192 C g : B \u2212\u2192 A\\C \u22b3g : A\u2297B \u2212\u2192 C (14) f : C \u2212\u2192 B \u2295A \u25ed f : B ; C \u2212\u2192 A f : C \u2212\u2192 B \u2295A \u25ee f : C \u2298A \u2212\u2192 B (15) g : B ; C \u2212\u2192 A \u25ed g : C \u2212\u2192 B \u2295A g : C \u2298A \u2212\u2192 B \u25ee g : C \u2212\u2192 B \u2295A (16) 5 As remarked above, the Lambek-Grishin calculus exhibits two involutive symmetries, at the level of types and proofs: a left-right symmetry \u00b7 and an arrow reversing symmetry \u00b7 such that f \u266e : A \u2212\u2192 B iff f : A \u2212\u2192 B iff f \u2020 : B \u2212\u2192 A (17) with, on the type level, the translation tables below (abbreviating a long list of defining equations (A\u2297B) . = B \u2297A, (B \u2297A) . = A \u2297B, . . . ) A\u2297B A/B A\u2295B A\u2298B B \u2297A B\\A B \u2295A B ; A \u266e A/B A\u2297B B\\A B ; A B \u2295A A\u2298B \u2020 and on the level of proofs (1A) \u266e = 1A\u266e , (g \u25e6 f) \u266e = g \u25e6 f , (1A) \u2020 = 1A\u2020 , (g \u25e6 f) = f \u2020 \u25e6 g, and the list of defining equations (\u22b3f) . = \u22b2f , (\u22b3f) . =\u25ee f , . . . corresponding to the translation tables above. The distributivity principles, in aLG, take the form of extra axioms (primitive arrows). Below arrows d, b for the interaction between ; and \u2297. For the leftright symmetric pair d, q we write b, p dA,B,C : (A ; B)\u2297 C \u2212\u2192 A ; (B \u2297 C) qA,B,C : C \u2297 (A ; B) \u2212\u2192 A ; (C \u2297B) (18) To establish the equivalence between aLG and the sequent calculus sLG, to be discussed in the next section, we will use the fact that the monotonicity rules are derived rules of inference of aLG. For example, f/g can be defined as in (19) below. f : A \u2212\u2192 A g : B \u2212\u2192 B f/g : A/B \u2212\u2192 A/B f/g . = (\u22b2(f \u25e6 (\u22b21A/B)))) \u25e6 (\u22b2 \u22b3 \u22121 ((\u22b3 \u22b2 1A/B\u2032) \u25e6 g)) (19) Similarly, for the distributivity postulates, we will rely on a rule form, which for d would be B \u2297 C \u2192 A\u2295D A ; B \u2192 D/C (20) The inference rule (20) is derived as shown in (21). dA,B,C : (A ; B)\u2297 C \u2212\u2192 A ; (B \u2297 C) f : B \u2297 C \u2212\u2192 A\u2295D \u25ed f : A ; (B \u2297 C) \u2212\u2192 D (\u25ed f) \u25e6 dA,B,C : (A ; B)\u2297 C \u2212\u2192 D \u22b2((\u25ed f) \u25e6 dA,B,C) : A ; B \u2212\u2192 D/C (21) 2 Display sequent calculus and proof nets Is there a decision procedure to determine whether A \u2192 B holds? In the presence of expanding patterns as we saw them in (8), this is not immediately clear. For 6 the language with /,\u2297, \\, the key result of Lambek\u2019s original papers was to establish decidability by applying Gentzen\u2019s method: the Syntactic Calculus is recast as a sequent calculus; for the sequent presentation one then shows that the Cut rule (the sequent form of transitivity) is admissible; backward-chaining, cut-free proof search then yields the desired decision procedure. In \u00a72.1 below, we work through a similar agenda for LG. We introduce sLG, a sequent system for the Lambek-Grishin calculus in the style of Display Logic (Gor\u00e9 1997), and show that it is equivalent to aLG. The sequent presentation enjoys Cut Elimination; decidability follows. Sequent proof search, though decidable, remains suboptimal in that it allows a great many derivations for what in effect one would like to consider as \u2018the same\u2019 proof. In \u00a72.2, we introduce proof nets for LG, and show how these nets remove the spurious forms of nondeterminism of sequent proof search. 2.1 sLG: display sequent calculus The arrows of aLG are morphisms between types. In the sequent calculus, derivability is a relation between structures built from types. We will present the sequent calculus for LG in the format of a Display Logic (see (Gor\u00e9 1997) for a comprehensive display logical view on the substructural landscape). The characteristic feature of Display Logic is that for every logical connective, there is a corresponding structural connective. We use the same symbols for the logical operations and their structural counterparts; structural operations are marked off by centerdots. Below the grammar for input (sequent left hand side), and output structures (sequent rhs). I ::= F | I \u00b7 \u2297 \u00b7 I | I \u00b7 \u2298 \u00b7 O | O \u00b7 ; \u00b7 I O ::= F | O \u00b7 \u2295 \u00b7 O | I \u00b7 \\ \u00b7 O | O \u00b7 / \u00b7 I The rules of sLG come in three groups: the identity group (Axiom, Cut), the structural group (Display Postulates, Distributivity Postulates), and the logical group (left and right introduction rules for the logical connectives). Variables X,Y, Z in these rules range over structures, input or output, depending on whether they appear left or right of the sequent arrow. Axiom, Cut A \u21d2 A Ax X \u21d2 A A \u21d2 Y X \u21d2 Y Cut (22) Display postulates The (dual) residuation principles are formulated at the structural level. These rules ensure that any formula constituent of a sequent can be displayed as the single occupant of the sequent lhs or rhs\u2014hence the name.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: English Conversational Telephone Speech Recognition by Humans and Machines\nAbstract: One of the most difficult speech recognition tasks is accurate recognition of human to human communication. Advances in deep learning over the last few years have produced major speech recognition improvements on the representative Switchboard conversational corpus. Word error rates that just a few years ago were 14% have dropped to 8.0%, then 6.6% and most recently 5.8%, and are now believed to be within striking range of human performance. This then raises two issues what IS human performance, and how far down can we still drive speech recognition error rates? A recent paper by Microsoft suggests that we have already achieved human performance. In trying to verify this statement, we performed an independent set of human performance measurements on two conversational tasks and found that human performance may be considerably better than what was earlier reported, giving the community a significantly harder goal to achieve. We also report on our own efforts in this area, presenting a set of acoustic and language modeling techniques that lowered the word error rate of our own English conversational telephone LVCSR system to the level of 5.5%/10.3% on the Switchboard/CallHome subsets of the Hub5 2000 evaluation, which at least at the writing of this paper is a new performance milestone (albeit not at what we measure to be human performance!). On the acoustic side, we use a score fusion of three models: one LSTM with multiple feature inputs, a second LSTM trained with speaker-adversarial multitask learning and a third residual net (ResNet) with 25 convolutional layers and time-dilated convolutions. On the language modeling side, we use word and character LSTMs and convolutional WaveNet-style language models.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Addressing Limited Data for Textual Entailment Across Domains\nAbstract: We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analyzing the Language of Food on Social Media\nAbstract: We investigate the predictive power behind the language of food on social media. We collect a corpus of over three million food-related posts from Twitter and demonstrate that many latent population characteristics can be directly predicted from this data: overweight rate, diabetes rate, political leaning, and home geographical location of authors. For all tasks, our language-based models significantly outperform the majorityclass baselines. Performance is further improved with more complex natural language processing, such as topic modeling. We analyze which textual features have most predictive power for these datasets, providing insight into the connections between the language of food, geographic locale, and community characteristics. Lastly, we design and implement an online system for real-time query and visualization of the dataset. Visualization tools, such as geo-referenced heatmaps, semantics-preserving wordclouds and temporal histograms, allow us to discover more complex, global patterns mirrored in the language of food.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sentiment Analysis of Twitter Data for Predicting Stock Market Movements\nAbstract: Predicting stock market movements is a well-known problem of interest. Now-a-days social media is perfectly representing the public sentiment and opinion about current events. Especially, twitter has attracted a lot of attention from researchers for studying the public sentiments. Stock market prediction on the basis of public sentiments expressed on twitter has been an intriguing field of research. Previous studies have concluded that the aggregate public mood collected from twitter may well be correlated with Dow Jones Industrial Average Index (DJIA). The thesis of this work is to observe how well the changes in stock prices of a company, the rises and falls, are correlated with the public opinions being expressed in tweets about that company. Understanding author\u2019s opinion from a piece of text is the objective of sentiment analysis. The present paper have employed two different textual representations, Word2vec and Ngram, for analyzing the public sentiments in tweets. In this paper, we have applied sentiment analysis and supervised machine learning principles to the tweets extracted from twitter and analyze the correlation between stock market movements of a company and sentiments in tweets. In an elaborate way, positive news and tweets in social media about a company would definitely encourage people to invest in the stocks of that company and as a result the stock price of that company would increase. At the end of the paper, it is shown that a strong correlation exists between the rise and falls in stock prices with the public sentiments in tweets.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Content-based Approach for Vietnamese Spam SMS Filtering\nAbstract: Short Message Service (SMS) spam is a serious problem in Vietnam because of the availability of very cheap prepaid SMS packages. There are some systems to detect and filter spam messages for English, most of which use machine learning techniques to analyze the content of messages and classify them. For Vietnamese, there is some research on spam email filtering but none focused on SMS. In this work, we propose the first system for filtering Vietnamese spam SMS. We first propose an appropriate preprocessing method since existing tools for Vietnamese preprocessing cannot give good accuracy on our dataset. We then experiment with vector representations and classifiers to find the best model for this problem. Our system achieves an accuracy of 94% when labelling spam messages while the misclassification rate of legitimate messages is relatively small, about only 0.4%. This is an encouraging result compared to that of English and can be served as a strong baseline for future development of Vietnamese SMS spam prevention systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: THE MICROSOFT 2017 CONVERSATIONAL SPEECH RECOGNITION SYSTEM\nAbstract: We describe the 2017 version of Microsoft\u2019s conversational<lb>speech recognition system, in which we update our 2016<lb>system with recent developments in neural-network-based<lb>acoustic and language modeling to further advance the state<lb>of the art on the Switchboard speech recognition task. The<lb>system adds a CNN-BLSTM acoustic model to the set of<lb>model architectures we combined previously, and includes<lb>character-based and dialog session aware LSTM language<lb>models in rescoring. For system combination we adopt a two-<lb>stage approach, whereby subsets of acoustic models are first<lb>combined at the senone/frame level, followed by a word-level<lb>voting via confusion networks. We also added a confusion<lb>network rescoring step after system combination. The result-<lb>ing system yields a 5.1% word error rate on the 2000 Switch-<lb>board evaluation set.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Simple, Fast Diverse Decoding Algorithm for Neural Generation\nAbstract: In this paper, we propose a simple, fast decoding algorithm that fosters diversity in neural generation. The algorithm modifies the standard beam search algorithm by adding an intersibling ranking penalty, favoring choosing hypotheses from diverse parents. We evaluate the proposed model on the tasks of dialogue response generation, abstractive summarization and machine translation. We find that diverse decoding helps across all tasks, especially those for which reranking is needed. We further propose a variation that is capable of automatically adjusting its diversity decoding rates for different inputs using reinforcement learning (RL). We observe a further performance boost from this RL technique.1\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Recent work on reinforcement learning and other gradient estimators for latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time. Surprisingly, these models often perform better at sentence understanding tasks than models that use parse trees from conventional parsers. This paper aims to investigate what these latent tree learning models learn. We replicate two such models in a shared codebase and find that (i) they do outperform baselines on sentence classification, but that (ii) their parsing strategies are not especially consistent across random restarts, (iii) the parses they produce tend to be shallower than PTB parses, and (iv) these do not resemble those of PTB or of any other recognizable semantic or syntactic grammar formalism.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Surrogate-based Generic Classifier for Chinese Movie Reviews\nAbstract: With the emerging of various online video platforms like Youtube, Youku and LeTV, online movie reviews become more and more important both for movie viewers and producers. As a result, automatically classifying reviews according to different requirements evolves as a popular research topic and is very essential in our daily life. In this paper, we focused on reviews of hot TV series in China and successfully trained generic classifiers based on 8 predefined categories. The experimental results showed promising performance and effectiveness of its generalization to different TV series.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discrimination between Arabic and Latin from bilingual documents\nAbstract: One of the important tasks in machine learning is the electronic reading of documents. The discrimination between languages is one of the first steps in the problem of automatic documents text recognition. We are interested in this work to the printed document Arabic and Latin (mixed). Our method is based essentially on the extraction of words from any document. Extracting structural features of each word; and then the recognition of language writing from a classification step. We present the found results of classification step, with a discussion on possible improvements. Language identification;structural features; word extraction\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Survey of Data Mining Techniques for Social Media Analysis\nAbstract: Social Media in the last decade has gained remarkable attention. This is attributed to the affordability of accessing social network sites such as Twitter, Google+, Facebook and other social network sites through the internet and the web 2.0 technologies. Many people are becoming interested in and relying on the SM for information and opinion of other users on diverse subject matters. It is important to translate sentiment expressed by SM users to useful information using data mining techniques [39]. This underscores the importance of data mining techniques on SM. Data mining techniques are capable of handling the three dominant research issues with SM data which are size, noise and dynamism. This paper reviews data mining techniques currently in use on analysing SM and looked at other data mining techniques that can be considered in the\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Today\u2019s world is a world of Internet, almost all work can be done with the help of it, from simple mobile phone recharge to biggest business deals can be done with the help of this technology. People spent their most of the times on surfing on the Web; it becomes a new source of entertainment, education, communication, shopping etc. Users not only use these websites but also give their feedback and suggestions that will be useful for other users. In this way a large amount of reviews of users are collected on the Web that needs to be explored, analyse and organized for better decision making. Opinion Mining or Sentiment Analysis is a Natural Language Processing and Information Extraction task that identifies the user\u2019s views or opinions explained in the form of positive, negative or neutral comments and quotes underlying the text. Aspect based opinion mining is one of the level of Opinion mining that determines the aspect of the given reviews and classify the review for each feature. In this paper an aspect based opinion mining system is proposed to classify the reviews as positive, negative and neutral for each feature. Negation is also handled in the proposed system. Experimental results using reviews of products show the effectiveness of the system.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Much of human dialogue occurs in semicooperative settings, where agents with different goals attempt to agree on common decisions. Negotiations require complex communication and reasoning skills, but success is easy to measure, making this an interesting task for AI. We gather a large dataset of human-human negotiations on a multi-issue bargaining task, where agents who cannot observe each other\u2019s reward functions must reach an agreement (or a deal) via natural language dialogue. For the first time, we show it is possible to train end-to-end models for negotiation, which must learn both linguistic and reasoning skills with no annotated dialogue states. We also introduce dialogue rollouts, in which the model plans ahead by simulating possible complete continuations of the conversation, and find that this technique dramatically improves performance. Our code and dataset are publicly available.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Toward Automatic Understanding of the Function of Affective Language in Support Groups\nAbstract: Understanding expressions of emotions in support forums has considerable value and NLP methods are key to automating this. Many approaches understandably use subjective categories which are more finegrained than a straightforward polaritybased spectrum. However, the definition of such categories is non-trivial and, in fact, we argue for a need to incorporate communicative elements even beyond subjectivity. To support our position, we report experiments on a sentiment-labelled corpus of posts taken from a medical support forum. We argue that not only is a more fine-grained approach to text analysis important, but simultaneously recognising the social function behind affective expressions enable a more accurate and valuable level of understanding.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating Video Descriptions with Topic Guidance\nAbstract: Generating video descriptions in natural language (a.k.a. video captioning) is a more challenging task than image captioning as the videos are intrinsically more complicated than images in two aspects. First, videos cover a broader range of topics, such as news, music, sports and so on. Second, multiple topics could coexist in the same video. In this paper, we propose a novel caption model, topic-guided model (TGM), to generate topic-oriented descriptions for videos in the wild via exploiting topic information. In addition to prede\u0080ned topics, i.e., category tags crawled from the web, we also mine topics in a data-driven way based on training captions by an unsupervised topic mining model. We show that data-driven topics re\u0083ect a be\u008aer topic schema than the prede\u0080ned topics. As for testing video topic prediction, we treat the topic mining model as teacher to train the student, the topic prediction model, by utilizing the full multi-modalities in the video especially the speech modality. We propose a series of caption models to exploit topic guidance, including implicitly using the topics as input features to generate words related to the topic and explicitly modifying the weights in the decoder with topics to function as an ensemble of topic-aware language decoders. Our comprehensive experimental results on the current largest video caption dataset MSR-VTT prove the e\u0082ectiveness of our topic-guided model, which signi\u0080cantly surpasses the winning performance in the 2016 MSR video to language challenge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-Source Neural Translation\nAbstract: We build a multi-source machine translation model and train it to maximize the probability of a target English string given French and German sources. Using the neural encoder-decoder framework, we explore several combination methods and report up to +4.8 Bleu increases on top of a very strong attention-based neural translation model.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Code-switching is the phenomenon by which bilingual speakers switch between multiple languages during communication. The importance of developing language technologies for codeswitching data is immense, given the large populations that routinely code-switch. High-quality linguistic annotations are extremely valuable for any NLP task, and performance is often limited by the amount of high-quality labeled data. However, little such data exists for code-switching. In this paper, we describe crowd-sourcing universal part-of-speech tags for the Miami Bangor Corpus of Spanish-English code-switched speech. We split the annotation task into three subtasks: one in which a subset of tokens are labeled automatically, one in which questions are specifically designed to disambiguate a subset of high frequency words, and a more general cascaded approach for the remaining data in which questions are displayed to the worker following a decision tree structure. Each subtask is extended and adapted for a multilingual setting and the universal tagset. The quality of the annotation process is measured using hidden check questions annotated with gold labels. The overall agreement between gold standard labels and the majority vote is between 0.95 and 0.96 for just three labels and the average recall across part-of-speech tags is between 0.87 and 0.99, depending on the task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Summarizing Decisions in Spoken Meetings\nAbstract: This paper addresses the problem of summarizing decisions in spoken meetings: our goal is to produce a concise decision abstract for each meeting decision. We explore and compare token-level and dialogue act-level automatic summarization methods using both unsupervised and supervised learning frameworks. In the supervised summarization setting, and given true clusterings of decisionrelated utterances, we find that token-level summaries that employ discourse context can approach an upper bound for decision abstracts derived directly from dialogue acts. In the unsupervised summarization setting,we find that summaries based on unsupervised partitioning of decision-related utterances perform comparably to those based on partitions generated using supervised techniques (0.22 ROUGE-F1 using LDA-based topic models vs. 0.23 using SVMs).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-ofspeech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common partsof-speech for 22 different languages. We highlight the use of this resource via two experiments, including one that reports competitive accuracies for unsupervised grammar induction without gold standard part-of-speech tags.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Neural Networks for Czech Multi-label Document Classification\nAbstract: This paper is focused on automatic multi-label document classification of Czech text documents. The current approaches usually use some preprocessing which can have negative impact (loss of information, additional implementation work, etc). Therefore, we would like to omit it and use deep neural networks that learn from simple features. This choice was motivated by their successful usage in many other machine learning fields. Two different networks are compared: the first one is a standard multi-layer perceptron, while the second one is a popular convolutional network. The experiments on a Czech newspaper corpus show that both networks significantly outperform baseline method which uses a rich set of features with maximum entropy classifier. We have also shown that convolutional network gives the best results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation\nAbstract: Text alignment is crucial to the accuracy of Machine Translation (MT) systems, some NLP tools or any other text processing tasks requiring bilingual data. This research proposes a language independent sentence alignment approach based on Polish (not position-sensitive language) to English experiments. This alignment approach was developed on the TED Talks corpus, but can be used for any text domain or language pair. The proposed approach implements various heuristics for sentence recognition. Some of them value synonyms and semantic text structure analysis as a part of additional information. Minimization of data loss was ensured. The solution is compared to other sentence alignment implementations. Also an improvement in MT system score with text processed with described tool is shown.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exploiting Text and Network Context for Geolocation of Social Media Users\nAbstract: Research on automatically geolocating social media users has conventionally been based on the text content of posts from a given user or the social network of the user, with very little crossover between the two, and no benchmarking of the two approaches over comparable datasets. We bring the two threads of research together in first proposing a text-based method based on adaptive grids, followed by a hybrid networkand text-based method. Evaluating over three Twitter datasets, we show that the empirical difference between textand network-based methods is not great, and that hybridisation of the two is superior to the component methods, especially in contexts where the user graph is not well connected. We achieve state-of-the-art results on all three datasets.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ONTS: \u201cOptima\u201d News Translation System\nAbstract: We propose a real-time machine translation<lb>system that allows users to select a news<lb>category and to translate the related live<lb>news articles from Arabic, Czech, Danish,<lb>Farsi, French, German, Italian, Polish, Por-<lb>tuguese, Spanish and Turkish into English.<lb>The Moses-based system was optimised for<lb>the news domain and differs from other<lb>available systems in four ways: (1) News<lb>items are automatically categorised on the<lb>source side, before translation; (2) Named<lb>entity translation is optimised by recog-<lb>nising and extracting them on the source<lb>side and by re-inserting their translation in<lb>the target language, making use of a sep-<lb>arate entity repository; (3) News titles are<lb>translated with a separate translation sys-<lb>tem which is optimised for the specific style<lb>of news titles; (4) The system was opti-<lb>mised for speed in order to cope with the<lb>large volume of daily news articles.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?\nAbstract: We conduct large-scale studies on \u2018human attention\u2019 in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by stateof-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). We find that depending on the implementation used, machine-generated attention maps are either negatively correlated with human attention or have positive correlation worse than task-independent saliency. Overall, our experiments paint a bleak picture for the current generation of attention models in VQA.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Word Entropy of Natural Languages\nAbstract: The average uncertainty associated with words is an informationtheoretic concept at the heart of quantitative and computational linguistics. The entropy has been established as a measure of this average uncertainty also called average information content. We here use parallel texts of 21 languages to establish the number of tokens at which word entropies converge to stable values. These convergence points are then used to select texts from a massively parallel corpus, and to estimate word entropies across more than 1000 languages. Our results help to establish quantitative language comparisons, to understand the performance of multilingual translation systems, and to normalize semantic similarity measures.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Identifying mathematical relations expressed in text is essential to understanding a broad range of natural language text from election reports, to financial news, to sport commentaries to mathematical word problems. This paper focuses on identifying and understanding mathematical relations described within a single sentence. We introduce the problem of Equation Parsing \u2013 given a sentence, identify noun phrases which represent variables, and generate the mathematical equation expressing the relation described in the sentence. We introduce the notion of projective equation parsing and provide an efficient algorithm to parse text to projective equations. Our system makes use of a high precision lexicon of mathematical expressions and a pipeline of structured predictors, and generates correct equations in 70% of the cases. In 60% of the time, it also identifies the correct noun phrase \u2192 variables mapping, significantly outperforming baselines. We also release a new annotated dataset for task evaluation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recurrent Additive Networks\nAbstract: We introduce recurrent additive networks (RANs), a new gated RNN which is distinguished by the use of purely additive latent state updates. At every time step, the new state is computed as a gated component-wise sum of the input and the previous state, without any of the non-linearities commonly used in RNN transition dynamics. We formally show that RAN states are weighted sums of the input vectors, and that the gates only contribute to computing the weights of these sums. Despite this relatively simple functional form, experiments demonstrate that RANs outperform both LSTMs and GRUs on benchmark language modeling problems. This result shows that many of the non-linear computations in LSTMs and related networks are not essential, at least for the problems we consider, and suggests that the gates are doing more of the computational work than previously understood.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We present our submitted systems for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of SpanishEnglish sentences, each system must estimate their semantic similarity by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these methods in unsupervised and supervised way. Our best run ranked 1 on track 4a with a correlation of 83.02% with human annotations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: TransA: An Adaptive Approach for Knowledge Graph Embedding\nAbstract: Knowledge representation is a major topic in AI, and many studies attempt to represent entities and relations of knowledge base in a continuous vector space. Among these attempts, translation-based methods build entity and relation vectors by minimizing the translation loss from a head entity to a tail one. In spite of the success of these methods, translation-based methods also suffer from the oversimplified loss metric, and are not competitive enough to model various and complex entities/relations in knowledge bases. To address this issue, we propose TransA, an adaptive metric approach for embedding, utilizing the metric learning ideas to provide a more flexible embedding method. Experiments are conducted on the benchmark datasets and our proposed method makes significant and consistent improvements over the state-of-the-art baselines.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Robust Named Entity Recognition in Idiosyncratic Domains\nAbstract: Named entity recognition often fails in idiosyncratic domains. That causes a problem for depending tasks, such as entity linking and relation extraction. We propose a generic and robust approach for high-recall named entity recognition. Our approach is easy to train and offers strong generalization over diverse domainspecific language, such as news documents (e.g. Reuters) or biomedical text (e.g. Medline). Our approach is based on deep contextual sequence learning and utilizes stacked bidirectional LSTM networks. Our model is trained with only few hundred labeled sentences and does not rely on further external knowledge. We report from our results F1 scores in the range of 84\u201394% on standard datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Semi-Supervised Instance Population of an Ontology using Word Vector Embeddings\nAbstract: In many modern day systems such as information extraction and knowledge management agents, ontologies play a vital role in maintaining the concept hierarchies of the selected domain. However, ontology population has become a problematic process due to its nature of heavy coupling with manual human intervention. With the use of word embeddings in the filed of natural language processing, it became a popular topic due to its ability to cope up with semantic sensitivity. Hence, in this study we propose a novel way of semi-supervised ontology population through word embeddings as the basis. We built several models including traditional benchmark models and new types of models which are based on word embeddings. Finally, we ensemble them together to come up with a synergistic model with better accuracy. We demonstrate that our ensemble model can outperform the individual models. keywords: Ontology, Ontology Population, Word Embeddings, word2vec\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We introduce a novel sub-character architecture that exploits a unique compositional structure of the Korean language. Our method decomposes each character into a small set of primitive phonetic units called jamo letters from which characterand word-level representations are induced. The jamo letters divulge syntactic and semantic information that is difficult to access with conventional character-level units. They greatly alleviate the data sparsity problem, reducing the observation space to 1.6% of the original while increasing accuracy in our experiments. We apply our architecture to dependency parsing and achieve dramatic improvement over strong lexical baselines.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recurrent Neural Network based Part-of-Speech Tagger for Code-Mixed Social Media Text\nAbstract: This paper describes Centre for Development of Advanced Computing\u2019s (CDACM) submission to the shared task\u2019Tool Contest on POS tagging for CodeMixed Indian Social Media (Facebook, Twitter, and Whatsapp) Text\u2019, collocated with ICON-2016. The shared task was to predict Part of Speech (POS) tag at word level for a given text. The codemixed text is generated mostly on social media by multilingual users. The presence of the multilingual words, transliterations, and spelling variations make such content linguistically complex. In this paper, we propose an approach to POS tag code-mixed social media text using Recurrent Neural Network Language Model (RNN-LM) architecture. We submitted the results for Hindi-English (hi-en), BengaliEnglish (bn-en), and Telugu-English (teen) code-mixed data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Studying Positive Speech on Twitter\nAbstract: We present results of empirical studies on positive speech on Twitter. By positive speech we understand speech that works for the betterment of a given situation, in this case relations between different communities in a conflict-prone country. We worked with four Twitter data sets. Through semimanual opinion mining, we found that positive speech accounted for < 1% of the data . In fully automated studies, we tested two approaches: unsupervised statistical analysis, and supervised text classification based on distributed word representation. We discuss benefits and challenges of those approaches and report empirical evidence obtained in the study.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We present an unsupervised and languageagnostic method for learning root-andpattern morphology in Semitic languages. We harness the syntactico-semantic information in distributed word representations to solve the long standing problem of root-and-pattern discovery in Semitic languages. The root-and-pattern morphological rules we learn in an unsupervised manner are validated by native speakers in Arabic, Hebrew, and Amharic. Further, the rules are used to construct an unsupervised root extractor called JZR, which we show to compare favorably with ISRI, a widely used and carefully engineered root extractor for Arabic.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The standard unsupervised recurrent neural network language model (RNNLM)<lb>generates sentences one word at a time and does not work from an explicit global<lb>distributed sentence representation. In this work, we present an RNN-based vari-<lb>ational autoencoder language model that incorporates distributed latent represen-<lb>tations of entire sentences. This factorization allows it to explicitly model holis-<lb>tic properties of sentences such as style, topic, and high-level syntactic features.<lb>Samples from the prior over these sentence representations remarkably produce<lb>diverse and well-formed sentences through simple deterministic decoding. By ex-<lb>amining paths through this latent space, we are able to generate coherent novel<lb>sentences that interpolate between known sentences. We present techniques for<lb>solving the difficult learning problem presented by this model, demonstrate strong<lb>performance in the imputation of missing tokens, and explore many interesting<lb>properties of the latent sentence space.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Weakly Supervised Memory Networks\nAbstract: In this paper we introduce a variant of Memory Networks [16] that needs significantly less supervision to perform question and answering tasks. The original model requires that the sentences supporting the answer be explicitly indicated during training. In contrast, our approach only requires the answer to the question during training. We apply the model to the synthetic bAbI tasks, showing that our approach is competitive with the supervised approach, particularly when trained on a sufficiently large amount of data. Furthermore, it decisively beats other weakly supervised approaches based on LSTMs. The approach is quite general and can potentially be applied to many other tasks that require capturing longterm dependencies.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Lexical Access for Speech Understanding using Minimum Message Length Encoding\nAbstract: The Lexical Access Problem consists of deter\u00ad mining the intended sequence of words corre\u00ad sponding to an input sequence of phonemes (ba\u00ad sic speech sounds) that come from a low-level phoneme recognizer. In this paper we present an information-theoretic approach based on the Minimum Message Length Criterion for solv\u00ad ing the Lexical Access Problem. We model sentences using phoneme realizations seen in training, and word and part-of-speech informa\u00ad tion obtained from text corpora. We show res\u00ad ults on multiple-speaker, continuous, read speech and discuss a heuristic using equivalence classes of similar sounding words which speeds up the recognition process without significant deteriora\u00ad tion in recognition accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Morphological Constraints for Phrase Pivot Statistical Machine Translation\nAbstract: The lack of parallel data for many language pairs is an important challenge to statistical machine translation (SMT). One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations especially when a poor morphology language is used as the pivot between rich morphology languages. In this paper, we examine the use of synchronous morphology constraint features to improve the quality of phrase pivot SMT. We compare hand-crafted constraints to those learned from limited parallel data between source and target languages. The learned morphology constraints are based on projected alignments between the source and target phrases in the pivot phrase table. We show positive results on Hebrew-Arabic SMT (pivoting on English). We get 1.5 BLEU points over a phrase pivot baseline and 0.8 BLEU points over a system combination baseline with a direct model built from parallel data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Compositional Approaches for Representing Relations Between Words: A Comparative Study\nAbstract: Identifying the relations that exist between words (or entities) is important for various natural language processing tasks such as, relational search, nounmodifier classification and analogy detection. A popular approach to represent the relations between a pair of words is to extract the patterns in which the words co-occur with from a corpus, and assign each word-pair a vector of pattern frequencies. Despite the simplicity of this approach, it suffers from data sparseness, information scalability and linguistic creativity as the model is unable to handle previously unseen word pairs in a corpus. In contrast, a compositional approach for representing relations between words overcomes these issues by using the attributes of each individual word to indirectly compose a representation for the common relations that hold between the two words. This study aims to compare different operations for creating relation representations from word-level representations. We investigate the performance of the compositional methods by measuring the relational similarities using several benchmark datasets for word analogy. Moreover, we evaluate the different relation representations in a knowledge base completion task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Drug-drug Interaction Extraction via Recurrent Neural Network with Multiple Attention Layers\nAbstract: Drug-drug interaction (DDI) is a vital information when physicians and pharmacists prepare for the combined use of two or more drugs. Thus, several DDI databases are constructed to avoid mistakenly medicine administering. In recent years, automatically extracting DDIs from biomedical text has drawn researchers\u2019 attention. However, the existing work need either complex feature engineering or NLP tools, both of which are insufficient for sentence comprehension. Inspired by the deep learning approaches in natural language processing, we propose a recurrent neural network model with multiple attention layers for DDI classification. We evaluate our model on 2013 SemEval DDIExtraction dataset. The experiments show that our model classifies most of the drug pairs into correct DDI categories, which outperforms the existing NLP or deep learning method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Where to put the Image in an Image Caption Generator\u2217\nAbstract: When a neural language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network \u2013 conditioning the language model by injecting image features \u2013 or in a layer following the recurrent neural network \u2013 conditioning the language model by merging the image features. While merging implies that visual features are bound at the end of the caption generation process, injecting can bind the visual features at a variety stages. In this paper we empirically show that late binding is superior to early binding in terms of different evaluation metrics. This suggests that the different modalities (visual and linguistic) for caption generation should not be jointly encoded by the RNN; rather, the multimodal integration should be delayed to a subsequent stage. Furthermore, this suggests that recurrent neural networks should not be viewed as actually generating text, but only as encoding it for prediction in a subsequent\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unsupervised, Knowledge-Free, and Interpretable Word Sense Disambiguation\nAbstract: Interpretability of a predictive model is a powerful feature that gains the trust of users in the correctness of the predictions. In word sense disambiguation (WSD), knowledge-based systems tend to be much more interpretable than knowledge-free counterparts as they rely on the wealth of manually-encoded elements representing word senses, such as hypernyms, usage examples, and images. We present a WSD system that bridges the gap between these two so far disconnected groups of methods. Namely, our system, providing access to several state-of-the-art WSD models, aims to be interpretable as a knowledgebased system while it remains completely unsupervised and knowledge-free. The presented tool features a Web interface for all-word disambiguation of texts that makes the sense predictions human readable by providing interpretable word sense inventories, sense representations, and disambiguation results. We provide a public API, enabling seamless integration.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-Level Analysis and Annotation of Arabic Corpora for Text-to-Sign Language MT\nAbstract: The Arabic language is morphologically rich and syntactically complex with many differences from European languages, and this creates a challenge when porting existing annotation tools to Arabic. In this paper, we present an ongoing effort in lexical semantic analysis and annotation of Modern Standard Arabic (MSA) text, a semi automatic annotation tool concerned with the morphologic, syntactic, and semantic levels of description. Besides the aim of providing a multi-level annotation tool for Arabic corpora, our goals are (1) to investigate the suitability of Frame Semantics (FS) approach (Fillmore 1985) for representing and analysing Arabic text (2) to provide corpus-attested linguistics materials for frame-based contrastive text analysis between Arabic and English in terms of lexicalization patterns; (3) to automatically derive mappings rules from annotated sentences. Such corpus-attested mapping rules between linguistic form and its meaning can support semantic analysis in knowledge-based NLP systems such as machine translation, information extraction etc. Following syntactically-based annotation projects for English, serious attempts have been made to annotate Arabic corpora, such as the Penn Arabic Treebank (PATB), (Maamouri et al. 2004) and the Quranic Arabic Dependency Treebank (QADT) (Dukes et al. 2010). However, semantically-based annotation for Arabic corpora has not yet been garnering the same attention. Our semantic representations are based upon use of frame-semantic paradigm; it is actually used in a MT system from Arabic to Algerian Sign Language aimed to assist deaf children and in order to bridge the gap between Arabic written texts and Algerian Sign Language (Lakhfif and Laskri 2010a,b, 2011). Annotation outputs are available in XML format compatible with the FrameNet project (Fillmore and Petruck 2003) design and can be portable to other NLP systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Harnessing Cognitive Features for Sarcasm Detection\nAbstract: In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruityimplicit or explicitaffects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of Fscore), over the performance of the best reported system.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: W2VLDA: Almost Unsupervised System for Aspect Based Sentiment Analysis\nAbstract: With the increase of online customer opinions in specialised websites and social networks, the necessity of automatic systems to help to organise and classify customer reviews by domain-specific aspect/categories and sentiment polarity is more important than ever. Supervised approaches for Aspect Based Sentiment Analysis obtain good results for the domain/language they are trained on, but having manually labelled data for training supervised systems for all domains and languages is usually very costly and time consuming. In this work we describe W2VLDA, an almost unsupervised system based on topic modelling, that combined with some other unsupervised methods and a minimal configuration, performs aspect/category classification, aspectterms/opinion-words separation and sentiment polarity classification for any given domain and language. We evaluate the performance of the aspect and sentiment classification in the multilingual SemEval 2016 task 5 (ABSA) dataset. We show competitive results for several languages (English, Spanish, French and Dutch) and domains (hotels, restaurants, electronic devices).\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to Predict Charges for Criminal Cases with Legal Basis\nAbstract: The charge prediction task is to determine appropriate charges for a given case, which is helpful for legal assistant systems where the user input is fact description. We argue that relevant law articles play an important role in this task, and therefore propose an attention-based neural network method to jointly model the charge prediction task and the relevant article extraction task in a unified framework. The experimental results show that, besides providing legal basis, the relevant articles can also clearly improve the charge prediction results, and our full model can effectively predict appropriate charges for cases with different expression styles.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analysing Temporally Annotated Corpora with CAVaT\nAbstract: We present CAVaT, a tool that performs Corpus Analysis and Validation for TimeML. CAVaT is an open source, modular checking utility for statistical analysis of features specific to temporally-annotated natural language corpora. It provides reporting, highlights salient links between a variety of general and time-specific linguistic features, and also validates a temporal annotation to ensure that it is logically consistent and sufficiently annotated. Uniquely, CAVaT provides analysis specific to TimeML-annotated temporal information. TimeML is a standard for annotating temporal information in natural language text. In this paper, we present the reporting part of CAVaT, and then its error-checking ability, including the workings of several novel TimeML document verification methods. This is followed by the execution of some example tasks using the tool to show relations between times, events, signals and links. We also demonstrate inconsistencies in a TimeML corpus (TimeBank) that have been detected with CAVaT.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Time-dependent Hierarchical Dirichlet Model for Timeline Generation\nAbstract: Timeline Generation aims at summarizing news from different epochs and telling readers how an event evolves. It is a new challenge that combines salience ranking with novelty detection. For long-term public events, the main topic usually includes various aspects across different epochs and each aspect has its own evolving pattern. Existing approaches neglect such hierarchical topic structure involved in the news corpus in timeline generation. In this paper, we develop a novel time-dependent Hierarchical Dirichlet Model (HDM) for timeline generation. Our model can aptly detect different levels of topic information across corpus and such structure is further used for sentence selection. Based on the topic mined fro HDM, sentences are selected by considering different aspects such as relevance, coherence and coverage. We develop experimental systems to evaluate 8 long-term events that public concern. Performance comparison between different systems demonstrates the effectiveness of our model in terms of ROUGE metrics.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Abstract\u2014 Now a days, the text document is spontaneously increasing over the internet, e-mail and web pages and they are stored in the electronic database format. To arrange and browse the document it becomes difficult. To overcome such problem the document preprocessing, term selection, attribute reduction and maintaining the relationship between the important terms using background knowledge, WordNet, becomes an important parameters in data mining. In these paper the different stages are formed, firstly the document preprocessing is done by removing stop words, stemming is performed using porter stemmer algorithm, word net thesaurus is applied for maintaining relationship between the important terms, global unique words, and frequent word sets get generated, Secondly, data matrix is formed, and thirdly terms are extracted from the documents by using term selection approaches tf-idf, tf-df, and tf2 based on their minimum threshold value. Further each and every document terms gets preprocessed, where the frequency of each term within the document is counted for representation. The purpose of this approach is to reduce the attributes and find the effective term selection method using WordNet for better clustering accuracy. Experiments are evaluated on Reuters Transcription Subsets, wheat, trade, money grain, and ship, Reuters 21578, Classic 30, 20 News group (atheism), 20 News group (Hardware), 20 News group (Computer Graphics) etc.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automatic Text Summarization Approaches to Speed up Topic Model Learning Process\nAbstract: The number of documents available into Internet moves each day up. For this reason, processing this amount of information effectively and expressibly becomes a major concern for companies and scientists. Methods that represent a textual document by a topic representation are widely used in Information Retrieval (IR) to process big data such as Wikipedia articles. One of the main difficulty in using topic model on huge data collection is related to the material resources (CPU time and memory) required for model estimate. To deal with this issue, we propose to build topic spaces from summarized documents. In this paper, we present a study of topic space representation in the context of big data. The topic space representation behavior is analyzed on different languages. Experiments show that topic spaces estimated from text summaries are as relevant as those estimated from the complete documents. The real advantage of such an approach is the processing time gain: we showed that the processing time can be drastically reduced using summarized documents (more than 60% in general). This study finally points out the differences between thematic representations of documents depending on the targeted languages such as English or latin languages.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: CONDITOR\nAbstract: Conditor is a software tool which works with textual documents containing historical information. The purpose of this work two-fold: firstly to show the validity of the developed engine to correctly identify and label the entities of the universe of discourse with a labelled-combined XTM-DITA model. Secondly to explain the improvements achieved in the information retrieval process thanks to the use of an object-oriented database (JPOX) as well as its integration into the Lucene-type database search process to not only accomplish more accurate searches, but to also help the future development of a recommender system [21]. We finish with a brief demo in a 3D-graph of the results of the aforementioned search.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Balancing Novelty and Salience: Adaptive Learning to Rank Entities for Timeline Summarization of High-impact Events\nAbstract: Long-running, high-impact events such as the Boston Marathon bombing often develop through many stages and involve a large number of entities in their unfolding. Timeline summarization of an event by key sentences eases story digestion, but does not distinguish between what a user remembers and what she might want to re-check. In this work, we present a novel approach for timeline summarization of high-impact events, which uses entities instead of sentences for summarizing the event at each individual point in time. Such entity summaries can serve as both (1) important memory cues in a retrospective event consideration and (2) pointers for personalized event exploration. In order to automatically create such summaries, it is crucial to identify the \u201cright\u201d entities for inclusion. We propose to learn a ranking function for entities, with a dynamically adapted trade-off between the in-document salience of entities and the informativeness of entities across documents, i.e., the level of new information associated with an entity for a time point under consideration. Furthermore, for capturing collective attention for an entity we use an innovative soft labeling approach based on Wikipedia. Our experiments on a real large news datasets confirm the effectiveness of the proposed methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper introduces a greedy parser based on neural networks, which leverages a new compositional sub-tree representation. The greedy parser and the compositional procedure are jointly trained, and tightly depends on each-other. The composition procedure outputs a vector representation which summarizes syntactically (parsing tags) and semantically (words) sub-trees. Composition and tagging is achieved over continuous (word or tag) representations, and recurrent neural networks. We reach F1 performance on par with well-known existing parsers, while having the advantage of speed, thanks to the greedy nature of the parser. We provide a fully functional implementation of the method described in this paper 1.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Don\u2019t \u2018have a clue\u2019? Unsupervised co-learning of downward-entailing operators\nAbstract: Researchers in textual entailment have begun to consider inferences involving downward-entailing operators, an interesting and important class of lexical items that change the way inferences are made. Recent work proposed a method for learning English downward-entailing operators that requires access to a high-quality collection of negative polarity items (NPIs). However, English is one of the very few languages for which such a list exists. We propose the first approach that can be applied to the many languages for which there is no pre-existing high-precision database of NPIs. As a case study, we apply our method to Romanian and show that our method yields good results. Also, we perform a cross-linguistic analysis that suggests interesting connections to some findings in linguistic typology.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Iterative Refinement for Machine Translation\nAbstract: Existing machine translation decoding algorithms generate translations in a strictly monotonic fashion and never revisit previous decisions. As a result, earlier mistakes cannot be corrected at a later stage. In this paper, we present a translation scheme that starts from an initial guess and then makes iterative improvements that may revisit previous decisions. We parameterize our model as a convolutional neural network that predicts discrete substitutions to an existing translation based on an attention mechanism over both the source sentence as well as the current translation output. By making less than one modification per sentence, we improve the output of a phrase-based translation system by up to 0.4 BLEU on WMT15 German-English translation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Accurately segmenting a citation string into fields for authors, titles, etc. is a challenging task because the output typically obeys various global constraints. Previous work has shown that modeling soft constraints, where the model is encouraged, but not require to obey the constraints, can substantially improve segmentation performance. On the other hand, for imposing hard constraints, dual decomposition is a popular technique for efficient prediction given existing algorithms for unconstrained inference. We extend dual decomposition to perform prediction subject to soft constraints. Moreover, with a technique for performing inference given soft constraints, it is easy to automatically generate large families of constraints and learn their costs with a simple convex optimization problem during training. This allows us to obtain substantial gains in accuracy on a new, challenging citation extraction dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Most work on building knowledge bases has focused on collecting entities and facts from as large a collection of documents as possible. We argue for and describe a new paradigm where the focus is on a high-recall extraction over a small collection of documents under the supervision of a human expert, that we call Interactive Knowledge Base Population (IKBP).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reasoning About Pragmatics with Neural Listeners and Speakers\nAbstract: We present a model for pragmatically describing scenes, in which contrastive behavior results from a combination of inference-driven pragmatics and learned semantics. Like previous learned approaches to language generation, our model uses a simple feature-driven architecture (here a pair of neural \u201clistener\u201d and \u201cspeaker\u201d models) to ground language in the world. Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances. For training, our approach requires only ordinary captions, annotated without demonstration of the pragmatic behavior the model ultimately exhibits. In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to a 64% success rate using existing techniques.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Edge-Linear First-Order Dependency Parsing with Undirected Minimum Spanning Tree Inference\nAbstract: The run time complexity of state-of-theart inference algorithms in graph-based dependency parsing is super-linear in the number of input words (n). Recently, pruning algorithms for these models have shown to cut a large portion of the graph edges, with minimal damage to the resulting parse trees. Solving the inference problem in run time complexity determined solely by the number of edges (m) is hence of obvious importance. We propose such an inference algorithm for first-order models, which encodes the problem as a minimum spanning tree (MST) problem in an undirected graph. This allows us to utilize state-of-the-art undirected MST algorithms whose run time is O(m) at expectation and with a very high probability. A directed parse tree is then inferred from the undirected MST and is subsequently improved with respect to the directed parsing model through local greedy updates, both steps running inO(n) time. In experiments with 18 languages, a variant of the first-order MSTParser (McDonald et al., 2005b) that employs our algorithm performs very similarly to the original parser that runs an O(n2) directed MST inference.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mining Worse and Better Opinions Unsupervised and Agnostic Aggregation of Online Reviews\nAbstract: In this paper, we propose a novel approach for aggregating online reviews, according to the opinions they express. Our methodology is unsupervised due to the fact that it does not rely on pre-labeled reviews and it is agnostic since it does not make any assumption about the domain or the language of the review content. We measure the adherence of a review content to the domain terminology extracted from a review set. First, we demonstrate the informativeness of the adherence metric with respect to the score associated with a review. Then, we exploit the metric values to group reviews, according to the opinions they express. Our experimental campaign has been carried out on two large datasets collected from Booking and Amazon, respectively.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Question Answering Approach to Emotion Cause Extraction\nAbstract: Emotion cause extraction aims to identify the reasons behind a certain emotion expressed in text. It is a much more difficult task compared to emotion classification. Inspired by recent advances in using deep memory networks for question answering (QA), we propose a new approach which considers emotion cause identification as a reading comprehension task in QA. Inspired by convolutional neural networks, we propose a new mechanism to store relevant context in different memory slots to model context information. Our proposed approach can extract both word level sequence features and lexical features. Performance evaluation shows that our method achieves the state-of-the-art performance on a recently released emotion cause dataset, outperforming a number of competitive baselines by at least 3.01% in F-measure.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analyzing Features for the Detection of Happy Endings in German Novels\nAbstract: With regard to a computational representation of literary plot, this paper looks at the use of sentiment analysis for happy ending detection in German novels. Its focus lies on the investigation of previously proposed sentiment features in order to gain insight about the relevance of specific features on the one hand and the implications of their performance on the other hand. Therefore, we study various partitionings of novels, considering the highly variable concept of \"ending\". We also show that our approach, even though still rather simple, can potentially lead to substantial findings relevant to literary studies. Introduction Plot is fundamental for the structure of literary works. Methods for the computational representation of plot or special plot elements would therefore be a great achievement for digital literary studies. This paper looks at one such element: happy endings. We employ sentiment analysis for the detection of happy endings, but focus on a qualitative analysis of specific features and their performance in order to gain deeper insight into the automatic classification. In addition, we show how the applied method can be used for subsequent research questions, yielding interesting results with regard to publishing periods of the novels. Related Work One of the first works was on folkloristic tales, done by Mark Finlayson, who created an algorithm capable of detecting events and higher-level abstractions, such as villainy or reward (Finlayson 2012). Reiter et al., again on tales, identify events, their participants and order and use machine learning methods to find structural similarities across texts (Reiter 2013, Reiter et al. 2014). Recently, a significant amount of attention has been paid to sentiment analysis, when Matthew Jockers proposed emotional arousal as a new \u201cmethod for detecting plot\u201d (Jockers 2014). He described his idea to split novels into segments and use those to form plot trajectories (Jockers 2015). Despite general acceptance of the idea to employ sentiment analysis, his use of the Fourier Transformation to smooth the resulting plot curves was criticized (Swafford 2015, Schmidt 2015). Among other features, Micha Elsner (Elsner 2015) builds plot representations of romantic novels, again by using sentiment trajectories. He also links such trajectories with specific characters and looks at character co-occurrences. To evaluate his approach, he distinguishes real novels from artificially reordered surrogates with considerable success, showing that his methods indeed capture certain aspects of plot structure. In previous work, we used sentiment features to detect happy endings as a major plot element in German novels, reaching an F1-score of 73% (Zehe et al. 2016). Corpus and Resources Our dataset consists of 212 novels in German language mostly from the 19th century . Each 1 novel has been manually annotated as either having a happy ending (50%) or not (50%). The relevant information has been obtained from summaries of the Kindler Literary Lexikon Online and Wikipedia. If no summary was available, the corresponding parts of the novel 2 have been read by the annotators. Sentiment analysis requires a resource which lists sentiment values that human readers typically associate with certain words or phrases in a text. This paper relies on the NRC Sentiment Lexicon (Mohammad and Turney 2013), which is available in an automatically translated German version . A notable feature of this lexicon is that besides specifying binary 3 values (0 or 1) for negative and positive connotations (2 features) it also categorizes words into 8 basic emotions (anger, fear, disgust, surprise, joy, anticipation, trust and sadness), see Table 1 for an example. We add another value (the polarity) by subtracting the negative from the positive value (e.g. a word with a positive value of 0 and a negative value of 1 has a polarity value of -1). The polarity serves as an overall sentiment score, which results in 11 features. Table 1 \u200b : Example entries from the NRC Sentiment Lexicon Word/Dimension verabscheuen (to detest) bewundernswert (admirable) Zufall (coincidence) Positive 0 1 0 Negative 1 0 0 Polarity -1 1 0 Anger 1 0 0 Anticipation 0 0 0 Disgust 1 0 0 Fear 1 0 0 Joy 0 1 0 Sadness 0 0 0 Surprise 0 0 1 Trust 0 1 0 Experiments The goal of this paper is to investigate features that have been used for the detection of happy endings in novels in order to gain insight about the relevance of specific feature sets on the one hand and the implications of their performance on the other hand. To that end, we adopt the features and methods presented in Zehe et al. (2016). The parameters of the linear SVM and the partitioning into 75 segments are also adopted from this paper. 1 Source: https://textgrid.de/digitale-bibliothek 2 www.kll-online.de 3 http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm Features. Since reliable chapter annotations were not available, each novel has been split into 75 equally sized blocks, called \u200bsegments \u200b . For each lemmatized word, we look up the 11 sentiment values (including polarity, see above). Then, for each segment, we calculate the respective averages, resulting in 11 scores per segment. We group those 11 scores into one feature set. Qualitative Feature Analysis \u200b . As our corpus consists of an equal number of novels with and without happy ending, the random baseline as well the majority vote baseline amount to 50% classification accuracy. Since we assumed that the relevant information for identifying happy endings can be found at the end of a novel, we first used the sentiment scores of the final segment ( ) as the fd,n only feature set, reaching an F1-score of 67%. Following the intuition that not only the last segment by itself, but also its relation to the rest of the novel are meaningful for the classification, we introduced the notion of \u200bsections \u200b : the last segment of a novel constitutes the \u200bfinal section \u200b , whereas the remaining segments belong to the \u200bmain section \u200b . Averages were also calculated for the sections by taking the mean of each feature over all segments in the section. To further emphasize the relation between these sections, we added the differences between the sentiment scores of the final section and the average sentiment scores over all segments in the main section. However, this change did not influence the results. This led us to believe that our notion of an \u201cending\u201d was not accurate enough, as the number of segments for each novel and therefore the boundaries of the final segment have been chosen rather arbitrarily. To approach this issue, we varied the partitioning into main and final section so that the final section can contain more than just the last segment. Figure 1\u200b: \u200bClassification F1-score for different partitionings into main and final section. The dashed line represents a random baseline, the dotted line shows where the maximum F1-score is reached. Figure 1 shows that classification accuracy improves when at least 75% of the segments are in the main section and reaches a peak at about 95% (this means 4 segments in the final section and 71 segments in the main section, for a total of 75 segments). With this partitioning strategy, we improve the F1-score to 68% using only the feature set for the final section ( ) and reach an F1-score of 69% when also including the differences to the fd, f inal average sentiment scores of the main section ( ). fd, main\u2212f inal Since adding the relation between the main section and the final section improved our results in the previous setting, we tried to model the development of the sentiments towards the end of the novel in a more profound way. For example, a catastrophic event might happen shortly before the end of a novel and finally be resolved in a happy ending. To capture this intuition, we introduced one more section, namely the \u200blate-main section, which focuses on the segments right \u200bbefore the final section, and used the difference between the feature sets for the late-main and the final section as an additional feature set ( ). fd, late\u2212f inal Using those three feature sets, the classification of happy endings reaches an F1-score of 70% and increases to 73% when including the feature set for the final segment. Table 2 \u200b : Classification F1-score for the different feature sets\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting and Explaining Crisis\nAbstract: Individuals on social media may reveal themselves to be in various states of crisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis from social media text automatically and accurately can have profound consequences. However, detecting a general state of crisis without explaining why has limited applications. An explanation in this context is a coherent, concise subset of the text that rationalizes the crisis detection. We explore several methods to detect and explain crisis using a combination of neural and non-neural techniques. We evaluate these techniques on a unique data set obtained from Koko, an anonymous emotional support network available through various messaging applications. We annotate a small subset of the samples labeled with crisis with corresponding explanations. Our best technique significantly outperforms the baseline for detection and explanation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LOST IN SPACE: GEOLOCATION IN EVENT DATA\nAbstract: Extracting the \u201ccorrect\u201d location information from text data, i.e., determining the place of event, has long been a goal for automated text processing. To approximate human-like coding schema, we introduce a supervised machine learning algorithm that classifies each location word to be either correct or incorrect. We use news articles collected from around the world (Integrated Crisis Early Warning System [ICEWS] data and Open Event Data Alliance [OEDA] data) to test our algorithm that consists of two stages. In the feature selection stage, we extract contextual information from texts, namely, the N-gram patterns for location words, the frequency of mention, and the context of the sentences containing location words. In the classification stage, we use three classifiers to estimate the model parameters in the training set and then to predict whether a location word in the test set news articles is the place of the event. The validation results show that our algorithm improves the accuracy rate of the current geolocation methods of dictionary approach by as much as 25%. Keyword: Natural Language Processing, Information Extraction, Text Analysis, Supervised Machine Learning, Geolocation, Event Data\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exploiting Lists of Names for Named Entity Identification of Financial Institutions from Unstructured Documents\nAbstract: There is a wealth of information about financial systems that is embedded in document collections. In this paper, we focus on a specialized text extraction task for this domain. The objective is to extract mentions of names of financial institutions, or FI names, from financial prospectus documents, and to identify the corresponding real world entities, e.g., by matching against a corpus of such entities. The tasks are Named Entity Recognition (NER) and Entity Resolution (ER); both are well studied in the literature. Our contribution is to develop a rule-based approach that will exploit lists of FI names for both tasks; our solution is labeled Dict-based NER and Rank-based ER. Since the FI names are typically represented by a root, and a suffix that modifies the root, we use these lists of FI names to create specialized root and suffix dictionaries. To evaluate the effectiveness of our specialized solution for extracting FI names, we compare Dict-based NER with a general purpose rule-based NER solution, ORG NER. Our evaluation highlights the benefits and limitations of specialized versus general purpose approaches, and presents additional suggestions for tuning and customization for FI name extraction. To our knowledge, our proposed solutions, Dict-based NER and Rank-based ER, and the root and suffix dictionaries, are the first attempt to exploit specialized knowledge, i.e., lists of FI names, for rule-based NER and ER. CCS Concepts: rInformation systems\u2192 Extraction, transformation and loading; rComputing methodologies\u2192 Information extraction;\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast and unsupervised methods for multilingual cognate clustering\nAbstract: In this paper we explore the use of unsupervised methods for detecting cognates in multilingual word lists. We use online EM to train sound segment similarity weights for computing similarity between two words. We tested our online systems on geographically spread sixteen different language groups of the world and show that the Online PMI system (Pointwise Mutual Information) outperforms a HMM based system and two linguistically motivated systems: LexStat and ALINE. Our results suggest that a PMI system trained in an online fashion can be used by historical linguists for fast and accurate identification of cognates in not so well-studied language families.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Macquarie University at BioASQ 5b \u2013 Query-based Summarisation Techniques for Selecting the Ideal Answers\nAbstract: Macquarie University\u2019s contribution to the BioASQ challenge (Task 5b Phase B) focused on the use of query-based extractive summarisation techniques for the generation of the ideal answers. Four runs were submitted, with approaches ranging from a trivial system that selected the first n snippets, to the use of deep learning approaches under a regression framework. Our experiments and the ROUGE results of the five test batches of BioASQ indicate surprisingly good results for the trivial approach. Overall, most of our runs on the first three test batches achieved the best ROUGE-SU4 results in the challenge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ROOT13: Spotting Hypernyms, Co-Hyponyms and Randoms\nAbstract: In this paper, we describe ROOT13, a supervised system for the classification of hypernyms, co-hyponyms and random words. The system relies on a Random Forest algorithm and 13 unsupervised corpus-based features. We evaluate it with a 10-fold cross validation on 9,600 pairs, equally distributed among the three classes and involving several Parts-OfSpeech (i.e. adjectives, nouns and verbs). When all the classes are present, ROOT13 achieves an F1 score of 88.3%, against a baseline of 57.6% (vector cosine). When the classification is binary, ROOT13 achieves the following results: hypernyms-co-hyponyms (93.4% vs. 60.2%), hypernymsrandom (92.3% vs. 65.5%) and co-hyponyms-random (97.3% vs. 81.5%). Our results are competitive with stateof-the-art models. Introduction and Related Work Distinguishing hypernyms (e.g. dog-animal) from cohyponyms (e.g. dog-cat) and, in turn, discriminating them from random words (e.g. dog-fruit) is a fundamental task in Natural Language Processing (NLP). Hypernymy in fact represents a key organization principle of semantic memory (Murphy, 2002), the backbone of taxonomies and ontologies, and one of the crucial inferences supporting lexical entailment (Geffet and Dagan, 2005). Cohyponymy (or coordination), on the other hand, is the relation held by words sharing a close hypernym, which are therefore attributionally similar (Weeds et al., 2014). The ability of discriminating hypernymy, co-hyponymy and random words has potentially infinite applications, including automatic thesauri creation, paraphrasing, textual entailment, sentiment analysis and so on (Weeds et al., 2014). For this reason, in the last decades, numerous methods, datasets and shared tasks have been proposed to improve computers\u2019 ability in such discrimination, generally achieving promising results (Weeds et al., 2014; Rimmel, Copyright \u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 2014; Geffet and Dagan, 2005). Both supervised and unsupervised approaches have been investigated. The former have been shown to outperform the latter in Weeds et al. (2014), even though Levy et al. (2015) have recently claimed that these methods may learn whether a term y is a prototypical hypernym, regardless of its actual relation with a term x. In this paper, we propose a supervised method, based on a Random Forest algorithm and 13 corpus-based features. In our evaluation, carried out using the 10-fold cross validation on 9,600 pairs, we achieved an accuracy of 88.3% when the three classes are present, and of 92.3% and 97.3% when only two classes are present. Such results are competitive with the state-of-the-art (Weeds et al., 2014). Method and Evaluation ROOT13 uses the Random Forest algorithm implemented in Weka (Breiman, 2001), with the default settings. It relies on 13 features that are described below. Each of them is automatically extracted from a window-based Vector Space Model (VSM), built on a combination of ukWaC and WaCkypedia corpora (around 2.7 billion words) and recording word co-occurrences within the 5 nearest content words to the left and right of each target. FEATURES. The feature set was designed to identify several distributional properties characterizing the terms in the pairs. On top of the standard features (e.g. vector cosine, co-occurrence and frequencies), we have added several features capturing the generality of the terms and of their contexts, plus two unsupervised measures for capturing similarity (Santus et al., 2014b-c). All the features are normalized in the range 0-1: \u2022 Cos: vector cosine (Turney and Pantel, 2010); \u2022 Cooc: co-occurrence frequency; \u2022 Freq 1, 2: two features storing the frequency the terms; \u2022 Entr 1, 2: two features storing the entropy of the terms; 1 Generality is measured as for Santus et al. (2014a). \u2022 Shared: extent of the intersection between the top 1k most mutually related contexts of the two terms; \u2022 APSyn: for every context in the intersection between the top 1k most mutually related contexts of the two terms, this measure adds 1, divided by its average rank (Santus et al. 2014b-c); \u2022 Diff Freqs: difference between the terms frequencies; \u2022 Diff Entrs: difference between the terms entropies; \u2022 C-Freq 1, 2: two features storing the average frequency among the top 1k most mutually related contexts for each term; \u2022 C-Entr 1, 2: two features, storing the average entropy among the top 1k most mutually related contexts for each term. DATASET. We have used 9,600 pairs, randomly extracted from three datasets: Lenci/Benotto (Santus et al., 2014b), BLESS (Baroni and Lenci, 2011) and EVALution (Santus et al., 2015). The pairs are equally distributed among the three classes (i.e. hypernyms, co-hyponyms and random words) and involve several Parts-Of-Speech. TASKS. Four classification tasks have been carried out. One involving all classes and three tasks involving only two of them. F1 score on a 10-fold cross validation was chosen as accuracy measure. BASELINE. Vector cosine is used as baseline. It achieves a reasonable accuracy, which is anyway far below the results obtained by our model. As it will be shown below, our model does not benefit from its use. RESULTS. Table 1 describes the features\u2019 contributions in the four classification tasks. As can be seen, when all the classes are involved, every feature contributes for an increment between 0.4% and 4.8%, except for the feature Shared, whose contribution is +12.5%. The relevance of this feature is confirmed also in the other three tasks. Interestingly, instead, the vector cosine does not contribute to our score. It instead penalizes it in three tasks out of four. The only task in which it actually contributes for 0.1% is the discrimination between co-hyponyms and randoms, which is its main function.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Knowlege Graph Embedding by Flexible Translation\nAbstract: Knowledge graph embedding refers to projecting entities and relations in knowledge graph into continuous vector spaces. State-of-the-art methods, such as TransE, TransH, and TransR build embeddings by treating relation as translation from head entity to tail entity. However, previous models can not deal with reflexive/one-to-many/manyto-one/many-to-many relations properly, or lack of scalability and efficiency. Thus, we propose a novel method, flexible translation, named TransF, to address the above issues. TransF regards relation as translation between head entity vector and tail entity vector with flexible magnitude. To evaluate the proposed model, we conduct link prediction and triple classification on benchmark datasets. Experimental results show that our method remarkably improve the performance compared with several state-of-the-art baselines.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The Right Frontier Constraint (RFC), as a constraint on the attachment of new constituents to an existing discourse structure, has important implications for the interpretation of anaphoric elements in discourse and for Machine Learning (ML) approaches to learning discourse structures. In this paper we provide strong empirical support for SDRT\u2019s version of RFC. The analysis of about 100 doubly annotated documents by five different naive annotators shows that SDRT\u2019s RFC is respected about 95% of the time. The qualitative analysis of presumed violations that we have performed shows that they are either click-errors or structural misconceptions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EmojiNet: Building a Machine Readable Sense Inventory for Emoji\nAbstract: Emoji are a contemporary and extremely popular way to enhance electronic communication. Without rigid semantics attached to them, emoji symbols take on different meanings based on the context of a message. Thus, like the word sense disambiguation task in natural language processing, machines also need to disambiguate the meaning or \u2018sense\u2019 of an emoji. In a first step toward achieving this goal, this paper presents EmojiNet, the first machine readable sense inventory for emoji. EmojiNet is a resource enabling systems to link emoji with their context-specific meaning. It is automatically constructed by integrating multiple emoji resources with BabelNet, which is the most comprehensive multilingual sense inventory available to date. The paper discusses its construction, evaluates the automatic resource creation process, and presents a use case where EmojiNet disambiguates emoji usage in tweets. EmojiNet is available online for use at http://emojinet.knoesis.org.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A NEW HYBRID METRIC FOR VERIFYING PARALLEL\nAbstract: This paper discusses a new metric that has been applied to verify the quality in translation between sentence pairs in parallel corpora of Arabic-English. This metric combines two techniques, one based on sentence length and the other based on compression code length. Experiments on sample test parallel Arabic-English corpora indicate the combination of these two techniques improves accuracy of the identification of satisfactory and unsatisfactory sentence pairs compared to sentence length and compression code length alone. The new method proposed in this research is effective at filtering noise and reducing mis-translations resulting in greatly improved quality.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Overview of the NLPCC 2015 Shared Task: Chinese Word Segmentation and POS Tagging for Micro-blog Texts\nAbstract: In this paper, we give an overview for the shared task at the 4th CCF Conference on Natural Language Processing & Chinese Computing (NLPCC 2015): Chinese word segmentation and part-of-speech (POS) tagging for micro-blog texts. Different with the popular used newswire datasets, the dataset of this shared task consists of the relatively informal micro-texts. The shared task has two sub-tasks: (1) individual Chinese word segmentation and (2) joint Chinese word segmentation and POS Tagging. Each subtask has three tracks to distinguish the systems with different resources. We first introduce the dataset and task, then we characterize the different approaches of the participating systems, report the test results, and provide a overview analysis of these results. An online system is available for open registration and evaluation at http://nlp.fudan.edu.cn/nlpcc2015.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Lexical Normalisation of Twitter Data\nAbstract: Twitter with over 500 million users globally, generates over 100,000 tweets per minute. The 140 character limit per tweet has, perhaps unintentionally, encourages users to use shorthand notations and to strip spellings to their bare minimum \u201csyllables\u201d or elisions e.g. \u201csrsly\u201d. The analysis of twitter messages which typically contain misspellings, elisions, and grammatical errors, poses a challenge to established Natural Language Processing (NLP) tools which are generally designed with the assumption that the data conforms to the basic grammatical structure commonly used in English language. In order to make sense of Twitter messages it is necessary to first transform them into a canonical form, consistent with the dictionary or grammar. This process, performed at the level of individual tokens (\u201cwords\u201d), is called lexical normalisation. This paper investigates various techniques for lexical normalisation of Tweeter data and presents the findings as the techniques are applied to process raw data from Tweeter.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Who did What: A Large-Scale Person-Centered Cloze Dataset\nAbstract: We have constructed a new \u201cWho-did-What\u201d dataset of over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus. The WDW dataset has a variety of novel features. First, in contrast with the CNN and Daily Mail datasets (Hermann et al., 2015) we avoid using article summaries for question formation. Instead, each problem is formed from two independent articles \u2014 an article given as the passage to be read and a separate article on the same events used to form the question. Second, we avoid anonymization \u2014 each choice is a person named entity. Third, the problems have been filtered to remove a fraction that are easily solved by simple baselines, while remaining 84% solvable by humans. We report performance benchmarks of standard systems and propose the WDW dataset as a challenge task for the community.1\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Machine Translation with Source-Side Latent Graph Parsing\nAbstract: This paper presents a novel neural machine translation model which jointly learns translation and source-side latent graph representations of sentences. Unlike existing pipelined approaches using syntactic parsers, our end-to-end model learns a latent graph parser as part of the encoder of an attention-based neural machine translation model, so the parser is optimized according to the translation objective. Experimental results show that our model significantly outperforms the previous best results on the standard Englishto-Japanese translation dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: AttSum: Joint Learning of Focusing and Summarization with Neural Attention\nAbstract: Query relevance ranking and sentence saliency ranking are the two main tasks in extractive queryfocused summarization. Previous supervised summarization systems often perform the two tasks in isolation. However, since reference summaries are the trade-off between relevance and saliency, using them as supervision, neither of the two rankers could be trained well. This paper proposes a novel summarization system called AttSum, which tackles the two tasks jointly. It automatically learns distributed representations for sentences as well as the document cluster. Meanwhile, it applies the attention mechanism to simulate the attentive reading of human behavior when a query is given. Extensive experiments are conducted on DUC query-focused summarization benchmark datasets. Without using any hand-crafted features, AttSum achieves competitive performance. It is also observed that the sentences recognized to focus on the query indeed meet the query need.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We present a neural transition-based parser for spinal trees, a dependency representation of constituent trees. The parser uses Stack-LSTMs that compose constituent nodes with dependency-based derivations. In experiments, we show that this model adapts to different styles of dependency relations, but this choice has little effect for predicting constituent structure, suggesting that LSTMs induce useful states by themselves.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequence to Sequence Learning for Event Prediction\nAbstract: This paper presents an approach to the task of predicting an event description from a preceding sentence in a text. Our approach explores sequence-to-sequence learning using a bidirectional multi-layer recurrent neural network. Our approach substantially outperforms previous work in terms of the BLEU score on two datasets derived from WIKIHOW and DESCRIPT respectively. Since the BLEU score is not easy to interpret as a measure of event prediction, we complement our study with a second evaluation that exploits the rich linguistic annotation of gold paraphrase sets of events.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Event Structure of Transitive Verb: A MARVS perspective\nAbstract: Module-Attribute Representation of Verbal Semantics (MARVS) is a theory of the representation of verbal semantics that is based on Mandarin Chinese data (Huang et al. 2000). In the MARVS theory, there are two different types of modules: Event Structure Modules and Role Modules. There are also two sets of attributes: Event-Internal Attributes and Role-Internal Attributes, which are linked to the Event Structure Module and the Role Module, respectively. In this study, we focus on four transitive verbs as chi1 \u201ceat\u201d, wan2 \u201cplay\u201d, huan4 \u201cchange\u201d and shao1 \u201cburn\u201d and explore their event structures by the MARVS theory. Keyword: MARVS, event structure, event structure modules, intransitive verb\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Co-channel Interference Cancellation for Space-Time Coded OFDM Systems Using Adaptive Beamforming and Null Deepening\nAbstract: Combined with space-time coding, the orthogonal frequency division multiplexing (OFDM) system explores space<lb>diversity. It is a potential scheme to offer spectral efficiency and robust high data rate transmissions over frequency-selective<lb>fading channel. However, space-time coding impairs the system ability to suppress interferences as the signals transmitted from<lb>two transmit antennas are superposed and interfered at the receiver antennas. In this paper, we developed an adaptive<lb>beamforming based on least mean squared error algorithm and null deepening to combat co-channel interference (CCI) for the<lb>space-time coded OFDM (STC-OFDM) system. To illustrate the performance of the presented approach, it is compared to the<lb>null steering beamformer which requires a prior knowledge of directions of arrival (DOAs). The structure of space-time decoders<lb>are preserved although there is the use of beamformers before decoding. By incorporating the proposed beamformer as a CCI<lb>canceller in the STC-OFDM systems, the performance improvement is achieved as shown in the simulation results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discovering Conversational Dependencies between Messages in Dialogs\nAbstract: We investigate the task of inferring conversational dependencies between messages in one-on-one online chat, which has become one of the most popular forms of customer service. We propose a novel probabilistic classifier that leverages conversational, lexical and semantic information. The approach is evaluated empirically on a set of customer service chat logs from a Chinese e-commerce website. It outperforms heuristic baselines.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Civique: Using Social Media to Detect Urban Emergencies\nAbstract: We present the Civique system for emergency detection in urban areas by monitoring micro blogs like Tweets. The system detects emergency related events, and classifies them into appropriate categories like \u201cfire\u201d, \u201caccident\u201d, \u201cearthquake\u201d, etc. We demonstrate our ideas by classifying Twitter posts in real time, visualizing the ongoing event on a map interface and alerting users with options to contact relevant authorities, both online and offline. We evaluate our classifiers for both the steps, i.e., emergency detection and categorization, and obtain F-scores exceeding 70% and 90%, respectively. We demonstrate Civique using a web interface and on an Android application, in realtime, and show its use for both tweet detection and visualization.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Feelings: A Massive Cross-Lingual Study on the Relation between Emotions and Virality\nAbstract: This article provides a comprehensive investigation on the relations between virality of news articles and the emotions they are found to evoke. Virality, in our view, is a phenomenon with many facets, i.e. under this generic term several different effects of persuasive communication are comprised. By exploiting a high-coverage and bilingual corpus of documents containing metrics of their spread on social networks as well as a massive affective annotation provided by readers, we present a thorough analysis of the interplay between evoked emotions and viral facets. We highlight and discuss our findings in light of a cross-lingual approach: while we discover differences in evoked emotions and corresponding viral effects, we provide preliminary evidence of a generalized explanatory model rooted in the deep structure of emotions: the Valence-Arousal-Dominance (VAD) circumplex. We find that viral facets appear to be consistently affected by particular VAD configurations, and these configurations indicate a clear connection with distinct phenomena underlying persuasive communication.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Phrase Mining from Massive Text Corpora\nAbstract: As one of the fundamental tasks in text analysis, phrase mining aims at extracting quality phrases from a text corpus. Phrase mining is important in various tasks such as information extraction/retrieval, taxonomy construction, and topic modeling. Most existing methods rely on complex, trained linguistic analyzers, and thus likely have unsatisfactory performance on text corpora of new domains and genres without extra but expensive adaption. Recently, a few data-driven methods have been developed successfully for extraction of phrases from massive domain-specific text. However, none of the state-of-the-art models is fully automated because they require human experts for designing rules or labeling phrases. Since one can easily obtain many quality phrases from public knowledge bases to a scale that is much larger than that produced by human experts, in this paper, we propose a novel framework for automated phrase mining, AutoPhrase, which leverages this large amount of high-quality phrases in an effective way and achieves better performance compared to limited human labeled phrases. In addition, we develop a POS-guided phrasal segmentation model, which incorporates the shallow syntactic information in part-of-speech (POS) tags to further enhance the performance, when a POS tagger is available. Note that, AutoPhrase can support any language as long as a general knowledge base (e.g., Wikipedia) in that language is available, while benefiting from, but not requiring, a POS tagger. Compared to the state-of-the-art methods, the new method has shown significant improvements in effectiveness on five real-world datasets across different domains and languages.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Japanese Sentiment Classification using a Tree-Structured Long Short-Term Memory with Attention\nAbstract: Previous approaches to training syntax-<lb>based sentiment classification models re-<lb>quired phrase-level annotated corpora,<lb>which are not readily available in many<lb>languages other than English. Thus, we<lb>propose the use of tree-structured Long<lb>Short-Term Memory with an attention<lb>mechanism that pays attention to each sub-<lb>tree of the parse tree. Experimental results<lb>indicate that our model achieves the state-<lb>of-the-art performance in a Japanese sen-<lb>timent classification task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: WEAKLY SUPERVISED PLDA TRAINING\nAbstract: PLDA is a popular normalization approach for the i-vector model, and it has delivered state-of-the-art performance in speaker verification. However, PLDA training requires a large amount of labelled development data, which is highly expensive in most cases. We present a cheap PLDA training approach, which assumes that speakers in the same session can be easily separated, and speakers in different sessions are simply different. This results in \u2018weak labels\u2019 which are not fully accurate but cheap, leading to a weak PLDA training. Our experimental results on real-life large-scale telephony customer service achieves demonstrated that the weak training can offer good performance when human-labelled data are limited. More interestingly, the weak training can be employed as a discriminative adaptation approach, which is more efficient than the prevailing unsupervised method when human-labelled data are insufficient.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Meaning has been called the \u201choly grail\u201d of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences [1]. The field of Artifical Intelligence (AI) is very much a part of that list: the development of sophisticated natural language semantics is a sine qua non for achieving a level of intelligence comparable to humans. Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience [2]; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities [3]. Despite this, AI research in general, and its subdisciplines such as computational linguistics and computer vision in particular, have focused primarily on tasks that involve a single modality. Here, we propose virtual embodiment as an alternative, long-term strategy for AI research that is multi-modal in nature and that allows for the kind of scalability required to develop the field coherently and incrementally, in an ethically responsible fashion.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Crowdsourcing and Cooperation in Linguistic Resources\nAbstract: Linguistic resources can be populated with data through the use of such approaches as crowdsourcing and gamification when motivated people are involved. However, current crowdsourcing genre taxonomies lack the concept of cooperation, which is the principal element of modern video games and may potentially drive the annotators\u2019 interest. This survey on crowdsourcing taxonomies and cooperation in linguistic resources provides recommendations on using cooperation in existent genres of crowdsourcing and an evidence of the efficiency of cooperation using a popular Russian linguistic resource created through crowdsourcing as an example.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: INRIASAC: Simple Hypernym Extraction Methods\nAbstract: Given a set of terms from a given domain, how can we structure them into a taxonomy without manual intervention? This is the task 17 of SemEval 2015. Here we present our simple taxonomy structuring techniques which, despite their simplicity, ranked first in this 2015 benchmark. We use large quantities of text (English Wikipedia) and simple heuristics such as term overlap and document and sentence co-occurrence to produce hypernym lists. We describe these techniques and present an initial evaluation of results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Post-edit Analysis of Collective Biography Generation\nAbstract: Text generation is increasingly common but often requires manual post-editing where high precision is critical to end users. However, manual editing is expensive so we want to ensure this effort is focused on high-value tasks. And we want to maintain stylistic consistency, a particular challenge in crowd settings. We present a case study, analysing human post-editing in the context of a templatebased biography generation system. An edit flow visualisation combined with manual characterisation of edits helps identify and prioritise work for improving end-to-end efficiency and accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Inferring Informational Goals from Free-Text Queries: A Bayesian Approach\nAbstract: People using consumer software applications typically do not use technical jargon when querying an online database of help topics. Rather, they attempt to communicate their goals with common words and phrases that describe software functionality in terms of structure and objects they understand. We describe a Bayesian approach to modeling the relationship between words in a user's query for assistance and the informational goals of the user. After reviewing the general method, we describe several extensions that center on integrating additional distinctions and struc\u00ad ture about language usage and user goals into the Bayesian models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Modern statistical machine translation (SMT) systems usually use a linear combination of features to model the quality of each translation hypothesis. The linear combination assumes that all the features are in a linear relationship and constrains that each feature interacts with the rest features in an linear manner, which might limit the expressive power of the model and lead to a under-fit model on the current data. In this paper, we propose a nonlinear modeling for the quality of translation hypotheses based on neural networks, which allows more complex interaction between features. A learning framework is presented for training the non-linear models. We also discuss possible heuristics in designing the network structure which may improve the non-linear learning performance. Experimental results show that with the basic features of a hierarchical phrase-based machine translation system, our method produce translations that are better than a linear model.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Emotion Detection on TV Show Transcripts with Sequence-based Convolutional Neural Networks\nAbstract: While there have been significant advances in detecting emotions from speech and image recognition, emotion detection on text is still under-explored and remained as an active research field. This paper introduces a corpus for text-based emotion detection on multiparty dialogue as well as deep neural models that outperform the existing approaches for document classification. We first present a new corpus that provides annotation of seven emotions on consecutive utterances in dialogues extracted from the show, Friends. We then suggest four types of sequence-based convolutional neural network models with attention that leverage the sequence information encapsulated in dialogue. Our best model shows the accuracies of 37.9% and 54% for fineand coarsegrained emotions, respectively. Given the difficulty of this task, this is promising.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\nAbstract: Inspired by recent advances in multimodal learning and machine translation, we introduce an encoder-decoder pipeline that learns (a): a multimodal joint embedding space with images and text and (b): a novel language model for decoding distributed representations from our space. Our pipeline effectively unifies joint image-text embedding models with multimodal neural language models. We introduce the structure-content neural language model that disentangles the structure of a sentence to its content, conditioned on representations produced by the encoder. The encoder allows one to rank images and sentences while the decoder can generate novel descriptions from scratch. Using LSTM to encode sentences, we match the state-of-the-art performance on Flickr8K and Flickr30K without using object detections. We also set new best results when using the 19-layer Oxford convolutional network. Furthermore we show that with linear encoders, the learned embedding space captures multimodal regularities in terms of vector space arithmetic e.g. *image of a blue car* \"blue\" + \"red\" is near images of red cars. Sample captions generated for 800 images are made available for comparison.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Referring expression generation (REG)models that use speaker-dependent information require a considerable amount of training data produced by every individual speaker, or may otherwise perform poorly. In this work we present a simple REG experiment that allows the use of larger training data sets by grouping speakers according to their overspecification preferences. Intrinsic evaluation shows that this method generally outperforms the personalised method found in previous work.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Evaluating semantic models with word-sentence relatedness\nAbstract: Semantic textual similarity (STS) systems are designed to encode and evaluate the semantic similarity between words, phrases, sentences, and documents. One method for assessing the quality or authenticity of semantic information encoded in these systems is by comparison with human judgments. A data set for evaluating semantic models was developed consisting of 775 English word-sentence pairs, each annotated for semantic relatedness by human raters engaged in a Maximum Difference Scaling (MDS) task, as well as a faster alternative task. As a sample application of this relatedness data, behavior-based relatedness was compared to the relatedness computed via four off-the-shelf STS models: n-gram, Latent Semantic Analysis (LSA), Word2Vec, and UMBC Ebiquity. Some STS models captured much of the variance in the human judgments collected, but they were not sensitive to the implicatures and entailments that were processed and considered by the participants. All text stimuli and judgment data have been made freely available.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An empirical study for Vietnamese dependency parsing\u2217\nAbstract: This paper presents an empirical comparison of different dependency parsers for Vietnamese, which has some unusual characteristics such as copula drop and verb serialization. Experimental results show that the neural network-based parsers perform significantly better than the traditional parsers. We report the highest parsing scores published to date for Vietnamese with the labeled attachment score (LAS) at 73.53% and the unlabeled attachment score (UAS) at 80.66%.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequence-to-sequence neural network models for transliteration\nAbstract: Transliteration is a key component of machine translation systems and software internationalization. This paper demonstrates that neural sequence-to-sequence models obtain state of the art or close to state of the art results on existing datasets. In an effort to make machine transliteration accessible, we open source a new Arabic to English transliteration dataset and our trained models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: ions that are not shown include: \uf0b7 The multiple dimension systems of the Person object frame class; these typically include: o A special \u201ccomponent holder\u201d dimension system. o A 4D dimension system (a Cartesian coordinate + time system). \uf0b7 Transforms between the above two dimension systems. Some of the descriptions of definitions in the following sections will refer to this diagram. Structural Parent (a global frame of reference)\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Iterative Multi-document Neural Attention for Multiple Answer Prediction\nAbstract: People have information needs of varying complexity, which can be solved by an intelligent agent able to answer questions formulated in a proper way, eventually considering user context and preferences. In a scenario in which the user profile can be considered as a question, intelligent agents able to answer questions can be used to find the most relevant answers for a given user. In this work we propose a novel model based on Artificial Neural Networks to answer questions with multiple answers by exploiting multiple facts retrieved from a knowledge base. The model is evaluated on the factoid Question Answering and top-n recommendation tasks of the bAbI Movie Dialog dataset. After assessing the performance of the model on both tasks, we try to define the long-term goal of a conversational recommender system able to interact using natural language and to support users in their information seeking processes in a personalized way. 1 Motivation and Background We are surrounded by a huge variety of technological artifacts which \u201clive\u201d with us today. These artifacts can help us in several ways because they have the power to accomplish complex and timeconsuming tasks. Unfortunately, common software systems can do for us only specific types of tasks, in a strictly algorithmic way which is pre-defined by the software designer. Machine Learning (ML), a branch of Artificial Intelligence (AI), gives machines the ability to learn to complete tasks without being explicitly programmed. People have information needs of varying complexity, ranging from simple questions about common facts which can be found in encyclopedias, to more sophisticated cases in which they need to know what movie to watch during a romantic evening. These tasks can be solved by an intelligent agent able to answer questions formulated in a proper way, eventually considering user context and preferences. Question Answering (QA) emerged in the last decade as one of the most promising fields in AI, since it allows to design intelligent systems which are able to give correct answers to user questions expressed in natural language. Whereas, recommender systems produce individualized recommendations as output and have the effect of guiding the user in a personalized way to interesting or useful objects in a large space of possible options. In a scenario in which the user profile (the set of user preferences) can be represented by a question, intelligent agents able to answer questions can be used to find the most appealing items for a given user, which is the classical task that recommender systems can solve. Despite the efficacy of classical recommender systems, generally they are not able to handle a conversation with the user so they miss the possibility of understanding his contextual information, emotions and feedback to refine the user profile and provide enhanced suggestions. Conversational recommender systems assist online users in their information-seeking and decision making tasks by supporting an interactive process [10] which could be goal oriented with the task of starting general and, through a series of interaction cycles, narrowing down the user interests until the desired item is obtained [17]. In this work we propose a novel model based on Artificial Neural Networks to answer questions exploiting multiple facts retrieved from a knowledge base and evaluate it on a QA task. Moreover, the effectiveness of the model is evaluated on the top-n recommendation task, where the aim of the system is to produce a list of suggestions ranked according to the user preferences. After having assessed the performance of the model on both tasks, we try to define the long-term goal of a conversational recommender system able to interact with the user using natural language and to support him in the information seeking process in a personalized way. In order to fulfill our long-term goal of building a conversational recommender system we need to assess the performance of our model on specific tasks involved in this scenario. A recent work which goes in this direction is reported in [6], which presents the bAbI Movie Dialog dataset, composed by different tasks such as factoid QA, top-n recommendation and two more complex tasks, one which mixes QA and recommendation and one which contains turns of dialogs taken from Reddit. Having more specific tasks like QA and recommendation, and a more complex one which mixes both tasks gives us the possibility to evaluate our model on different levels of granularity. Moreover, the subdivision in turns of the more complex task provides a proper benchmark of the model capability to handle an effective dialog with the user. For the task related to QA, a lot of datasets have been released in order to assess the machine reading and comprehension capabilities and a lot of neural network-based models have been proposed. Our model takes inspiration from [19], which is able to answer Cloze-style [22] questions repeating an attention mechanism over the query and the documents multiple times. Despite the effectiveness on the Cloze-style task, the original model does not consider multiple documents as a source of information to answer questions, which is fundamental in order to extract the answer from different relevant facts. The restricted assumption that the answer is contained in the given document does not allow the model to provide an answer which does not belong to the document. Moreover, this kind of task does not expect multiple answers for a given question, which is important for the complex information needs required for a conversational recommender system. According to our vision, the main outcomes of our work can be considered as building blocks for a conversational recommender system and can be summarized as follows: 1. we extend the model reported in [19] to let the inference process exploit evidences observed in multiple documents coming from an external knowledge base represented as a collection of textual documents; 2. we design a model able to leverage the attention weights generated by the inference process to provide multiple answers which does not necessarily belong to the documents through a multi-layer neural network which may uncover possible relationships between the most relevant evidences; 3. we assess the efficacy of our model through an experimental evaluation on factoid QA and top-n recommendation tasks supporting our hypothesis that a QA model can be used to solve top-n recommendation, too. The paper is organized as follows: Section 2 describes our model, while Section 3 summarizes the evaluation of the model on the two above-mentioned tasks and the comparison with respect to stateof-the-art approaches. Section 4 gives an overview of the literature of both QA and recommender systems, while final remarks and our long-term vision are reported in Section 5.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Ontology Verbalization using Semantic-Refinement\nAbstract: In this paper, we propose a rule-based technique to generate redundancy-free natural language (NL) descriptions of Web Ontology Language (OWL) entities. The existing approaches which address the problem of verbalizing OWL ontologies generate NL text segments which are close to their counterpart statements in the ontology. Some of these approaches also perform grouping and aggregating of these NL text segments to generate a more fluent and comprehensive form of the content. Restricting our attention to description of individuals and atomic concepts, we find that the approach currently followed in the available tools is that of determining the set of all logical conditions that are satisfied by the given individual/concept name and translate these conditions verbatim into corresponding NL descriptions. Human-understandability of such descriptions is affected by the presence of repetitions and redundancies, as they have high fidelity to the OWL representation of the entities. In the literature, no efforts had been taken to remove redundancies and repetitions at the logical level before generating the NL descriptions of entities and we find this to be the main reason for lack of readability of the generated text. In this paper, we propose a technique called semantic-refinement to generate meaningful and easily-understandable (what we call redundancy-free) text descriptions of individuals and concepts of a given OWL ontology. We identify the combinations of OWL/DL constructs that lead to repetitive/redundant descriptions and propose a series of refinement rules to rewrite the conditions that are satisfied by an individual/concept in a meaning-preserving manner. The reduced set of conditions are then employed for generating textual descriptions. Our experiments show that, semantic-refinement technique leads to significantly improved descriptions of ontology entities. We also test the effectiveness and usefulness of the the generated descriptions for the purpose of validating the ontologies and find that the proposed technique is indeed helpful in the context. The details of an empirical study to support the claim are provided in the paper.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We propose a cognitively and linguistically motivated set of sorts for lexical semantics in a compositional setting: the classifiers in languages that do have such pronouns. These sorts are needed to include lexical considerations in a semantical analyser such as Boxer or Grail. Indeed, all proposed lexical extensions of usual Montague semantics to model restriction of selection, felicitous and infelicitous copredication require a rich and refined type systemwhose base types are the lexical sorts, the basis of the many-sorted logic in which semantical representations of sentences are stated. However, none of those approaches define precisely the actual base types or sorts to be used in the lexicon. In this article, we shall discuss some of the options commonly adopted by researchers in formal lexical semantics, and defend the view that classifiers in the languages which have such pronouns are an appealing solution, both linguistically and cognitively motivated.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: HARD MONOTONIC ATTENTION\nAbstract: We present a supervised sequence to sequence transduction model with a hard attention mechanism which combines the more traditional statistical alignment methods with the power of recurrent neural networks. We evaluate the model on the task of morphological inflection generation and show that it provides state of the art results in various setups compared to the previous neural and non-neural approaches. Eventually we present an analysis of the learned representations for both hard and soft attention models, shedding light on the features such models extract in order to solve the task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Siamese convolutional networks based on phonetic features for cognate identification\nAbstract: In this paper, we explore the use of convolutional networks (ConvNets) for the purpose of cognate identification. We compare our architecture with binary classifiers based on string similarity measures on different language families. Our experiments show that convolutional networks achieve competitive results across concepts and across language families at the task of cognate identification.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Enhancing the LexVec Distributed Word Representation Model Using Positional Contexts and External Memory\nAbstract: In this paper we take a state-of-the-art model for distributed word representation that explicitly factorizes the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling and address two of its shortcomings. We improve syntactic performance by using positional contexts, and solve the need to store the PPMI matrix in memory by working on aggregate data in external memory. The effectiveness of both modifications is shown using word similarity and analogy tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Character-based Joint Segmentation and POS Tagging for Chinese using Bidirectional RNN-CRF\nAbstract: We present a character-based model for joint segmentation and POS tagging for Chinese. The bidirectional RNN-CRF architecture for general sequence tagging is adapted and applied with novel vector representations of Chinese characters that capture rich contextual information and sub-character level features. The proposed model is extensively evaluated and compared with a state-of-the-art tagger respectively on CTB5, CTB9 and UD Chinese. The experimental results indicate that our model is accurate and robust across datasets in different sizes, genres and annotation schemes. We obtain stateof-the-art performance on CTB5, achieving 94.38 F1-score for joint segmentation and POS tagging.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Global Normalization of Convolutional Neural Networks for Joint Entity and Relation Classification\nAbstract: We introduce globally normalized convolutional neural networks for joint entity classification and relation extraction. In particular, we propose a way to utilize a linear-chain conditional random field output layer for predicting entity types and relations between entities at the same time. Our experiments show that global normalization outperforms a locally normalized softmax layer on a benchmark dataset.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dissecting a Social Botnet: Growth, Content and Influence in Twitter\nAbstract: Social botnets have become an important phenomenon on social media. There are many ways in which social bots can disrupt or influence online discourse, such as, spam hashtags, scam twitter users, and astroturfing. In this paper we considered one specific social botnet in Twitter to understand how it grows over time, how the content of tweets by the social botnet differ from regular users in the same dataset, and lastly, how the social botnet may have influenced the relevant discussions. Our analysis is based on a qualitative coding for approximately 3000 tweets in Arabic and English from the Syrian social bot that was active for 35 weeks on Twitter before it was shutdown. We find that the growth, behavior and content of this particular botnet did not specifically align with common conceptions of botnets. Further we identify interesting aspects of the botnet that distinguish it from regular users.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Macro Grammars and Holistic Triggering for Efficient Semantic Parsing\nAbstract: To learn a semantic parser from denota-<lb>tions, a learning algorithm must search<lb>over a combinatorially large space of log-<lb>ical forms for ones consistent with the an-<lb>notated denotations. We propose a new<lb>online learning algorithm that searches<lb>faster as training progresses. The two<lb>key ideas are using macro grammars to<lb>cache the abstract patterns of useful log-<lb>ical forms found thus far, and holistic trig-<lb>gering to efficiently retrieve the most rele-<lb>vant patterns based on sentence similarity.<lb>On the WIKITABLEQUESTIONS dataset,<lb>we first expand the search space of an ex-<lb>isting model to improve the state-of-the-<lb>art accuracy from 38.7% to 42.7%, and<lb>then use macro grammars and holistic trig-<lb>gering to achieve an 11x speedup and an<lb>accuracy of 43.7%.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The NLTK FrameNet API: Designing for Discoverability with a Rich Linguistic Resource\nAbstract: A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Hybrid Model for Enhancing Lexical Statistical Machine Translation (SMT)\nAbstract: The interest in statistical machine translation systems increases currently due to political and social events in the world. A proposed Statistical Machine Translation (SMT) based model that can be used to translate a sentence from the source Language (English) to the target language (Arabic) automatically through efficiently incorporating different statistical and Natural Language Processing (NLP) models such as language model, alignment model, phrase based model, reordering model, and translation model. These models are combined to enhance the performance of statistical machine translation (SMT). Many implementation tools have been used in this work such as Moses, Gizaa++, IRSTLM, KenLM, and BLEU. Based on the implementation, evaluation of this model, and comparing the generated translation with other implemented machine translation systems like Google Translate, it was proved that this proposed model has enhanced the results of the statistical machine translation, and forms a reliable and efficient model in this field of research.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting and Extracting Events from Text Documents\nAbstract: Events of various kinds are mentioned and discussed in text documents, whether they are books, news articles, blogs or microblog feeds. The paper starts by giving an overview of how events are treated in linguistics and philosophy. We follow this discussion by surveying how events and associated information are handled in computationally. In particular, we look at how textual documents can be mined to extract events and ancillary information. These days, it is mostly through the application of various machine learning techniques. We also discuss applications of event detection and extraction systems, particularly in summarization, in the medical domain and in the context of Twitter posts. We end the paper with a discussion of challenges and future directions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We explore the factors influencing the dependence of single sentences on their larger textual context in order to automatically identify candidate sentences for language learning exercises from corpora which are presentable in isolation. An in-depth investigation of this question has not been previously carried out. Understanding this aspect can contribute to a more efficient selection of candidate sentences which, besides reducing the time required for item writing, can also ensure a higher degree of variability and authenticity. We present a set of relevant aspects collected based on the qualitative analysis of a smaller set of contextdependent corpus example sentences. Furthermore, we implemented a rule-based algorithm using these criteria which achieved an average precision of 0.76 for the identification of different issues related to context dependence. The method has also been evaluated empirically where 80% of the sentences in which our system did not detect context-dependent elements were also considered context-independent by human raters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sharing Network Parameters for Crosslingual Named Entity Recognition\nAbstract: Most state of the art approaches for Named Entity Recognition rely on hand crafted features and annotated corpora. Recently Neural network based models have been proposed which do not require handcrafted features but still require annotated corpora. However, such annotated corpora may not be available for many languages. In this paper, we propose a neural network based model which allows sharing the decoder as well as word and character level parameters between two languages thereby allowing a resource fortunate language to aid a resource deprived language. Specifically, we focus on the case when limited annotated corpora is available in one language (L1) and abundant annotated corpora is available in another language (L2). Sharing the network architecture and parameters between L1 and L2 leads to improved performance in L1. Further, our approach does not require any hand crafted features but instead directly learns meaningful feature representations from the training data itself. We experiment with 4 language pairs and show that indeed in a resource constrained setup (lesser annotated corpora), a model jointly trained with data from another language performs better than a model trained only on the limited corpora in one language.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Extraction of Number of Subjects in Randomised Controlled Trials\nAbstract: We present a simple approach for automatically extracting the number of subjects involved in randomised controlled trials (RCT). Our approach first applies a set of rule-based techniques to extract candidate study sizes from the abstracts of the articles. Supervised classification is then performed over the candidates with support vector machines, using a small set of lexical, structural, and contextual features. With only a small annotated training set of 201 RCTs, we obtained an accuracy of 88%. We believe that this system will aid complex medical text processing tasks such as summarisation and question answering.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient Learning for Undirected Topic Models\nAbstract: Replicated Softmax model, a well-known undirected topic model, is powerful in extracting semantic representations of documents. Traditional learning strategies such as Contrastive Divergence are very inefficient. This paper provides a novel estimator to speed up the learning based on Noise Contrastive Estimate, extended for documents of variant lengths and weighted inputs. Experiments on two benchmarks show that the new estimator achieves great learning efficiency and high accuracy on document retrieval and classification.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: \u0423 \u0441\u0442\u0430\u0442\u0442\u0456 \u043e\u043f\u0438\u0441\u0430\u043d\u043e \u043c\u0435\u0442\u043e\u0434\u0438\u043a\u0443 \u0442\u0430 \u043f\u0440\u0438\u043d\u0446\u0438\u043f\u0438 \u0443\u043a\u043b\u0430\u0434\u0430\u043d\u043d\u044f \u0447\u0430\u0441\u0442\u043e\u0442\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u043d\u0438\u043a\u0430 \u0440\u043e\u043c\u0430\u043d\u0443 \u0406. \u0424\u0440\u0430\u043d\u043a\u0430 \u201c\u0414\u043b\u044f \u0434\u043e\u043c\u0430\u0448\u043d\u044c\u043e\u0433\u043e \u043e\u0433\u043d\u0438\u0449\u0430\u201d. \u041e\u0442\u0440\u0438\u043c\u0430\u043d\u043e \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u043d\u0456 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0438 \u043b\u0435\u043a\u0441\u0438\u043a\u0438 \u0442\u0432\u043e\u0440\u0443, \u0437\u043e\u043a\u0440\u0435\u043c\u0430, \u0456\u043d\u0434\u0435\u043a\u0441\u0438 \u0440\u0456\u0437\u043d\u043e\u043c\u0430\u043d\u0456\u0442\u043d\u043e\u0441\u0442\u0456 (\u0431\u0430\u0433\u0430\u0442\u0441\u0442\u0432\u043e \u0441\u043b\u043e\u0432\u043d\u0438\u043a\u0430), \u0432\u0438\u043d\u044f\u0442\u043a\u043e\u0432\u043e\u0441\u0442\u0456, \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430\u0446\u0456\u0457, \u0441\u043f\u0456\u0432\u0432\u0456\u0434\u043d\u043e\u0448\u0435\u043d\u043d\u044f \u043c\u0456\u0436 \u0440\u0430\u043d\u0433\u043e\u043c \u0441\u043b\u043e\u0432\u0430 \u0442\u0430 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u043e\u044e \u043f\u043e\u043a\u0440\u0438\u0442\u0442\u044f \u0442\u0435\u043a\u0441\u0442\u0443 \u0442\u043e\u0449\u043e. \u041d\u0430 \u043e\u0441\u043d\u043e\u0432\u0456 \u0447\u0430\u0441\u0442\u043e\u0442\u043d\u0438\u0445 \u0441\u043b\u043e\u0432\u043d\u0438\u043a\u0456\u0432 \u0440\u043e\u043c\u0430\u043d\u0456\u0432 \u0406. \u0424\u0440\u0430\u043d\u043a\u0430 \u201c\u041f\u0435\u0440\u0435\u0445\u0440\u0435\u0441\u043d\u0456 \u0441\u0442\u0435\u0436\u043a\u0438\u201d (2007) \u0442\u0430 \u201c\u0414\u043b\u044f \u0434\u043e\u043c\u0430\u0448\u043d\u044c\u043e\u0433\u043e \u043e\u0433\u043d\u0438\u0449\u0430\u201d (2010) \u0437\u0434\u0456\u0439\u0441\u043d\u0435\u043d\u043e \u043f\u043e\u0440\u0456\u0432\u043d\u044f\u043d\u043d\u044f \u043e\u0441\u043d\u043e\u0432\u043d\u0438\u0445 \u043a\u0456\u043b\u044c\u043a\u0456\u0441\u043d\u0438\u0445 \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a \u0432\u043a\u0430\u0437\u0430\u043d\u0438\u0445 \u0442\u0435\u043a\u0441\u0442\u0456\u0432.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification\nAbstract: In this paper, we address the challenge of land use and land cover classification using remote sensing satellite images. For this challenging task, we use the openly and freely accessible Sentinel-2 satellite images provided within the scope of the Earth observation program Copernicus. The key contributions are as follows. We present a novel dataset based on satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Network (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards a number of Earth observation applications. We demonstrate how the classification system can be used for detecting land use or land cover changes and how it can assist in improving geographical maps.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Concept Taxonomies from Multi-modal Data\nAbstract: We study the problem of automatically building hypernym taxonomies from textual and visual data. Previous works in taxonomy induction generally ignore the increasingly prominent visual data, which encode important perceptual semantics. Instead, we propose a probabilistic model for taxonomy induction by jointly leveraging text and images. To avoid hand-crafted feature engineering, we design end-to-end features based on distributed representations of images and words. The model is discriminatively trained given a small set of existing ontologies and is capable of building full taxonomies from scratch for a collection of unseen conceptual label items with associated images. We evaluate our model and features on the WordNet hierarchies, where our system outperforms previous approaches by a large gap.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Data-driven Rank Breaking for Efficient Rank Aggregation\nAbstract: Rank aggregation systems collect ordinal preferences from individuals to produce a global ranking that represents the social preference. Rank-breaking is a common practice to reduce the computational complexity of learning the global ranking. The individual preferences are broken into pairwise comparisons and applied to efficient algorithms tailored for independent paired comparisons. However, due to the ignored dependencies in the data, naive rank-breaking approaches can result in inconsistent estimates. The key idea to produce accurate and consistent estimates is to treat the pairwise comparisons unequally, depending on the topology of the collected data. In this paper, we provide the optimal rank-breaking estimator, which not only achieves consistency but also achieves the best error bound. This allows us to characterize the fundamental tradeoff between accuracy and complexity. Further, the analysis identifies how the accuracy depends on the spectral gap of a corresponding comparison graph.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization, Experimental Design and Bandits\nAbstract: BayesOpt is a library with state-of-the-art Bayesian optimization methods to solve nonlinear optimization, stochastic bandits or sequential experimental design problems. Bayesian optimization is sample efficient by building a posterior distribution to capture the evidence and prior knowledge for the target function. Built in standard C++, the library is extremely efficient while being portable and flexible. It includes a common interface for C, C++, Python, Matlab and Octave.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Bayesian Active Learning with Image Data\nAbstract: Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detecting Novel Processes with CANDIES \u2013 An Holistic Novelty Detection Technique based on Probabilistic Models\nAbstract: In this article, we propose CANDIES (Combined Approach for Novelty Detection in Intelligent Embedded Systems), a new approach to novelty detection in technical systems. We assume that in a technical system several processes interact. If we observe these processes with sensors, we are able to model the observations (samples) with a probabilistic model, where, in an ideal case, the components of the parametric mixture density model we use, correspond to the processes in the real world. Eventually, at run-time, novel processes emerge in the technical systems such as in the case of an unpredictable failure. As a consequence, new kinds of samples are observed that require an adaptation of the model. CANDIES relies on mixtures of Gaussians which can be used for classification purposes, too. New processes may emerge in regions of the models\u2019 input spaces where few samples were observed before (low-density regions) or in regions where already many samples were available (high-density regions). The latter case is more difficult, but most existing solutions focus on the former. Novelty detection in lowand high-density regions requires different detection strategies. With CANDIES, we introduce a new technique to detect novel processes in high-density regions by means of a fast online goodness-of-fit test. For detection in low-density regions we combine this approach with a 2SND (Two-Stage-Novelty-Detector) which we presented in preliminary work. The properties of CANDIES are evaluated using artificial data and benchmark data from the field of intrusion detection in computer networks, where the task is to detect new kinds of attacks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Autoencoder-Driven Weather Clustering for Source Estimation during Nuclear Events\nAbstract: Emergency response applications for nuclear or radiological events can be significantly improved via deep feature learning due to the hidden complexity of the data and models involved. In this paper we present a novel methodology for rapid source estimation during radiological releases based on deep feature extraction and weather clustering. Atmospheric dispersions are then calculated based on identified predominant weather patterns and are matched against simulated incidents indicated by radiation readings on the ground. We evaluate the accuracy of our methods over multiple years of weather reanalysis data in the European region. We juxtapose these results with deep classification convolution networks and discuss advantages and disadvantages.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: For Internet applications like sponsored search, cautions need to be taken when using machine learning to optimize their mechanisms (e.g., auction) since selfinterested agents in these applications may change their behaviors (and thus the data distribution) in response to the mechanisms. To tackle this problem, a framework called game-theoretic machine learning (GTML) was recently proposed, which first learns a Markov behavior model to characterize agents behaviors, and then learns the optimal mechanism by simulating agents\u2019 behavior changes in response to the mechanism. While GTML has demonstrated practical success, its generalization analysis is challenging because the behavior data are non-i.i.d. and dependent on the mechanism. To address this challenge, first, we decompose the generalization error for GTML into the behavior learning error and the mechanism learning error; second, for the behavior learning error, we obtain novel non-asymptotic error bounds for both parametric and non-parametric behavior learning methods; third, for the mechanism learning error, we derive a uniform convergence bound based on a new concept called nested covering number of the mechanism space and the generalization analysis techniques developed for mixing sequences. To the best of our knowledge, this is the first work on the generalization analysis of GTML, and we believe it has general implications to the theoretical analysis of other complicated machine learning problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Expressive recommender systems through normalized nonnegative models\nAbstract: We introduce normalized nonnegative models (NNM) for explorative data analysis. NNMs are partial convexifications of models from probability theory. We demonstrate their value at the example of item recommendation. We show that NNM-based recommender systems satisfy three criteria that all recommender systems should ideally satisfy: high predictive power, computational tractability, and expressive representations of users and items. Expressive user and item representations are important in practice to succinctly summarize the pool of customers and the pool of items. In NNMs, user representations are expressive because each user\u2019s preference can be regarded as normalized mixture of preferences of stereotypical users. The interpretability of item and user representations allow us to arrange properties of items (e.g., genres of movies or topics of documents) or users (e.g., personality traits) hierarchically.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Submodular Maximization under a Matroid Constraint with Application to Learning Assignments\nAbstract: Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efficient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 \u2212 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. Finally, we present a second algorithm that handles the more general case in which the feasible sets are given by a matroid constraint, while still maintaining a 1\u2212 1/e asymptotic performance ratio.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Local Invariant Mahalanobis Distances\nAbstract: For many tasks and data types, there are natural transformations to which the data should be invariant or insensitive. For instance, in visual recognition, natural images should be insensitive to rotation and translation. This requirement and its implications have been important in many machine learning applications, and tolerance for image transformations was primarily achieved by using robust feature vectors. In this paper we propose a novel and computationally efficient way to learn a local Mahalanobis metric per datum, and show how we can learn a local invariant metric to any transformation in order to improve performance. Metric learning is a machine learning task which learns a distance metric d(x, y) between data points, based on data instances. As distances play an important role in many machine learning algorithms, e.g. k-Nearest Neighbor and k-Means clustering, finding an appropriate metric for the task can improve performance considerably. This approach has been applied successfully to many problems such as face identification [11], image retrieval [12, 6], ranking [16] and clustering [22] to name just a few. A standard approach to metric learning is to learn a global Mahalanobis metric d(x, y)M = (x\u2212 y)M(x\u2212 y) (1) Where M is a positive semi-definite matrix (PSD). The PSD constraint only assures this is a pseudometric , but for simplicity we will not make this distinction. Various algorithms [21, 1, 9] differ by the objective through which they learn the matrix M from the data. As M is a PSD matrix, it can be written as M = LL and therefore d(x, y)M = (x\u2212 y)M(x\u2212 y) = ||x\u0303\u2212 \u1ef9||2 x\u0303 = Lx, \u1ef9 = Ly. This means that finding an optimal Mahalanobis distance is equivalent to finding the optimal linear transformation on the data, and then using L2 distance on the transformed data. This approach has two limitations, first it is limited to linear transformation. Second, it requires a large amount of labeled data. One approach that can be used to overcome the first limitation is to use local distances [10] where we learn a unique distance function per training datum. Local approaches do not produce, in general, a global metric (as they are usually not symmetrical) but are commonly considered metric learning nonetheless. These methods, in 1 ar X iv :1 50 2. 01 17 6v 1 [ cs .L G ] 4 F eb 2 01 5 general, need similar and dissimilar training data for each local metric. In our current work we use a local approach inspired by the work on exemplar-SVM [18], that showed that using only negative examples can suffice for good performance. The intuition behind this is that objects of the same class do not necessarily have to be similar, but objects from different classes must be dissimilar. We will show how to learn a local Mahalanobis distance that for each datum tries to keep the non-class as far away as possible. This approach can use a large amount of weakly supervised data, as in many cases negative examples are easier then positive examples to acquire. For example, if we are interested in face identification, we can learn a local metric around a query face image given a bank of train face images, which we only assume do not belong to the queried person. Unlike other metric learning methods, we will not need any labels on which image belongs to which person in the negative set. The intuition why Mahalanobis distances are the natural model for local metrics is simple. Assume we have some metric d(x, y) on the dataset and assume that it is smooth (at least continuously twice differentiable). From the metric properties we know that if we fix x and look at f(y) = d(y, x) then f has a global minimum at y = x. Applying second order Tylor approximation to f around x we get d(y, x) = f(y) \u2248 f(x) + (y \u2212 x)\u2207f(x)+ (y \u2212 x)\u2207f(x)(y \u2212 x) = (y \u2212 x)\u2207f(x)(y \u2212 x) (2) The equality holds since x is the global minimum with value f(x) = d(x, x) = 0, and this also implies that \u2207f(x) is positive semidefinite. While the Taylor approximation only holds for values of y close to x, as metric methods such as k-NN focus on similar objects the approximation should be good at the points of interest. This observation leads us to look for local matrices that are of the form of a Mahalanobis distance. We will first define our local Mahalanobis distance learning method as a semidefinite programming problem. We will then show how this problem can be solved efficiently without any costly matrix decompositions. This allows us to solve high dimensional problems that regular semidefinite solvers cannot handle. The second major contribution of this paper will be to show how invariant local matrices can be learned. In many cases we know there are simple transformations that our metric should not be sensitive to. For example, small translation and rotation on natural images. We know a priori that if x\u2032 = T (x), where T is the said transformation, then d(x, x\u2032) \u2248 0. We will show how this prior knowledge about our data can by incorporated by learning a local invariant metric. This also can be done in an efficient manner, and we will show that this improves performance in our experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analysis of Massive Heterogeneous Temporal-Spatial Data with 3D Self-Organizing Map and Time Vector\nAbstract: Self-organizing map(SOM) have been widely applied in clustering, this paper focused on centroids of clusters and what they reveal. When the input vectors consists of time, latitude and longitude, the map can be strongly linked to physical world, providing valuable information. Beyond basic clustering, a novel approach to address the temporal element is developed, enabling 3D SOM to track behaviors in multiple periods concurrently. Combined with adaptations targeting to process heterogeneous data relating to distribution in time and space, the paper offers a fresh scope for business and services based on temporal-spatial pattern.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Architectural Complexity Measures of Recurrent Neural Networks\nAbstract: In this paper, we systematically analyse the connecting architectures of recurrent neural networks (RNNs). Our main contribution is twofold: first, we present a rigorous graphtheoretic framework describing the connecting architectures of RNNs in general. Second, we propose three architecture complexity measures of RNNs: (a) the recurrent depth, which captures the RNN\u2019s over-time nonlinear complexity, (b) the feedforward depth, which captures the local input-output nonlinearity (similar to the \u201cdepth\u201d in feedforward neural networks (FNNs)), and (c) the recurrent skip coefficient which captures how rapidly the information propagates over time. Our experimental results show that RNNs might benefit from larger recurrent depth and feedforward depth. We further demonstrate that increasing recurrent skip coefficient offers performance boosts on long term dependency problems, as we improve the state-of-the-art for sequential MNIST dataset.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Toward better feature weighting algorithms: a focus on Relief\nAbstract: Feature weighting algorithms try to solve a problem of great importance nowadays in machine learning: The search of a relevance measure for the features of a given domain. This relevance is primarily used for feature selection as feature weighting can be seen as a generalization of it, but it is also useful to better understand a problem\u2019s domain or to guide an inductor in its learning process. Relief family of algorithms are proven to be very effective in this task. Some other feature weighting methods are reviewed in order to give some context and then the different existing extensions to the original algorithm are explained. One of Relief\u2019s known issues is the performance degradation of its estimates when redundant features are present. A novel theoretical definition of redundancy level is given in order to guide the work towards an extension of the algorithm that is more robust against redundancy. A new extension is presented that aims for improving the algorithms performance. Some experiments were driven to test this new extension against the existing ones with a set of artificial and real datasets and denoted that in certain cases it improves the weight\u2019s estimation accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast K-Means with Accurate Bounds\nAbstract: We propose a novel accelerated exact k-means algorithm, which outperforms the current stateof-the-art low-dimensional algorithm in 18 of 22 experiments, running up to 3\u00d7 faster. We also propose a general improvement of existing stateof-the-art accelerated exact k-means algorithms through better estimates of the distance bounds used to reduce the number of distance calculations, obtaining speedups in 36 of 44 experiments, of up to 1.8\u00d7. We have conducted experiments with our own implementations of existing methods to ensure homogeneous evaluation of performance, and we show that our implementations perform as well or better than existing available implementations. Finally, we propose simplified variants of standard approaches and show that they are faster than their fully-fledged counterparts in 59 of 62 experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Near-Optimal Entrywise Sampling for Data Matrices\nAbstract: We consider the problem of selecting non-zero entries of a matrix A in order to produce a sparse sketch of it, B, that minimizes \u2016A\u2212B\u20162. For large m\u00d7n matrices, such that n m (for example, representing n observations over m attributes) we give sampling distributions that exhibit four important properties. First, they have closed forms computable from minimal information regarding A. Second, they allow sketching of matrices whose non-zeros are presented to the algorithm in arbitrary order as a stream, with O(1) computation per non-zero. Third, the resulting sketch matrices are not only sparse, but their non-zero entries are highly compressible. Lastly, and most importantly, under mild assumptions, our distributions are provably competitive with the optimal offline distribution. Note that the probabilities in the optimal offline distribution may be complex functions of all the entries in the matrix. Therefore, regardless of computational complexity, the optimal distribution might be impossible to compute in the streaming model.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stein Variational Autoencoder\nAbstract: A new method for learning variational autoencoders is developed, based on an application of Stein\u2019s operator. The framework represents the encoder as a deep nonlinear function through which samples from a simple distribution are fed. One need not make parametric assumptions about the form of the encoder distribution, and performance is further enhanced by integrating the proposed encoder with importance sampling. Example results are demonstrated across multiple unsupervised and semi-supervised problems, including semi-supervised analysis of the ImageNet data, demonstrating the scalability of the model to large datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: High-Performance Distributed ML at Scale through Parameter Server Consistency Models\nAbstract: As Machine Learning (ML) applications increase in data size and model complexity, practitioners turn to distributed clusters to satisfy the increased computational and memory demands. Unfortunately, effective use of clusters for ML requires considerable expertise in writing distributed code, while highly-abstracted frameworks like Hadoop have not, in practice, approached the performance seen in specialized ML implementations. The recent Parameter Server (PS) paradigm is a middle ground between these extremes, allowing easy conversion of single-machine parallel ML applications into distributed ones, while maintaining high throughput through relaxed \u201cconsistency models\u201d that allow inconsistent parameter reads. However, due to insufficient theoretical study, it is not clear which of these consistency models can really ensure correct ML algorithm output; at the same time, there remain many theoretically-motivated but undiscovered opportunities to maximize computational throughput. Motivated by this challenge, we study both the theoretical guarantees and empirical behavior of iterative-convergent ML algorithms in existing PS consistency models. We then use the gleaned insights to improve a consistency model using an \u201ceager\u201d PS communication mechanism, and implement it as a new PS system that enables ML algorithms to reach their solution more quickly.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Continuous-time Mutually-Exciting Point Process Framework for Prioritizing Events in Social Media\nAbstract: The overwhelming amount and rate of information update in online social media is making it increasingly difficult for users to allocate their attention to their topics of interest, thus there is a strong need for prioritizing news feeds. The attractiveness of a post to a user depends on many complex contextual and temporal features of the post. For instance, the contents of the post, the responsiveness of a third user, and the age of the post may all have impact. So far, these static and dynamic features has not been incorporated in a unified framework to tackle the post prioritization problem. In this paper, we propose a novel approach for prioritizing posts based on a feature modulated multi-dimensional point process. Our model is able to simultaneously capture textual and sentiment features, and temporal features such as self-excitation, mutual-excitation and bursty nature of social interaction. As an evaluation, we also curated a real-world conversational benchmark dataset crawled from Facebook. In our experiments, we demonstrate that our algorithm is able to achieve the-stateof-the-art performance in terms of analyzing, predicting, and prioritizing events. In terms of interpretability of our method, we observe that features indicating individual user profile and linguistic characteristics of the events work best for prediction and prioritization of new events.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: EFFICIENT IMAGE CLASSIFICATION\nAbstract: We propose a new method for creating computationally efficient convolutional neural networks (CNNs) by using low-rank representations of convolutional filters. Rather than approximating filters in previously-trained networks with more efficient versions, we learn a set of small basis filters from scratch; during training, the network learns to combine these basis filters into more complex filters that are discriminative for image classification. To train such networks, a novel weight initialization scheme is used. This allows effective initialization of connection weights in convolutional layers composed of groups of differently-shaped filters. We validate our approach by applying it to several existing CNN architectures and training these networks from scratch using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or higher accuracy than conventional CNNs with much less compute. Applying our method to an improved version of VGG11 network using global max-pooling, we achieve comparable validation accuracy using 41% less compute and only 24% of the original VGG-11 model parameters; another variant of our method gives a 1 percentage point increase in accuracy over our improved VGG-11 model, giving a top-5 center-crop validation accuracy of 89.7% while reducing computation by 16% relative to the original VGG-11 model. Applying our method to the GoogLeNet architecture for ILSVRC, we achieved comparable accuracy with 26% less compute and 41% fewer model parameters. Applying our method to a near state-of-the-art network for CIFAR, we achieved comparable accuracy with 46% less compute and 55% fewer parameters.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards\nAbstract: Ground vehicles equipped with monocular vision systems are a valuable source of high resolution image data for precision agriculture applications in orchards. This paper presents an image processing framework for fruit detection and counting using orchard image data. A general purpose image segmentation approach is used, including two feature learning algorithms; multi-scale Multi-Layered Perceptrons (MLP) and Convolutional Neural Networks (CNN). These networks were extended by including contextual information about how the image data was captured (metadata), which correlates with some of the appearance variations and/or class distributions observed in the data. The pixel-wise fruit segmentation output is processed using the Watershed Segmentation (WS) and Circular Hough Transform (CHT) algorithms to detect and count individual fruits. Experiments were conducted in a commercial apple orchard near Melbourne, Australia. The results show an improvement in fruit segmentation performance with the inclusion of metadata on the previously benchmarked MLP network. We extend this work with CNNs, bringing agrovision closer to the state-of-the-art in computer vision, where although metadata had negligible influence, the best pixel-wise F1-score of 0.791 was achieved. The WS algorithm produced the best apple detection and counting results, with a detection F1-score of 0.858. As a final step, image fruit counts were accumulated over multiple rows at the orchard and compared against the post-harvest fruit counts that were obtained from a grading and counting machine. The count estimates using CNN and WS resulted in the best performance for this dataset, with a squared correlation coefficient of r = 0.826.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Safe Reinforcement Learning via Shielding\nAbstract: Reinforcement learning algorithms discover policies that maximize reward, but do not necessarily guarantee safety during learning or execution phases. We introduce a new approach to learn optimal policies while enforcing properties expressed in temporal logic. To this end, given the temporal logic specification that is to be obeyed by the learning system, we propose to synthesize a reactive system called a shield. The shield is introduced in the traditional learning process in two alternative ways, depending on the location at which the shield is implemented. In the first one, the shield acts each time the learning agent is about to make a decision and provides a list of safe actions. In the second way, the shield is introduced after the learning agent. The shield monitors the actions from the learner and corrects them only if the chosen action causes a violation of the specification. We discuss which requirements a shield must meet to preserve the convergence guarantees of the learner. Finally, we demonstrate the versatility of our approach on several challenging reinforcement learning scenarios.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Manifold learning methods are useful for high dimensional data analysis. Many of the existing methods produce a low dimensional representation that attempts to describe the intrinsic geometric structure of the original data. Typically, this process is computationally expensive and the produced embedding is limited to the training data. In many real life scenarios, the ability to produce embedding of unseen samples is essential. In this paper we propose a Bayesian non-parametric approach for out-of-sample extension. The method is based on Gaussian Process Regression and independent of the manifold learning algorithm. Additionally, the method naturally provides a measure for the degree of abnormality for a newly arrived data point that did not participate in the training process. We derive the mathematical connection between the proposed method and the Nystrom extension and show that the latter is a special case of the former. We present extensive experimental results that demonstrate the performance of the proposed method and compare it to other existing out-of-sample extension methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Clustering to extract Personality Information from socio economic data\nAbstract: It has become apparent that models that have been applied widely in economics, including Machine Learning techniques and Data Mining methods, should take into consideration principles that derive from the theories of Personality Psychology in order to discover more comprehensive knowledge regarding complicated economic behaviours. In this work, we present a method to extract Behavioural Groups by using simple clustering techniques that can potentially reveal aspects of the Personalities for their members. We believe that this is very important because the psychological information regarding the Personalities of individuals is limited in real world applications and because it can become a useful tool in improving the traditional models of Knowledge Economy. Keywords-component; Data Mining; Clustering; Behavior Mining; Personality Psychology;\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: One-shot Learning with Memory-Augmented Neural Networks\nAbstract: Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \u201cone-shot learning.\u201d Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Stochastic Algorithms for SVD and PCA: Convergence Properties and Convexity\nAbstract: We study the convergence properties of the VR-PCA algorithm introduced by [19] for fast computation of leading singular vectors. We prove several new results, including a formal analysis of a block version of the algorithm, and convergence from random initialization. We also make a few observations of independent interest, such as how pre-initializing with just a single exact power iteration can significantly improve the runtime of stochastic methods, and what are the convexity and non-convexity properties of the underlying optimization problem.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Contrastive Feature Induction for Efficient Structure Learning of Conditional Random Fields\nAbstract: Structure learning of Conditional Random Fields (CRFs) can be cast into L1-regularized optimization problems, which can be solved by efficient gradient-based optimization methods. However, optimizing a fully linked model may require inference on dense graphs which can be time prohibitive and inaccurate. Gain-based or gradient-based feature selection methods avoid this problem by starting from an empty model and incrementally adding top ranked features to it. However, training time with these incremental methods can be dominated by the cost of evaluating the gain or gradient of candidate features for high-dimensional problems. In this study we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI) based on Mean Field Contrastive Divergence (CD MF ). CFI only evaluates a subset of features which involve variables with high signals (deviation from mean) or errors (prediction residue). We prove that the gradient of candidate features can be represented solely as a function of signals and errors, and that CFI is an efficient approximation of gradient-based evaluation methods. Experiments on synthetic and real datasets show competitive learning speed and accuracy of CFI on pairwise CRFs, compared to state-of-the-art structure learning methods such as full optimization over all features, and Grafting. More interestingly, CFI is not only faster than other methods but also produces models with higher prediction accuracy by focusing on large prediction errors during induction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards a learning-theoretic analysis of spike-timing dependent plasticity\nAbstract: This paper suggests a learning-theoretic perspective on how synaptic plasticity benefits global brain functioning. We introduce a model, the selectron, that (i) arises as the fast time constant limit of leaky integrate-and-fire neurons equipped with spiking timing dependent plasticity (STDP) and (ii) is amenable to theoretical analysis. We show that the selectron encodes reward estimates into spikes and that an error bound on spikes is controlled by a spiking margin and the sum of synaptic weights. Moreover, the efficacy of spikes (their usefulness to other reward maximizing selectrons) also depends on total synaptic strength. Finally, based on our analysis, we propose a regularized version of STDP, and show the regularization improves the robustness of neuronal learning when faced with multiple stimuli.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Thresholding based Efficient Outlier Robust PCA\nAbstract: We consider the problem of outlier robust PCA (OR-PCA) where the goal is to recover principal<lb>directions despite the presence of outlier data points. That is, given a data matrix M\u2217, where (1 \u2212 \u03b1)<lb>fraction of the points are noisy samples from a low-dimensional subspace while \u03b1 fraction of the points can<lb>be arbitrary outliers, the goal is to recover the subspace accurately. Existing results for OR-PCA have<lb>serious drawbacks: while some results are quite weak in the presence of noise, other results have runtime<lb>quadratic in dimension, rendering them impractical for large scale applications.<lb>In this work, we provide a novel thresholding based iterative algorithm with per-iteration complexity<lb>at most linear in the data size. Moreover, the fraction of outliers, \u03b1, that our method can handle is tight<lb>up to constants while providing nearly optimal computational complexity for a general noise setting. For<lb>the special case where the inliers are obtained from a low-dimensional subspace with additive Gaussian<lb>noise, we show that a modification of our thresholding based method leads to significant improvement<lb>in recovery error (of the subspace) even in the presence of a large fraction of outliers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On The Direct Maximization of Quadratic Weighted Kappa\nAbstract: In recent years, quadratic weighted kappa has been growing in popularity in the machine learning community as an evaluation metric in domains where the target labels to be predicted are drawn from integer ratings, usually obtained from human experts. For example, it was the metric of choice in several recent, high profile machine learning contests hosted on Kaggle : www.kaggle.com/c/asap-aes , www.kaggle.com/c/asap-sas , www.kaggle.com/c/diabeticretinopathy-detection . Yet, little is understood about the nature of this metric, its underlying mathematical properties, where it fits among other common evaluation metrics such as mean squared error (MSE) and correlation, or if it can be optimized analytically, and if so, how. Much of this is due to the cumbersome way that this metric is commonly defined. In this paper we first derive an equivalent but much simpler, and more useful, definition for quadratic weighted kappa, and then employ this alternate form to address the above issues. 1. Preliminaries Although first developed in the statistical community as a measure of inter-rater agreement, \u03ba has more recently become a popular performance metric in supervised machine learning, specifically in situations where the target (dependent) variable y is a discrete, interval variable (usually drawn from non-negative integers) such as is common in most human rating scales (e.g.\u201con a scale from 1 to 10\u201d). This differs from the ordinal regression setting, where there only exists an ordering over labels, but no intrinsic or constant length interval between them. Some have argued that the use of quadratic weighted kappa as a metric in the domain of human ratings imposes the erroneous assumption of \u201cequal intervals\u201d where there should be none (how this assumption is expressed in the metric itself will be made clear in the following section). For example, when rating student essays on a scale from 1 to 5, the difference between a 1 and a 2 may not be equal to the difference between a 4 and a 5. While this may or may not be true in certain cases, we will not be concerned with that here. 1.1. Standard Definition Quadratic weighted kappa, which we write \u03ba to distinguish from linear weighted kappa, was originally developed as a measure of inter-rater agreement. In this scenario, there are two raters, A and B, each associated with a vector of n integer ratings a,b \u2208 Ln\u00d71 where L = {1, 2, \u00b7 \u00b7 \u00b7 , `} is a finite set of ` possible values. We seek to quantify the level of agreement between a and b. In order to compute \u03ba(a,b), it is customary to start by computing frequency tables. The observed confusion matrix U = (ui,j) \u2208 N`\u00d7` is first computed as:\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We study exploration in Multi-Armed Bandits in a setting where k players collaborate in order to identify an \u03b5-optimal arm. Our motivation comes from recent employment of bandit algorithms in computationally intensive, large-scale applications. Our results demonstrate a non-trivial tradeoff between the number of arm pulls required by each of the players, and the amount of communication between them. In particular, our main result shows that by allowing the k players to communicate only once, they are able to learn \u221a k times faster than a single player. That is, distributing learning to k players gives rise to a factor \u221a k parallel speed-up. We complement this result with a lower bound showing this is in general the best possible. On the other extreme, we present an algorithm that achieves the ideal factor k speed-up in learning performance, with communication only logarithmic in 1/\u03b5.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Human Intellect and Machine Failures: Troubleshooting Integrative Machine Learning Systems\nAbstract: We study the problem of troubleshooting machine learning systems that rely on analytical pipelines of distinct components. Understanding and fixing errors that arise in such integrative systems is difficult as failures can occur at multiple points in the execution workflow. Moreover, errors can propagate, become amplified or be suppressed, making blame assignment difficult. We propose a human-in-the-loop methodology which leverages human intellect for troubleshooting system failures. The approach simulates potential component fixes through human computation tasks and measures the expected improvements in the holistic behavior of the system. The method provides guidance to designers about how they can best improve the system. We demonstrate the effectiveness of the approach on an automated image captioning system that has been pressed into real-world use.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Efficient Structured Sparse Models\nAbstract: We present a comprehensive framework for structured sparse coding and modeling extending the recent ideas of using learnable fast regressors to approximate exact sparse codes. For this purpose, we propose an efficient feed forward architecture derived from the iteration of the block-coordinate algorithm. This architecture approximates the exact structured sparse codes with a fraction of the complexity of the standard optimization methods. We also show that by using different training objective functions, the proposed learnable sparse encoders are not only restricted to be approximants of the exact sparse code for a pre-given dictionary, but can be rather used as full-featured sparse encoders or even modelers. A simple implementation shows several orders of magnitude speedup compared to the state-of-the-art exact optimization algorithms at minimal performance degradation, making the proposed framework suitable for real time and largescale applications.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Communication Lower Bounds for Distributed Convex Optimization: Partition Data on Features\nAbstract: Recently, there has been an increasing interest in designing distributed convex optimization algorithms under the setting where the data matrix is partitioned on features. Algorithms under this setting sometimes have many advantages over those under the setting where data is partitioned on samples, especially when the number of features is huge. Therefore, it is important to understand the inherent limitations of these optimization problems. In this paper, with certain restrictions on the communication allowed in the procedures, we develop tight lower bounds on communication rounds for a broad class of non-incremental algorithms under this setting. We also provide a lower bound on communication rounds for a class of (randomized) incremental algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Sequence Component Analysis for Attack Detection in Synchrophasor Networks\nAbstract: Modern power systems have begun integrating synchrophasor technologies into part of daily operations. Given the amount of solutions offered and the maturity rate of application development it is not a matter of \u201cif\u201d but a matter of \u201cwhen\u201d in regards to these technologies becoming ubiquitous in control centers around the world. While the benefits are numerous, the functionality of operator-level applications can easily be nullified by injection of deceptive data signals disguised as genuine measurements. Such deceptive action is a common precursor to nefarious, often malicious activity. A correlation coefficient characterization and machine learning methodology are proposed to detect and identify injection of spoofed data signals. The proposed method utilizes statistical relationships intrinsic to power system parameters, which are quantified and presented. Several spoofing schemes have been developed to qualitatively and quantitatively demonstrate detection capabilities. Keywords\u2014spoofing, phasor measurement unit, PMU, correlation, event detection, support vector machine.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We construct a universal prediction system in the spirit of Popper\u2019s falsifiability and Kolmogorov complexity. This prediction system does not depend on any statistical assumptions, but under the IID assumption it dominates, although in a rather weak sense, conformal prediction. Not for nothing do we call the laws of nature \u201claws\u201d: the more they prohibit, the more they say. The Logic of Scientific Discovery Karl Popper\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Large-scale deep neural networks (DNN) have been successfully used in a number of tasks from image recognition to natural language processing. They are trained using large training sets on large models, making them computationally and memory intensive. As such, there is much interest in research development for faster training and test time. In this paper, we present a unique approach using lower precision weights for more efficient and faster training phase. We separate imagery into different frequency bands (e.g. with different information content) such that the neural net can better learn using less bits. We present this approach as a complement existing methods such as pruning network connections and encoding learning weights. We show results where this approach supports more stable learning with 2-4X reduction in precision with 17X reduction in DNN parameters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequential Update of Bayesian Network Structure\nAbstract: There is an obvious need for improving the per\u00ad formance and accuracy of a Bayesian network as new data is observed. Because of errors in model construction and changes in the dynamics of the domains, we cannot afford to ignore the infor\u00ad mation in new data. While sequential update of parameters for a fixed structure can be accom\u00ad plished using standard techniques, sequential up\u00ad date of network structure is still an open problem. In this paper, we investigate sequential update of Bayesian networks were both parameters and structure are expected to change. We introduce a new approach that allows for the flexible ma\u00ad nipulation of the tradeoff between the quality of the learned networks and the amount of informa\u00ad tion that is maintained about past observations. We formally describe our approach including the necessary modifications to the scoring functions for learning Bayesian networks, evaluate its effec\u00ad tiveness through and empirical study, and extend it to the case of missing data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Sparse Subspace Clustering (SSC) has achieved state-of-the-art clustering quality by performing spectral clustering over a l-norm based similarity graph. However, SSC is a transductive method which does not handle with the data not used to construct the graph (out-of-sample data). For each new datum, SSC requires solving n optimization problems in O(n) variables for performing the algorithm over the whole data set, where n is the number of data points. Therefore, it is inefficient to apply SSC in fast online clustering and scalable graphing. In this letter, we propose an inductive spectral clustering algorithm, called inductive Sparse Subspace Clustering (iSSC), which makes SSC feasible to cluster outof-sample data. iSSC adopts the assumption that high-dimensional data actually lie on the low-dimensional manifold such that out-of-sample data could be grouped in the embedding space learned from in-sample data. Experimental results show that iSSC is promising in clustering out-ofsample data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-relational Learning Using Weighted Tensor Decomposition with Modular Loss\nAbstract: We propose a modular framework for multirelational learning via tensor decomposition. In our learning setting, the training data contains multiple types of relationships among a set of objects, which we represent by a sparse three-mode tensor. The goal is to predict the values of the missing entries. To do so, we model each relationship as a function of a linear combination of latent factors. We learn this latent representation by computing a low-rank tensor decomposition, using quasi-Newton optimization of a weighted objective function. Sparsity in the observed data is captured by the weighted objective, leading to improved accuracy when training data is limited. Exploiting sparsity also improves efficiency, potentially up to an order of magnitude over unweighted approaches. In addition, our framework accommodates arbitrary combinations of smooth, task-specific loss functions, making it better suited for learning different types of relations. For the typical cases of real-valued functions and binary relations, we propose several loss functions and derive the associated parameter gradients. We evaluate our method on synthetic and real data, showing significant improvements in both accuracy and scalability over related factorization techniques.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Data Generation as Sequential Decision Making\nAbstract: We connect a broad class of generative models through their shared reliance on sequential decision making. We show how changes motivated by our point of view can improve an already-strong model, and then explore this idea further in the context of data imputation \u2013 perhaps the simplest setting in which to investigate the relation between unconditional and conditional generative modelling. We formulate data imputation as an MDP and develop models capable of representing effective policies for it. We construct our models using neural networks and train them using a form of guided policy search [9]. Through empirical tests, we show that our approach can learn effective policies for imputation problems of varying difficulty and across multiple datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Autoregressive Distribution Estimation\nAbstract: We present Neural Autoregressive Distribution Estimation (NADE) models, which are neural network architectures applied to the problem of unsupervised distribution and density estimation. They leverage the probability product rule and a weight sharing scheme inspired from restricted Boltzmann machines, to yield an estimator that is both tractable and has good generalization performance. We discuss how they achieve competitive performance in modeling both binary and real-valued observations. We also present how deep NADE models can be trained to be agnostic to the ordering of input dimensions used by the autoregressive product rule decomposition. Finally, we also show how to exploit the topological structure of pixels in images using a deep convolutional architecture for NADE.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Renewable Energy Prediction using Weather Forecasts for Optimal Scheduling in HPC Systems\nAbstract: The objective of the GreenPAD project is to use green energy to power data-centers. As a part of this it is important to predict the Wind energy for efficient scheduling (executing jobs that require higher energy when there is more green energy available and vice-versa). For predicting the wind energy we first analyze the historical data to find a statistical model that gives relation between wind energy and weather attributes. Then we use this model on the weather forecast data to predict the green energy availability in the future.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalised Random Forest Space Overview\nAbstract: Assuming a view of the Random Forest as a special case of a nested ensemble of interchangeable modules, we construct a generalisation space allowing one to easily develop novel methods based on this algorithm. We discuss the role and required properties of modules at each level, especially in context of some already proposed RF generalisations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Supervised cross-modal factor analysis\nAbstract: In this paper we study the problem of learning from multiple modal data for purpose of document classification. In this problem, each document is composed two different modals of data, i.e., an image and a text. Cross-modal factor analysis (CFA) has been proposed to project the two different modals of data to a shared data space, so that the classification of a image or a text can be performed directly in this space. A disadvantage of CFA is that it has ignored the supervision information. In this paper, we improve CFA by incorporating the supervision information to represent and classify both image and text modals of documents. We project both image and text data to a shared data space by factor analysis, and then train a class label predictor in the shared space to use the class label information. The factor analysis parameter and the predictor parameter are learned jointly by solving one single objective function. With this objective function, we minimize the distance between the projections of image and text of the same document, and the classification error of the projection measured by hinge loss function. The objective function is optimized by an alternate optimization strategy in an iterative algorithm. Experiments in two different multiple modal document data sets show the advantage of the proposed algorithm over other CFA methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sparse Learning for Large-scale and High-dimensional Data: A Randomized Convex-concave Optimization Approach\nAbstract: In this paper, we develop a randomized algorithm and theory for learning a sparse model from large-scale and high-dimensional data, which is usually formulated as an empirical risk minimization problem with a sparsity-inducing regularizer. Under the assumption that there exists a (approximately) sparse solution with high classification accuracy, we argue that the dual solution is also sparse or approximately sparse. The fact that both primal and dual solutions are sparse motivates us to develop a randomized approach for a general convex-concave optimization problem. Specifically, the proposed approach combines the strength of random projection with that of sparse learning: it utilizes random projection to reduce the dimensionality, and introduces l1-norm regularization to alleviate the approximation error caused by random projection. Theoretical analysis shows that under favored conditions, the randomized algorithm can accurately recover the optimal solutions to the convex-concave optimization problem (i.e., recover both the primal and dual solutions). Furthermore, the solutions returned by our algorithm are guaranteed to be approximately sparse.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Gaussian Quadrature for Kernel Features\nAbstract: Kernel methods have recently attracted resurgent interest, matching the performance of deep neural networks in tasks such as speech recognition. The random Fourier features map is a technique commonly used to scale up kernel machines, but employing the randomized feature map means that O(\u01eb) samples are required to achieve an approximation error of at most \u01eb. In this paper, we investigate some alternative schemes for constructing feature maps that are deterministic, rather than random, by approximating the kernel in the frequency domain using Gaussian quadrature. We show that deterministic feature maps can be constructed, for any \u03b3 > 0, to achieve error \u01eb with O(e + \u01eb) samples as \u01eb goes to 0. We validate our methods on datasets in different domains, such as MNIST and TIMIT, showing that deterministic features are faster to generate and achieve comparable accuracy to the state-of-the-art kernel methods based on random Fourier features.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: jsCoq: Towards Hybrid Theorem Proving Interfaces\nAbstract: We describe jsCoq, a new platform and user environment for the Coq interactive proof assistant. The jsCoq system targets the HTML5\u2013ECMAScript 2015 specification, and it is typically run inside a standards-compliant browser, without the need of external servers or services. Targeting educational use, jsCoq allows the user to start interaction with proof scripts right away, thanks to its self-contained nature. Indeed, a full Coq environment is packed along the proof scripts, easing distribution and installation. Starting to use jsCoq is as easy as clicking on a link. The current release ships more than 10 popular Coq libraries, and supports popular books such as Software Foundations or Certified Programming with Dependent Types. The new target platform has opened up new interaction and display possibilities. It has also fostered the development of some new Coq-related technology. In particular, we have implemented a new serialization-based protocol for interaction with the proof assistant, as well as a new package format for library distribution.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Diffusion-Convolutional Neural Networks\nAbstract: We present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data. Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graphstructured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on the GPU. Through several experiments with real structured datasets, we demonstrate that DCNNs are able to outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Steps Toward Deep Kernel Methods from Infinite Neural Networks\nAbstract: Contemporary deep neural networks exhibit impressive results on practical problems. These networks generalize well although their inherent capacity may extend significantly beyond the number of training examples. We analyze this behavior in the context of deep, infinite neural networks. We show that deep infinite layers are naturally aligned with Gaussian processes and kernel methods, and devise stochastic kernels that encode the information of these networks. We show that stability results apply despite the size, offering an explanation for their empir-\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Spacetime Approach to Generalized Cognitive Reasoning in Multi-scale Learning\nAbstract: In modern machine learning, pattern recognition replaces realtime semantic reasoning. The mapping from input to output is learned with fixed semantics by training outcomes deliberately. This is an expensive and static approach which depends heavily on the availability of a very particular kind of prior training data to make inferences in a single step. Conventional semantic network approaches, on the other hand, base multi-step reasoning on modal logics and handcrafted ontologies, which are ad hoc, expensive to construct, and fragile to inconsistency. Both approaches may be enhanced by a hybrid approach, which completely separates reasoning from pattern recognition. In this report, a quasi-linguistic approach to knowledge representation is discussed, motivated by spacetime structure. Tokenized patterns from diverse sources are integrated to build a lightly constrained and approximately scale-free network. This is then be parsed with very simple recursive algorithms to generate \u2018brainstorming\u2019 sets of reasoned knowledge.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DYVEDEEP: DYNAMIC VARIABLE EFFORT DEEP NEURAL NETWORKS\nAbstract: Deep Neural Networks (DNNs) have advanced the state-of-the-art in a variety of machine learning tasks and are deployed in increasing numbers of products and services. However, the computational requirements of training and evaluating large-scale DNNs are growing at a much faster pace than the capabilities of the underlying hardware platforms that they are executed upon. In this work, we propose Dynamic Variable Effort Deep Neural Networks (DyVEDeep) to reduce the computational requirements of DNNs during inference. Previous efforts propose specialized hardware implementations for DNNs, statically prune the network, or compress the weights. Complementary to these approaches, DyVEDeep is a dynamic approach that exploits the heterogeneity in the inputs to DNNs to improve their compute efficiency with comparable classification accuracy. DyVEDeep equips DNNs with dynamic effort mechanisms that, in the course of processing an input, identify how critical a group of computations are to classify the input. DyVEDeep dynamically focuses its compute effort only on the critical computations, while skipping or approximating the rest. We propose 3 effort knobs that operate at different levels of granularity viz. neuron, feature and layer levels. We build DyVEDeep versions for 5 popular image recognition benchmarks \u2014 one for CIFAR-10 and four for ImageNet (AlexNet, OverFeat and VGG-16, weightcompressed AlexNet). Across all benchmarks, DyVEDeep achieves 2.1\u00d7-2.6\u00d7 reduction in the number of scalar operations, which translates to 1.8\u00d7-2.3\u00d7 performance improvement over a Caffe-based implementation, with < 0.5% loss in accuracy.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Hyperparameter Optimization for Ensemble Learning\nAbstract: In this paper, we bridge the gap between hyperparameter optimization and ensemble learning by performing Bayesian optimization of an ensemble with regards to its hyperparameters. Our method consists in building a fixed-size ensemble, optimizing the configuration of one classifier of the ensemble at each iteration of the hyperparameter optimization algorithm, taking into consideration the interaction with the other models when evaluating potential performances. We also consider the case where the ensemble is to be reconstructed at the end of the hyperparameter optimization phase, through a greedy selection over the pool of models generated during the optimization. We study the performance of our proposed method on three different hyperparameter spaces, showing that our approach is better than both the best single model and a greedy ensemble construction over the models produced by a standard Bayesian optimization.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Brain-Inspired Deep Networks for Image Aesthetics Assessment\nAbstract: Image aesthetics assessment has been challenging due to its subjective nature. Being extensively inspired by the scientific advances in the human visual perception and neuroaesthetics, we design the Brain-Inspired Deep Networks (BDN) for this task. BDN first learns attributes through the parallel supervised pathways, on a variety of selected feature dimensions. A high-level synthesis network is trained to associate and transform those attributes into the overall aesthetics rating. We then extend BDN to predicting the distribution of human ratings, since aesthetics ratings often vary somewhat from observer to observer. Another highlight is our first-of-its-kind study of label-preserving transformations in the context of aesthetics assessment, which leads to effective data augmentation approaches. Experimental results on the AVA dataset show that our biological inspired, task-specific BDN model leads to significantly improved performances, compared to other state-of-the-art models with the same or higher parameter capacity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Deep and Autoregressive Approach for Topic Modeling of Multimodal Data\nAbstract: Topic modeling based on latent Dirichlet allocation (LDA) has been a framework of choice to deal with multimodal data, such as in image annotation tasks. Another popular approach to model the multimodal data is through deep neural networks, such as the deep Boltzmann machine (DBM). Recently, a new type of topic model called the Document Neural Autoregressive Distribution Estimator (DocNADE) was proposed and demonstrated state-of-theart performance for text document modeling. In this work, we show how to successfully apply and extend this model to multimodal data, such as simultaneous image classification and annotation. First, we propose SupDocNADE, a supervised extension of DocNADE, that increases the discriminative power of the learned hidden topic features and show how to employ it to learn a joint representation from image visual words, annotation words and class label information. We test our model on the LabelMe and UIUC-Sports data sets and show that it compares favorably to other topic models. Second, we propose a deep extension of our model and provide an efficient way of training the deep model. Experimental results show that our deep model outperforms its shallow version and reaches state-of-the-art performance on the Multimedia Information Retrieval (MIR) Flickr data set.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Evaluation of Machine Learning Methods to Predict Coronary Artery Disease Using Metabolomic Data\nAbstract: Metabolomic data can potentially enable accurate, non-invasive and lowcost prediction of coronary artery disease. Regression-based analytical approaches however might fail to fully account for interactions between metabolites, rely on a priori selected input features and thus might suffer from poorer accuracy. Supervised machine learning methods can potentially be used in order to fully exploit the dimensionality and richness of the data. In this paper, we systematically implement and evaluate a set of supervised learning methods (L1 regression, random forest classifier) and compare them to traditional regression-based approaches for disease prediction using metabolomic data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We consider a recent innovative theory by Chastain et al. on the role of sex in evolution [Chastain et al., 2014]. In short, the theory suggests that the evolutionary process of gene recombination implements the celebrated multiplicative weights updates algorithm (MWUA). They prove that the population dynamics induced by sexual reproduction can be precisely modeled by genes that use MWUA as their learning strategy in a particular coordination game. The result holds in the environments of weak selection, under the assumption that the population frequencies remain a product distribution. We revisit the theory, eliminating both the requirement of weak selection and any assumption on the distribution of the population. Removing the assumption of product distributions is crucial, since as we show, this assumption is inconsistent with the population dynamics. We show that the marginal allele distributions induced by the population dynamics precisely match the marginals induced by a multiplicative weights update algorithm in this general setting, thereby affirming and substantially generalizing these earlier results. We further revise the implications for convergence and utility or fitness guarantees in coordination games. In contrast to the claim of Chastain et al. [2014], we conclude that the sexual evolutionary dynamics does not entail any property of the population distribution, beyond those already implied by convergence.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Approximation Guarantees for Greedy Low Rank Optimization\nAbstract: <lb>We provide new approximation guarantees for greedy low rank matrix estimation under standard assumptions<lb>of restricted strong convexity and smoothness. Our novel analysis also uncovers previously unknown connections<lb>between the low rank estimation and combinatorial optimization, so much so that our bounds are reminiscent of<lb>corresponding approximation bounds in submodular maximization. Additionally, we also provide statistical recovery<lb>guarantees. Finally, we present empirical comparison of greedy estimation with established baselines on two important<lb>real-world problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to Rank Scientific Documents from the Crowd\nAbstract: Motivation: Finding related published articles is an important task in any science, but with the explosion of new work in the biomedical domain it has become especially challenging. Most existing methodologies use text similarity metrics to identify whether two articles are related or not. However biomedical knowledge discovery is hypothesis-driven. The most related articles may not be ones with the highest text similarities. In this study, we first develop an innovative crowd-sourcing approach to build an expert-annotated document-ranking corpus. Using this corpus as the gold standard, we then evaluate the approaches of using text similarity to rank the relatedness of articles. Finally, we develop and evaluate a new supervised model to automatically rank related scientific articles. Results: Our results show that authors\u2019 ranking differ significantly from rankings by textsimilarity-based models. By training a learning-to-rank model on a subset of the annotated corpus, we found the best supervised learning-to-rank model (SVM) significantly surpassed state-of-the-art baseline systems. Availability: Code and data are both publicly available. \u2020\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Reinforcement Learning for Visual Object Tracking in Videos\nAbstract: Convolutional neural network (CNN) models have achieved tremendous success in many visual detection and recognition tasks. Unfortunately, visual tracking, a fundamental computer vision problem, is not handled well using the existing CNN models, because most object trackers implemented with CNN do not effectively leverage temporal and contextual information among consecutive frames. Recurrent neural network (RNN) models, on the other hand, are often used to process text and voice data due to their ability to learn intrinsic representations of sequential and temporal data. Here, we propose a novel neural network tracking model that is capable of integrating information over time and tracking a selected target in video. It comprises three components: a CNN extracting best tracking features in each video frame, an RNN constructing video memory state, and a reinforcement learning (RL) agent making target location decisions. The tracking problem is formulated as a decision-making process, and our model can be trained with RL algorithms to learn good tracking policies that pay attention to continuous, inter-frame correlation and maximize tracking performance in the long run. We compare our model with an existing neural-network based tracking method and show that the proposed tracking approach works well in various scenarios by performing rigorous validation experiments on artificial video sequences with ground truth. To the best of our knowledge, our tracker is the first neural-network tracker that combines convolutional and recurrent networks with RL algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Regularized Discriminant Embedding for Visual Descriptor Learning\nAbstract: Images can vary according to changes in viewpoint, resolution, noise, and illumination. In this paper, we aim to learn representations for an image, which are robust to wide changes in such environmental conditions, using training pairs of matching and non-matching local image patches that are collected under various environmental conditions. We present a regularized discriminant analysis that emphasizes two challenging categories among the given training pairs: (1) matching, but far apart pairs and (2) non-matching, but close pairs in the original feature space (e.g., SIFT feature space). Compared to existing work on metric learning and discriminant analysis, our method can better distinguish relevant images from irrelevant, but look-alike images.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MANIFOLD REGULARIZED DISCRIMINATIVE NEURAL NETWORKS\nAbstract: Unregularized deep neural networks (DNNs) can be easily overfit with a limited sample size. We argue that this is mostly due to the disriminative nature of DNNs which directly model the conditional probability (or score) of labels given the input. The ignorance of input distribution makes DNNs difficult to generalize to unseen data. Recent advances in regularization techniques, such as pretraining and dropout, indicate that modeling input data distribution (either explicitly or implicitly) greatly improves the generalization ability of a DNN. In this work, we explore the manifold hypothesis which assumes that instances within the same class lie in a smooth manifold. We accordingly propose two simple regularizers to a standard discriminative DNN. The first one, named Label-Aware Manifold Regularization, assumes the availability of labels and penalizes large norms of the loss function w.r.t. data points. The second one, named Label-Independent Manifold Regularization, does not use label information and instead penalizes the Frobenius norm of the Jacobian matrix of prediction scores w.r.t. data points, which makes semi-supervised learning possible. We perform extensive control experiments on fully supervised and semi-supervised tasks using the MNIST, CIFAR10 and SVHN datasets and achieve excellent results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Optimal Cluster Recovery in the Labeled Stochastic Block Model\nAbstract: We consider the problem of community detection or clustering in the labeled Stochastic Block Model (LSBM) with a finite number K of clusters of sizes linearly growing with the global population of items n. Every pair of items is labeled independently at random, and label l appears with probability p(i, j, l) between two items in clusters indexed by i and j, respectively. The objective is to reconstruct the clusters from the observation of these random labels. Clustering under the SBM and their extensions has attracted much attention recently. Most existing work aimed at characterizing the set of parameters such that it is possible to infer clusters either positively correlated with the true clusters, or with a vanishing proportion of misclassified items, or exactly matching the true clusters. We find the set of parameters such that there exists a clustering algorithm with at most s misclassified items in average under the general LSBM and for any s = o(n), which solves one open problem raised in [2]. We further develop an algorithm, based on simple spectral methods, that achieves this fundamental performance limit within O(npolylog(n)) computations and without the a-priori knowledge of the model parameters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Independently Controllable Features\nAbstract: Finding features that disentangle the different causes of variation in real data is a difficult task, that has nonetheless received considerable attention in static domains like natural images. Interactive environments, in which an agent can deliberately take actions, offer an opportunity to tackle this task better, because the agent can experiment with different actions and observe their effects. We introduce the idea that in interactive environments, latent factors that control the variation in observed data can be identified by figuring out what the agent can control. We propose a naive method to find factors that explain or measure the effect of the actions of a learner, and test it in illustrative experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Provably Good Early Detection of Diseases using Non-Sparse Covariance-Regularized Linear Discriminant Analysis\nAbstract: To improve the performance of Linear Discriminant Analysis (LDA) for early detection of diseases using Electronic Health Records (EHR) data, we propose ED \u2013 a novel framework for EHR based Early Detection of Diseases on top of Covariance-Regularized LDA models. Specifically, ED employs a non-sparse inverse covariance matrix (or namely precision matrix) estimator derived from graphical lasso and incorporates the estimator into LDA classifiers to improve classification accuracy. Theoretical analysis on ED shows that it can bound the expected error rate of LDA classification, under certain assumptions. Finally, we conducted extensive experiments using a large-scale realworld EHR dataset \u2013 CHSN. We compared our solution with other regularized LDA and downstream classifiers. The result shows ED outperforms all baselines and backups our theoretical analysis.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SoK: Applying Machine Learning in Security - A Survey\nAbstract: The idea of applying machine learning(ML) to solve prob-<lb>lems in security domains is almost 3 decades old. As infor-<lb>mation and communications grow more ubiquitous and more<lb>data become available, many security risks arise as well as<lb>appetite to manage and mitigate such risks. Consequently,<lb>research on applying and designing ML algorithms and sys-<lb>tems for security has grown fast, ranging from intrusion de-<lb>tection systems(IDS) and malware classification to security<lb>policy management(SPM) and information leak checking. In this paper, we systematically study the methods, algorithms, and system designs in academic publications from 2008-2015 that applied ML in security domains. 98% of the surveyed papers appeared in the 6 highest-ranked academic<lb>security conferences and 1 conference known for pioneering<lb>ML applications in security. We examine the generalized<lb>system designs, underlying assumptions, measurements, and<lb>use cases in active research. Our examinations lead to 1) a<lb>taxonomy on ML paradigms and security domains for future exploration and exploitation, and 2) an agenda detailing open and upcoming challenges. Based on our survey, we also suggest a point of view that treats security as a game theory problem instead of a batch-trained ML prob-<lb>lem.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Time-Series Classification Through Histograms of Symbolic Polynomials\nAbstract: Time-series classification has attracted considerable research attention due to the various domains where timeseries data are observed, ranging from medicine to econometrics. Traditionally, the focus of time-series classification has been on short time-series data composed of a unique pattern with intraclass pattern distortions and variations, while recently there have been attempts to focus on longer series composed of various local patterns. This study presents a novel method which can detect local patterns in long time-series via fitting local polynomial functions of arbitrary degrees. The coefficients of the polynomial functions are converted to symbolic words via equivolume discretizations of the coefficients\u2019 distributions. The symbolic polynomial words enable the detection of similar local patterns by assigning the same words to similar polynomials. Moreover, a histogram of the frequencies of the words is constructed from each time-series\u2019 bag of words. Each row of the histogram enables a new representation for the series and symbolize the existence of local patterns and their frequencies. Experimental evidence demonstrates outstanding results of our method compared to the state-of-art baselines, by exhibiting the best classification accuracies in all the datasets and having statistically significant improvements in the absolute majority of experiments.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stochastic Optimization of PCA with Capped MSG\nAbstract: We study PCA as a stochastic optimization problem and propose a novel stochastic approximation algorithm which we refer to as \u201cMatrix Stochastic Gradient\u201d (MSG), as well as a practical variant, Capped MSG. We study the method both theoretically and empirically.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent\nAbstract: Stochastic Gradient Descent (SGD) updates network parameters with a noisy gradient computed from a random batch, and each batch evenly updates the network once in an epoch. This model applies the same training effort to each batch, but it overlooks the fact that the gradient variance, induced by Sampling Bias and Intrinsic Image Difference, renders different training dynamics on batches. In this paper, we develop a new training strategy for SGD, referred to as Inconsistent Stochastic Gradient Descent (ISGD) to address this problem. The core concept of ISGD is the inconsistent training, which dynamically adjusts the training effort w.r.t the loss. ISGD models the training as a stochastic process that gradually reduces down the mean of batch\u2019s loss, and it utilizes a dynamic upper control limit to identify a large loss batch on the fly. Then, it solves a new subproblem on the identified batch to accelerate the training while avoiding drastic parameter changes. ISGD is straightforward, computationally efficient and without requiring auxiliary memories. A series of empirical evaluations on real world datasets and networks demonstrate the promising performance of inconsistent training.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Inductive Kernel Low-rank Decomposition with Priors: A Generalized Nystro\u0308m Method\nAbstract: Low-rank matrix decomposition has gained great popularity recently in scaling up kernel methods to large amounts of data. However, some limitations could prevent them from working effectively in certain domains. For example, many existing approaches are intrinsically unsupervised, which does not incorporate side information (e.g., class labels) to produce task specific decompositions; also, they typically work \u201ctransductively\u201d, i.e., the factorization does not generalize to new samples, so the complete factorization needs to be recomputed when new samples become available. To solve these problems, in this paper we propose an \u201cinductive\u201d-flavored method for low-rank kernel decomposition with priors. We achieve this by generalizing the Nystr\u00f6m method in a novel way. On the one hand, our approach employs a highly flexible, nonparametric structure that allows us to generalize the low-rank factors to arbitrarily new samples; on the other hand, it has linear time and space complexities, which can be orders of magnitudes faster than existing approaches and renders great efficiency in learning a low-rank kernel decomposiAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). tion. Empirical results demonstrate the efficacy and efficiency of the proposed method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Communication-efficient Algorithms for Distributed Stochastic Principal Component Analysis\nAbstract: We study the fundamental problem of Principal Component Analysis in a statistical distributed setting in which each machine out of m stores a sample of n points sampled i.i.d. from a single unknown distribution. We study algorithms for estimating the leading principal component of the population covariance matrix that are both communication-efficient and achieve estimation error of the order of the centralized ERM solution that uses all mn samples. On the negative side, we show that in contrast to results obtained for distributed estimation under convexity assumptions, for the PCA objective, simply averaging the local ERM solutions cannot guarantee error that is consistent with the centralized ERM. We show that this unfortunate phenomena can be remedied by performing a simple correction step which correlates between the individual solutions, and provides an estimator that is consistent with the centralized ERM for sufficiently-large n. We also introduce an iterative distributed algorithm that is applicable in any regime of n, which is based on distributed matrix-vector products. The algorithm gives significant acceleration in terms of communication rounds over previous distributed algorithms, in a wide regime of parameters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reducing the Model Order of Deep Neural Networks Using Information Theory\nAbstract: Deep neural networks are typically represented by a much larger number of parameters than shallow models, making them prohibitive for small footprint devices. Recent research shows that there is considerable redundancy in the parameter space of deep neural networks. In this paper, we propose a method to compress deep neural networks by using the Fisher Information metric, which we estimate through a stochastic optimization method that keeps track of secondorder information in the network. We first remove unimportant parameters and then use non-uniform fixed point quantization to assign more bits to parameters with higher Fisher Information estimates. We evaluate our method on a classification task with a convolutional neural network trained on the MNIST data set. Experimental results show that our method outperforms existing methods for both network pruning and quantization.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Restricted Boltzmann Networks\nAbstract: Building a good generative model for image has long been an important topic in computer vision and machine learning. Restricted Boltzmann machine (RBM) [5] is one of such models that is simple but powerful. However, its restricted form also has placed heavy constraints on the model\u2019s representation power and scalability. Many extensions have been invented based on RBM in order to produce deeper architectures with greater power. The most famous ones among them are deep belief network [6], which stacks multiple layer-wise pretrained RBMs to form a hybrid model, and deep Boltzmann machine [15], which allows connections between hidden units to form a multi-layer structure. In this paper, we present a new method to compose RBMs to form a multi-layer network style architecture and a training method that trains all layers/RBMs jointly. We call the resulted structure deep restricted Boltzmann network. We further explore the combination of convolutional RBM with the normal fully connected RBM, which is made trivial under our composition framework. Experiments show that our model can generate descent images and outperform the normal RBM significantly in terms of image quality and feature quality, without losing much efficiency for training.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Large-Scale Learning with Less RAM via Randomization\nAbstract: We reduce the memory footprint of popular large-scale online learning methods by projecting our weight vector onto a coarse discrete set using randomized rounding. Compared to standard 32-bit float encodings, this reduces RAM usage by more than 50% during training and by up to 95% when making predictions from a fixed model, with almost no loss in accuracy. We also show that randomized counting can be used to implement percoordinate learning rates, improving model quality with little additional RAM. We prove these memory-saving methods achieve regret guarantees similar to their exact variants. Empirical evaluation confirms excellent performance, dominating standard approaches across memory versus accuracy tradeoffs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Geometric Mean Metric Learning\nAbstract: We revisit the task of learning a Euclidean metric from data. We approach this problem from first principles and formulate it as a surprisingly simple optimization problem. Indeed, our formulation even admits a closed form solution. This solution possesses several very attractive properties: (i) an innate geometric appeal through the Riemannian geometry of positive definite matrices; (ii) ease of interpretability; and (iii) computational speed several orders of magnitude faster than the widely used LMNN and ITML methods. Furthermore, on standard benchmark datasets, our closed-form solution consistently attains higher classification accuracy.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MIN MAX GENERALIZATION FOR DETERMINISTIC BATCH MODE REINFORCEMENT LEARNING: RELAXATION SCHEMES\nAbstract: We study the min max optimization problem introduced in [22] for computing policies for batch mode reinforcement learning in a deterministic setting. First, we show that this problem is NP-hard. In the twostage case, we provide two relaxation schemes. The first relaxation scheme works by dropping some constraints in order to obtain a problem that is solvable in polynomial time. The second relaxation scheme, based on a Lagrangian relaxation where all constraints are dualized, leads to a conic quadratic programming problem. We also theoretically prove and empirically illustrate that both relaxation schemes provide better results than those given in [22].\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MetaGrad: Faster Convergence Without Curvature in Online Convex Optimization\nAbstract: In online convex optimization it is well known that objective functions with curvature are much easier than arbitrary convex functions. Here we show that the regret can be significantly reduced even without curvature, in cases where there is a stable optimum to converge to. More precisely, the regret of existing methods is determined by the norms of the encountered gradients, and matching worst-case performance lower bounds tell us that this cannot be improved uniformly. Yet we argue that this is a rather pessimistic assessment of the complexity of the problem. We introduce a new parameter-free algorithm, called MetaGrad, for which the gradient norms in the regret are scaled down by the distance to the (unknown) optimum. So when the optimum is reasonably stable over time, making the algorithm converge, this new scaling leads to orders of magnitude smaller regret even when the gradients themselves do not vanish. MetaGrad does not require any manual tuning, but instead tunes a learning rate parameter automatically for the data. Unlike all previous methods with provable guarantees, its learning rates are not monotonically decreasing over time, but instead are based on a novel aggregation technique. We provide two versions of MetaGrad. The first maintains a full covariance matrix to guarantee the sharpest bounds for problems where we can afford update time quadratic in the dimension. The second version maintains only the diagonal. Its linear cost in the dimension makes it suitable for large-scale problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Predicting user responses, such as click-through rate and conversion rate, are critical in many web applications including web search, personalised recommendation, and online advertising. Different from continuous raw features that we usually found in the image and audio domains, the input features in web space are always of multi-field and are mostly discrete and categorical while their dependencies are little known. Major user response prediction models have to either limit themselves to linear models or require manually building up high-order combination features. The former loses the ability of exploring feature interactions, while the latter results in a heavy computation in the large feature space. To tackle the issue, we propose two novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users\u2019 ad clicks. To get our DNNs efficiently work, we propose to leverage three feature transformation methods, i.e., factorisation machines (FMs), restricted Boltzmann machines (RBMs) and denoising auto-encoders (DAEs). This paper presents the structure of our models and their efficient training algorithms. The large-scale experiments with real-world data demonstrate that our methods work better than major state-of-the-art models.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Zero-Shot Learning by Convex Combination of Semantic Embeddings\nAbstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate task, such as a natural language processing task on a text corpus, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning \u2013 the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classification mechanism and any existing semantic embedding space which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: A novel reinforcement learning benchmark, called Industrial Benchmark, is introduced. The Industrial Benchmark aims at being be realistic in the sense, that it includes a variety of aspects that we found to be vital in industrial applications. It is not designed to be an approximation of any real system, but to pose the same hardness and complexity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automatic moth detection from trap images for pest management\nAbstract: Monitoring the number of insect pests is a crucial component in pheromone-based pest management systems. In this paper, we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps. Applied to a commercial codling moth dataset, our method shows promising performance both qualitatively and quantitatively. Compared to previous attempts at pest detection, our approach uses no pest-specific engineering which enables it to adapt to other species and environments with minimal human effort. It is amenable to implementation on parallel hardware and therefore capable of deployment in settings where real-time performance is required.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Comparison of Random Forests and Ferns on Recognition of Instruments in Jazz Recordings\nAbstract: In this paper, we first apply random ferns for classification of real music recordings of a jazz band. No initial segmentation of audio data is assumed, i.e., no onset, offset, nor pitch data are needed. The notion of random ferns is described in the paper, to familiarize the reader with this classification algorithm, which was introduced quite recently and applied so far in image recognition tasks. The performance of random ferns is compared with random forests for the same data. The results of experiments are presented in the paper, and conclusions are drawn.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scale-invariant learning and convolutional networks\nAbstract: The conventional classification schemes \u2014 notably multinomial logistic regression \u2014 used in conjunction with convolutional networks (convnets) are classical in statistics, designed without consideration for the usual coupling with convnets, stochastic gradient descent, and backpropagation. In the specific application to supervised learning for convnets, a simple scale-invariant classification stage turns out to be more robust than multinomial logistic regression, appears to result in slightly lower errors on several standard test sets, has similar computational costs, and features precise control over the actual rate of learning. \u201cScale-invariant\u201d means that multiplying the input values by any nonzero scalar leaves the output unchanged.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We introduce a new model of teaching named \u201cpreference-based teaching\u201d and a corresponding complexity parameter\u2014the preference-based teaching dimension (PBTD)\u2014representing the worst-case number of examples needed to teach any concept in a given concept class. Although the PBTD coincides with the well-known recursive teaching dimension (RTD) on finite classes, it is radically different on infinite ones: the RTD becomes infinite already for trivial infinite classes (such as half-intervals) whereas the PBTD evaluates to reasonably small values for a wide collection of infinite classes including classes consisting of so-called closed sets w.r.t. a given closure operator, including various classes related to linear sets over N0 (whose RTD had been studied quite recently) and including the class of Euclidean half-spaces. On top of presenting these concrete results, we provide the reader with a theoretical framework (of a combinatorial flavor) which helps to derive bounds on the PBTD.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We propose a novel framework for efficient parallelization of deep reinforcement learning algorithms, enabling these algorithms to learn from multiple actors on a single machine. The framework is algorithm agnostic and can be applied to on-policy, off-policy, value based and policy gradient based algorithms. Given its inherent parallelism, the framework can be efficiently implemented on a GPU, allowing the usage of powerful models while significantly reducing training time. We demonstrate the effectiveness of our framework by implementing an advantage actor-critic algorithm on a GPU, using on-policy experiences and employing synchronous updates. Our algorithm achieves stateof-the-art performance on the Atari domain after only a few hours of training. Our framework thus opens the door for much faster experimentation on demanding problem domains. Our implementation is open-source and is made public at https://github.com/alfredvc/paac.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Graph-based Isometry Invariant Representation Learning\nAbstract: Learning transformation invariant representations of visual data is an important problem in computer vision. Deep convolutional networks have demonstrated remarkable results for image and video classification tasks. However, they have achieved only limited success in the classification of images that undergo geometric transformations. In this work we present a novel Transformation Invariant Graph-based Network (TIGraNet), which learns graph-based features that are inherently invariant to isometric transformations such as rotation and translation of input images. In particular, images are represented as signals on graphs, which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformations. Our experiments show high performance on rotated and translated images from the test set compared to classical architectures that are very sensitive to transformations in the data. The inherent invariance properties of our framework provide key advantages, such as increased resiliency to data variability and sustained performance with limited training sets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Toward Supervised Anomaly Detection\nAbstract: Anomaly detection is being regarded as an unsupervised learning task as anomalies stem from adversarial or unlikely events with unknown distributions. However, the predictive performance of purely unsupervised anomaly detection often fails to match the required detection rates in many tasks and there exists a need for labeled data to guide the model generation. Our first contribution shows that classical semi-supervised approaches, originating from a supervised classifier, are inappropriate and hardly detect new and unknown anomalies. We argue that semi-supervised anomaly detection needs to ground on the unsupervised learning paradigm and devise a novel algorithm that meets this requirement. Although being intrinsically non-convex, we further show that the optimization problem has a convex equivalent under relatively mild assumptions. Additionally, we propose an active learning strategy to automatically filter candidates for labeling. In an empirical study on network intrusion detection data, we observe that the proposed learning methodology requires much less labeled data than the state-of-the-art, while achieving higher detection accuracies.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Doubly Stochastic Neighbor Embedding on Spheres\nAbstract: Recently, Stochastic Neighbor Embedding (SNE) methods have widely been applied in data visualization. These methods minimize the divergence between the pairwise similarities of highand low-dimensional data. Despite their popularity, the current SNE methods experience the \u201ccrowding problem\u201d when the data include highly imbalanced similarities. This implies that the data points with higher total similarity tend to get crowded around the display center. To solve this problem, we normalize the similarity matrix to be doubly stochastic such that all the data points have equal total similarities. A fast normalization method is proposed. Furthermore, we show empirically and theoretically that the doubly stochasticity constraint often leads to approximately spherical embeddings. This suggests replacing a flat space with spheres as the embedding space. The spherical embedding eliminates the discrepancy between the center and the periphery in visualization and thus resolves the \u201ccrowding problem\u201d. We compared the proposed method with the state-of-the-art SNE method on three real-world datasets. The results indicate that our method is more favorable in terms of visualization quality.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Discriminative Nonparametric Latent Feature Relational Models with Data Augmentation\nAbstract: We present a discriminative nonparametric latent feature relational model (LFRM) for link prediction to automatically infer the dimensionality of latent features. Under the generic RegBayes (regularized Bayesian inference) framework, we handily incorporate the prediction loss with probabilistic inference of a Bayesian model; set distinct regularization parameters for different types of links to handle the imbalance issue in real networks; and unify the analysis of both the smooth logistic log-loss and the piecewise linear hinge loss. For the nonconjugate posterior inference, we present a simple Gibbs sampler via data augmentation, without making restricting assumptions as done in variational methods. We further develop an approximate sampler using stochastic gradient Langevin dynamics to handle large networks with hundreds of thousands of entities and millions of links, orders of magnitude larger than what existing LFRM models can process. Extensive studies on various real networks show promising performance.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Nonparametric Bayesian Storyline Detection from Microtexts\nAbstract: News events and social media are composed of evolving storylines, which capture public attention for a limited period of time. Identifying storylines requires integrating temporal and linguistic information, and prior work takes a largely heuristic approach. We present a novel online non-parametric Bayesian framework for storyline detection, using the distance-dependent Chinese Restaurant Process (dd-CRP). To ensure efficient linear-time inference, we employ a fixed-lag Gibbs sampling procedure, which is novel for the dd-CRP. We evaluate on the TREC Twitter Timeline Generation (TTG), obtaining encouraging results: despite using a weak baseline retrieval model, the dd-CRP story clustering method is competitive with the best entries in the 2014 TTG task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed stochastic optimization for deep learning\nAbstract: We study the problem of how to distribute the training of large-scale deep learning models in the parallel computing environment. We propose a new distributed stochastic optimization method called Elastic Averaging SGD (EASGD). We analyze the convergence rate of the EASGD method in the synchronous scenario and compare its stability condition with the existing ADMM method in the round-robin scheme. An asynchronous and momentum variant of the EASGD method is applied to train deep convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Our approach accelerates the training and furthermore achieves better test accuracy. It also requires a much smaller amount of communication than other common baseline approaches such as the DOWNPOUR method. We then investigate the limit in speedup of the initial and the asymptotic phase of the mini-batch SGD, the momentum SGD, and the EASGD methods. We find that the spread of the input data distribution has a big impact on their initial convergence rate and stability region. We also find a surprising connection between the momentum SGD and the EASGD method with a negative moving average rate. A non-convex case is also studied to understand when EASGD can get trapped by a saddle point. Finally, we scale up the EASGD method by using a tree structured network topology. We show empirically its advantage and challenge. We also establish a connection between the EASGD and the DOWNPOUR method with the classical Jacobi and the Gauss-Seidel method, thus unifying a class of distributed stochastic optimization methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Quasi-Newton Methods: A New Direction\nAbstract: Four decades after their invention, quasiNewton methods are still state of the art in unconstrained numerical optimization. Although not usually interpreted thus, these are learning algorithms that fit a local quadratic approximation to the objective function. We show that many, including the most popular, quasi-Newton methods can be interpreted as approximations of Bayesian linear regression under varying prior assumptions. This new notion elucidates some shortcomings of classical algorithms, and lights the way to a novel nonparametric quasi-Newton method, which is able to make more efficient use of available information at computational cost similar to its predecessors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Pseudo-Euclidean Iteration for Optimal Recovery in Noisy ICA\nAbstract: Independent Component Analysis (ICA) is a popular model for blind signal separation. The<lb>ICA model assumes that a number of independent source signals are linearly mixed to form the<lb>observed signals. We propose a new algorithm, PEGI (for pseudo-Euclidean Gradient Iteration),<lb>for provable model recovery for ICA with Gaussian noise. The main technical innovation of the<lb>algorithm is to use a fixed point iteration in a pseudo-Euclidean (indefinite \u201cinner product\u201d)<lb>space. The use of this indefinite \u201cinner product\u201d resolves technical issues common to several<lb>existing algorithms for noisy ICA. This leads to an algorithm which is conceptually simple,<lb>efficient and accurate in testing.<lb>Our second contribution is combining PEGI with the analysis of objectives for optimal re-<lb>covery in the noisy ICA model. It has been observed that the direct approach of demixing with<lb>the inverse of the mixing matrix is suboptimal for signal recovery in terms of the natural Signal<lb>to Interference plus Noise Ratio (SINR) criterion. There have been several partial solutions<lb>proposed in the ICA literature. It turns out that any solution to the mixing matrix reconstruc-<lb>tion problem can be used to construct an SINR-optimal ICA demixing, despite the fact that<lb>SINR itself cannot be computed from data. That allows us to obtain a practical and provably<lb>SINR-optimal recovery method for ICA with arbitrary Gaussian noise.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tree-structured composition in neural networks without tree-structured architectures\nAbstract: Tree-structured neural networks encode a particular tree geometry for a sentence in the network design. However, these models have at best only slightly outperformed simpler sequence-based models. We hypothesize that neural sequence models like LSTMs are in fact able to discover and implicitly use recursive compositional structure, at least for tasks with clear cues to that structure in the data. We demonstrate this possibility using an artificial data task for which recursive compositional structure is crucial, and find that the sequence model can learn the underlying patterning. The sequence model is better in that it learns the value of tree structure from the data in an emergent way, while the treestructured model is better in being able to learn with greater statistical efficiency due to its informative prior model structure.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Statistical Cost Sharing\nAbstract: We study the cost sharing problem for cooperative games in situations where the cost function C is not available via oracle queries, but must instead be derived from data, represented as tuples (S,C(S)), for different subsets S of players. We formalize this approach, which we call STATISTICAL COST SHARING, and consider the computation of the core and the Shapley value, when the tuples are drawn from some distribution D. Previous work by Balcan et al. [8] in this setting showed how to compute cost shares that satisfy the core property with high probability for limited classes of functions. We expand on their work and give an algorithm that computes such cost shares for any function with a non-empty core. We complement these results by proving an inapproximability lower bound for a weaker relaxation. We then turn our attention to the Shapley value. We first show that when cost functions come from the family of submodular functions with bounded curvature, \u03ba, the Shapley value can be approximated from samples up to a \u221a 1\u2212 \u03ba factor, and that the bound is tight. We then define statistical analogues of the Shapley axioms, and derive a notion of statistical Shapley value. We show that these can always be approximated arbitrarily well for general functions over any distribution D. \u2217School of Engineering and Applied Sciences, Harvard University, ericbalkanski@g.harvard.edu. \u2020Google NYC, usyed@google.com. \u2021Google NYC, sergeiv@google.com. 1 ar X iv :1 70 3. 03 11 1v 1 [ cs .G T ] 9 M ar 2 01 7\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The fuzzy K-means problem is a generalization of the classical K-means problem to soft clusterings, i.e. clusterings where each points belongs to each cluster to some degree. Although popular in practice, prior to this work the fuzzy K-means problem has not been studied from a complexity theoretic or algorithmic perspective. We show that optimal solutions for fuzzy K-means cannot, in general, be expressed by radicals over the input points. Surprisingly, this already holds for very simple inputs in one-dimensional space. Hence, one cannot expect to compute optimal solutions exactly. We give the first (1+ \u01eb)-approximation algorithms for the fuzzy K-means problem. First, we present a deterministic approximation algorithm whose runtime is polynomial in N and linear in the dimension D of the input set, given that K is constant, i.e. a polynomial time approximation algorithm given a fixed K. We achieve this result by showing that for each soft clustering there exists a hard clustering with comparable properties. Second, by using techniques known from coreset constructions for the K-means problem, we develop a deterministic approximation algorithm that runs in time almost linear in N but exponential in the dimension D. We complement these results with a randomized algorithm which imposes some natural restrictions on the input set and whose runtime is comparable to some of the most efficient approximation algorithms for Kmeans, i.e. linear in the number of points and the dimension, but exponential in the number of clusters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: REGULARIZING NEURAL NETWORKS BY PENALIZING CONFIDENT OUTPUT DISTRIBUTIONS\nAbstract: We systematically explore regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. Furthermore, we connect a maximum entropy based confidence penalty to label smoothing through the direction of the KL divergence. We exhaustively evaluate the proposed confidence penalty and label smoothing on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT\u201914 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and the confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyperparameters, suggesting the wide applicability of these regularizers.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Analyzing Estimation Errors due to Constrained Connections in Online Review Systems\nAbstract: In this work, we study how constrained connections can cause estimation errors in online review systems. Constrained connection is the phenomenon that a reviewer can only review a subset of products/services due to reviewer\u2019s narrow range of interests or limited attention capacity. We find that reviewers\u2019 constrained connections will cause poor inference performance, both from the measurements of estimation accuracy and Bayesian Cram\u00e9r Rao lower bound.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Approach for Self-Training Audio Event Detectors Using Web Data\nAbstract: Audio Event Detection (AED) aims to recognize sounds within audio and video recordings. AED employs machine learning algorithms commonly trained and tested on annotated datasets. However, available datasets are limited in number of samples and hence it is difficult to model acoustic diversity. Therefore, we propose combining labeled audio from a dataset and unlabeled audio from the web to improve the sound models. The audio event detectors are trained on the labeled audio and ran on the unlabeled audio downloaded from YouTube. Whenever the detectors recognized any of the known sounds with high confidence, the unlabeled audio was use to re-train the detectors. The performance of the re-trained detectors is compared to the one from the original detectors using the annotated test set. Results showed an improvement of the AED, and uncovered challenges of using web audio from videos.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deciding How to Decide:  Dynamic Routing in Artificial Neural Networks\nAbstract: We propose and systematically evaluate three strategies for training dynamically-routed artificial neural networks: graphs of learned transformations through which different input signals may take different paths. Though some approaches have advantages over others, the resulting networks are often qualitatively similar. We find that, in dynamically-routed networks trained to classify images, layers and branches become specialized to process distinct categories of images. Additionally, given a fixed computational budget, dynamically-routed networks tend to perform better than comparable staticallyrouted networks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Compared to Multilayer Neural Networks with real weights, Binary Multilayer Neural Networks (BMNNs) can be implemented more efficiently on dedicated hardware. BMNNs have been demonstrated to be effective on binary classification tasks with Expectation BackPropagation (EBP) algorithm on high dimensional text datasets. In this paper, we investigate the capability of BMNNs using the EBP algorithm on multiclass image classification tasks. The performances of binary neural networks with multiple hidden layers and different numbers of hidden units are examined on MNIST. We also explore the effectiveness of image spatial filters and the dropout technique in BMNNs. Experimental results on MNIST dataset show that EBP can obtain 2.12% test error with binary weights and 1.66% test error with real weights, which is comparable to the results of standard BackPropagation algorithm on fully connected MNNs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Weak Convergence Properties of Constrained Emphatic Temporal-difference Learning with Constant and Slowly Diminishing Stepsize\u2217\nAbstract: We consider the emphatic temporal-difference (TD) algorithm, ETD(\u03bb), for learning the value functions of stationary policies in a discounted, finite state and action Markov decision process. The ETD(\u03bb) algorithm was recently proposed by Sutton, Mahmood, and White [46] to solve a long-standing divergence problem of the standard TD algorithm when it is applied to off-policy training, where data from an exploratory policy are used to evaluate other policies of interest. The almost sure convergence of ETD(\u03bb) has been proved in our recent work under general off-policy training conditions, but for a narrow range of diminishing stepsize. In this paper we present convergence results for constrained versions of ETD(\u03bb) with constant stepsize and with diminishing stepsize from a broad range. Our results characterize the asymptotic behavior of the trajectory of iterates produced by those algorithms, and are derived by combining key properties of ETD(\u03bb) with powerful convergence theorems from the weak convergence methods in stochastic approximation theory. For the case of constant stepsize, in addition to analyzing the behavior of the algorithms in the limit as the stepsize parameter approaches zero, we also analyze their behavior for a fixed stepsize and bound the deviations of their averaged iterates from the desired solution. These results are obtained by exploiting the weak Feller property of the Markov chains associated with the algorithms, and by using ergodic theorems for weak Feller Markov chains, in conjunction with the convergence results we get from the weak convergence methods. Besides ETD(\u03bb), our analysis also applies to the off-policy TD(\u03bb) algorithm, when the divergence issue is avoided by setting \u03bb sufficiently large. It yields, for that case, new results on the asymptotic convergence properties of constrained off-policy TD(\u03bb) with constant or slowly diminishing stepsize.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Learning to Rank with Top-k Feedback\nAbstract: We consider two settings of online learning to rank where feedback is restricted to top ranked items. The problem is cast as an online game between a learner and sequence of users, over T rounds. In both settings, the learners objective is to present ranked list of items to the users. The learner\u2019s performance is judged on the entire ranked list and true relevances of the items. However, the learner receives highly restricted feedback at end of each round, in form of relevances of only the top k ranked items, where k m. The first setting is non-contextual, where the list of items to be ranked is fixed. The second setting is contextual, where lists of items vary, in form of traditional query-document lists. No stochastic assumption is made on the generation process of relevances of items and contexts. We provide efficient ranking strategies for both the settings. The strategies achieve O(T ) regret, where regret is based on popular ranking measures in first setting and ranking surrogates in second setting. We also provide impossibility results for certain ranking measures and a certain class of surrogates, when feedback is restricted to the top ranked item, i.e. k = 1. We empirically demonstrate the performance of our algorithms on simulated and real world datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Matrix Completion Under Monotonic Single Index Models\nAbstract: Most recent results in matrix completion assume that the matrix under consideration is low-rank or that the columns are in a union of low-rank subspaces. In real-world settings, however, the linear structure underlying these models is distorted by a (typically unknown) nonlinear transformation. This paper addresses the challenge of matrix completion in the face of such nonlinearities. Given a few observations of a matrix that are obtained by applying a Lipschitz, monotonic function to a low rank matrix, our task is to estimate the remaining unobserved entries. We propose a novel matrix completion method that alternates between lowrank matrix estimation and monotonic function estimation to estimate the missing matrix elements. Mean squared error bounds provide insight into how well the matrix can be estimated based on the size, rank of the matrix and properties of the nonlinear transformation. Empirical results on synthetic and real-world datasets demonstrate the competitiveness of the proposed approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Enhancing LambdaMART Using Oblivious Trees\nAbstract: Learning to rank is a machine learning technique broadly used in many areas such as document retrieval, collaborative filtering or question answering. We present experimental results which suggest that the performance of the current state-of-the-art learning to rank algorithm LambdaMART, when used for document retrieval for search engines, can be improved if standard regression trees are replaced by oblivious trees. This paper provides a comparison of both variants and our results demonstrate that the use of oblivious trees can improve the performance by more than 2.2%. Additional experimental analysis of the influence of a number of features and of a size of the training set is also provided and confirms the desirability of properties of oblivious decision trees.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Concentration Bounds for High Sensitivity Functions Through Differential Privacy*\nAbstract: A new line of work [6, 9, 15, 2] demonstrates how differential privacy [8] can be used as a mathematical tool for guaranteeing generalization in adaptive data analysis. Specifically, if a differentially private analysis is applied on a sample S of i.i.d. examples to select a lowsensitivity function f , then w.h.p. f (S) is close to its expectation, although f is being chosen based on the data. Very recently, Steinke and Ullman [16] observed that these generalization guarantees can be used for proving concentration bounds in the non-adaptive setting, where the low-sensitivity function is fixed beforehand. In particular, they obtain alternative proofs for classical concentration bounds for low-sensitivity functions, such as the Chernoff bound and McDiarmid\u2019s Inequality. In this work, we set out to examine the situation for functions with high-sensitivity, for which differential privacy does not imply generalization guarantees under adaptive analysis. We show that differential privacy can be used to prove concentration bounds for such functions in the non-adaptive setting.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We introduce techniques for rapidly transferring the information stored in one neural net into another neural net. The main purpose is to accelerate the training of a significantly larger neural net. During real-world workflows, one often trains very many different neural networks during the experimentation and design process. This is a wasteful process in which each new model is trained from scratch. Our Net2Net technique accelerates the experimentation process by instantaneously transferring the knowledge from a previous network to each new deeper or wider network. Our techniques are based on the concept of function-preserving transformations between neural network specifications. This differs from previous approaches to to pre-training that altered the function represented by a neural net when adding layers to it. Using our knowledge transfer mechanism to add depth to Inception modules, we demonstrate a new state of the art accuracy rating on the ImageNet dataset.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient Learning of Generalized Linear and Single Index Models with Isotonic Regression\nAbstract: Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide powerful generalizations of linear regression, where the target variable is assumed to be a (possibly unknown) 1-dimensional function of a linear predictor. In general, these problems entail non-convex estimation procedures, and, in practice, iterative local search heuristics are often used. Kalai and Sastry (2009) recently provided the first provably efficient method for learning SIMs and GLMs, under the assumptions that the data are in fact generated under a GLM and under certain monotonicity and Lipschitz constraints. However, to obtain provable performance, the method requires a fresh sample every iteration. In this paper, we provide algorithms for learning GLMs and SIMs, which are both computationally and statistically efficient. We also provide an empirical study, demonstrating their feasibility in practice.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DIRECT LOSS MINIMIZATION FOR TRAINING DEEP NEURAL NETS\nAbstract: Supervised training of deep neural nets typically relies on minimizing crossentropy. However, in many domains, we are interested in performing well on specific application-specific metrics. In this paper we proposed a direct loss minimization approach to train deep neural networks, taking into account the application-specific loss functions. This can be non-trivial, when these functions are non-smooth and non-decomposable. We demonstrate the effectiveness of our approach in the context of maximizing average precision for ranking problems. Towards this goal, we propose a dynamic programming algorithm that can efficiently compute the weight updates. Our approach proves superior to a variety of baselines in the context of action classification and object detection.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: One of the most widely used techniques for data clustering is agglomerative clustering. Such algorithms have been long used across many different fields ranging from computational biology to social sciences to computer vision in part because their output is easy to interpret. Unfortunately, it is well known, however, that many of the classic agglomerative clustering algorithms are not robust to noise. In this paper we propose and analyze a new robust algorithm for bottom-up agglomerative clustering. We show that our algorithm can be used to cluster accurately in cases where the data satisfies a number of natural properties and where the traditional agglomerative algorithms fail. We also show how to adapt our algorithm to the inductive setting where our given data is only a small random sample of the entire data set. Experimental evaluations on synthetic and real world data sets show that our algorithm achieves better performance than other hierarchical algorithms in the presence of noise.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization\nAbstract: Majorization-minimization algorithms consist of iteratively minimizing a majorizing surrogate of an objective function. Because of its simplicity and its wide applicability, this principle has been very popular in statistics and in signal processing. In this paper, we intend to make this principle scalable. We introduce a stochastic majorization-minimization scheme which is able to deal with largescale or possibly infinite data sets. When applied to convex optimization problems under suitable assumptions, we show that it achieves an expected convergence rate of O(1/ \u221a n) after n iterations, and of O(1/n) for strongly convex functions. Equally important, our scheme almost surely converges to stationary points for a large class of non-convex problems. We develop several efficient algorithms based on our framework. First, we propose a new stochastic proximal gradient method, which experimentally matches state-of-the-art solvers for large-scale l1logistic regression. Second, we develop an online DC programming algorithm for non-convex sparse estimation. Finally, we demonstrate the effectiveness of our approach for solving large-scale structured matrix factorization problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data\nAbstract: One of the defining properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overfitting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous in this \u201cdeep learning\u201d regime. In order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hiddenunit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classifiers with millions of parameters trained on only tens of thousands of examples. We connect our findings to recent and old work on flat minima and MDL-based explanations of generalization.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In this paper we propose a simple and efficient method for improving stochastic gradient descent methods by using feedback from the objective function. The method tracks the relative changes in the objective function with a running average, and uses it to adaptively tune the learning rate in stochastic gradient descent. We specifically apply this idea to modify Adam, a popular algorithm for training deep neural networks. We conduct experiments to compare the resulting algorithm, which we call Eve, with state of the art methods used for training deep learning models. We train CNNs for image classification, and RNNs for language modeling and question answering. Our experiments show that Eve outperforms all other algorithms on these benchmark tasks. We also analyze the behavior of the feedback mechanism during the training process.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: S-NN: Stacked Neural Networks\nAbstract: It has been proven that transfer learning provides an easy way to achieve state-of-the-art accuracies on several vision tasks by training a simple classifier on top of features obtained from pre-trained neural networks. The goal of this project is to generate better features for transfer learning from multiple publicly available pretrained neural networks. To this end, we propose a novel architecture called Stacked Neural Networks which leverages the fast training time of transfer learning while simultaneously being much more accurate. We show that using a stacked NN architecture can result in up to 8% improvements in accuracy over state-of-the-art techniques using only one pre-trained network for transfer learning. A second aim of this project is to make network finetuning retain the generalizability of the base network to unseen tasks. To this end, we propose a new technique called \u201cjoint finetuning\u201d that is able to give accuracies comparable to finetuning the same network individually over two datasets. We also show that a jointly finetuned network generalizes better to unseen tasks when compared to a network finetuned over a single task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Revenue Optimization with Approximate Bid Predictions\nAbstract: In the context of advertising auctions, finding good reserve prices is a notoriously challenging learning problem. This is due to the heterogeneity of ad opportunity types and the non-convexity of the objective function. In this work, we show how to reduce reserve price optimization to the standard setting of prediction under squared loss, a well understood problem in the learning community. We further bound the gap between the expected bid and revenue in terms of the average loss of the predictor. This is the first result that formally relates the revenue gained to the quality of a standard machine learned model.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Price of Differential Privacy For Online Learning\nAbstract: We design differentially private algorithms for the problem of online linear optimization in the full information and bandit settings with optimal \u00d5( \u221a T ) regret bounds. In the full-information setting, our results demonstrate that (\u03b5, \u03b4)-differential privacy may be ensured for free \u2013 in particular, the regret bounds scale as O( \u221a T ) + \u00d5 ( 1 \u03b5 log 1 \u03b4 ) . For bandit linear optimization, and as a special case, for non-stochastic multi-armed bandits, the proposed algorithm achieves a regret of O (\u221a T log T \u03b5 log 1 \u03b4 ) , while the previously best known bound was \u00d5 (\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Semi-supervised Multitask Learning for Sequence Labeling\nAbstract: We propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Window-Object Relationship Guided Representation Learning for Generic Object Detections\nAbstract: In existing works that learn representation for object detection, the relationship between a candidate window and the ground truth bounding box of an object is simplified by thresholding their overlap. This paper shows information loss in this simplification and picks up the relative location/size information discarded by thresholding. We propose a representation learning pipeline to use the relationship as supervision for improving the learned representation in object detection. Such relationship is not limited to object of the target category, but also includes surrounding objects of other categories. We show that image regions with multiple contexts and multiple rotations are effective in capturing such relationship during the representation learning process and in handling the semantic and visual variation caused by different window-object configurations. Experimental results show that the representation learned by our approach can improve the object detection accuracy by 6.4% in mean average precision (mAP) on ILSVRC2014 [15]. On the challenging ILSVRC2014 test dataset [15], 48.6% mAP is achieved by our single model and it is the best among published results. On PASCAL VOC, it outperforms the state-of-the-art result of Fast RCNN [6] by 3.3% in absolute mAP.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hierarchically-Attentive RNN for Album Summarization and Storytelling\nAbstract: We address the problem of end-to-end visual storytelling. Given a photo album, our model first selects the most representative (summary) photos, and then composes a natural language story for the album. For this task, we make use of the Visual Storytelling dataset and a model composed of three hierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album photos, select representative (summary) photos, and compose the story. Automatic and human evaluations show our model achieves better performance on selection, generation, and retrieval than baselines.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Complexity of One-class SVM for Multiple Instance Learning\nAbstract: In traditional multiple instance learning (MIL), both positive and negative bags are required to learn a prediction function. However, a high human cost is needed to know the label of each bag\u2014positive or negative. Only positive bags contain our focus (positive instances) while negative bags consist of noise or background (negative instances). So we do not expect to spend too much to label the negative bags. Contrary to our expectation, nearly all existing MIL methods require enough negative bags besides positive ones. In this paper we propose an algorithm called \u201cPositive Multiple Instance\u201d (PMI), which learns a classifier given only a set of positive bags. So the annotation of negative bags becomes unnecessary in our method. PMI is constructed based on the assumption that the unknown positive instances in positive bags be similar each other and constitute one compact cluster in feature space and the negative instances locate outside this cluster. The experimental results demonstrate that PMI achieves the performances close to or a little worse than those of the traditional MIL algorithms on benchmark and real data sets. However, the number of training bags in PMI is reduced significantly compared with traditional MIL algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Optimization with Safety Constraints: Safe and Automatic Parameter Tuning in Robotics\nAbstract: Robotics algorithms typically depend on various parameters, the choice of which significantly affects the robot\u2019s performance. While an initial guess for the parameters may be obtained from dynamic models of the robot, parameters are usually tuned manually on the real system to achieve the best performance. Optimization algorithms, such as Bayesian optimization, have been used to automate this process. However, these methods may evaluate parameters during the optimization process that lead to safety-critical system failures. Recently, a safe Bayesian optimization algorithm, called SAFEOPT, has been developed and applied in robotics, which guarantees that the performance of the system never falls below a critical value; that is, safety is defined based on the performance function. However, coupling performance and safety is not desirable in most cases. In this paper, we define separate functions for performance and safety. We present a generalized SAFEOPT algorithm that, given an initial safe guess for the parameters, maximizes performance but only evaluates parameters that satisfy all safety constraints with high probability. It achieves this by modeling the underlying and unknown performance and constraint functions as Gaussian processes. We provide a theoretical analysis and demonstrate in experiments on a quadrotor vehicle that the proposed algorithm enables fast, automatic, and safe optimization of tuning parameters. Moreover, we show an extension to contextor environmentdependent, safe optimization in the experiments.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DEEPDSL: A COMPILATION-BASED DOMAIN- SPECIFIC LANGUAGE FOR DEEP LEARNING\nAbstract: In recent years, Deep Learning (DL) has found great success in domains such as multimedia understanding. However, the complex nature of multimedia data makes it difficult to develop DL-based software. The state-of-the-art tools, such as Caffe, TensorFlow, Torch7, and CNTK, while are successful in their applicable domains, are programming libraries with fixed user interface, internal representation, and execution environment. This makes it difficult to implement portable and customized DL applications. In this paper, we present DeepDSL, a domain specific language (DSL) embedded in Scala, that compiles deep networks written in DeepDSL to Java source code. Deep DSL provides (1) intuitive constructs to support compact encoding of deep networks; (2) symbolic gradient derivation of the networks; (3) static analysis for memory consumption and error detection; and (4) DSL-level optimization to improve memory and runtime efficiency. DeepDSL programs are compiled into compact, efficient, customizable, and portable Java source code, which operates the CUDA and CUDNN interfaces running on Nvidia GPU via a Java Native Interface (JNI) library. We evaluated DeepDSL with a number of popular DL networks. Our experiments show that the compiled programs have very competitive runtime performance and memory efficiency compared to the existing libraries.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\nAbstract: We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Infinite Mixed Membership Matrix Factorization\nAbstract: Rating and recommendation systems have become a popular application area for applying a suite of machine learning techniques. Current approaches rely primarily on probabilistic interpretations and extensions of matrix factorization, which factorizes a user-item ratings matrix into latent user and item vectors. Most of these methods fail to model significant variations in item ratings from otherwise similar users, a phenomenon known as the \u201cNapoleon Dynamite\u201d effect. Recent efforts have addressed this problem by adding a contextual bias term to the rating, which captures the mood under which a user rates an item or the context in which an item is rated by a user. In this work, we extend this model in a nonparametric sense by learning the optimal number of moods or contexts from the data, and derive Gibbs sampling inference procedures for our model. We evaluate our approach on the MovieLens 1M dataset, and show significant improvements over the optimal parametric baseline, more than twice the improvements previously encountered for this task. We also extract and evaluate a DBLP dataset, wherein we predict the number of papers co-authored by two authors, and present improvements over the parametric baseline on this alternative domain as well.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mixed Membership Word Embeddings for Computational Social Science\nAbstract: Word embeddings improve the performance of NLP systems by revealing the hidden structural relationships between words. These models have recently risen in popularity due to the performance of scalable algorithms trained in the big data setting. Despite their success, word embeddings have seen very little use in computational social science NLP tasks, presumably due to their reliance on big data, and to a lack of interpretability. I propose a probabilistic model-based word embedding method which can recover interpretable embeddings, without big data. The key insight is to leverage the notion of mixed membership modeling, in which global representations are shared, but individual entities (i.e. dictionary words) are free to use these representations to uniquely differing degrees. Leveraging connections to topic models, I show how to train these models in high dimensions using a combination of state-of-the-art techniques for word embeddings and topic modeling. Experimental results show an improvement in predictive performance of up to 63% in MRR over the skip-gram on small datasets. The models are interpretable, as embeddings of topics are used to encode embeddings for words (and hence, documents) in a model-based way. I illustrate this with two computational social science case studies, on NIPS articles and State of the Union addresses.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Revisiting k-means: New Algorithms via Bayesian Nonparametrics\nAbstract: One of the many benefits of Bayesian nonparametric processes such as the Dirichlet process is that they can be used for modeling infinite mixture models, thus providing a flexible answer to the question of how many clusters exist in a data set. For the most part, such flexibility is currently lacking in techniques based on hard clustering, such as k-means, graph cuts, and Bregman hard clustering. For finite mixture models, there is a precise connection between k-means and mixtures of Gaussians, obtained by an appropriate limiting argument. In this paper, we apply a similar technique to an infinite mixture arising from the Dirichlet process (DP). We show that a Gibbs sampling algorithm for DP mixtures approaches a hard clustering algorithm in the limit, and further that the resulting algorithm monotonically minimizes an elegant underlying k-means-like objective that includes a penalty term based on the number of clusters. We generalize our analysis to the case of clustering multiple related data sets through a similar asymptotic argument with the hierarchical Dirichlet process. We discuss additional extensions that further highlight the benefits of our analysis: i) a spectral relaxation involving thresholded eigenvectors, and ii) a normalized cut graph clustering algorithm that requires O(|E|) time per iteration and automatically determines the number of clusters in a graph.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Transfer Learning, Soft Distance-Based Bias, and the Hierarchical BOA\nAbstract: An automated technique has recently been proposed to transfer learning in the hierarchical Bayesian optimization algorithm (hBOA) based on distance-based statistics. The technique enables practitioners to improve hBOA efficiency by collecting statistics from probabilistic models obtained in previous hBOA runs and using the obtained statistics to bias future hBOA runs on similar problems. The purpose of this paper is threefold: (1) test the technique on several classes of NP-complete problems, including MAXSAT, spin glasses and minimum vertex cover; (2) demonstrate that the technique is effective even when previous runs were done on problems of different size; (3) provide empirical evidence that combining transfer learning with other efficiency enhancement techniques can often yield nearly multiplicative speedups.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Can deep learning help you find the perfect match?\nAbstract: Is he/she attractive or not? We can often answer this question in a split of a second, and this ability is one of the main reasons behind the success of recent dating apps. In this paper we explore if we can predict attractiveness from profile pictures with convolutional networks. We argue that the introduced task is difficult due to i) the large number of variations in profile pictures and ii) the noise in attractiveness labels. We find that our self-labeled dataset of 9364 pictures is too small to apply a convolutional network directly. We resort to transfer learning and compare feature representations transferred from VGGNet[14] and a self-trained gender prediction network. Our findings show that VGGNet features transfer better and we conclude that our best model, achieving 68.1% accuracy on the test set, is moderately successful at predicting attractiveness.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Meta Networks\nAbstract: Deep neural networks have been successfully applied in applications with a large amount of labeled data. However, there are major drawbacks of the neural networks that are related to rapid generalization with small data and continual learning of new concepts without forgetting. We present a novel meta learning method, Meta Networks (MetaNet), that acquires a meta-level knowledge across tasks and shifts its inductive bias via fast parameterization for the rapid generalization. When tested on the standard oneshot learning benchmarks, our MetaNet models achieved near human-level accuracy. We demonstrated several appealing properties of MetaNet relating to generalization and continual learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Asynchronous Typestates for Android Classes\nAbstract: In event-driven programming frameworks, such as Android, the client and the framework interact using callins (framework methods that the client invokes) and callbacks (client methods that the framework invokes). The protocols for interacting with these frameworks can often be described by finite-state machines we dub asynchronous typestates. Asynchronous typestates are akin to classical typestates, with the key difference that their outputs (callbacks) are produced asynchronously. We present an algorithm to infer asynchronous typestates for Android framework classes. It is based on the L\u2217 algorithm that uses membership and equivalence queries. We show how to implement these queries for Android classes. Membership queries are implemented using testing. Under realistic assumptions, equivalence queries can be implemented using membership queries. We provide an improved algorithm for equivalence queries that is better suited for our application than the algorithms from literature. Instead of using a bound on the size of the typestate to be learned, our algorithm uses a distinguisher bound. The distinguisher bound quantifies how two states in the typestate are locally different. We implement our approach and evaluate it empirically. We use our tool, Starling, to learn asynchronous typestates for Android classes both for cases where one is already provided by the documentation, and for cases where the documentation is unclear. The results show that Starling learns asynchronous typestates accurately and efficiently. Additionally, in several cases, the synthesized asynchronous typestates uncovered surprising and undocumented behaviors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Convolution by Evolution Differentiable Pattern Producing Networks\nAbstract: In this work we introduce a differentiable version of the Compositional Pattern Producing Network, called the DPPN. Unlike a standard CPPN, the topology of a DPPN is evolved but the weights are learned. A Lamarckian algorithm, that combines evolution and learning, produces DPPNs to reconstruct an image. Our main result is that DPPNs can be evolved/trained to compress the weights of a denoising autoencoder from 157684 to roughly 200 parameters, while achieving a reconstruction accuracy comparable to a fully connected network with more than two orders of magnitude more parameters. The regularization ability of the DPPN allows it to rediscover (approximate) convolutional network architectures embedded within a fully connected architecture. Such convolutional architectures are the current state of the art for many computer vision applications, so it is satisfying that DPPNs are capable of discovering this structure rather than having to build it in by design. DPPNs exhibit better generalization when tested on the Omniglot dataset after being trained on MNIST, than directly encoded fully connected autoencoders. DPPNs are therefore a new framework for integrating learning and evolution.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Inferring Graphs from Cascades: A Sparse Recovery Framework\nAbstract: In the Network Inference problem, one seeks to recover the edges of an unknown graph from the observations of cascades propagating over this graph. In this paper, we approach this problem from the sparse recovery perspective. We introduce a general model of cascades, including the voter model and the independent cascade model, for which we provide the first algorithm which recovers the graph\u2019s edges with high probability and O(s logm) measurements where s is the maximum degree of the graph and m is the number of nodes. Furthermore, we show that our algorithm also recovers the edge weights (the parameters of the diffusion process) and is robust in the context of approximate sparsity. Finally we prove an almost matching lower bound of \u03a9(s log ms ) and validate our approach empirically on synthetic graphs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning to learn by gradient descent by gradient descent\nAbstract: The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Networks with Few Multiplications\nAbstract: For most deep learning algorithms training is notoriously time consuming. Since most of the computation in training neural networks is typically spent on floating point multiplications, we investigate an approach to training that eliminates the need for most of these. Our method consists of two parts: First we stochastically binarize weights to convert multiplications involved in computing hidden states to sign changes. Second, while back-propagating error derivatives, in addition to binarizing the weights, we quantize the representations at each layer to convert the remaining multiplications into binary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardwarefriendly training of neural networks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Empirical Evaluation of Parallel Training Algorithms on Acoustic Modeling\nAbstract: Deep learning models (DLMs) are state-of-the-art techniques in speech recognition. However, training good DLMs can be time consuming especially for production-size models and corpora. Although several parallel training algorithms have been proposed to improve training efficiency, there is no clear guidance on which one to choose for the task in hand due to lack of systematic and fair comparison among them. In this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition, namely asynchronous stochastic gradient descent (ASGD), blockwise model-update filtering (BMUF), bulk synchronous parallel (BSP) and elastic averaging stochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using feed-forward deep neural networks (DNNs) and convolutional, long short-term memory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the top choice to train acoustic models since it is most stable, scales well with number of GPUs, can achieve reproducible results, and in many cases even outperforms singleGPU SGD. ASGD can be used as a substitute in some cases.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Relational Dependency Networks for Relation Extraction\nAbstract: We consider the task of KBP slot filling \u2013 extracting relation information from newswire documents for knowledge base construction. We present our pipeline, which employs Relational Dependency Networks (RDNs) to learn linguistic patterns for relation extraction. Additionally, we demonstrate how several components such as weak supervision, word2vec features, joint learning and the use of human advice, can be incorporated in this relational framework. We evaluate the different components in the benchmark KBP 2015 task and show that RDNs effectively model a diverse set of features and perform competitively with current state-of-the-art relation extraction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: TSEB: More Efficient Thompson Sampling for Policy Learning\nAbstract: In model-based solution approaches to the problem of learning in an unknown environment, exploring to learn the model parameters takes a toll on the regret. The optimal performance with respect to regret or PAC bounds is achievable, if the algorithm exploits with respect to reward or explores with respect to the model parameters, respectively. In this paper, we propose TSEB, a Thompson Sampling based algorithm with adaptive exploration bonus that aims to solve the problem with tighter PAC guarantees, while being cautious on the regret as well. The proposed approach maintains distributions over the model parameters which are successively refined with more experience. At any given time, the agent solves a model sampled from this distribution, and the sampled reward distribution is skewed by an exploration bonus in order to generate more informative exploration. The policy by solving is then used for generating more experience that helps in updating the posterior over the model parameters. We provide a detailed analysis of the PAC guarantees, and convergence of the proposed approach. We show that our adaptive exploration bonus encourages the additional exploration required for better PAC bounds on the algorithm. We provide empirical analysis on two different simulated domains.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Spiking Deep Networks with LIF Neurons\nAbstract: We train spiking deep networks using leaky integrate-and-fire (LIF) neurons, and achieve state-of-the-art results for spiking networks on the CIFAR-10 and MNIST datasets. This demonstrates that biologically-plausible spiking LIF neurons can be integrated into deep networks can perform as well as other spiking models (e.g. integrate-and-fire). We achieved this result by softening the LIF response function, such that its derivative remains bounded, and by training the network with noise to provide robustness against the variability introduced by spikes. Our method is general and could be applied to other neuron types, including those used on modern neuromorphic hardware. Our work brings more biological realism into modern image classification models, with the hope that these models can inform how the brain performs this difficult task. It also provides new methods for training deep networks to run on neuromorphic hardware, with the aim of fast, power-efficient image classification for robotics applications.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Characterization of the Dirichlet Distribution with Application to Learning Bayesian Networks\nAbstract: We provide a new characterization of the Dirichlet distribution. This characterization implies that under assumptions made by sev\u00ad eral previous authors for learning belief net\u00ad works, a Dirichlet prior on the parameters is inevitable.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MULTI-TASK LEARNING OF DEEP NEURAL NETWORKS FOR AUDIO VISUAL AUTOMATIC SPEECH RECOGNITION\nAbstract: Multi-task learning (MTL) involves the simultaneous training of two or more related tasks over shared representations. In this work, we apply MTL to audio-visual automatic speech recognition(AV-ASR). Our primary task is to learn a mapping between audio-visual fused features and frame labels obtained from acoustic GMM/HMM model. This is combined with an auxiliary task which maps visual features to frame labels obtained from a separate visual GMM/HMM model. The MTL model is tested at various levels of babble noise and the results are compared with a base-line hybrid DNN-HMM AVASR model. Our results indicate that MTL is especially useful at higher level of noise. Compared to base-line, upto 7% relative improvement in WER is reported at -3 SNR dB1.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Theoretical Capacity of Evolution Strategies to Statistically Learn the Landscape Hessian\nAbstract: We study the theoretical capacity to statistically learn local landscape information by Evolution Strategies (ESs). Specifically, we investigate the covariance matrix when constructed by ESs operating with the selection operator alone. We model continuous generation of candidate solutions about quadratic basins of attraction, with deterministic selection of the decision vectors that minimize the objective function values. Our goal is to rigorously show that accumulation of winning individuals carries the potential to reveal valuable information about the search landscape, e.g., as already practically utilized by derandomized ES variants. We first show that the statistically-constructed covariance matrix over such winning decision vectors shares the same eigenvectors with the Hessian matrix about the optimum. We then provide an analytic approximation of this covariance matrix for a non-elitist multi-child (1, \u03bb)-strategy, which holds for a large population size \u03bb. Finally, we also numerically corroborate our results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ASlib: A Benchmark Library for Algorithm Selection\nAbstract: The task of algorithm selection involves choosing an algorithm from a set of algorithms on a per-instance basis in order to exploit the varying performance of algorithms over a set of instances. The algorithm selection problem is attracting increasing attention from researchers and practitioners in AI. Years of fruitful applications in a number of domains have resulted in a large amount of data, but the community lacks a standard format or repository for this data. This situation makes it difficult to share and compare different approaches effectively, as is done in other, more established fields. It also unnecessarily hinders new researchers who want to work in this area. To address this problem, we introduce a standardized format for representing algorithm selection scenarios and a repository that contains a growing number of data sets from the literature. Our format has been designed to be able to express a wide variety of different scenarios. Demonstrating the breadth and power of our platform, we describe a set of example experiments that build and evaluate algorithm selection models through a common interface. The results display the potential of algorithm selection to achieve significant performance improvements across a broad range of problems and algorithms.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Beyond Monte Carlo Tree Search: Playing Go with Deep Alternative Neural Network and Long-Term Evaluation\nAbstract: Monte Carlo tree search (MCTS) is extremely popular in computer Go which determines each action by enormous simulations in a broad and deep search tree. However, human experts select most actions by pattern analysis and careful evaluation rather than brute search of millions of future interactions. In this paper, we propose a computer Go system that follows experts way of thinking and playing. Our system consists of two parts. The first part is a novel deep alternative neural network (DANN) used to generate candidates of next move. Compared with existing deep convolutional neural network (DCNN), DANN inserts recurrent layer after each convolutional layer and stacks them in an alternative manner. We show such setting can preserve more contexts of local features and its evolutions which are beneficial for move prediction. The second part is a long-term evaluation (LTE) module used to provide a reliable evaluation of candidates rather than a single probability from move predictor. This is consistent with human experts nature of playing since they can foresee tens of steps to give an accurate estimation of candidates. In our system, for each candidate, LTE calculates a cumulative reward after several future interactions when local variations are settled. Combining criteria from the two parts, our system determines the optimal choice of next move. For more comprehensive experiments, we introduce a new professional Go dataset (PGD), consisting of 253, 233 professional records. Experiments on GoGoD and PGD datasets show the DANN can substantially improve performance of move prediction over pure DCNN. When combining LTE, our system outperforms most relevant approaches and open engines based on\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Stability of Empirical Risk Minimization in the Presence of Multiple Risk Minimizers\nAbstract: Recently Kutin and Niyogi investigated several notions of algorithmic stability\u2014a property of a learning map conceptually similar to continuity\u2014showing that training-stability is sufficient for consistency of Empirical Risk Minimization while distribution-free CV-stability is necessary and sufficient for having finite VC-dimension. This paper concerns a phase transition in the training stability of ERM, conjectured by the same authors. Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a unique risk minimizer has training stability that scales exponentially with sample size, and conjectured that the existence of multiple risk minimizers prevents even super-quadratic convergence. We prove this result for the strictly weaker notion of CV-stability, positively resolving the conjecture.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Differentially Private Distributed Online Learning\nAbstract: In this paper, we propose a novel distributed online learning algorithm to handle massive data in Big Data era. Comparing to the typical centralized scenario, our proposed distributed online learning has multi-learners. Each learner optimizes its own learning parameter based on local data source and communicates timely with neighbors. We study the regret of the distributed online learning algorithm. However, communications among the learners may lead to privacy breaches. Thus, we use differential privacy to preserve the privacy of the learners, and study the influence of guaranteeing differential privacy on the regret of the algorithm. Furthermore, our online learning algorithm can be used to achieve fast convergence rates for offline learning algorithms in distributed scenarios. We demonstrate that the differentially private offline learning algorithm has high variance, but we can use mini-batch to improve the performance. The simulations show that our proposed theorems are correct and our differentially private distributed online learning algorithm is a general framework.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Risk Minimization Framework for Multiple Instance Learning from Positive and Unlabeled Bags\nAbstract: Multiple instance learning (MIL) is a variation of traditional supervised learning problems where data (referred to as bags) are composed of sub-elements (referred to as instances) and only bag labels are available. MIL has a variety of applications such as content-based image retrieval, text categorization and medical diagnosis. Most of the previous work for MIL assume that the training bags are fully labeled. However, it is often difficult to obtain an enough number of labeled bags in practical situations, while many unlabeled bags are available. A learning framework called PU learning (positive and unlabeled learning) can address this problem. In this paper, we propose a convex PU learning method to solve an MIL problem. We experimentally show that the proposed method achieves better performance with significantly lower computational costs than an existing method for PU-MIL.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing\nAbstract: Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural \u201cno-free-lunch\u201d requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentivecompatible mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers. We further extend our results to a more general setting in which workers are required to provide a quantized confidence for each question. Interestingly, this unique mechanism takes a \u201cmultiplicative\u201d form. The simplicity of the mechanism is an added benefit. In preliminary experiments involving over 900 worker-task pairs, we observe a significant drop in the error rates under this unique mechanism for the same or lower monetary expenditure.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Beyond Convexity: Stochastic Quasi-Convex Optimization\nAbstract: Stochastic convex optimization is a basic and well studied primitive in machine learning. It is well known that convex and Lipschitz functions can be minimized efficiently using Stochastic Gradient Descent (SGD). The Normalized Gradient Descent (NGD) algorithm, is an adaptation of Gradient Descent, which updates according to the direction of the gradients, rather than the gradients themselves. In this paper we analyze a stochastic version of NGD and prove its convergence to a global minimum for a wider class of functions: we require the functions to be quasi-convex and locally-Lipschitz. Quasi-convexity broadens the concept of unimodality to multidimensions and allows for certain types of saddle points, which are a known hurdle for first-order optimization methods such as gradient descent. Locally-Lipschitz functions are only required to be Lipschitz in a small region around the optimum. This assumption circumvents gradient explosion, which is another known hurdle for gradient descent variants. Interestingly, unlike the vanilla SGD algorithm, the stochastic normalized gradient descent algorithm provably requires a minimal minibatch size.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hierarchical Quasi-Clustering Methods for Asymmetric Networks\nAbstract: This paper introduces hierarchical quasiclustering methods, a generalization of hierarchical clustering for asymmetric networks where the output structure preserves the asymmetry of the input data. We show that this output structure is equivalent to a finite quasi-ultrametric space and study admissibility with respect to two desirable properties. We prove that a modified version of single linkage is the only admissible quasi-clustering method. Moreover, we show stability of the proposed method and we establish invariance properties fulfilled by it. Algorithms are further developed and the value of quasi-clustering analysis is illustrated with a study of internal migration within United States.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Resisting Adversarials for Convolutional Neural Networks using Internal Projection\nAbstract: We introduce a novel artificial neural network architecture that integrates robustness to adversarial input in the network structure. The main idea of our approach is to force the network to make predictions on what the given instance of the class under consideration would look like and subsequently test those predictions. By forcing the network to redraw the relevant parts of the image and subsequently comparing this new image to the original, we are having the network give a \u201cproof\u201d of the presence of the object.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tree-based Convolution: A New Architecture for Sentence Modeling\nAbstract: This paper proposes a new convolutional neural architecture based on treestructures, called the tree-based convolutional neural network (TBCNN). Two variants take advantage of constituency trees and dependency trees, respectively, to model sentences. Compared with traditional \u201cflat\u201d convolutional neural networks (CNNs), TBCNNs explore explicitly the structural information of sentences; compared with recursive neural networks, TBCNNs have much shorter propagation paths, enabling more effective feature learning and extraction. In the experiment of sentiment analysis, our two models consistently outperform CNNs and RNNs in a controlled setting. Our models are also competitive to most stateof-the-art results, including RNNs based on long short term memory and deep CNNs/RNNs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: LightRNN: Memory and Computation-Efficient Recurrent Neural Networks\nAbstract: Recurrent neural networks (RNNs) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation. However, when the vocabulary is large, the RNN model will become very big (e.g., possibly beyond the memory capacity of a GPU device) and its training will become very inefficient. In this work, we propose a novel technique to tackle this challenge. The key idea is to use 2-Component (2C) shared embedding for word representations. We allocate every word in the vocabulary into a table, each row of which is associated with a vector, and each column associated with another vector. Depending on its position in the table, a word is jointly represented by two components: a row vector and a column vector. Since the words in the same row share the row vector and the words in the same column share the column vector, we only need 2 \u221a |V | vectors to represent a vocabulary of |V | unique words, which are far less than the |V | vectors required by existing approaches. Based on the 2-Component shared embedding, we design a new RNN algorithm and evaluate it using the language modeling task on several benchmark datasets. The results show that our algorithm significantly reduces the model size and speeds up the training process, without sacrifice of accuracy (it achieves similar, if not better, perplexity as compared to state-of-the-art language models). Remarkably, on the One-Billion-Word benchmark Dataset, our algorithm achieves comparable perplexity to previous language models, whilst reducing the model size by a factor of 40-100, and speeding up the training process by a factor of 2. We name our proposed algorithm LightRNN to reflect its very small model size and very high training speed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Multi-GPU Distributed Parallel Bayesian Differential Topic Modelling by Aaron(Qiaochu) Li Bachelor of Science(Advanced)(Honours) Research School of Computer Science Australian National University Doctor Wray Buntine, Supervisor Doctor Scott Sanner, Co-supervisor There is an explosion of data, documents, and other content, and people require tools to analyze and interpret these, tools to turn the content into information and knowledge. Topic modelling have been developed to solve these problems. Bayesian topic models such as Latent Dirichlet Allocation (LDA) [1] allow salient patterns in large collection of documents to be extracted and analyzed automatically. When analyzing texts, these patterns are called topics, represented as a distribution of words. Although numerous extensions of LDA have been created in academia in the last decade to address many problems, few of them can reliablily analyze multiple groups of documents and extract the similarities and differences in topics across these groups. Recently, the introduction of techniques for differential topic modelling, namely the Shadow Poisson Dirichlet Process model (SPDP) [2] performs uniformly better than many existing topic models in a discriminative setting. There is also a need to improve the running speed of algorithms for topic models. While some effort has been made for distributed algorithms, there is no work currently done using graphical processing units (GPU). Note the GPU framework has already become the most cost-efficient and popular parallel platform for many research and industry problems. In this thesis, I propose and implement a scalable multi-GPU distributed parallel framework which approximates SPDP, called MGPU-DP-SPDP, and a version running on a single GPU, Improved-GPU-SPDP. Through experiments, I have shown ImprovedGPU-SPDP improved the running speed of SPDP by about 50 times while being almost as accurate as SPDP, with only one single cheap laptop GPU. Furthermore, I have shown the speed improvement of MGPU-DP-SPDP is sublinearly scalable when multiple GPUs are used, while keeping the accuracy fairly comparable to SPDP. Therefore, on a mediumsized GPU cluster, the speed improvement could potentially reach a factor of a thousand. Note SPDP is just a representative of perhaps another hundred other extensions of LDA. Although my algorithm is implemented to work with SPDP, it is designed to be a general framework that can be extended to work with other LDA extensions and improve\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Relaxing Determinism in Arithmetic Circuits\nAbstract: The past decade has seen a significant interest in learning tractable probabilistic representations. Arithmetic circuits (ACs) were among the first proposed tractable representations, with some subsequent representations being instances of ACs with weaker or stronger properties. In this paper, we provide a formal basis under which variants on ACs can be compared, and where the precise roles and semantics of their various properties can be made more transparent. This allows us to place some recent developments on ACs in a clearer perspective and to also derive new results for ACs. This includes an exponential separation between ACs with and without determinism; completeness and incompleteness results; and tractability results (or lack thereof) when computing most probable explanations (MPEs).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Conceptual Development of Quench Prediction App build on LSTM and ELQA framework\nAbstract: This article presents a development of web application for quench prediction in Technology Department, Machine Protection and Electrical Integrity group, Electrical Engineering (TE-MPE-EE) at CERN. The authors describe an ELectrical Quality Assurance (ELQA) framework, a platform which was designed for rapid development of web integrated data analysis applications for different analysis needed during the hardware commissioning of the Large Hadron Collider (LHC). In second part the article describes a research carried out with the data collected from Quench Detection System by means of using an LSTM recurrent neural network. The article discusses and presents a conceptual work of implementing quench prediction application for TEMPE-EE based on the ELQA and quench prediction algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mixed Low-precision Deep Learning Inference using Dynamic Fixed Point\nAbstract: We propose a cluster-based quantization method to convert pre-trained full precision weights into ternary weights with minimal impact on the accuracy. In addition we also constrain the activations to 8-bits thus enabling sub 8-bit full integer inference pipeline. Our method uses smaller clusters of N filters with a common scaling factor to minimize the quantization loss, while also maximizing the number of ternary operations. We show that with cluster size of N=4 on Resnet-101, can achieve 71.8% TOP-1 accuracy, within 6% of the best full precision result, while replacing \u2248 85% of all multiplications with 8-bit accumulations. Using the same method with 4-bit weights achieves 76.3% TOP-1 accuracy which within 2% of the full precision result. We also study the impact of the size of the cluster on both performance and accuracy, larger cluster sizes N=64 can replace \u2248 98% of the multiplications with ternary operations but introduces significant drop in accuracy which necessitates fine tuning the parameters with retraining the network at lower precision. To address this we have also trained low-precision Resnet-50 with 8-bit activations and ternary weights by pre-initializing the network with full precision weights and achieve 68.9% TOP-1 accuracy within 4 additional epochs. Our final quantized model can run on a full 8-bit compute pipeline, with a potential 16x improvement in performance compared to baseline full-precision models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We explore the utility of clustering in reducing error in various prediction tasks. Previous work has hinted at the improvement in prediction accuracy attributed to clustering algorithms if used to pre-process the data. In this work we more deeply investigate the direct utility of using clustering to improve prediction accuracy and provide explanations for why this may be so. We look at a number of datasets, run k-means at different scales and for each scale we train predictors. This produces k sets of predictions. These predictions are then combined by a na\u00efve ensemble. We observed that this use of a predictor in conjunction with clustering improved the prediction accuracy in most datasets. We believe this indicates the predictive utility of exploiting structure in the data and the data compression handed over by clustering. We also found that using this method improves upon the prediction of even a Random Forests predictor which suggests this method is providing a novel, and useful source of variance in the prediction process.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning for Music\nAbstract: Our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans. Previous work in music generation has mainly been focused on creating a single melody. More recent work on polyphonic music modeling, centered around time series probability density estimation, has met some partial success. In particular, there has been a lot of work based off of Recurrent Neural Networks combined with Restricted Boltzmann Machines (RNNRBM) and other similar recurrent energy based models. Our approach, however, is to perform end-to-end learning and generation with deep neural nets alone.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MIT-QCRI ARABIC DIALECT IDENTIFICATION SYSTEM FOR THE 2017 MULTI-GENRE BROADCAST CHALLENGE\nAbstract: In order to successfully annotate the Arabic speech content found in open-domain media broadcasts, it is essential to be able to process a diverse set of Arabic dialects. For the 2017 Multi-Genre Broadcast challenge (MGB-3) there were two possible tasks: Arabic speech recognition, and Arabic Dialect Identification (ADI). In this paper, we describe our efforts to create an ADI system for the MGB-3 challenge, with the goal of distinguishing amongst four major Arabic dialects, as well as Modern Standard Arabic. Our research focused on dialect variability and domain mismatches between the training and test domain. In order to achieve a robust ADI system, we explored both Siamese neural network models to learn similarity and dissimilarities among Arabic dialects, as well as i-vector post-processing to adapt domain mismatches. Both Acoustic and linguistic features were used for the final MGB-3 submissions, with the best primary system achieving 75% accuracy on the official 10hr test set.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multilevel Anomaly Detection for Mixed Data\nAbstract: Anomalies are those deviating from the norm. Unsupervised anomaly detection often translates to identifying low density regions. Major problems arise when data is high-dimensional and mixed of discrete and continuous attributes. We propose MIXMAD, which stands for MIXed data Multilevel Anomaly Detection, an ensemble method that estimates the sparse regions across multiple levels of abstraction of mixed data. The hypothesis is for domains where multiple data abstractions exist, a data point may be anomalous with respect to the raw representation or more abstract representations. To this end, our method sequentially constructs an ensemble of Deep Belief Nets (DBNs) with varying depths. Each DBN is an energy-based detector at a predefined abstraction level. At the bottom level of each DBN, there is a Mixed-variate Restricted Boltzmann Machine that models the density of mixed data. Predictions across the ensemble are finally combined via rank aggregation. The proposed MIXMAD is evaluated on high-dimensional real-world datasets of different characteristics. The results demonstrate that for anomaly detection, (a) multilevel abstraction of highdimensional and mixed data is a sensible strategy, and (b) empirically, MIXMAD is superior to popular unsupervised detection methods for both homogeneous and mixed data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An Efficient Primal Dual Prox Method for Non-Smooth Optimization\nAbstract: We study the non-smooth optimization problems in machine learning, where both the loss function and the regularizer are non-smooth functions. Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regularizer, making them unsuitable for non-smooth optimization. We develop a simple yet efficient method for a family of non-smooth optimization problems where the dual form of the loss function is bilinear in primal and dual variables. We cast a non-smooth optimization problem into a minimax optimization problem, and develop a primal dual prox method that solves the minimax optimization problem at a rate of O(1/T ) assuming that the proximal step can be efficiently solved, significantly faster than a standard subgradient descent method that has an O(1/ \u221a T ) convergence rate. Our empirical study verifies the efficiency of the proposed method for various non-smooth optimization problems that arise ubiquitously in machine learning by comparing it to the state-of-the-art first order methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Theoretical Analysis of the k-Means Algorithm \u2013 A Survey\nAbstract: Clustering is a basic process in data analysis. It aims to partition a set of objects into groups called clusters such that, ideally, objects in the same group are similar and objects in different groups are dissimilar to each other. There are many scenarios where such a partition is useful. It may, for example, be used to structure the data to allow efficient information retrieval, to reduce the data by replacing a cluster by one or more representatives or to extract the main \u2018themes\u2019 in the data. There are many surveys on clustering algorithms, including well-known classics [45, 48] and more recent ones [24, 47]. Notice that the title of [47] is Data clustering: 50 years beyond K-means in reference to the k-means algorithm, the probably most widely used clustering algorithm of all time. It was proposed in 1957 by Lloyd [58] (and independently in 1956 by Steinhaus [71]) and is the topic of this survey. The k-means algorithm solves the problem of clustering to minimize the sum of squared errors (SSE). In this problem, we are given a set of points P \u2282 Rd in a Euclidean space, and the goal is to find a set C \u2282 Rd of k points (not necessarily included in P ) such that the sum of the squared distances of the points in P to their nearest center in C is minimized. Thus, the objective function to be minimized is\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed Power Allocation with SINR Constraints Using Trial and Error Learning\nAbstract: In this paper, we address the problem of global transmit power minimization in a self-configuring network where radio devices are subject to operate at a minimum signal to interference plus noise ratio (SINR) level. We model the network as a parallel Gaussian interference channel and we introduce a fully decentralized algorithm (based on trial and error) able to statistically achieve a configuration where the performance demands are met. Contrary to existing solutions, our algorithm requires only local information and can learn stable and efficient working points by using only one bit feedback. We model the network under two different game theoretical frameworks: normal form and satisfaction form. We show that the converging points correspond to equilibrium points, namely Nash and satisfaction equilibrium. Similarly, we provide sufficient conditions for the algorithm to converge in both formulations. Moreover, we provide analytical results to estimate the algorithm\u2019s performance, as a function of the network parameters. Finally, numerical results are provided to validate our theoretical conclusions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recycling Randomness with Structure for Sublinear time Kernel Expansions\nAbstract: We propose a scheme for recycling Gaussian random vectors into structured matrices to approximate various kernel functions in sublinear time via random embeddings. Our framework includes the Fastfood construction of Le et al. (2013) as a special case, but also extends to Circulant, Toeplitz and Hankel matrices, and the broader family of structured matrices that are characterized by the concept of lowdisplacement rank. We introduce notions of coherence and graph-theoretic structural constants that control the approximation quality, and prove unbiasedness and low-variance properties of random feature maps that arise within our framework. For the case of low-displacement matrices, we show how the degree of structure and randomness can be controlled to reduce statistical variance at the cost of increased computation and storage requirements. Empirical results strongly support our theory and justify the use of a broader family of structured matrices for scaling up kernel methods using random features.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Probabilistic Vehicle Trajectory Prediction over Occupancy Grid Map via Recurrent Neural Network\nAbstract: In this paper, we propose an efficient vehicle trajectory prediction framework based on recurrent neural network. Basically, the characteristic of the vehicle\u2019s trajectory is different from that of regular moving objects since it is affected by various latent factors including road structure, traffic rules, and driver\u2019s intention. Previous state of the art approaches use sophisticated vehicle behavior model describing these factors and derive the complex trajectory prediction algorithm, which requires a system designer to conduct intensive model optimization for practical use. Our approach is data-driven and simple to use in that it learns complex behavior of the vehicles from the massive amount of trajectory data through deep neural network model. The proposed trajectory prediction method employs the recurrent neural network called long short-term memory (LSTM) to analyze the temporal behavior and predict the future coordinate of the surrounding vehicles. The proposed scheme feeds the sequence of vehicles\u2019 coordinates obtained from sensor measurements to the LSTM and produces the probabilistic information on the future location of the vehicles over occupancy grid map. The experiments conducted using the data collected from highway driving show that the proposed method can produce reasonably good estimate of future trajectory.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Global-Local Face Upsampling Network\nAbstract: Face hallucination, which is the task of generating a highresolution face image from a low-resolution input image, is a well-studied problem that is useful in widespread application areas. Face hallucination is particularly challenging when the input face resolution is very low (e.g., 10\u00d712 pixels) and/or the image is captured in an uncontrolled setting with large pose and illumination variations. In this paper, we revisit the algorithm introduced in [1] and present a deep interpretation of this framework that achieves state-of-the-art under such challenging scenarios. In our deep network architecture the global and local constraints that define a face can be efficiently modeled and learned end-to-end using training data. Conceptually our network design can be partitioned into two sub-networks: the first one implements the holistic face reconstruction according to global constraints, and the second one enhances face-specific details and enforces local patch statistics. We optimize the deep network using a new loss function for super-resolution that combines reconstruction error with a learned face quality measure in adversarial setting, producing improved visual results. We conduct extensive experiments in both controlled and uncontrolled setups and show that our algorithm improves the state of the art both numerically and visually.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Packet: A Novel Approach For Encrypted Traffic Classification Using Deep Learning\nAbstract: Internet traffic classification has become more important with rapid growth of current Internet network and online applications. There have been numerous studies on this topic which have led to many different approaches. Most of these approaches exploit predefined features extracted by an expert in order to classify network traffic. In contrast, in this study, we propose a deep learning based approach which integrate both feature extraction and classification phases into one system. Our proposed scheme, called \u201cDeep Packet,\u201d can handle both traffic categorization in which the network traffic is categorize into major classes (e.g., FTP, P2P, etc.) and application identification in which one identify end-user applications (e.g., BitTorrent, Skype, etc.). Contrary to most of the current methods, Deep Packet can identify encrypted traffic and also distinguishes between VPN and non-VPN network traffic. After initial pre-processing phase on data, packets are fed to Deep Packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic. Deep packet with CNN as its classification model achieved F1 score of 0.95 in application identification and it also accomplished F1 score of 0.97 in traffic categorization task. To the best of our knowledge, Deep Packet outperforms all of the classification and categorization methods on UNB ISCX VPN-nonVPN dataset.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering\nAbstract: Convolutional neural networks (CNNs) have greatly improved state-of-the-art performances in a number of fields, notably computer vision and natural language processing. In this work, we are interested in generalizing the formulation of CNNs from low-dimensional regular Euclidean domains, where images (2D), videos (3D) and audios (1D) are represented, to high-dimensional irregular domains such as social networks or biological networks represented by graphs. This paper introduces a formulation of CNNs on graphs in the context of spectral graph theory. We borrow the fundamental tools from the emerging field of signal processing on graphs, which provides the necessary mathematical background and efficient numerical schemes to design localized graph filters efficient to learn and evaluate. As a matter of fact, we introduce the first technique that offers the same computational complexity than standard CNNs, while being universal to any graph structure. Numerical experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs, as long as the graph is well-constructed.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalization and Equilibrium in Generative Adversarial Nets (GANs)\nAbstract: This paper makes progress on several open theoretical issues related to Generative Adversarial Networks. A definition is provided for what it means for the training to generalize, and it is shown that generalization is not guaranteed for the popular distances between distributions such as Jensen-Shannon or Wasserstein. We introduce a new metric called neural net distance for which generalization does occur. We also show that an approximate pure equilibrium in the 2-player game exists for a natural training objective (Wasserstein). Showing such a result has been an open problem (for any training objective). Finally, the above theoretical ideas lead us to propose a new training protocol, mix+gan, which can be combined with any existing method. We present experiments showing that it stabilizes and improves some existing methods.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Prior Swapping for Data-Independent Inference\nAbstract: While Bayesian methods are praised for their ability to incorporate useful prior knowledge, in practice, priors that allow for computationally convenient or tractable inference are more commonly used. In this paper, we investigate the following question: for a given model, is it possible to use any convenient prior to infer a false posterior, and afterwards, given some true prior of interest, quickly transform this result into the true posterior? We present a procedure to carry out this task: given an inferred false posterior and true prior, our algorithm generates samples from the true posterior. This transformation procedure, which we call \u201cprior swapping\u201d works for arbitrary priors. Notably, its cost is independent of data size. It therefore allows us, in some cases, to apply significantly less-costly inference procedures to more-sophisticated models than previously possible. It also lets us quickly perform any additional inferences, such as with updated priors or for many different hyperparameter settings, without touching the data. We prove that our method can generate asymptotically exact samples, and demonstrate it empirically on a number of models and priors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We show that the learning sample complexity of a sigmoidal neural network constructed by Sontag (1992) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast: for any prescribed rate of growth there is an input distribution having this rate as the sample complexity, and the bound is asymptotically tight. The rate can be superexponential, a nonrecursive function, etc. We further observe that Sontag\u2019s ANN is not Glivenko\u2013Cantelli under any input distribution having a non-atomic part. Keywords-PAC learnability, fixed distribution learning, sample complexity, infinite VC dimension, witness of irregularity, Sontag\u2019s ANN, precompactness.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian nonparametric models for ranked data\nAbstract: We develop a Bayesian nonparametric extension of the popular Plackett-Luce choice model that<lb>can handle an infinite number of choice items. Our framework is based on the theory of random atomic<lb>measures, with the prior specified by a gamma process. We derive a posterior characterization and a simple<lb>and effective Gibbs sampler for posterior simulation. We develop a time-varying extension of our model,<lb>and apply it to the New York Times lists of weekly bestselling books.<lb>Key-words: choice models, generalized Bradley-Terry model, Plackett-Luce model, gamma process,<lb>Markov Chain Monte Carlo \u2217 INRIA Bordeaux Sud-Ouest, Institut de Math\u00e9matiques de Bordeaux, University of Bordeaux, France<lb>\u2020 Department of Statistics, Oxford University, United Kingdom Mod\u00e8les bay\u00e9siens non param\u00e9triques pour les donn\u00e9es de rang<lb>R\u00e9sum\u00e9 : On s\u2019int\u00e9resse dans ce rapport \u00e0 une extension bay\u00e9sienne non param\u00e9trique du mod\u00e8le<lb>de Plackett-Luce pour les donn\u00e9es de rang, pouvant traiter un nombre potentiellement infini d\u2019\u00e9l\u00e9ments.<lb>Notre cadre se base sur la th\u00e9orie des mesures compl\u00e8tement al\u00e9atoires, avec comme a priori un processus<lb>de gamma. Nous d\u00e9rivons une caract\u00e9risation de la loi a posteriori et un \u00e9chantillonneur de Gibbs simple<lb>pour approcher la loi a posteriori. Nous d\u00e9veloppons \u00e9galement une version dynamique de notre mod\u00e8le,<lb>et l\u2019appliquons aux listes hebdomadaires des 20 meilleures ventes du New York Times.<lb>Mots-cl\u00e9s : Mod\u00e8les de choix, mod\u00e8le de Bradley-Terry g\u00e9n\u00e9ralis\u00e9, mod\u00e8le de Plackett-Luce, processus<lb>de gamma, m\u00e9thodes de Monte Carlo par cha\u0131\u0302ne de Markov Bayesian nonparametric models for ranked data<lb>3\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On End-to-End Program Generation from User Intention by Deep Neural Networks\nAbstract: This paper envisions an end-to-end program generation scenario using recurrent neural networks (RNNs): Users can express their intention in natural language; an RNN then automatically generates corresponding code in a characterby-character fashion. We demonstrate its feasibility through a case study and empirical analysis. To fully make such technique useful in practice, we also point out several crossdisciplinary challenges, including modeling user intention, providing datasets, improving model architectures, etc. Although much long-term research shall be addressed in this new field, we believe end-to-end program generation would become a reality in future decades, and we are looking forward to its practice.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning\nAbstract: We present a model of visually-grounded language learning based on stacked gated recurrent neural networks which learns to predict visual features given an image description in the form of a sequence of phonemes. The learning task resembles that faced by human language learners who need to discover both structure and meaning from noisy and ambiguous data across modalities. We show that our model indeed learns to predict features of the visual context given phonetically transcribed image descriptions, and show that it represents linguistic information in a hierarchy of levels: lower layers in the stack are comparatively more sensitive to form, whereas higher layers are more sensitive to meaning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adaptive Subgradient Methods for Online AUC Maximization\nAbstract: Learning for maximizing AUC performance is an important research problem in Machine Learning and Artificial Intelligence. Unlike traditional batch learning methods for maximizing AUC which often suffer from poor scalability, recent years have witnessed some emerging studies that attempt to maximize AUC by single-pass online learning approaches. Despite their encouraging results reported, the existing online AUC maximization algorithms often adopt simple online gradient descent approaches that fail to exploit the geometrical knowledge of the data observed during the online learning process, and thus could suffer from relatively larger regret. To address the above limitation, in this work, we explore a novel algorithm of Adaptive Online AUC Maximization (AdaOAM) which employs an adaptive gradient method that exploits the knowledge of historical gradients to perform more informative online learning. The new adaptive updating strategy of the AdaOAM is less sensitive to the parameter settings and maintains the same time complexity as previous non-adaptive counterparts. Additionally, we extend the algorithm to handle high-dimensional sparse data (SAdaOAM) and address sparsity in the solution by performing lazy gradient updating. We analyze the theoretical bounds and evaluate their empirical performance on various types of data sets. The encouraging empirical results obtained clearly highlighted the effectiveness and efficiency of the proposed algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Recently, nested dropout was proposed as a method for ordering representation units in autoencoders by their information content, without diminishing reconstruction cost (Rippel et al., 2014). However, it has only been applied to training fully-connected autoencoders in an unsupervised setting. We explore the impact of nested dropout on the convolutional layers in a CNN trained by backpropagation, investigating whether nested dropout can provide a simple and systematic way to determine the optimal representation size with respect to the desired accuracy and desired task and data complexity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Increasing the Action Gap: New Operators for Reinforcement Learning\nAbstract: This paper introduces new optimality-preserving operators on Q-functions. We first describe an operator for tabular representations, the consistent Bellman operator, which incorporates a notion of local policy consistency. We show that this local consistency leads to an increase in the action gap at each state; increasing this gap, we argue, mitigates the undesirable effects of approximation and estimation errors on the induced greedy policies. This operator can also be applied to discretized continuous space and time problems, and we provide empirical results evidencing superior performance in this context. Extending the idea of a locally consistent operator, we then derive sufficient conditions for an operator to preserve optimality, leading to a family of operators which includes our consistent Bellman operator. As corollaries we provide a proof of optimality for Baird\u2019s advantage learning algorithm and derive other gap-increasing operators with interesting properties. We conclude with an empirical study on 60 Atari 2600 games illustrating the strong potential of these new operators. Value-based reinforcement learning is an attractive solution to planning problems in environments with unknown, unstructured dynamics. In its canonical form, value-based reinforcement learning produces successive refinements of an initial value function through repeated application of a convergent operator. In particular, value iteration (Bellman 1957) directly computes the value function through the iterated evaluation of Bellman\u2019s equation, either exactly or from samples (e.g. Q-Learning, Watkins 1989). In its simplest form, value iteration begins with an initial value function V0 and successively computes Vk+1 := T Vk, where T is the Bellman operator. When the environment dynamics are unknown, Vk is typically replaced by Qk, the state-action value function, and T is approximated by an empirical Bellman operator. The fixed point of the Bellman operator, Q\u2217, is the optimal state-action value function or optimal Q-function, from which an optimal policy \u03c0\u2217 can be recovered. In this paper we argue that the optimal Q-function is inconsistent, in the sense that for any action a which is subop\u2217Now at Carnegie Mellon University. Copyright c \u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. timal in state x, Bellman\u2019s equation for Q\u2217(x, a) describes the value of a nonstationary policy: upon returning to x, this policy selects \u03c0\u2217(x) rather than a. While preserving global consistency appears impractical, we propose a simple modification to the Bellman operator which provides us a with a first-order solution to the inconsistency problem. Accordingly, we call our new operator the consistent Bellman operator. We show that the consistent Bellman operator generally devalues suboptimal actions but preserves the set of optimal policies. As a result, the action gap \u2013 the value difference between optimal and second best actions \u2013 increases. Increasing the action gap is advantageous in the presence of approximation or estimation error (Farahmand 2011), and may be crucial for systems operating at a fine time scale such as video games (Togelius et al. 2009; Bellemare et al. 2013), real-time markets (Jiang and Powell 2015), and robotic platforms (Riedmiller et al. 2009; Hoburg and Tedrake 2009; Deisenroth and Rasmussen 2011; Sutton et al. 2011). In fact, the idea of devaluating suboptimal actions underpins Baird\u2019s advantage learning (Baird 1999), designed for continuous time control, and occurs naturally when considering the discretized solution of continuous time and space MDPs (e.g. Munos and Moore 1998; 2002), whose limit is the Hamilton-Jacobi-Bellman equation (Kushner and Dupuis 2001). Our empirical results on the bicycle domain (Randlov and Alstrom 1998) show a marked increase in performance from using the consistent Bellman operator. In the second half of this paper we derive novel sufficient conditions for an operator to preserve optimality. The relative weakness of these new conditions reveal that it is possible to deviate significantly from the Bellman operator without sacrificing optimality: an optimality-preserving operator needs not be contractive, nor even guarantee convergence of the Q-values for suboptimal actions. While numerous alternatives to the Bellman operator have been put forward (e.g. recently Azar et al. 2011; Bertsekas and Yu 2012), we believe our work to be the first to propose such a major departure from the canonical fixed-point condition required from an optimality-preserving operator. As proof of the richness of this new operator family we describe a few practical instantiations with unique properties. We use our operators to obtain state-of-the-art empirical ar X iv :1 51 2. 04 86 0v 1 [ cs .A I] 1 5 D ec 2 01 5 results on the Arcade Learning Environment (Bellemare et al. 2013). We consider the Deep Q-Network (DQN) architecture of Mnih et al. (2015), replacing only its learning rule with one of our operators. Remarkably, this one-line change produces agents that significantly outperform the original DQN. Our work, we believe, demonstrates the potential impact of rethinking the core components of value-based reinforcement learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Optimal Black-Box Reductions Between Optimization Objectives\nAbstract: The diverse world of machine learning applications has given rise to a plethora of algorithms and optimization methods, finely tuned to the smoothness, convexity, and other parameterizations of the objective. In this paper we attempt to simplify and reduce the complexity of algorithm design for machine learning by reductions: we develop reductions that take a method developed for one setting and apply it to the entire spectrum of smoothness and strong-convexity found in practice. We show how these new reductions give rise to faster running times on training linear classifiers for certain families of loss functions, and that our reductions are optimal and cannot be improved in general. We conclude with experiments showing our reductions successfully transform methods between domains and achieve the desired performance predicted by theory.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Training Very Deep Networks\nAbstract: Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fast Exact k-Means, k-Medians and Bregman Divergence Clustering in 1D\nAbstract: The k-Means clustering problem on n points is NP-Hard for any dimension d \u2265 2, however, for the 1D case there exist exact polynomial time algorithms. Previous literature reported an O(kn) time dynamic programming algorithm that uses O(kn) space. We present a new algorithm computing the optimal clustering in only O(kn) time using linear space. For k = \u03a9(lg n), we improve this even further to n2 \u221a lg lgn lg k) time. We generalize the new algorithm(s) to work for the absolute distance instead of squared distance and to work for any Bregman Divergence as well. \u2217Aarhus University. Email: jallan@cs.au.dk. Supported by MADALGO Center for Massive Data Algorithmics, a Center of the Danish National Research Foundation. \u2020Aarhus University. Email: larsen@cs.au.dk. Supported by MADALGO, a Villum Young Investigator Grant and an AUFF Starting Grant. \u2021Aarhus University. Email: alexander.mathiasen@gmail.com. Supported by MADALGO and an AUFF Starting Grant. \u00a7Aarhus University. Email: jasn@cs.au.dk. Supported by MADALGO. \u00b6University of California, San Diego. Email: stschnei@cs.ucsd.edu. Supported by NSF grant CCF-1213151 from the Division of Computing and Communication Foundations. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. \u2016New Mexico State University. Email: joemsong@cs.nmsu.edu\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalized Multi-view Embedding for Visual Recognition and Cross-modal Retrieval\nAbstract: In this paper, the problem of multi-view embed-<lb>ding from different visual cues and modalities is considered.<lb>We propose a unified solution for subspace learning methods<lb>using the Rayleigh quotient, which is extensible for multiple<lb>views, supervised learning, and non-linear embeddings. Numer-<lb>ous methods including Canonical Correlation Analysis, Partial<lb>Least Square regression and Linear Discriminant Analysis are<lb>studied using specific intrinsic and penalty graphs within the<lb>same framework. Non-linear extensions based on kernels and<lb>(deep) neural networks are derived, achieving better performance<lb>than the linear ones. Moreover, a novel Multi-view Modular<lb>Discriminant Analysis (MvMDA) is proposed by taking the view<lb>difference into consideration. We demonstrate the effectiveness<lb>of the proposed multi-view embedding methods on visual object<lb>recognition and cross-modal image retrieval, and obtain superior<lb>results in both applications compared to related methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns\nAbstract: A function f : ZE+ \u2192 R+ is DR-submodular if it satisfies f(x+\u03c7i)\u2212f(x) \u2265 f(y+\u03c7i)\u2212f(y) for all x \u2264 y, i \u2208 E. Recently, the problem of maximizing a DR-submodular function f : ZE+ \u2192 R+ subject to a budget constraint \u2016x\u20161 \u2264 B as well as additional constraints has received significant attention [6, 7, 5, 8]. In this note, we give a generic reduction from the DR-submodular setting to the submodular setting. The running time of the reduction and the size of the resulting submodular instance depends only logarithmically on B. Using this reduction, one can translate the results for unconstrained and constrained submodular maximization to the DR-submodular setting for many types of constraints in a unified manner.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to Non-smooth Concave Maximization\nAbstract: Iterative Hard Thresholding (IHT) is a class of projected gradient descent methods for optimizing sparsity-constrained minimization models, with the best known efficiency and scalability in practice. As far as we know, the existing IHT-style methods are designed for sparse minimization in primal form. It remains open to explore duality theory and algorithms in such a non-convex and NP-hard problem setting. In this paper, we bridge this gap by establishing a duality theory for sparsity-constrained minimization with `2-regularized loss function and proposing an IHT-style algorithm for dual maximization. Our sparse duality theory provides a set of sufficient and necessary conditions under which the original NP-hard/non-convex problem can be equivalently solved in a dual formulation. The proposed dual IHT algorithm is a supergradient method for maximizing the non-smooth dual objective. An interesting finding is that the sparse recovery performance of dual IHT is invariant to the Restricted Isometry Property (RIP), which is required by virtually all the existing primal IHT algorithms without sparsity relaxation. Moreover, a stochastic variant of dual IHT is proposed for large-scale stochastic optimization. Numerical results demonstrate the superiority of dual IHT algorithms to the state-of-the-art primal IHT-style algorithms in model estimation accuracy and computational efficiency.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Decoupled Neural Interfaces using Synthetic Gradients\nAbstract: Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagating error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropagated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one\u2019s future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which are decoupled in both the forward and backwards pass \u2013 amounting to independent networks which co-learn such that they can be composed into a single functioning corporation.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Enriching Word Vectors with Subword Information\nAbstract: Continuous word representations, trained on<lb>large unlabeled corpora are useful for many<lb>natural language processing tasks. Many pop-<lb>ular models to learn such representations ig-<lb>nore the morphology of words, by assigning a<lb>distinct vector to each word. This is a limita-<lb>tion, especially for morphologically rich lan-<lb>guages with large vocabularies and many rare<lb>words. In this paper, we propose a new ap-<lb>proach based on the skip-gram model, where<lb>each word is represented as a bag of charac-<lb>ter n-grams. A vector representation is as-<lb>sociated to each character n-gram, words be-<lb>ing represented as the sum of these represen-<lb>tations. Our method is fast, allowing to train<lb>models on large corpus quickly. We evaluate<lb>the obtained word representations on five dif-<lb>ferent languages, on word similarity and anal-<lb>ogy tasks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Deep Learning for steganalysis is better than a Rich Model with an Ensemble Classifier, and is natively robust to the cover source-mismatch\nAbstract: Since the BOSS competition, in 2010, most steganalysis approaches use a learning methodology involving two steps: feature extraction, such as the Rich Models (RM), for the image representation, and use of the Ensemble Classifier (EC) for the learning step. In 2015, Qian et al. have shown that the use of a deep learning approach that jointly learns and computes the features, is very promising for the steganalysis. In this paper, we follow-up the study of Qian et al., and show that, due to intrinsic joint minimization, the results obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural Network (FNN), if well parameterized, surpass the conventional use of a RM with an EC. First, numerous experiments were conducted in order to find the best \u201dshape\u201d of the CNN. Second, experiments were carried out in the clairvoyant scenario in order to compare the CNN and FNN to an RM with an EC. The results show more than 16% reduction in the classification error with our CNN or FNN. Third, experiments were also performed in a cover-source mismatch setting. The results show that the CNN and FNN are naturally robust to the mismatch problem. In Addition to the experiments, we provide discussions on the internal mechanisms of a CNN, and weave links with some previously stated ideas, in order to understand the impressive results we obtained.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Applications of Online Deep Learning for Crisis Response Using Social Media Information\nAbstract: During natural or man-made disasters, humanitarian response organizations look for useful information to support their decisionmaking processes. Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management. Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task. In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: (i) identifying informative tweets and (ii) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. We test our models using a crisis-related real-world Twitter dataset.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analysis of Kernel Mean Matching under Covariate Shift\nAbstract: In real supervised learning scenarios, it is not uncommon that the training and test sample follow different probability distributions, thus rendering the necessity to correct the sampling bias. Focusing on a particular covariate shift problem, we derive high probability confidence bounds for the kernel mean matching (KMM) estimator, whose convergence rate turns out to depend on some regularity measure of the regression function and also on some capacity measure of the kernel. By comparing KMM with the natural plug-in estimator, we establish the superiority of the former hence provide concrete evidence/understanding to the effectiveness of KMM under covariate shift.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: As one of the simplest probabilistic topic modeling techniques, latent Dirichlet allocation (LDA) has found many important applications in text mining, computer vision and computational biology. Recent training algorithms for LDA can be interpreted within a unified message passing framework. However, message passing requires storing previous messages with a large amount of memory space, increasing linearly with the number of documents or the number of topics. Therefore, the high memory usage is often a major problem for topic modeling of massive corpora containing a large number of topics. To reduce the space complexity, we propose a novel algorithm without storing previous messages for training LDA: tiny belief propagation (TBP). The basic idea of TBP relates the message passing algorithms with the non-negative matrix factorization (NMF) algorithms, which absorb the message updating into the message passing process, and thus avoid storing previous messages. Experimental results on four large data sets confirm that TBP performs comparably well or even better than current state-of-the-art training algorithms for LDA but with a much less memory consumption. TBP can do topic modeling when massive corpora cannot fit in the computer memory, for example, extracting thematic topics from 7GB PUBMED corpora on a common desktop computer with 2GB memory.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets\nAbstract: Inference is typically intractable in high-treewidth undirected graphical models, making maximum likelihood learning a challenge. One way to overcome this is to restrict parameters to a tractable set, most typically the set of tree-structured parameters. This paper explores an alternative notion of a tractable set, namely a set of \u201cfast-mixing parameters\u201d where Markov chain Monte Carlo (MCMC) inference can be guaranteed to quickly converge to the stationary distribution. While it is common in practice to approximate the likelihood gradient using samples obtained from MCMC, such procedures lack theoretical guarantees. This paper proves that for any exponential family with bounded sufficient statistics, (not just graphical models) when parameters are constrained to a fast-mixing set, gradient descent with gradients approximated by sampling will approximate the maximum likelihood solution inside the set with high-probability. When unregularized, to find a solution \u01eb-accurate in log-likelihood requires a total amount of effort cubic in 1/\u01eb, disregarding logarithmic factors. When ridge-regularized, strong convexity allows a solution \u01eb-accurate in parameter distance with effort quadratic in 1/\u01eb. Both of these provide of a fully-polynomial time randomized approximation scheme.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Transfer from Multiple Linear Predictive State Representations (PSR)\nAbstract: In this paper we tackle the problem of transferring policy from multiple partially observable source environments to a partially observable target environment modeled as predictive state representation. This is an entirely new approach with no previous work, other than the case of transfer in fully observable domains. We develop algorithms to successfully achieve policy transfer when we have the model of both the source and target tasks and discuss in detail their performance and shortcomings. These algorithms could be a starting point for the field of transfer learning in partial observability.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: A generic and scalable Reinforcement Learning scheme for Artificial Neural Networks is presented,   providing a general purpose learning machine. By reference to a node threshold three features are  described 1) A mechanism for Primary Reinforcement, capable of solving linearly inseparable problems 2)   The learning scheme is extended to include a mechanism for Conditioned Reinforcement, capable of   forming long term strategy 3) The learning scheme is modified to use a threshold\u00adbased deep learning   algorithm, providing a robust and biologically inspired alternative to backpropagation. The model may be   used for supervised as well as unsupervised training regimes.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: DROW: Real-Time Deep Learning based Wheelchair Detection in 2D Range Data\nAbstract: We introduce the DROW detector, a deep learning based object detector operating on 2D range data. Laser scanners are lighting invariant, provide accurate 2D range data, and typically cover a large field of view, making them interesting sensors for robotics applications. So far, research on detection in laser 2D range data has been dominated by hand-crafted features and boosted classifiers, potentially losing performance due to suboptimal design choices. We propose a Convolutional Neural Network (CNN) based detector for this task. We show how to effectively apply CNNs for detection in 2D range data, and propose a depth preprocessing step and a voting scheme that significantly improve CNN performance. We demonstrate our approach on wheelchairs and walkers, obtaining state of the art detection results. Apart from the training data, none of our design choices limits the detector to these two classes, though. We provide a ROS node for our detector and release our dataset containing 464k laser scans, out of which 24k were annotated.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Gated Neural Networks for Option Pricing: Rationality by Design\nAbstract: We propose a neural network approach to price EU call options that significantly outperforms some existing pricing models and comes with guarantees that its predictions are economically reasonable. To achieve this, we introduce a class of gated neural networks that automatically learn to divide-and-conquer the problem space for robust and accurate pricing. We then derive instantiations of these networks that are \u2018rational by design\u2019 in terms of naturally encoding a valid call option surface that enforces no arbitrage principles. This integration of human insight within data-driven learning provides significantly better generalisation in pricing performance due to the encoded inductive bias in the learning, guarantees sanity in the model\u2019s predictions, and provides econometrically useful byproduct such as risk neutral density.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm\nAbstract: We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein\u2019s identity and a recently proposed kernelized Stein discrepancy, which is of independent interest.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Domain Adaptation with Soft-margin multiple feature-kernel learning beats Deep Learning for surveillance face recognition\nAbstract: Face recognition (FR) is the most preferred mode for biometric-based surveillance, due to its passive nature of detecting subjects, amongst all different types of biometric traits. FR under surveillance scenario does not give satisfactory performance due to low contrast, noise and poor illumination conditions on probes, as compared to the training samples. A state-of-the-art technology, Deep Learning, even fails to perform well in these scenarios. We propose a novel soft-margin based learning method for multiple feature-kernel combinations, followed by feature transformed using Domain Adaptation, which outperforms many recent state-of-the-art techniques, when tested using three real-world surveillance face datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Phoneme Classification in High-Dimensional Linear Feature Domains\nAbstract: Phoneme classification is investigated for linear feature domains with the aim of improving robustness to additive noise. In linear feature domains noise adaptation is exact, potentially leading to more accurate classification than representations involving non-linear processing and dimensionality reduction. A generative framework is developed for isolated phoneme classification using linear features. Initial results are shown for representations consisting of concatenated frames from the centre of the phoneme, each containing f frames. As phonemes have variable duration, no single f is optimal for all phonemes, therefore an average is taken over models with a range of values of f . Results are further improved by including information from the entire phoneme and transitions. In the presence of additive noise, classification in this framework performs better than an analogous PLP classifier, adapted to noise using cepstral mean and variance normalisation, below 18dB SNR. Finally we propose classification using a combination of acoustic waveform and PLP log-likelihoods. The combined classifier performs uniformly better than either of the individual classifiers across all noise levels.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Online Planning in MDPs: Rationality and Optimization\nAbstract: We consider online planning in Markov decision processes. An algorithm for this problem should explore the set of possible policies from the current state, and, when interrupted, recommend an action to follow based on the outcome of the exploration. The performance of such an algorithm is assessed in terms of its simple regret, that is the loss in performance resulting from choosing the recommended action instead of an optimal one, and/or in terms of probability that the recommended action is not an optimal one. The best guarantees provided by the state-of-the-art algorithms for reduction of these measures over time are only polynomial. We introduce a new algorithm, BRUE, that achieves over time exponential reduction of these two measures. The algorithm is based on a simple yet non-standard state-space sampling scheme in which different samples are dedicated to different objectives. Our preliminary empirical evaluation shows that BRUE not only provides superior performance guarantees, but is also very effective in practice and favorably compares to state-of-the-art.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Being Robust (in High Dimensions) Can Be Practical\nAbstract: Robust estimation is much more challenging in high dimensions than it is in one dimension: Most techniques either lead to intractable optimization problems or estimators that can tolerate only a tiny fraction of errors. Recent work in theoretical computer science has shown that, in appropriate distributional models, it is possible to robustly estimate the mean and covariance with polynomial time algorithms that can tolerate a constant fraction of corruptions, independent of the dimension. However, the sample and time complexity of these algorithms is prohibitively large for high-dimensional applications. In this work, we address both of these issues by establishing sample complexity bounds that are optimal, up to logarithmic factors, as well as giving various refinements that allow the algorithms to tolerate a much larger fraction of corruptions. Finally, we show on both synthetic and real data that our algorithms have state-of-the-art performance and suddenly make high-dimensional robust estimation a realistic possibility.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Fighting Bandits with a New Kind of Smoothness\nAbstract: We define a novel family of algorithms for the adversarial multi-armed bandit problem, and provide a simple analysis technique based on convex smoothing. We prove two main results. First, we show that regularization via the Tsallis entropy, which includes EXP3 as a special case, achieves the \u0398( \u221a TN) minimax regret. Second, we show that a wide class of perturbation methods achieve a near-optimal regret as low as O( \u221a TN logN) if the perturbation distribution has a bounded hazard rate. For example, the Gumbel, Weibull, Frechet, Pareto, and Gamma distributions all satisfy this key property.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Hash2Vec: Feature Hashing for Word Embeddings\nAbstract: In this paper we propose the application of feature hashing to create word embeddings for natural language processing. Feature hashing has been used successfully to create document vectors in related tasks like document classification. In this work we show that feature hashing can be applied to obtain word embeddings in linear time with the size of the data. The results show that this algorithm, that does not need training, is able to capture the semantic meaning of words. We compare the results against GloVe showing that they are similar. As far as we know this is the first application of feature hashing to the word embeddings problem and the results indicate this is a scalable technique with practical results for NLP applications.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Scalable Gradient-Based Tuning of  Continuous Regularization Hyperparameters\nAbstract: Hyperparameter selection generally relies on running multiple full training trials, with selection based on validation set performance. We propose a gradient-based approach for locally adjusting hyperparameters during training of the model. Hyperparameters are adjusted so as to make the model parameter gradients, and hence updates, more advantageous for the validation cost. We explore the approach for tuning regularization hyperparameters and find that in experiments on MNIST, SVHN and CIFAR-10, the resulting regularization levels are within the optimal regions. The additional computational cost depends on how frequently the hyperparameters are trained, but the tested scheme adds only 30% computational overhead regardless of the model size. Since the method is significantly less computationally demanding compared to similar gradientbased approaches to hyperparameter optimization, and consistently finds good hyperparameter values, it can be a useful tool for training neural network models.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Output Kernels for Multi-Task Problems\nAbstract: Simultaneously solving multiple related learning tasks is beneficial under a variety of circumstances, but the prior knowledge necessary to correctly model task relationships is rarely available in practice. In this paper, we develop a novel kernel-based multi-task learning technique that automatically reveals structural inter-task relationships. Building over the framework of output kernel learning (OKL), we introduce a method that jointly learns multiple functions and a low-rank multi-task kernel by solving a non-convex regularization problem. Optimization is carried out via a block coordinate descent strategy, where each subproblem is solved using suitable conjugate gradient (CG) type iterative methods for linear operator equations. The effectiveness of the proposed approach is demonstrated on pharmacological and collaborative filtering data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Ordered Representations with Nested Dropout\nAbstract: In this paper, we study ordered representations of data in which different dimensions have different degrees of importance. To learn these representations we introduce nested dropout, a procedure for stochastically removing coherent nested sets of hidden units in a neural network. We first present a sequence of theoretical results in the simple case of a semi-linear autoencoder. We rigorously show that the application of nested dropout enforces identifiability of the units, which leads to an exact equivalence with PCA. We then extend the algorithm to deep models and demonstrate the relevance of ordered representations to a number of applications. Specifically, we use the ordered property of the learned codes to construct hash-based data structures that permit very fast retrieval, achieving retrieval in time logarithmic in the database size and independent of the dimensionality of the representation. This allows codes that are hundreds of times longer than currently feasible for retrieval. We therefore avoid the diminished quality associated with short codes, while still performing retrieval that is competitive in speed with existing methods. We also show that ordered representations are a promising way to learn adaptive compression for efficient online data reconstruction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Normalization based K means Clustering Algorithm\nAbstract: K-means is an effective clustering technique used to separate similar data into groups based on initial centroids of clusters. In this paper, Normalization based K-means clustering algorithm(N-K means) is proposed. Proposed N-K means clustering algorithm applies normalization prior to clustering on the available data as well as the proposed approach calculates initial centroids based on weights. Experimental results prove the betterment of proposed N-K means clustering algorithm over existing K-means clustering algorithm in terms of complexity and overall performance. KeywordsClustering, Data mining, K means, Normalization, Weighted Average\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We consider the online sparse linear regression problem, which is the problem of sequentially making predictions observing only a limited number of features in each round, to minimize regret with respect to the best sparse linear regressor, where prediction accuracy is measured by square loss. We give an inefficient algorithm that obtains regret bounded by \u00d5( \u221a T ) after T prediction rounds. We complement this result by showing that no algorithm running in polynomial time per iteration can achieve regret bounded by O(T 1\u2212\u03b4) for any constant \u03b4 > 0 unless NP \u2286 BPP. This computational hardness result resolves an open problem presented in COLT 2014 (Kale, 2014) and also posed by Zolghadr et al. (2013). This hardness result holds even if the algorithm is allowed to access more features than the best sparse linear regressor up to a logarithmic factor in the dimension.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models\nAbstract: Batch Normalization is quite effective at accelerating and improving the training of deep models. However, its effectiveness diminishes when the training minibatches are small, or do not consist of independent samples. We hypothesize that this is due to the dependence of model layer inputs on all the examples in the minibatch, and different activations being produced between training and inference. We propose Batch Renormalization, a simple and effective extension to ensure that the training and inference models generate the same outputs that depend on individual examples rather than the entire minibatch. Models trained with Batch Renormalization perform substantially better than batchnorm when training with small or non-i.i.d. minibatches. At the same time, Batch Renormalization retains the benefits of batchnorm such as insensitivity to initialization and training efficiency.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recurrent Neural Network Encoder with Attention for Community Question Answering\nAbstract: We apply a general recurrent neural network (RNN) encoder framework to community question answering (cQA) tasks. Our approach does not rely on any linguistic processing, and can be applied to different languages or domains. Further improvements are observed when we extend the RNN encoders with a neural attention mechanism that encourages reasoning over entire sequences. To deal with practical issues such as data sparsity and imbalanced labels, we apply various techniques such as transfer learning and multitask learning. Our experiments on the SemEval-2016 cQA task show 10% improvement on a MAP score compared to an information retrieval-based approach, and achieve comparable performance to a strong handcrafted feature-based method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Strategic Dialogue Management via Deep Reinforcement Learning\nAbstract: Artificially intelligent agents equipped with strategic skills that can negotiate during their interactions with other natural or artificial agents are still underdeveloped. This paper describes a successful application of Deep Reinforcement Learning (DRL) for training intelligent agents with strategic conversational skills, in a situated dialogue setting. Previous studies have modelled the behaviour of strategic agents using supervised learning and traditional reinforcement learning techniques, the latter using tabular representations or learning with linear function approximation. In this study, we apply DRL with a high-dimensional state space to the strategic board game of Settlers of Catan\u2014where players can offer resources in exchange for others and they can also reply to offers made by other players. Our experimental results report that the DRL-based learnt policies significantly outperformed several baselines including random, rule-based, and supervised-based behaviours. The DRL-based policy has a 53% win rate versus 3 automated players (\u2018bots\u2019), whereas a supervised player trained on a dialogue corpus in this setting achieved only 27%, versus the same 3 bots. This result supports the claim that DRL is a promising framework for training dialogue systems, and strategic agents with negotiation abilities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: \uf020 Abstract \u2014 In machine learning, the use of an artificial neural network is the mainstream approach. Such a network consists of layers of neurons. These neurons are of the same type characterized by the two features: (1) an inner product of an input vector and a matching weighting vector of trainable parameters and (2) a nonlinear excitation function. Here we investigate the possibility of replacing the inner product with a quadratic function of the input vector, thereby upgrading the 1 order neuron to the 2 order neuron, empowering individual neurons, and facilitating the optimization of neural networks. Also, numerical examples are provided to illustrate the feasibility and merits of the 2 order neurons. Finally, further topics are discussed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Large Scale Variational Bayesian Inference for  Structured Scale Mixture Models\nAbstract: Natural image statistics exhibit hierarchical dependencies across multiple scales. Representing such prior knowledge in non-factorial latent tree models can boost performance of image denoising, inpainting, deconvolution or reconstruction substantially, beyond standard factorial \u201csparse\u201d methodology. We derive a large scale approximate Bayesian inference algorithm for linear models with nonfactorial (latent tree-structured) scale mixture priors. Experimental results on a range of denoising and inpainting problems demonstrate substantially improved performance compared to MAP estimation or to inference with factorial priors.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Visual and semantic interpretability of projections of high dimensional data for classification tasks\nAbstract: A number of visual quality measures have been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. These methods generally concentrate on the interpretability of the visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration of high dimensional labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first study how humans judge the quality of 2D scatterplots of various datasets with varying number of classes and provide comparisons with ten automated measures, including a number of visual quality measures and related measures from various machine learning fields. We then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. We conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Out-of-sample generalizations for supervised manifold learning for classification\nAbstract: Supervised manifold learning methods for data classification map data samples residing in a high-dimensional ambient space to a lower-dimensional domain in a structurepreserving way, while enhancing the separation between different classes in the learned embedding. Most nonlinear supervised manifold learning methods compute the embedding of the manifolds only at the initially available training points, while the generalization of the embedding to novel points, known as the out-of-sample extension problem in manifold learning, becomes especially important in classification applications. In this work, we propose a semi-supervised method for building an interpolation function that provides an out-of-sample extension for general supervised manifold learning algorithms studied in the context of classification. The proposed algorithm computes a radial basis function (RBF) interpolator that minimizes an objective function consisting of the total embedding error of unlabeled test samples, defined as their distance to the embeddings of the manifolds of their own class, as well as a regularization term that controls the smoothness of the interpolation function in a direction-dependent way. The class labels of test data and the interpolation function parameters are estimated jointly with a progressive procedure. Experimental results on face and object images demonstrate the potential of the proposed out-of-sample extension algorithm for the classification of manifold-modeled data sets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Characterization of Prediction Errors\nAbstract: Understanding prediction errors and determining how to fix them is critical to building effective predictive systems. In this paper, we delineate four types of prediction errors (mislabeling, representation, learner and boundary errors) and demonstrate that these four types characterize all prediction errors. In addition, we describe potential remedies and tools that can be used to reduce the uncertainty when trying to determine the source of a prediction error and when trying to take action to remove a prediction error.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The k-center problem is a canonical and long-studied facility location and clustering problem with many applications in both its symmetric and asymmetric forms. Both versions of the problem have tight approximation factors on worst case instances: a 2-approximation for symmetric k-center and a log\u2217(k)approximation for the asymmetric version. Therefore to improve on these ratios, one must go beyond the worst case. In this work, we take this approach and provide strong positive results both for the asymmetric and symmetric k-center problems under two very natural input stability (promise) conditions. We consider both the \u03b1-perturbation resilience notion of Bilu and Linial [11], which states that the optimal solution does not change under any \u03b1-factor perturbation to the input distances, and the (\u03b1, )approximation stability notion of Balcan et al. [6], which states that any \u03b1-approximation to the cost of the optimal solution should be -close in the solution space (i.e., the partitioning) to the optimal solution. We show that by merely assuming 3-perturbation resilience or (2, 0)-approximation stability, the exact solution for the asymmetric k-center problem can be found in polynomial time. To our knowledge, this is the first problem that is hard to approximate to any constant factor in the worst case, yet can be optimally solved in polynomial time under perturbation resilience for a constant value of \u03b1. In the case of 2approximation stability, we prove our result is tight by showing k-center under (2 \u2212 )-approximation stability is hard unless NP = RP . For the case of symmetric k-center, we give an efficient algorithm to cluster 2-perturbation resilient instances. Our results illustrate a surprising relation between symmetric and asymmetric k-center instances under these stability conditions. Unlike approximation ratio, for which symmetric k-center is easily solved to a factor of 2 but asymmetric k-center cannot be approximated to any constant factor, both symmetric and asymmetric k-center can be solved optimally under resilience to small constant-factor perturbations. \u2217Authors\u2019 addresses: {ninamf,nhaghtal,crwhite}@cs.cmu.edu. ar X iv :1 50 5. 03 92 4v 1 [ cs .D S] 1 4 M ay 2 01 5\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Structured Learning from Partial Annotations\nAbstract: Structured learning is appropriate when predicting structured outputs such as trees, graphs, or sequences. Most prior work requires the training set to consist of complete trees, graphs or sequences. Specifying such detailed ground truth can be tedious or infeasible for large outputs. Our main contribution is a large margin formulation that makes structured learning from only partially annotated data possible. The resulting optimization problem is non-convex, yet can be efficiently solve by concave-convex procedure (CCCP) with novel speedup strategies. We apply our method to a challenging trackingby-assignment problem of a variable number of divisible objects. On this benchmark, using only 25% of a full annotation we achieve a performance comparable to a model learned with a full annotation. Finally, we offer a unifying perspective of previous work using the hinge, ramp, or max loss for structured learning, followed by an empirical comparison on their practical performance.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Incremental sequence learning\nAbstract: Deep learning research over the past years has shown that by increasing the scope or difficulty of the learning problem over time, increasingly complex learning problems can be addressed. We study incremental learning in the context of sequence learning, using generative RNNs in the form of multi-layer recurrent Mixture Density Networks. We introduce Incremental Sequence Learning, a simple incremental approach to sequence learning. Incremental Sequence Learning starts out by using only the first few steps of each sequence as training data. Each time a performance criterion has been reached, the length of the parts of the sequences used for training is increased. To evaluate Incremental Sequence Learning and comparison methods, we introduce and make available a novel sequence learning task and data set: predicting and classifying MNIST pen stroke sequences, where the familiar handwritten digit images have been transformed to pen stroke sequences representing the skeletons of the digits. We find that Incremental Sequence Learning greatly speeds up sequence learning and reaches the best test performance level of regular sequence learning 20 times faster, reduces the test error by 74%, and in general performs more robustly; it displays lower variance and achieves sustained progress after all three comparison method have stopped improving. A trained sequence prediction model is also used in transfer learning to the task of sequence classification, where it is found that transfer learning realizes improved classification performance compared to methods that learn to classify from scratch.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Sequential Learning without Feedback\u2217\nAbstract: In many security and healthcare systems a sequence of features/sensors/tests are used for detection and diagnosis. Each test outputs a prediction of the latent state, and carries with it inherent costs. Our objective is to learn strategies for selecting tests to optimize accuracy & costs. Unfortunately it is often impossible to acquire-in-situ ground truth annotations and we are left with the problem of unsupervised sensor selection (USS). We pose USS as a version of stochastic partial monitoring problem with an unusual reward structure (even noisy annotations are unavailable). Unsurprisingly no learner can achieve sublinear regret without further assumptions. To this end we propose the notion of weak-dominance. This is a condition on the joint probability distribution of test outputs and latent state and says that whenever a test is accurate on an example, a later test in the sequence is likely to be accurate as well.We empirically verify that weak dominance holds on real datasets and prove that it is a maximal condition for achieving sublinear regret. We reduce USS to a special case of multi-armed bandit problem with side information and develop polynomial time algorithms that achieve sublinear regret.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Rank Aggregation for Course Sequence Discovery\nAbstract: In this work, we adapt the rank aggregation framework for the discovery of optimal course sequences at the university level. Each student provides a partial ranking of the courses taken throughout his or her undergraduate career. We compute pairwise rank comparisons between courses based on the order students typically take them, aggregate the results over the entire student population, and then obtain a proxy for the rank offset between pairs of courses. We extract a global ranking of the courses via several state-of-the art algorithms for ranking with pairwise noisy information, including SerialRank, Rank Centrality, and the recent SyncRank based on the group synchronization problem. We test this application of rank aggregation on 15 years of student data from the Department of Mathematics at the University of California, Los Angeles (UCLA). Furthermore, we experiment with the above approach on different subsets of the student population conditioned on final GPA, and highlight several differences in the obtained rankings that uncover hidden pre-requisites in the Mathematics curriculum.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We study the design of pricing mechanisms and auctions when the mechanism designer does not know the distribution of buyers\u2019 values. Instead the mechanism designer receives a set of samples from this distribution and his goal is to use the sample to design a pricing mechanism or auction with high expected profit. We provide generalization guarantees which bound the difference between average profit on the sample and expected profit over the distribution. These bounds are directly proportional to the intrinsic complexity of the mechanism class the designer is optimizing over. We present a single, overarching theorem that uses empirical Rademacher complexity to measure the intrinsic complexity of a variety of widely-studied singleand multi-item auction classes, including affine maximizer auctions, mixed-bundling auctions, and second-price item auctions. This all-encompassing theorem also applies to multiand singleitem pricing mechanisms in both multiand single-unit settings, such as linear and non-linear pricing mechanisms. Despite the extensive applicability of our main theorem, we match and improve over the best-known generalization guarantees for many mechanism classes. Finally, our central theorem allows us to easily derive generalization guarantees for every class in several finely grained hierarchies of auction and pricing mechanism classes. We demonstrate how to determine the precise level in a hierarchy with the optimal tradeoff between profit and generalization using structural profit maximization. The mechanism classes we study are significantly different from well-understood function classes typically found in machine learning, so bounding their complexity requires a sharp understanding of the interplay between mechanism parameters and buyer valuations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dropout Training for Support Vector Machines\nAbstract: Dropout and other feature noising schemes have shown promising results in controlling over-fitting by artificially corrupting the training data. Though extensive theoretical and empirical studies have been performed for generalized linear models, little work has been done for support vector machines (SVMs), one of the most successful approaches for supervised learning. This paper presents dropout training for linear SVMs. To deal with the intractable expectation of the non-smooth hinge loss under corrupting distributions, we develop an iteratively re-weighted least square (IRLS) algorithm by exploring data augmentation techniques. Our algorithm iteratively minimizes the expectation of a re-weighted least square problem, where the re-weights have closedform solutions. The similar ideas are applied to develop a new IRLS algorithm for the expected logistic loss under corrupting distributions. Our algorithms offer insights on the connection and difference between the hinge loss and logistic loss in dropout training. Empirical results on several real datasets demonstrate the effectiveness of dropout training on significantly boosting the classification accuracy of linear SVMs. Introduction Artificial feature noising augments the finite training data with an infinite number of corrupted versions, by corrupting the given training examples with a fixed noise distribution. Among the many noising schemes, dropout training (Hinton et al. 2012) is an effective way to control over-fitting by randomly omitting subsets of features at each iteration of a training procedure. By formulating the feature noising methods as minimizing the expectation of some loss functions under the corrupting distributions, recent work has provided theoretical understandings of such schemes from the perspective of adaptive regularization (Wager, Wang, and Liang 2013); and has shown promising empirical results in various applications, including document classification (van der Maaten et al. 2013; Wager, Wang, and Liang 2013), named entity recognition (Wang et al. 2013), and image classification (Wang and Manning 2013). Regarding the loss functions, though much work has been done on the quadratic loss, logistic loss, or the log-loss Copyright c \u00a9 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. induced from a generalized linear model (GLM) (van der Maaten et al. 2013; Wager, Wang, and Liang 2013; Wang et al. 2013), little work has been done on the margin-based hinge loss underlying the very successful support vector machines (SVMs) (Vapnik 1995). One technical challenge is that the non-smoothness of the hinge loss makes it hard to compute or even approximate its expectation under a given corrupting distribution. Existing methods are not directly applicable, therefore calling for new solutions. This paper attempts to address this challenge and fill up the gap by extending dropout training as well as other feature noising schemes to support vector machines. Previous efforts on learning SVMs with feature noising have been devoted to either explicit corruption or an adversarial worst-case analysis. For example, virtual support vector machines (Burges and Scholkopf 1997) explicitly augment the training data, which are usually support vectors from previous learning iterations for computational efficiency, with additional examples that are corrupted through some invariant transformation models. A standard SVM is then learned on the corrupted data. Though simple and effective, such an approach lacks elegance and the computational cost of processing the additional corrupted examples could be prohibitive for many applications. The other work (Globerson and Roweis 2006; Dekel and Shamir 2008; Teo et al. 2008) adopts an adversarial worst-case analysis to improve the robustness of SVMs against feature deletion in testing data. Though rigorous in theory, a worst-case scenario is unlikely to be encountered in practice. Moreover, the worst-case analysis usually results in solving a complex and computationally demanding problem. In this paper, we show that it is efficient to train linear SVM predictors on an infinite amount of corrupted copies of the training data by marginalizing out the corruption distributions, an average-case analysis. We concentrate on dropout training, but the results are directly applicable to other noising models, such as Gaussian, Poisson and Laplace (van der Maaten et al. 2013). For all these noising schemes, the resulting expected hinge loss can be upperbounded by a variational objective by introducing auxiliary variables, which follow a generalized inverse Gaussian distribution. We then develop an iteratively re-weighted least square (IRLS) algorithm to minimize the variational bounds. At each iteration, our algorithm minimizes the exar X iv :1 40 4. 41 71 v1 [ cs .L G ] 1 6 A pr 2 01 4 pectation of a re-weighted quadratic loss under the given corrupting distribution, where the re-weights are computed in a simple closed form. We further apply the similar ideas to develop a new IRLS algorithm for the dropout training of logistic regression, which extends the well-known IRLS algorithm for standard logistic regression (Hastie, Tibshirani, and Friedman 2009). Our IRLS algorithms shed light on the connection and difference between the hinge loss and logistic loss in the context of dropout training, complementing to the previous analysis (Rosasco et al. 2004; Globerson et al. 2007) in the supervised learning settings. Finally, empirical results on classification and a challenging \u201cnightmare at test time\u201d scenario (Globerson and Roweis 2006) demonstrate the effectiveness of our approaches, in comparison with various strong competitors. Preliminaries We setup the problem in question and review the learning with marginalized corrupted features. Regularized loss minimization Consider the binary classification, where each training example is a pair (x, y) with x \u2208 R being an input feature vector and y \u2208 {+1,\u22121} being a binary label. Given a set of training data D = {(xn, yn)}n=1, supervised learning aims to find a function f \u2208 F that maps each input to a label. To find the optimal candidate, it commonly solves a regularized loss minimization problem min f\u2208F \u03a9(f) + 2c \u00b7 R(D; f), (1) whereR(D; f) is the risk of applying f to the training data; \u03a9(f) is a regularization term to control over-fitting; and c is a non-negative regularization parameter. For linear models, the function f is simply parameterized as f(x;w, b) = w>x+ b, where w is the weight vector and b is an offset. We will denote \u03b8 := {w, b} for clarity. Then, the regularization can be any Euclidean norms1, e.g., the `2-norm, \u03a9(w) = \u2016w\u20162, or the `1-norm, \u03a9(w) = \u2016w\u20161. For the loss functions, the most relevant measure is the training error, \u2211N n=1 \u03b4(f(xn;\u03b8) 6= yn), which however is not easy to optimize. A convex surrogate loss is used instead, which normally upper bounds the training error. Two popular examples are the hinge loss and logistic loss2:\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: BliStr: The Blind Strategymaker pdfauthor=Josef Urban pdfkeywords=automated theorem proving, interactive theorem proving, machine learning, proof analysis, formal mathematics, mizar\nAbstract: BliStr is a system that automatically develops strategies for E prover on a large set of problems. The main idea is to interleave (i) iterated low-timelimit local search for new strategies on small sets of similar easy problems with (ii) higher-timelimit evaluation of the new strategies on all problems. The accummulated results of the global higher-timelimit runs are used to define and evolve the notion of \u201csimilar easy problems\u201d, and to control the selection of the next strategy to be improved. The technique was used to significantly strengthen the set of E strategies used by the MaLARea, PS-E, E-MaLeS, and E systems in the CASC@Turing 2012 competition, particularly in the Mizar division. Similar improvement was obtained on the problems created from the Flyspeck corpus.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dimensionality Reduction with Subspace Structure Preservation\nAbstract: Modeling data as being sampled from a union of independent subspaces has been widely applied to a number of real world applications. However, dimensionality reduction approaches that theoretically preserve this independence assumption have not been well studied. Our key contribution is to show that 2K projection vectors are sufficient for the independence preservation of any K class data sampled from a union of independent subspaces. It is this non-trivial observation that we use for designing our dimensionality reduction technique. In this paper, we propose a novel dimensionality reduction algorithm that theoretically preserves this structure for a given dataset. We support our theoretical analysis with empirical results on both synthetic and real world data achieving state-of-the-art results compared to popular dimensionality reduction techniques.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Embedding Lexical Features via Low-Rank Tensors\nAbstract: Modern NLP models rely heavily on engineered features, which often combine word and contextual information into complex lexical features. Such combination results in large numbers of features, which can lead to overfitting. We present a new model that represents complex lexical features\u2014comprised of parts for words, contextual information and labels\u2014in a tensor that captures conjunction information among these parts. We apply lowrank tensor approximations to the corresponding parameter tensors to reduce the parameter space and improve prediction speed. Furthermore, we investigate two methods for handling features that include n-grams of mixed lengths. Our model achieves state-of-the-art results on tasks in relation extraction, PPattachment, and preposition disambiguation.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A PAC-Bayesian Tutorial with A Dropout Bound\nAbstract: This tutorial gives a concise overview of existing PAC-Bayesian theory focusing on three generalization bounds. The first is an Occam bound which handles rules with finite precision parameters and which states that generalization loss is near training loss when the number of bits needed to write the rule is small compared to the sample size. The second is a PAC-Bayesian bound providing a generalization guarantee for posterior distributions rather than for individual rules. The PAC-Bayesian bound naturally handles infinite precision rule parameters, L2 regularization, provides a bound for dropout training, and defines a natural notion of a single distinguished PAC-Bayesian posterior distribution. The third bound is a training-variance bound \u2014 a kind of bias-variance analysis but with bias replaced by expected training loss. The training-variance bound dominates the other bounds but is more difficult to interpret. It seems to suggest variance reduction methods such as bagging and may ultimately provide a more meaningful analysis of dropouts.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An optimal algorithm for bandit convex optimization\nAbstract: We consider the problem of online convex optimization against an arbitrary adversary with bandit feedback, known as bandit convex optimization. We give the first \u00d5( \u221a T )-regret algorithm for this setting based on a novel application of the ellipsoid method to online learning. This bound is known to be tight up to logarithmic factors. Our analysis introduces new tools in discrete convex geometry.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention\nAbstract: Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable they should provide easy-tointerpret rationales for their behavior so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network\u2019s output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolution network endto-end from images to steering angle. The attention model highlights image regions that potentially influence the network\u2019s output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network\u2019s behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 hours of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network causally cues on a variety of features that are used by humans while driving.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exploiting Restricted Boltzmann Machines and Deep Belief Networks in Compressed Sensing\nAbstract: This paper proposes a CS scheme that exploits the representational power of restricted Boltzmann machines and deep learning architectures to model the prior distribution of the sparsity pattern of signals belonging to the same class. The determined probability distribution is then used in a maximum a posteriori (MAP) approach for the reconstruction. The parameters of the prior distribution are learned from training data. The motivation behind this approach is to model the higher\u2013order statistical dependencies between the coefficients of the sparse representation, with the final goal of improving the reconstruction. The performance of the proposed method is validated on the Berkeley Segmentation Dataset and the MNIST Database of handwritten digits.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Improving Frame Semantic Parsing with Hierarchical Dialogue Encoders\nAbstract: Conversational Language Understanding (CLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally CLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Hierarchical Dialogue Encoder Network, that allows encoding context from the dialogue history in chronological order. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed architecture results in reduced semantic frame error rates.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Vision-Based Deep Reinforcement Learning for Robotic Motion Control\nAbstract: This paper introduces a machine learning based system for controlling a robotic manipulator with visual perception only. The capability to autonomously learn robot controllers solely from raw-pixel images and without any prior knowledge of configuration is shown for the first time. We build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three-joint robot manipulator using external visual observation. A Deep Q Network (DQN) was demonstrated to perform target reaching after training in simulation. Transferring the network to real hardware and real observation in a naive approach failed, but experiments show that the network works when replacing camera images with synthetic images.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ASKIT: APPROXIMATE SKELETONIZATION KERNEL-INDEPENDENT TREECODE IN HIGH DIMENSIONS\nAbstract: We present a fast algorithm for kernel summation problems in high-dimensions. These problems appear in computational physics, numerical approximation, non-parametric statistics, and machine learning. In our context, the sums depend on a kernel function that is a pair potential defined on a dataset of points in a high-dimensional Euclidean space. A direct evaluation of the sum scales quadratically with the number of points. Fast kernel summation methods can reduce this cost to linear complexity, but the constants involved do not scale well with the dimensionality of the dataset. The main algorithmic components of fast kernel summation algorithms are the separation of the kernel sum between near and far field (which is the basis for pruning) and the efficient and accurate approximation of the far field. We introduce novel methods for pruning and for approximating the far field. Our far field approximation requires only kernel evaluations and does not use analytic expansions. Pruning is not done using bounding boxes but rather combinatorially using a sparsified nearest-neighbor graph of the input distribution. The time complexity of our algorithm depends linearly on the ambient dimension. The error in the algorithm depends on the low-rank approximability of the far field, which in turn depends on the kernel function and on the intrinsic dimensionality of the distribution of the points. The error of the far field approximation does not depend on the ambient dimension. We present the new algorithm along with experimental results that demonstrate its performance. As a highlight, we report results for Gaussian kernel sums for 100 million points in 64 dimensions, for one million points in 1000 dimensions, and for problems in which the Gaussian kernel has a variable bandwidth. To the best of our knowledge, all of these experiments are impossible or prohibitively expensive with existing fast kernel summation methods.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning with the Weighted Trace-norm under Arbitrary Sampling Distributions\nAbstract: We provide rigorous guarantees on learning with the weighted trace-norm under arbitrary<lb>sampling distributions. We show that the standard weighted trace-norm might fail when the<lb>sampling distribution is not a product distribution (i.e. when row and column indexes are<lb>not selected independently), present a corrected variant for which we establish strong learning<lb>guarantees, and demonstrate that it works better in practice. We provide guarantees when<lb>weighting by either the true or empirical sampling distribution, and suggest that even if the<lb>true distribution is known (or is uniform), weighting by the empirical distribution may be<lb>beneficial.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Machine learning based computational intelligence methods are widely used to analyze large scale data sets in this age of big data. Extracting useful predictive modeling from these types of data sets is a challenging problem due to their high complexity. Analyzing large amount of streaming data that can be leveraged to derive business value is another complex problem to solve. With high levels of data availability (i.e. Big Data) automatic classification of them has become an important and complex task. Hence, we explore the power of applying MapReduce based Distributed AdaBoosting of Extreme Learning Machine (ELM) to build a predictive bag of classification models. Accordingly, (i) data set ensembles are created; (ii) ELM algorithm is used to build weak learners (classifier functions); and (iii) builds a strong learner from a set of weak learners. We applied this training model to the benchmark knowledge discovery and data mining data sets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: AUTOMATIC TAGGING USING DEEP CONVOLUTIONAL NEURAL NETWORKS\nAbstract: We present a content-based automatic music tagging algorithm using fully convolutional neural networks (FCNs). We evaluate different architectures consisting of 2D convolutional layers and subsampling layers only. In the experiments, we measure the AUC-ROC scores of the architectures with different complexities and input types using the MagnaTagATune dataset, where a 4-layer architecture shows state-of-the-art performance with mel-spectrogram input. Furthermore, we evaluated the performances of the architectures with varying the number of layers on a larger dataset (Million Song Dataset), and found that deeper models outperformed the 4-layer architecture. The experiments show that mel-spectrogram is an effective time-frequency representation for automatic tagging and that more complex models benefit from more training data.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed Transfer Linear Support Vector Machines\nAbstract: Transfer learning has been developed to improve the performances of different but related tasks in machine learning. However, such processes become less efficient with the increase of the size of training data and the number of tasks. Moreover, privacy can be violated as some tasks may contain sensitive and private data, which are communicated between nodes and tasks. We propose a consensus-based distributed transfer learning framework, where several tasks aim to find the best linear support vector machine (SVM) classifiers in a distributed network. With alternating direction method of multipliers, tasks can achieve better classification accuracies more efficiently and privately, as each node and each task train with their own data, and only decision variables are transferred between different tasks and nodes. Numerical experiments on MNIST datasets show that the knowledge transferred from the source tasks can be used to decrease the risks of the target tasks that lack training data or have unbalanced training labels. We show that the risks of the target tasks in the nodes without the data of the source tasks can also be reduced using the information transferred from the nodes who contain the data of the source tasks. We also show that the target tasks can enter and leave in real-time without rerunning the whole algorithm.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Truth and Regret in Online Scheduling\nAbstract: We consider a scheduling problem where a cloud service provider has multiple units of a resource available over time. Selfish clients submit jobs, each with an arrival time, deadline, length, and value. The service provider\u2019s goal is to implement a truthful online mechanism for scheduling jobs so as to maximize the social welfare of the schedule. Recent work shows that under a stochastic assumption on job arrivals, there is a single-parameter family of mechanisms that achieves near-optimal social welfare. We show that given any such family of near-optimal online mechanisms, there exists an online mechanism that in the worst case performs nearly as well as the best of the given mechanisms. Our mechanism is truthful whenever the mechanisms in the given family are truthful and prompt, and achieves optimal (within constant factors) regret. We model the problem of competing against a family of online scheduling mechanisms as one of learning from expert advice. A primary challenge is that any scheduling decisions we make affect not only the payoff at the current step, but also the resource availability and payoffs in future steps. Furthermore, switching from one algorithm (a.k.a. expert) to another in an online fashion is challenging both because it requires synchronization with the state of the latter algorithm as well as because it affects the incentive structure of the algorithms. We further show how to adapt our algorithm to a non-clairvoyant setting where job lengths are unknown until jobs are run to completion. Once again, in this setting, we obtain truthfulness along with asymptotically optimal regret (within polylogarithmic factors). 1 ar X iv :1 70 3. 00 48 4v 1 [ cs .G T ] 1 M ar 2 01 7\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Causality-Aided Falsification\nAbstract: Falsification is drawing attention in quality assurance of heterogeneous systems whose complexities are beyond most verification techniques\u2019 scalability. In this paper we introduce the idea of causality aid in falsification: by providing a falsification solver\u2014that relies on stochastic optimization of a certain cost function\u2014with suitable causal information expressed by a Bayesian network, search for a falsifying input value can be efficient. Our experiment results show the idea\u2019s viability.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Gossip Dual Averaging for Decentralized Optimization of  Pairwise Functions\nAbstract: In decentralized networks (of sensors, connected objects, etc.), there is an important need for efficient algorithms to optimize a global cost function, for instance to learn a global model from the local data collected by each computing unit. In this paper, we address the problem of decentralized minimization of pairwise functions of the data points, where these points are distributed over the nodes of a graph defining the communication topology of the network. This general problem finds applications in ranking, distance metric learning and graph inference, among others. We propose new gossip algorithms based on dual averaging which aims at solving such problems both in synchronous and asynchronous settings. The proposed framework is flexible enough to deal with constrained and regularized variants of the optimization problem. Our theoretical analysis reveals that the proposed algorithms preserve the convergence rate of centralized dual averaging up to an additive bias term. We present numerical simulations on Area Under the ROC Curve (AUC) maximization and metric learning problems which illustrate the practical interest of our approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Max-Entropy Feed-Forward Clustering Neural Network\nAbstract: The outputs of non-linear feed-forward neural network are positive, which could be treated as probability when they are normalized to one. If we take Entropy-Based Principle into consideration, the outputs for each sample could be represented as the distribution of this sample for different clusters. Entropy-Based Principle is the principle with which we could estimate the unknown distribution under some limited conditions. As this paper defines two processes in Feed-Forward Neural Network, our limited condition is the abstracted features of samples which are worked out in the abstraction process. And the final outputs are the probability distribution for different clusters in the clustering process. As Entropy-Based Principle is considered into the feed-forward neural network, a clustering method is born. We have conducted some experiments on six open UCI datasets, comparing with a few baselines and applied purity as the measurement . The results illustrate that our method outperforms all the other baselines that are most popular clustering methods. Keywords\u2014Feed-Forward Neural Network, Clustering, Max-Entropy Principle, Probabilistic Models\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Modeling Images using Transformed Indian Buffet Processes\nAbstract: Latent feature models are attractive for image modeling, since images generally contain multiple objects. However, many latent feature models ignore that objects can appear at different locations or require pre-segmentation of images. While the transformed Indian buffet process (tIBP) provides a method for modeling transformation-invariant features in unsegmented binary images, its current form is inappropriate for real images because of its computational cost and modeling assumptions. We combine the tIBP with likelihoods appropriate for real images and develop an efficient inference, using the crosscorrelation between images and features, that is theoretically and empirically faster than existing inference techniques. Our method discovers reasonable components and achieve effective image reconstruction in natural images.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient Pairwise Learning Using Kernel Ridge Regression: an Exact Two-Step Method\nAbstract: Pairwise learning or dyadic prediction concerns the prediction of properties for pairs of objects. It can be seen as an umbrella covering various machine learning problems such as matrix completion, collaborative filtering, multi-task learning, transfer learning, network prediction and zero-shot learning. In this work we analyze kernel-based methods for pairwise learning, with a particular focus on a recently-suggested two-step method. We show that this method offers an appealing alternative for commonly-applied Kronecker-based methods that model dyads by means of pairwise feature representations and pairwise kernels. In a series of theoretical results, we establish correspondences between the two types of methods in terms of linear algebra and spectral filtering, and we analyze their statistical consistency. In addition, the two-step method allows us to establish novel algorithmic shortcuts for efficient training and validation on very large datasets. Putting those properties together, we believe that this simple, yet powerful method can become a standard tool for many problems. Extensive experimental results for a range of practical settings are reported.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Stance detection is the task of classifying the attitude expressed in a text towards a target such as \u201cClimate Change is a Real Concern\u201d to be \u201cpositive\u201d, \u201cnegative\u201d or \u201cneutral\u201d. Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms the independent encoding of tweet and target. Performance improves even further when the conditional model is augmented with bidirectional encoding. The method is evaluated on the SemEval 2016 Task 6 Twitter Stance Detection corpus and achieves performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state\u2013of-the-art results.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Comparative study of Authorship Identification Techniques for Cyber Forensics Analysis\nAbstract: Authorship Identification techniques are used to identify the most appropriate author from group of potential suspects of online messages and find evidences to support the conclusion. Cybercriminals make misuse of online communication for sending blackmail or a spam email and then attempt to hide their true identities to void detection.Authorship Identification of online messages is the contemporary research issue for identity tracing in cyber forensics. This is highly interdisciplinary area as it takes advantage of machine learning, information retrieval, and natural language processing. In this paper, a study of recent techniques and automated approaches to attributing authorship of online messages is presented. The focus of this review study is to summarize all existing authorship identification techniques used in literature to identify authors of online messages. Also it discusses evaluation criteria and parameters for authorship attribution studies and list open questions that will attract future work in this area. Keywords\u2014cyber crime; Author Identification; SVM\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-Source Multi-View Clustering via Discrepancy Penalty\nAbstract: With the advance of technology, entities can be observed in multiple views. Multiple views containing different types of features can be used for clustering. Although multi-view clustering has been successfully applied in many applications, the previous methods usually assume the complete instance mapping between different views. In many real-world applications, information can be gathered from multiple sources, while each source can contain multiple views, which are more cohesive for learning. The views under the same source are usually fully mapped, but they can be very heterogeneous. Moreover, the mappings between different sources are usually incomplete and partially observed, which makes it more difficult to integrate all the views across different sources. In this paper, we propose MMC (Multisource Multi-view Clustering), which is a framework based on collective spectral clustering with a discrepancy penalty across sources, to tackle these challenges. MMC has several advantages compared with other existing methods. First, MMC can deal with incomplete mapping between sources. Second, it considers the disagreements between sources while treating views in the same source as a cohesive set. Third, MMC also tries to infer the instance similarities across sources to enhance the clustering performance. Extensive experiments conducted on real-world data demonstrate the effectiveness of the proposed approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Higher Order Mutual Information Approximation for Feature Selection\nAbstract: Feature selection is a process of choosing a subset of relevant features so that the quality of prediction models can be improved. An extensive body of work exists on information-theoretic feature selection, based on maximizing Mutual Information (MI) between subsets of features and class labels. The prior methods use a lower order approximation, by treating the joint entropy as a summation of several single variable entropies. This leads to locally optimal selections and misses multi-way feature combinations. We present a higher order MI based approximation technique called Higher Order Feature Selection (HOFS). Instead of producing a single list of features, our method produces a ranked collection of feature subsets that maximizes MI, giving better comprehension (feature ranking) as to which features work best together when selected, due to their underlying interdependent structure. Our experiments demonstrate that the proposed method performs better than existing feature selection approaches while keeping similar running times and computational complexity.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Word Representations with Hierarchical Sparse Coding\nAbstract: We propose a new method for learning word representations using hierarchical regularization in sparse coding inspired by the linguistic study of word meanings. We apply an efficient online and distributed learning method. Experiments on various benchmark tasks\u2014word similarity ranking, analogies, sentence completion, and sentiment analysis\u2014demonstrate that the method outperforms or is competitive with state-of-the-art neural network representations. Our word representations are available at http://www.ark.cs.cmu.edu/dyogatam/wordvecs/\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Joint Optimization and Variable Selection of High-dimensional Gaussian Processes\nAbstract: Maximizing high-dimensional, non-convex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Simultaneous Feature and Expert Selection within Mixture of Experts\nAbstract: A useful strategy to deal with complex classification scenarios is the \u201cdivide and conquer\u201d approach. The mixture of experts (MOE) technique makes use of this strategy by joinly training a set of classifiers, or experts, that are specialized in different regions of the input space. A global model, or gate function, complements the experts by learning a function that weights their relevance in different parts of the input space. Local feature selection appears as an attractive alternative to improve the specialization of experts and gate function, particularly, for the case of high dimensional data. Our main intuition is that particular subsets of dimensions, or subspaces, are usually more appropriate to classify instances located in different regions of the input space. Accordingly, this work contributes with a regularized variant of MoE that incorporates an embedded process for local feature selection using L1 regularization, with a simultaneous expert selection. The experiments are still pending.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: An agent-driven semantical identifier using radial basis neural networks and reinforcement learning\nAbstract: Due to the huge availability of documents in digital form, and the deception possibility raise bound to the essence of digital documents and the way they are spread, the authorship attribution problem has constantly increased its relevance. Nowadays, authorship attribution, for both information retrieval and analysis, has gained great importance in the context of security, trust and copyright preservation. This work proposes an innovative multi-agent driven machine learning technique that has been developed for authorship attribution. By means of a preprocessing for word-grouping and timeperiod related analysis of the common lexicon, we determine a bias reference level for the recurrence frequency of the words within analysed texts, and then train a Radial Basis Neural Networks (RBPNN)-based classifier to identify the correct author. The main advantage of the proposed approach lies in the generality of the semantic analysis, which can be applied to different contexts and lexical domains, without requiring any modification. Moreover, the proposed system is able to incorporate an external input, meant to tune the classifier, and then self-adjust by means of continuous learning reinforcement.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Possibility and necessity functions over non-classical logics\nAbstract: We propose an integration of possibility the\u00ad ory into non-classical logics. We obtain many formal results that generalize the case where possibility and necessity functions are based on classical logic. We show how useful such an approach is by applying it to reasoning un\u00ad der uncertain and inconsistent information.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Several studies on sentence processing suggest that the mental lexicon keeps track of the mutual expectations between words. Current DSMs, however, represent context words as separate features, which causes the loss of important information for word expectations, such as word order and interrelations. In this paper, we present a DSM which addresses the issue by defining verb contexts as joint dependencies. We test our representation in a verb similarity task on two datasets, showing that joint contexts are more efficient than single dependencies, even with a relatively small amount of training data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Telling cause from effect in deterministic linear dynamical systems\nAbstract: <lb>Inferring a cause from its effect using observed time series data is a major challenge in natural<lb>and social sciences. Assuming the effect is generated by the cause trough a linear system,<lb>we propose a new approach based on the hypothesis that nature chooses the \u201ccause\u201d and the<lb>\u201cmechanism that generates the effect from the cause\u201d independent of each other. We therefore<lb>postulate that the power spectrum of the time series being the cause is uncorrelated with the<lb>square of the transfer function of the linear filter generating the effect. While most causal<lb>discovery methods for time series mainly rely on the noise, our method relies on asymmetries of<lb>the power spectral density properties that can be exploited even in the context of deterministic<lb>systems. We describe mathematical assumptions in a deterministic model under which the<lb>causal direction is identifiable with this approach. We also discuss the method\u2019s performance<lb>under the additive noise model and its relationship to Granger causality. Experiments show<lb>encouraging results on synthetic as well as real-world data. Overall, this suggests that the<lb>postulate of Independence of Cause and Mechanism is a promising principle for causal inference<lb>on empirical time series.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Student performance prediction using classification data mining techniques Analysis of Student data to find factors influencing student performance\nAbstract: Students opting engineering as their disciple is increasing rapidly. But due to various factors and inappropriate primary education in India dropout rates are high. Students are unable to excel in core engineering subjects which are complex and mathematical, hence mostly get drop / keep term (kt) in that subject. With the help of data mining techniques we can predict the performance of students in terms of grades and dropout for a subject. This paper compares various techniques such as na\u00efve Bayes, LibSVM, J48, random forest, and JRip and try to choose one of them as per our needs and their accuracy. Based on the rules obtained from this technique(s), we derive the key factors influencing student performance. Keywords\u2014 dropout; prediction; classification; data mining; education.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bound Founded Answer Set Programming\nAbstract: Answer Set Programming (ASP) is a powerful modelling formalism that is very efficient in solving combinatorial problems. ASP solvers implement the stable model semantics that eliminates circular derivations between Boolean variables from the solutions of a logic program. Due to this, ASP solvers are better suited than propositional satisfiability (SAT) and Constraint Programming (CP) solvers to solve a certain class of problems whose specification includes inductive definitions such as reachability in a graph. On the other hand, ASP solvers suffer from the grounding bottleneck that occurs due to their inability to model finite domain variables. Furthermore, the existing stable model semantics are not sufficient to disallow circular reasoning on the bounds of numeric variables. An example where this is required is in modelling shortest paths between nodes in a graph. Just as reachability can be encoded as an inductive definition with one or more base cases and recursive rules, shortest paths between nodes can also be modelled with similar base cases and recursive rules for their upper bounds. This deficiency of stable model semantics introduces another type of grounding bottleneck in ASP systems that cannot be removed by naively merging ASP with CP solvers, but requires a theoretical extension of the semantics from Booleans and normal rules to bounds over numeric variables and more general rules. In this work, we propose Bound Founded Answer Set Programming (BFASP) that resolves this issue and consequently, removes all types of grounding bottleneck inherent in ASP systems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Independence of Causal Influence and Clique Tree Propagation\nAbstract: This paper explores the role of independence of causal influence (ICI) in Bayesian network inference. ICI allows one to factorize a con\u00ad ditional probability table into smaller pieces. We describe a method for exploiting the fac\u00ad torization in clique tree propagation (CTP) the state-of-the-art exact inference algo\u00ad rithm for Bayesian networks. We also present empirical results showing that the resulting algorithm is significantly more efficient than the combination of CTP and previous tech\u00ad niques for exploiting ICI.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Noisy Search with Comparative Feedback\nAbstract: We present theoretical results in terms of lower and upper bounds on the query complexity of noisy search with comparative feedback. In this search model, the noise in the feedback depends on the distance between query points and the search target. Consequently, the error probability in the feedback is not fixed but varies for the queries posed by the search algorithm. Our results show that a target out of n items can be found in O(log n) queries. We also show the surprising result that for k possible answers per query, the speedup is not log k (as for k-ary search) but only log log k in some cases.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Well-typed Lightweight Situation Calculus\u2217\nAbstract: Situation calculus has been widely applied in Artificial Intelligence related fields. This formalism is considered as a dialect of logic programming language and mostly used in dynamic domain modeling. However, type systems are hardly deployed in situation calculus in the literature. To achieve a correct and sound typed program written in situation calculus, adding typing elements into the current situation calculus will be quite helpful. In this paper, we propose to add more typing mechanisms to the current version of situation calculus, especially for three basic elements in situation calculus: situations, actions and objects, and then perform rigid type checking for existing situation calculus programs to find out the well-typed and ill-typed ones. In this way, type correctness and soundness in situation calculus programs can be guaranteed by type checking based on our type system. This modified version of a lightweight situation calculus is proved to be a robust and well-typed system.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using a Distributional Semantic Vector Space with a Knowledge Base for Reasoning in Uncertain Conditions\nAbstract: The inherent inflexibility and incompleteness of commonsense knowledge bases (KB) has limited their usefulness. We describe a system called Displacer for performing KB queries extended with the analogical capabilities of the word2vec distributional semantic vector space (DSVS). This allows the system to answer queries with information which was not contained in the original KB in any form. By performing analogous queries on semantically related terms and mapping their answers back into the context of the original query using displacement vectors, we are able to give approximate answers to many questions which, if posed to the KB alone, would return no results. We also show how the hand-curated knowledge in a KB can be used to increase the accuracy of a DSVS in solving analogy problems. In these ways, a KB and a DSVS can make up for each other\u2019s weaknesses.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Representing and Solving Asymmetric Bayesian Decision Problems\nAbstract: This paper deals with the representation and solution of asymmetric Bayesian decision problems. We present a formal framework, termed asymmetric influence diagrams, that is based on the influence diagram and al\u00ad lows an efficient representation of asymmet\u00ad ric decision problems. As opposed to exist\u00ad ing frameworks, the asymmetric influence di\u00ad agram primarily encodes asymmetry at the qualitative level and it can therefore be read directly from the model. We give an algorithm for solving asymmetric influence diagrams. The algorithm initially decomposes the asymmetric decision problem into a structure of symmetric subproblems organized as a tree. A solution to the de\u00ad cision problem can then be found by propa\u00ad gating from the leaves towards the root using existing evaluation methods to solve the sub\u00ad problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Git4Voc: Git-based Versioning for Collaborative Vocabulary Development\nAbstract: Collaborative vocabulary development in the context of data integration is the process of finding consensus between the experts of the different systems and domains. The complexity of this process is increased with the number of involved people, the variety of the systems to be integrated and the dynamics of their domain. In this paper we advocate that the realization of a powerful version control system is the heart of the problem. Driven by this idea and the success of Git in the context of software development, we investigate the applicability of Git for collaborative vocabulary development. Even though vocabulary development and software development have much more similarities than differences there are still important differences. These need to be considered within the development of a successful versioning and collaboration system for vocabulary development. Therefore, this paper starts by presenting the challenges we were faced with during the creation of vocabularies collaboratively and discusses its distinction to software development. Based on these insights we propose Git4Voc which comprises guidelines how Git can be adopted to vocabulary development. Finally, we demonstrate how Git hooks can be implemented to go beyond the plain functionality of Git by realizing vocabulary-specific features like syntactic validation and semantic diffs.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Co-adaptation in a Handwriting Recognition System\nAbstract: Handwriting is a natural and versatile method for humancomputer interaction, especially on small mobile devices such as smart phones. However, as handwriting varies significantly from person to person, it is difficult to design handwriting recognizers that perform well for all users. A natural solution is to use machine learning to adapt the recognizer to the user. One complicating factor is that, as the computer adapts to the user, the user also adapts to the computer and probably changes their handwriting. This paper investigates the dynamics of co-adaptation, a process in which both the computer and the user are adapting their behaviors in order to improve the speed and accuracy of the communication through handwriting. We devised an information-theoretic framework for quantifying the efficiency of a handwriting system where the system includes both the user and the computer. Using this framework, we analyzed data collected from an adaptive handwriting recognition system and characterized the impact of machine adaptation and of human adaptation. We found that both machine adaptation and human adaptation have significant impact on the input rate and must be considered together in order to improve the efficiency of the system as a whole.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Quantified Linguistic Approximation\nAbstract: Most fuzzy systems including fuzzy decision support and fuzzy control systems provide out\u00ad puts in the form of fuzzy sets that represent the inferred conclusions. Linguistic interpretation of such outputs often involves the use of linguistic approximation that assigns a linguistic label to a fuzzy set based on the predefined primary terms, linguistic modifiers and linguistic connectives. More generally, linguistic approximation can be formalized in the terms of the re-translation rules that correspond to the translation rules in ex\u00ad plicitation (e.g. simple, modifier, composite, quantification and qualification rules) in com\u00ad puting with words [Zadeh 1996]. However most existing methods of linguistic approximation use the simple, modifier and composite re-translation rules only. Although these methods can provide a sufficient approximation of simple fuzzy sets the approximation of more complex ones that are typical in many practical applications of fuzzy systems may be less satisfactory. Therefore the question arises why not use in linguistic ap\u00ad proximation also other re-translation rules corre\u00ad sponding to the translation rules in explicitation to advantage. In particular linguistic quantifica\u00ad tion may be desirable in situations where the conclusions interpreted as quantified linguistic propositions can be more informative and natu\u00ad ral. This paper presents some aspects of linguis\u00ad tic approximation in the context of the re\u00ad translation rules and proposes an approach to linguistic approximation with the use of quantifi\u00ad cation rules, i.e. quantified linguistic approxima\u00ad tion. Two methods of the quantified linguistic approximation are considered with the use of lin\u00ad guistic quantifiers based on the concepts of the non-fuzzy and fuzzy cardinalities of fuzzy sets. A number of examples are provided to illustrate the proposed approach.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We study the data space D of any given data set X and explain how functions and relations are defined over D. From D and for a specific domain \u2206 we construct the information space I of X by interpreting variables, functions, and explicit relations over D in \u2206 and by including other relations that D implies under the interpretation in \u2206. Then from I we build up the knowledge space K of X as the product of two spaces KT and KP , where KT is obtained from I by using the induction principle to generalize propositional relations to quantified relations, the deduction principle to generate new relations, and standard mechanisms to validate relations and KP is the space of specifications of methods with operational instructions which are valid in KT . Through our construction of the three topological spaces the following key observation is made clear: the retrieval of information from the given data set for \u2206 consists essentially in mining domain objects and relations, and the discovery of knowledge from the retrieved information consists essentially in applying the induction and deduction principles to generate propositions, synthesizing and modeling the information to generate specifications of methods with operational instructions, and validating the propositions and specifications. Based on this observation, efficient approaches may be designed to discover profound knowledge automatically from simple data, as demonstrated by the result of our study in the case of geometry.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed Constraint Optimization Problems and Applications: A Survey\nAbstract: The field of Multi-Agent System (MAS) is an active area of research within Artificial Intelligence, with an increasingly important impact in industrial and other real-world applications. In a MAS, autonomous agents interact to pursue personal interests and/or to achieve common objectives. Distributed Constraint Optimization Problems (DCOPs) have emerged as a prominent agent model to govern the agents\u2019 autonomous behavior, where both algorithms and communication models are driven by the structure of the specific problem. During the last decade, several extensions to the DCOP model have been proposed to enable support of MAS in complex, realtime, and uncertain environments. This survey provides an overview of the DCOP model, offering a classification of its multiple extensions and addressing both resolution methods and applications that find a natural mapping within each class of DCOPs. The proposed classification suggests several future perspectives for DCOP extensions, and identifies challenges in the design of efficient resolution algorithms, possibly through the adaptation of strategies from different areas.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Design of a GIS-based Assistant Software Agent for the Incident Commander to Coordinate Emergency Response Operations\nAbstract: Problem: This paper addresses the design of an intelligent software system for the IC (incident commander) of a team in order to coordinate actions of agents\u2013 field units or robots \u2013in the domain of emergency/crisis response operations. Objective: This paper proposes GICoordinator. It is a GISbased assistant software agent that assists and collaborates with the human planner in strategic planning and macro tasks assignment for centralized multi-agent coordination. Method: Our approach to design GICoordinator was to: analyze the problem, design a complete data model, design an architecture of GICoordinator, specify required capabilities of human and system in coordination problem solving, specify development tools, and deploy. Result: The result was an architecture/design of GICoordinator that contains system requirements. Findings: GICoordinator efficiently integrates geoinformatics with artifice intelligent techniques in order to provide a spatial intelligent coordinator system for an IC to efficiently coordinate and control agents by making macro/strategic decisions. Results define a framework for future works to develop this system.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The concept of \u201ctask\u201d is at the core of artificial intelligence (AI): Tasks are used for training and evaluating AI systems, which are built in order to perform and automatize tasks we deem useful. In other fields of engineering theoretical foundations allow thorough evaluation of designs by methodical manipulation of well understood parameters with a known role and importance; this allows an aeronautics engineer, for instance, to systematically assess the effects of wind speed on an airplane\u2019s performance and stability. No framework exists in AI that allows this kind of methodical manipulation: Performance results on the few tasks in current use (cf. board games, question-answering) cannot be easily compared, however similar or different. The issue is even more acute with respect to artificial general intelligence systems, which must handle unanticipated tasks whose specifics cannot be known beforehand. A task theory would enable addressing tasks at the class level, bypassing their specifics, providing the appropriate formalization and classification of tasks, environments, and their parameters, resulting in more rigorous ways of measuring, comparing, and evaluating intelligent behavior. Even modest improvements in this direction would surpass the current ad-hoc nature of machine learning and AI evaluation. Here we discuss the main elements of the argument for a task theory and present an outline of what it might look like for physical tasks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Good, the Bad, and the Odd: Cycles in Answer-Set Programs\nAbstract: Backdoors of answer-set programs are sets of atoms that represent \u201cclever reasoning shortcuts\u201d through the search space. Assignments to backdoor atoms reduce the given program to several programs that belong to a tractable target class. Previous research has considered target classes based on notions of acyclicity where various types of cycles (good and bad cycles) are excluded from graph representations of programs. We generalize the target classes by taking the parity of the number of negative edges on bad cycles into account and consider backdoors for such classes. We establish new hardness results and non-uniform polynomialtime tractability relative to directed or undirected cycles.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency\nAbstract: A semantics is given to possibilistic logic, a logic that handles weighted classical logic formulae, and where weights are interpreted as lower bounds on degrees of certainty or possibility, in the sense of Zadeh's possibility theory. The proposed semantics is based on fuzzy sets of interpretations. It is tolerant to partial inconsistency. Satisfiability is extended from interpretations to fuzzy sets of interpretations, each fuzzy set representing a possibility distribution describing what is known about the state of the world. A possibilistic know ledge base is then viewed as a set of possibility distributions that satisfy it. The refutation method of automated deduction in possibilistic logic, based on previously introduced generalized resolution principle is proved to be sound and complete with respect to the proposed semantics, including the case of partial inconsistency.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Dynamic consistency and decision making under vacuous belief\nAbstract: The ideas about decision making under ignorance in economics are combined with the ideas about uncertainty representation in computer science. The combination sheds new light on the question of how artificial agents can act in a dynamically consistent manner. The notion of sequential consistency is formalized by adapting the law of iterated expectation for plausibility measures. The necessary and sufficient condition for a certainty equivalence operator for NehringPuppe\u2019s preference to be sequentially consistent is given. This result sheds light on the models of decision making under uncertainty.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient Machine Learning for Big Data: A Review\nAbstract: With the emerging technologies and all associated devices, it is predicted that massive amount of data will be created in the next few years \u2013 in fact, as much as 90% of current data were created in the last couple of years \u2013 a trend that will continue for the foreseeable future. Sustainable computing studies the process by which computer engineer/scientist designs computers and associated subsystems efficiently and effectively with minimal impact on the environment. However, current intelligent machine-learning systems are performance driven \u2013 the focus is on the predictive/classification accuracy, based on known properties learned from the training samples. For instance, most machine-learning-based nonparametric models are known to require high computational cost in order to find the global optima. With the learning task in a large dataset, the number of hidden nodes within the network will therefore increase significantly, which eventually leads to an exponential rise in computational complexity. This paper thus reviews the theoretical and experimental data-modeling literature, in large-scale data-intensive fields, relating to: (1) model efficiency, including computational requirements in learning, and data-intensive areas\u2019 structure and design, and introduces (2) new algorithmic approaches with the least memory requirements and processing to minimize computational cost, while maintaining/improving its predictive/classification accuracy and stability.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SYSTEM-GENERATED REQUESTS FOR REWRITING PROPOSALS\nAbstract: We present an online deliberation system using mutual evaluation in order to collaboratively develop solutions. Participants submit their proposals and evaluate each other\u2019s proposals; some of them may then be invited by the system to rewrite \u201cproblematic\u201d proposals. Two cases are discussed: a proposal supported by many, but not by a given person, who is then invited to rewrite it for making yet more acceptable; and a poorly presented but presumably interesting proposal. The first of these cases has been successfully implemented. Proposals are evaluated along two axes\u2014understandability (or clarity, or, more generally, quality), and agreement. The latter is used by the system to cluster proposals according to their ideas, while the former is used both to present the best proposals on top of their clusters, and to find poorly written proposals candidates for rewriting. These functionalities may be considered as important components of a large scale online deliberation system.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Compliant Conditions for Polynomial Time Approximation of Operator Counts\nAbstract: In this paper, we develop a computationally simpler version of the operator count heuristic for a particular class of domains. The contribution of this abstract is threefold, we (1) propose an efficient closed form approximation to the operator count heuristic using the Lagrangian dual; (2) leverage compressed sensing techniques to obtain an integer approximation for operator counts in polynomial time; and (3) discuss the relationship of the proposed formulation to existing heuristics and investigate properties of domains where such approaches appear to be useful.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Use of Non-Stationary Policies for Stationary Infinite-Horizon Markov Decision Processes\nAbstract: We consider infinite-horizon stationary \u03b3-discounted Markov Decision Processes, for which it is known that there exists a stationary optimal policy. Using Value and Policy Iteration with some error \u01eb at each iteration, it is well-known that one can compute stationary policies that are 2\u03b3 (1\u2212\u03b3)2 \u01eb-optimal. After arguing that this guarantee is tight, we develop variations of Value and Policy Iteration for computing non-stationary policies that can be up to 2\u03b3 1\u2212\u03b3 \u01eb-optimal, which constitutes a significant improvement in the usual situation when \u03b3 is close to 1. Surprisingly, this shows that the problem of \u201ccomputing near-optimal non-stationary policies\u201d is much simpler than that of \u201ccomputing near-optimal stationary policies\u201d.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Visual Analysis of Hidden State Dynamics in  Recurrent Neural Networks \nAbstract: Recurrent neural networks, and in particular long short-term memory networks (LSTMs), are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVIS a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows a user to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with domain specific structural annotations. We further show several use cases of the tool for analyzing specific hidden state properties on data sets containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Relation Between Acausality and Interference in Quantum-Like Bayesian Networks\nAbstract: We analyse a quantum-like Bayesian Network that puts together cause/effect relationships and semantic similarities between events. These semantic similarities constitute acausal connections according to the Synchronicity principle and provide new relationships to quantum like probabilistic graphical models. As a consequence, beliefs (or any other event) can be represented in vector spaces, in which quantum parameters are determined by the similarities that these vectors share between them. Events attached by a semantic meaning do not need to have an explanation in terms of cause and effect.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Toward the Automatic Generation of a Semantic VRML Model from Unorganized 3D Point Clouds\nAbstract: This paper presents our experience regarding the creation of 3D semantic facility model out of unorganized 3D point clouds. Thus, a knowledge-based detection approach of objects using the OWL ontology language is presented. This knowledge is used to define SWRL detection rules. In addition, the combination of 3D processing built-ins and topological Built-Ins in SWRL rules aims at combining geometrical analysis of 3D point clouds and specialist\u2019s knowledge. This combination allows more flexible and intelligent detection and the annotation of objects contained in 3D point clouds. The created WiDOP prototype takes a set of 3D point clouds as input, and produces an indexed scene of colored objects visualized within VRML language as output. The context of the study is the detection of railway objects materialized within the Deutsche Bahn scene such as signals, technical cupboards, electric poles, etc. Therefore, the resulting enriched and populated domain ontology, that contains the annotations of objects in the point clouds, is used to feed a GIS system. Keywords-Semantic facility information model; Semantic VRML model; Geometric analysis; Topological analysis; 3D processing algorithm; Semantic web; knowledge modeling; ontology; 3D scene reconstruction; object\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards an Ontology based integrated Framework for Semantic Web\nAbstract: This Ontologies are widely used as a means for solving the information heterogeneity problems on the web because of their capability to provide explicit meaning to the information. They become an efficient tool for knowledge representation in a structured manner. There is always more than one ontology for the same domain. Furthermore, there is no standard method for building ontologies, and there are many ontology building tools using different ontology languages. Because of these reasons, interoperability between the ontologies is very low. Current ontology tools mostly use functions to build, edit and inference the ontology. Methods for merging heterogeneous domain ontologies are not included in most tools. This paper presents ontology merging methodology for building a single global ontology from heterogeneous eXtensible Markup Language (XML) data sources to capture and maintain all the knowledge which XML data sources can contain. Keywords-Ontologies; Ontology management; ontology mapping; ontology merging.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: of Thesis presented to LNCC/MCT in partial fulfillment of the requirements for the degree of Doctor of Sciences (D.Sc.) MANAGING LARGE-SCALE SCIENTIFIC HYPOTHESES AS UNCERTAIN AND PROBABILISTIC DATA Bernardo Gon\u00e7alves February 2015 Advisor: Fabio Porto, D.Sc. In view of the paradigm shift that makes science ever more data-driven, in this thesis we propose a synthesis method for encoding and managing large-scale deterministic scientific hypotheses as uncertain and probabilistic data. In the form of mathematical equations, hypotheses symmetrically relate aspects of the studied phenomena. For computing predictions, however, deterministic hypotheses can be abstracted as functions. We build upon Simon\u2019s notion of structural equations in order to efficiently extract the (so-called) causal ordering between variables, implicit in a hypothesis structure (set of mathematical equations). We show how to process the hypothesis predictive structure effectively through original algorithms for encoding it into a set of functional dependencies (fd\u2019s) and then performing causal reasoning in terms of acyclic pseudo-transitive reasoning over fd\u2019s. Such reasoning reveals important causal dependencies implicit in the hypothesis predictive data and guide our synthesis of a probabilistic database. Like in the field of graphical models in AI, such a probabilistic database should be normalized so that the uncertainty arisen from competing hypotheses is decomposed into factors and propagated properly onto predictive data by recovering its joint probability distribution through a lossless join. That is motivated as a design-theoretic principle for data-driven hypothesis management and predictive analytics. The method is applicable to both quantitative and qualitative deterministic hypotheses and demonstrated in realistic use cases from computational science. Resumo da Tese apresentada ao LNCC/MCT como parte dos requisitos necess\u00e1rios para a obten\u00e7\u00e3o do grau de Doutor em Ci\u00eancias (D.Sc.) GER\u00caNCIA DE HIP\u00d3TESES CIENT\u00cdFICAS DE LARGA-ESCALA COMO DADOS INCERTOS E PROBABIL\u00cdSTICOS Bernardo Gon\u00e7alves Fevereiro, 2015 Orientador: Fabio Porto, D.Sc. Tendo em vista a mudan\u00e7a de paradigma que faz da ci\u00eancia cada vez mais guiada por dados, nesta tese propomos um m\u00e9todo para codifica\u00e7\u00e3o e ger\u00eancia de hip\u00f3teses cient\u0301\u0131ficas determi\u0144\u0131sticas de larga escala como dados incertos e probabi\u013a\u0131sticos. Na forma de equa\u00e7\u00f5es matem\u00e1ticas, hip\u00f3teses relacionam simetricamente aspectos do fen\u00f4meno de estudo. Para computa\u00e7\u00e3o de predi\u00e7\u00f5es, no entanto, hip\u00f3teses determi\u0144\u0131sticas podem ser abstr\u00e1\u0131das como fun\u00e7\u00f5es. Levamos adiante a no\u00e7\u00e3o de Simon de equa\u00e7\u00f5es estruturais para extrair de forma eficiente a ent\u00e3o chamada ordena\u00e7\u00e3o causal imp\u013a\u0131cita na estrutura de uma hip\u00f3tese. Mostramos como processar a estrutura preditiva de uma hip\u00f3tese atrav\u00e9s de algoritmos originais para sua codifica\u00e7\u00e3o como um conjunto de depend\u00eancias funcionais (df\u2019s) e ent\u00e3o realizamos infer\u00eancia causal em termos de racio\u0107\u0131nio a\u0107\u0131clico pseudo-transitivo sobre df\u2019s. Tal racio\u0107\u0131nio revela importantes depend\u00eancias causais imp\u013a\u0131citas nos dados preditivos da hip\u00f3tese, que conduzem nossa \u015b\u0131ntese do banco de dados probabi\u013a\u0131stico. Como na \u00e1rea de modelos gr\u00e1ficos (IA), o banco de dados probabi\u013a\u0131stico deve ser normalizado de tal forma que a incerteza oriunda de hip\u00f3teses alternativas seja decomposta em fatores e propagada propriamente recuperando sua distribui\u00e7\u00e3o de probabilidade conjunta via jun\u00e7\u00e3o \u2018lossless.\u2019 Isso \u00e9 motivado como um prin\u0107\u0131pio te\u00f3rico de projeto para ger\u00eancia e an\u00e1lise de hip\u00f3teses. O m\u00e9todo proposto \u00e9 aplic\u00e1vel a hip\u00f3teses determi\u0144\u0131sticas quantitativas e qualitativas e \u00e9 demonstrado em casos rea\u013a\u0131sticos de ci\u00eancia computacional.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SAS+ Planning as Satisfiability\nAbstract: Planning as satisfiability is a principal approach to planning with many eminent advantages. The existing planning as satisfiability techniques usually use encodings compiled from STRIPS. We introduce a novel SAT encoding scheme (SASE) based on the SAS+ formalism. The new scheme exploits the structural information in SAS+, resulting in an encoding that is both more compact and efficient for planning. We prove the correctness of the new encoding by establishing an isomorphism between the solution plans of SASE and that of STRIPS based encodings. We further analyze the transition variables newly introduced in SASE to explain why it accommodates modern SAT solving algorithms and improves performance. We give empirical statistical results to support our analysis. We also develop a number of techniques to further reduce the encoding size of SASE, and conduct experimental studies to show the strength of each individual technique. Finally, we report extensive experimental results to demonstrate significant improvements of SASE over the state-of-the-art STRIPS based encoding schemes in terms of both time and memory efficiency.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper discusses the root cause of systems perceiving the self experience and how to exploit adaptive and learning features without introducing ethically problematic system properties. 1  Ethics and Conscious\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Restricted Visual Turing Test for Deep Scene and Event Understanding\nAbstract: This paper presents a restricted visual Turing test (VTT) for story-line based deep understanding in long-term and multi-camera captured videos. Given a set of videos of a scene (such as a multi-room office, a garden, and a parking lot.) and a sequence of story-line based queries, the task is to provide answers either simply in binary form \u201ctrue/false\u201d (to a polar query) or in an accurate natural language description (to a non-polar query). Queries, polar or nonpolar, consist of view-based queries which can be answered from a particular camera view and scene-centered queries which involves joint inference across different cameras. The story lines are collected to cover spatial, temporal and causal understanding of input videos. The data and queries distinguish our VTT from recently proposed visual question answering in images and video captioning. A vision system is proposed to perform joint video and query parsing which integrates different vision modules, a knowledge base and a query engine. The system provides unified interfaces for different modules so that individual modules can be reconfigured to test a new method. We provide a benchmark dataset and a toolkit for ontology guided story-line query generation which consists of about 93.5 hours videos captured in four different locations and 3,426 queries split into 127 story lines . We also provide a baseline implementation and result analyses.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Algorithms and Limits for Compact Plan Representations\nAbstract: Compact representations of objects is a common concept in computer science. Automated planning can be viewed as a case of this concept: a planning instance is a compact implicit representation of a graph and the problem is to find a path (a plan) in this graph. While the graphs themselves are represented compactly as planning instances, the paths are usually represented explicitly as sequences of actions. Some cases are known where the plans always have compact representations, for example, using macros. We show that these results do not extend to the general case, by proving a number of bounds for compact representations of plans under various criteria, like efficient sequential or random access of actions. In addition to this, we show that our results have consequences for what can be gained from reformulating planning into some other problem. As a contrast to this we also prove a number of positive results, demonstrating restricted cases where plans do have useful compact representations, as well as proving that macro plans have favourable access properties. Our results are finally discussed in relation to other relevant contexts.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Brief Introduction to Temporality and Causality\nAbstract: Causality is a non-obvious concept that is often considered to be related to temporality. In this paper we present a number of past and present approaches to the definition of temporality and causality from philosophical, physical, and computational points of view. We note that time is an important ingredient in many relationships and phenomena. The topic is then divided into the two main areas of temporal discovery, which is concerned with finding relations that are stretched over time, and causal discovery, where a claim is made as to the causal influence of certain events on others. We present a number of computational tools used for attempting to automatically discover temporal and causal relations in data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generating Explanations for Evidential Reasoning\nAbstract: In this paper, we present two methods to provide explanations for reasoning with be\u00ad lief functions in the valuation-based systems. One approach, inspired by Strat's method, is based on sensitivity analysis, but its com\u00ad putation is simpler thus easier to implement than Strat 's. The other one is to examine the impact of evidence on the conclusion based on the measure of the information content in the evidence. We show the property of ad\u00ad ditivity for the pieces of evidence that are conditional independent within the context of the valuation-based systems. We will give an example to show how these approaches are applied in an evidential network.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Harmony Search Algorithm for Curriculum-Based Course Timetabling Problem\nAbstract: In this paper, harmony search algorithm is applied to curriculum-based course timetabling. The implementation, specifically the process of improvisation consists of memory consideration, random consideration and pitch adjustment. In memory consideration, the value of the course number for new solution was selected from all other course number located in the same column of the Harmony Memory. This research used the highest occurrence of the course number to be scheduled in a new harmony. The remaining courses that have not been scheduled by memory consideration will go through random consideration, i.e. will select any feasible location available to be scheduled in the new harmony solution. Each course scheduled out of memory consideration is examined as to whether it should be pitch adjusted with probability of eight procedures. However, the algorithm produced results that were not comparatively better than those previously known as best solution. With proper modification in terms of the approach in this algorithm would make the algorithm perform better on curriculum-based course\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Lethal Autonomous Weapons promise to revolutionize warfare \u2014 and raise a multitude of ethical and legal questions. It has thus been suggested to program values and principles of conduct (such as the Geneva Conventions) into the machines\u2019 control, thereby rendering them both physically and morally superior to human combatants. We employ mathematical logic and theoretical computer science to explore fundamental limitations to the moral behaviour of intelligent machines in a series of Gedankenexperiments: Refining and sharpening variants of the Trolley Problem leads us to construct an (admittedly artificial but) fully deterministic situation where a robot is presented with two choices: one morally clearly preferable over the other \u2014 yet, based on the undecidability of the Halting problem, it provably cannot decide algorithmically which one. Our considerations have surprising implications to the question of responsibility and liability for an autonomous system\u2019s actions and lead to specific technical recommendations.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Kiwi is a minimalist and extendable Constraint Programming (CP) solver specifically designed for education. The particularities of Kiwi stand in its generic trailing state restoration mechanism and its modulable use of variables. By developing Kiwi, the author does not aim to provide an alternative to full featured constraint solvers but rather to provide readers with a basic architecture that will (hopefully) help them to understand the core mechanisms hidden under the hood of constraint solvers, to develop their own extended constraint solver, or to test innovative ideas.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Feature Selection Using Regularization in Approximate Linear Programs for Markov Decision Processes\nAbstract: Approximate dynamic programming has been used successfully in a large variety of domains, but it relies on a small set of provided approximation features to calculate solutions reliably. Large and rich sets of features can cause existing algorithms to overfit because of a limited number of samples. We address this shortcoming using L1 regularization in approximate linear programming. Because the proposed method can automatically select the appropriate richness of features, its performance does not degrade with an increasing number of features. These results rely on new and stronger sampling bounds for regularized approximate linear programs. We also propose a computationally efficient homotopy method. The empirical evaluation of the approach shows that the proposed method performs well on simple MDPs and standard benchmark problems.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Tractability through Exchangeability: A New Perspective on Efficient Probabilistic Inference\nAbstract: Exchangeability is a central notion in statistics and probability theory. The assumption that an infinite sequence of data points is exchangeable is at the core of Bayesian statistics. However, finite exchangeability as a statistical property that renders probabilistic inference tractable is less well-understood. We develop a theory of finite exchangeability and its relation to tractable probabilistic inference. The theory is complementary to that of independence and conditional independence. We show that tractable inference in probabilistic models with high treewidth and millions of variables can be explained with the notion of finite (partial) exchangeability. We also show that existing lifted inference algorithms implicitly utilize a combination of conditional independence and partial exchangeability.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A History of Metaheuristics\u2217\nAbstract: This chapter describes the history of metaheuristics in five distinct periods, starting long before the first use of the term and ending a long time in the future.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Reasoning within Fuzzy Description Logics\nAbstract: Description Logics (DLs) are suitable, well-known, logics for managing structured knowledge. They allow reasoning about individuals and well defined concepts, i.e. set of individuals with common properties. The experience in using DLs in applications has shown that in many cases we would like to extend their capabilities. In particular, their use in the context of Multimedia Information Retrieval (MIR) leads to the convincement that such DLs should allow the treatment of the inherent imprecision in multimedia object content representation and retrieval. In this paper we will present a fuzzy extension of ALC, combining Zadeh\u2019s fuzzy logic with a classical DL. In particular, concepts becomes fuzzy and, thus, reasoning about imprecise concepts is supported. We will define its syntax, its semantics, describe its properties and present a constraint propagation calculus for reasoning in it.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Proposing Plausible Answers for Open-ended Visual Question Answering\nAbstract: Answering open-ended questions is an essential capability for any intelligent agent. One of the most interesting recent open-ended question answering challenges is Visual Question Answering (VQA) which attempts to evaluate a system\u2019s visual understanding through its answers to natural language questions about images. There exist many approaches to VQA, the majority of which do not exhibit deeper semantic understanding of the candidate answers they produce. We study the importance of generating plausible answers to a given question by introducing the novel task of \u2018Answer Proposal\u2019: for a given open-ended question, a system should generate a ranked list of candidate answers informed by the semantics of the question. We experiment with various models including a neural generative model as well as a semantic graph matching one. We provide both intrinsic and extrinsic evaluations for the task of Answer Proposal, showing that our best model learns to propose plausible answers with a high recall and performs competitively with some other solutions to VQA.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Structured Text Representations\nAbstract: In this paper, we focus on learning structureaware document representations from data without recourse to a discourse parser or additional annotations. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases. Experimental evaluation across different tasks and datasets shows that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Medical diagnosis as pattern recognition in a framework of information compression by multiple alignment, unification and search\nAbstract: This paper describes a novel approach to medical diagnosis based on the SP theory of computing and cognition. The main attractions of this approach are: a format for representing diseases that is simple and intuitive; an ability to cope with errors and uncertainties in diagnostic information; the simplicity of storing statistical information as frequencies of occurrence of diseases; a method for evaluating alternative diagnostic hypotheses that yields true probabilities; and a framework that should facilitate unsupervised learning of medical knowledge and the integration of medical diagnosis with other AI applications.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Automated Reasoning and Presentation Support for Formalizing Mathematics in Mizar\nAbstract: This paper presents a combination of several automated reasoning and proof presentation tools with the Mizar system for formalization of mathematics. The combination forms an online service called MizAR, similar to the SystemOnTPTP service for first-order automated reasoning. The main differences to SystemOnTPTP are the use of the Mizar language that is oriented towards human mathematicians (rather than the pure first-order logic used in SystemOnTPTP), and setting the service in the context of the large Mizar Mathematical Library of previous theorems, definitions, and proofs (rather than the isolated problems that are solved in SystemOnTPTP). These differences poses new challenges and new opportunities for automated reasoning and for proof presentation tools. This paper describes the overall structure of MizAR, and presents the automated reasoning systems and proof presentation tools that are combined to make MizAR a useful mathematical service.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: New Results on Equilibria in Strategic Candidacy\nAbstract: We consider a voting setting where candidates have preferences about the outcome of the election and are free to join or leave the election. The corresponding candidacy game, where candidates choose strategically to participate or not, has been studied in very few papers, mainly by Dutta et al. [4], [5], who showed that no non-dictatorial voting procedure satisfying unanimity is candidacystrategyproof, or equivalently, is such that the joint action where all candidates enter the election is always a pure strategy Nash equilibrium. They also showed that for voting trees, there are candidacy games with no pure strategy equilibria. However, no results were known about other voting rules. Here we prove several such results. Some are positive (a pure strategy Nash equilibrium is guaranteed for Copeland and the uncovered set, whichever the number of candidates, and for all Condorcet-consistent rules, for 4 candidates). Some are negative, namely for plurality and maximin. We also study the existence of strong equilibria and relate it to a stronger variant of candidate control.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Attacker and Defender Counting Approach for Abstract Argumentation1\nAbstract: In Dung\u2019s abstract argumentation, arguments are either acceptable or unacceptable, given a chosen notion of acceptability. This gives a coarse way to compare arguments. In this paper, we propose a counting approach for a more fine-gained assessment to arguments by counting the number of their respective attackers and defenders based on argument graph and argument game. An argument is more acceptable if the proponent puts forward more number of defenders for it and the opponent puts forward less number of attackers against it. We show that our counting model has two well-behaved properties: normalization and convergence. Then, we define a counting semantics based on this model, and investigate some general properties of the semantics.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A PROPOSED DECISION SUPPORT SYSTEM/EXPERT SYSTEM FOR GUIDING FRESH STUDENTS IN SELECTING A FACULTY IN GOMAL UNIVERSITY, PAKISTAN\nAbstract: This paper presents the design and development of a proposed rule based Decision Support System that will help students in selecting the best suitable faculty/major decision while taking admission in Gomal University, Dera Ismail Khan, Pakistan. The basic idea of our approach is to design a model for testing and measuring the student capabilities like intelligence, understanding, comprehension, mathematical concepts plus his/her past academic record plus his/her intelligence level , and applying the module results to a rule-based decision support system to determine the compatibility of those capabilities with the available faculties/majors in Gomal University. The result is shown as a list of suggested faculties/majors with the student capabilities and abilities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Formal Model of Uncertainty for Possibilistic Rules\nAbstract: The study of such assignments and their properties falls within the purview of possibility theory [DP88, Y80, Z78]. It, like probability theory, assigns values between 0 and 1 to express likelihoods of outcomes. Here, however, the similarity ends. Possibility theory uses the maximum and minimum functions to com\u00ad bine uncertainties, whereas probability theory uses the plus and times operations. This leads to very dissim\u00ad ilar theories in terms of analy tical framework, even though they share several semantic concepts. One of the shared concepts consists of expressing quantita\u00ad tively the uncertainty associated with a given distribu\u00ad tion. In probability theory its value corresponds to the gain of information that would result from conduct\u00ad ing an experiment and ascertaining an actual result. This gain of information can equally well be viewed as a decrease in uncertainty about the outcome of an experiment. In this case the standard measure of in\u00ad formation, and thus uncertainty, is Shannon entropy [AD75, G77]. It enjoys several advantages-it is char\u00ad acterized uniquely by a few, very natural properties, and it can be conveniently used in decision processes. This application is based on the principle of maximum entropy; it has become a popular method of relating decisions to uncertainty.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Incremental Pruning: A Simple, Fast, Exact Method for Partially Observable Markov Decision Processes\nAbstract: Most exact algorithms for general par\u00ad tially observable Markov decision processes (POMDPs) use a form of dynamic program\u00ad ming in which a piecewise-linear and con\u00ad vex representation of one value function is transformed into another. We examine vari\u00ad ations of the \"incremental pruning\" method for solving this problem and compare them to earlier algorithms from theoretical and em\u00ad pirical perspectives. We find that incremen\u00ad tal pruning is presently the most efficient ex\u00ad act method for solving POMDPs.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Operation Research deals with the application of advanced analytical methods such as optimization models applied to help in taking better decisions. Theoretically, models are developed, tested and then operated in an organization. Unfortunately, the environment wherein the solution is developed differs from the one wherein the solution is operated. Different unexpected events occur while operating the optimal decision, therefore there is a need expressed by the operators which is the ability to quickly adapt a plan in operation to take into account events making it anymore or in part inapplicable.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Extended Breadth-First Search Algorithm\nAbstract: The task of artificial intelligence is to provide representation techniques for describing problems, as well as search algorithms that can be used to answer our questions. A widespread and elaborated model is state-space representation, which, however, has some shortcomings. Classical search algorithms are not applicable in practice when the state space contains even only a few tens of thousands of states. We can give remedy to this problem by defining some kind of heuristic knowledge. In case of classical state-space representation, heuristic must be defined so that it qualifies an arbitrary state based on its \u201cgoodness,\u201d which is obviously not trivial. In our paper, we introduce an algorithm that gives us the ability to handle huge state spaces and to use a heuristic concept which is easier to embed into search algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Opposition-Based Electromagnetism-Like for Global Optimization\nAbstract: * Erik Cuevas 1 , + Diego Oliva, * Daniel Zaldivar, * Marco P\u00e9rez-Cisneros and + Gonzalo Pajares Departamento de Ciencias Computacionales Universidad de Guadalajara, CUCEI Av. Revoluci\u00f3n 1500, Guadalajara, Jal, M\u00e9xico {erik.cuevas, daniel.zaldivar, marco.perez}@cucei.udg.mx Dpto. Ingenier\u00eda del Software e Inteligencia Artificial, Facultad Inform\u00e1tica, Universidad Complutense, Av. Complutense S/N, 28040, Madrid, Spain doliva@estumail.ucm.es, pajares@fdi.ucm.es\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results. We address this shortcoming of existing approaches by introducing partial meet and ensconcement constructions for logic program belief change, which allow us to define syntax-preserving operators that satisfy preservation and support. Our work is novel in that our constructions not only preserve more information from a logic program during a change operation than existing ones, but they also facilitate natural definitions of contraction operators, the first in the field to the best of our knowledge. In order to evaluate the rationality of our operators, we translate the revision and contraction postulates from the AGM and belief base frameworks to the logic programming setting. We show that our operators fully comply with the belief base framework and formally state the interdefinability between our operators. We further propose an algorithm that is based on modularising a logic program to reduce partial meet and ensconcement revisions or contractions to performing the operation only on the relevant modules of that program. Finally, we compare our approach to two state-of-the-art logic program revision methods and demonstrate that our operators address the shortcomings of one and generalise the other method.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper has three main contributions to our understanding of fixed-depth minimax search: (A) A new formulation for Stockman\u2019s SSS* algorithm, based on Alpha-Beta, is presented. It solves all the perceived drawbacks of SSS*, finally transforming it into a practical algorithm. In effect, we show that SSS* = + transposition tables. The crucial step is the realization that transposition tables contain so-called solution trees, structures that are used in best-first search algorithms like SSS*. Having created a practical version, we present performance measurements with tournament game-playing programs for three different minimax games, yielding results that contradict a number of publications. (B) Based on the insights gained in our attempts at understanding SSS*, we present a framework that facilitates the construction of several best-first fixeddepth game-tree search algorithms, known and new. The framework is based on depth-first null-window Alpha-Beta search, enhanced with storage to allow for the refining of previous search results. It focuses attention on the essential differences between algorithms. (C) We present a new instance of the framework, MTD(\u0192). It is well-suited for use with iterative deepening, and performs better than algorithms that are currently used in most state-of-the-art game-playing programs. We provide experimental evidence to explain why MTD(\u0192) performs better than the other fixed-depth minimax algorithms.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Worst-Case Upper Bound for (1, 2)-QSAT\nAbstract: The rigorous theoretical analysis of the algorithm for a subclass of QSAT, i.e. (1, 2)-QSAT, has been proposed in the literature. (1, 2)-QSAT, first introduced in SAT\u201908, can be seen as quantified extended 2-CNF formulas. Until now, within our knowledge, there exists no algorithm presenting the worst upper bound for (1, 2)-QSAT. Therefore in this paper, we present an exact algorithm to solve (1, 2)-QSAT. By analyzing the algorithms, we obtain a worst-case upper bound O(1.4142), where m is the number of clauses.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Planning over Chain Causal Graphs for Variables with Domains of Size 5 Is NP-Hard\nAbstract: Recently, considerable focus has been given to the problem of determining the boundary between tractable and intractable planning problems. In this paper, we study the complexity of planning in the class C n of planning problems, characterized by unary operators and directed path causal graphs. Although this is one of the simplest forms of causal graphs a planning problem can have, we show that planning is intractable for C n (unless P = NP), even if the domains of state variables have bounded size. In particular, we show that plan existence for C n is NP-hard for k \u2265 5 by reduction from Cnf-Sat. Here, k denotes the upper bound on the size of the state variable domains. Our result reduces the complexity gap for the class C n to cases k = 3 and k = 4 only, since C n is known to be tractable.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are not (anti-)monotonic, which makes it difficult to generate patterns satisfying these constraints. In this paper we introduce the notion of projection-antimonotonicity and \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm that allows efficient generation of the best patterns for some nonmonotonic constraints. In this paper we consider stability and \u0394-measure, which are nonmonotonic constraints, and apply them to interval tuple datasets. In the experiments, we compute best interval tuple patterns w.r.t. these measures and show the advantage of our approach over postfiltering approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recognition in-the-Tail: Training Detectors for Unusual Pedestrians with Synthetic Imposters\nAbstract: As autonomous vehicles become an every-day reality, high-accuracy pedestrian detection is of paramount practical importance. Pedestrian detection is a highly researched topic with mature methods, but most datasets focus on common scenes of people engaged in typical walking poses on sidewalks. But performance is most crucial for dangerous scenarios, such as children playing in the street or people using bicycles/skateboards in unexpected ways. Such \u201cinthe-tail\u201d data is notoriously hard to observe, making both training and testing difficult. To analyze this problem, we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset. Even given a dedicated collection effort, it is relatively small by contemporary standards (\u2248 1000 images). To explore largescale data-driven learning, we explore the use of synthetic data generated by a game engine. A significant challenge is selected the right \u201cpriors\u201d or parameters for synthesis: we would like realistic data with realistic poses and object configurations. Inspired by Generative Adversarial Networks, we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset, which we deem Synthetic Imposters. We demonstrate that this pipeline allows one to generate realistic training data by making use of rendering/animation engines. Interestingly, we also demonstrate that such data can be used to rank algorithms, suggesting that Synthetic Imposters can also be used for \u201cin-the-tail\u201d validation at test-time, a notoriously difficult challenge for real-world deployment.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Mining the Networks of Supply and Demand of Public Transport for Overload and Waste of Resources\nAbstract: We propose here a methodology to help to understand the shortcomings of public transportation in a city via the mining of complex networks representing the supply and demand of public transport. We show how to build these networks based upon data on smart card use in buses via the application of algorithms that estimate an OD and reconstruct the complete itinerary of the passengers. The overlapping of the two networks sheds light in potential overload and waste in the offer of resources that can be mitigated with strategies for balancing supply and demand.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-granular Perspectives on Covering\nAbstract: Covering model provides a general framework for granular computing in that overlapping among granules are almost indispensable. For any given covering, both intersection and union of covering blocks containing an element are exploited as granules to form granular worlds at different abstraction levels, respectively, and transformations among these different granular worlds are also discussed. As an application of the presented multi-granular perspective on covering, relational interpretation and axiomization of four types of covering based rough upper approximation operators are investigated, which can be dually applied\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Explicit Learning Curves for Transduction and Application to Clustering and Compression Algorithms\nAbstract: Inductive learning is based on inferring a general rule from a finite data set and using it to label new data. In transduction one attempts to solve the problem of using a labeled training set to label a set of unlabeled points, which are given to the learner prior to learning. Although transduction seems at the outset to be an easier task than induction, there have not been many provably useful algorithms for transduction. Moreover, the precise relation between induction and transduction has not yet been determined. The main theoretical developments related to transduction were presented by Vapnik more than twenty years ago. One of Vapnik\u2019s basic results is a rather tight error bound for transductive classification based on an exact computation of the hypergeometric tail. While tight, this bound is given implicitly via a computational routine. Our first contribution is a somewhat looser but explicit characterization of a slightly extended PAC-Bayesian version of Vapnik\u2019s transductive bound. This characterization is obtained using concentration inequalities for the tail of sums of random variables obtained by sampling without replacement. We then derive error bounds for compression schemes such as (transductive) support vector machines and for transduction algorithms based on clustering. The main observation used for deriving these new error bounds and algorithms is that the unlabeled test points, which in the transductive setting are known in advance, can be used in order to construct useful data dependent prior distributions over the hypothesis space.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Recognizing Activities and Spatial Context Using Wearable Sensors\nAbstract: We introduce a new dynamic model with the capability of recognizing both activities that an individual is performing as well as where that individual is located. Our approach is novel in that it utilizes a dynamic graphical model to jointly estimate both activity and spatial context over time based on the simultaneous use of asynchronous observations consisting of GPS measurements, and a small mountable sensor board. Joint inference is quite desirable as it has the ability to improve accuracy of the model and consistency of the location and activity estimates. The parameters of our model are trained on partially labeled data. We apply virtual evidence to improve data annotation, giving the user high flexibility when labeling training data. We present results indicating the performance gains achieved by virtual evidence for data annotation and the joint inference performed by our system.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Linear Programming for Large-Scale Markov Decision Problems\nAbstract: We consider the problem of controlling a Markov decision process (MDP) with a large state space, so as to minimize average cost. Since it is intractable to compete with the optimal policy for large scale problems, we pursue the more modest goal of competing with a lowdimensional family of policies. We use the dual linear programming formulation of the MDP average cost problem, in which the variable is a stationary distribution over state-action pairs, and we consider a neighborhood of a low-dimensional subset of the set of stationary distributions (defined in terms of state-action features) as the comparison class. We propose two techniques, one based on stochastic convex optimization, and one based on constraint sampling. In both cases, we give bounds that show that the performance of our algorithms approaches the best achievable by any policy in the comparison class. Most importantly, these results depend on the size of the comparison class, but not on the size of the state space. Preliminary experiments show the effectiveness of the proposed algorithms in a queuing application.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Comparing Dataset Characteristics that Favor the Apriori, Eclat or FP-Growth Frequent Itemset Mining Algorithms\nAbstract: Frequent itemset mining is a popular data mining technique. Apriori, Eclat, and FP-Growth are among the most common algorithms for frequent itemset mining. Considerable research has been performed to compare the relative performance between these three algorithms, by evaluating the scalability of each algorithm as the dataset size increases. While scalability as data size increases is important, previous papers have not examined the performance impact of similarly sized datasets that contain different itemset characteristics. This paper explores the effects that two dataset characteristics can have on the performance of these three frequent itemset algorithms. To perform this empirical analysis, a dataset generator is created to measure the effects of frequent item density and the maximum transaction size on performance. The generated datasets contain the same number of rows. This provides some insight into dataset characteristics that are conducive to each algorithm. The results of this paper\u2019s research demonstrate Eclat and FP-Growth both handle increases in maximum transaction size and frequent itemset density considerably better than the Apriori algorithm.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-Objective Deep Reinforcement Learning\nAbstract: We propose Deep Optimistic Linear Support Learning (DOL) to solve highdimensional multi-objective decision problems where the relative importances of the objectives are not known a priori. Using features from the high-dimensional inputs, DOL computes the convex coverage set containing all potential optimal solutions of the convex combinations of the objectives. To our knowledge, this is the first time that deep reinforcement learning has succeeded in learning multiobjective policies. In addition, we provide a testbed with two experiments to be used as a benchmark for deep multi-objective reinforcement learning.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Query answering in Answer Set Programming (ASP) is usually solved by computing (a subset of) the cautious consequences of a logic program. This task is computationally very hard, and there are programs for which computing cautious consequences is not viable in reasonable time. However, current ASP solvers produce the (whole) set of cautious consequences only at the end of their computation. This paper reports on strategies for computing cautious consequences, also introducing anytime algorithms able to produce sound answers during the computation. To appear in Theory and Practice of Logic Programming (TPLP).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Query Answering in Object Oriented Knowledge Bases in Logic Programming: Description and Challenge for ASP\nAbstract: Research on developing efficient and scalable ASP solvers can substantially benefit by the availability of data sets to experiment with. KB Bio 101 contains knowledge from a biology textbook, has been developed as part of Project Halo, and has recently become available for research use. KB Bio 101 is one of the largest KBs available in ASP and the reasoning with it is undecidable in general. We give a description of this KB and ASP programs for a suite of queries that have been of practical interest. We explain why these queries pose significant practical challenges for the current ASP solvers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bandit-Based Random Mutation Hill-Climbing\nAbstract: The Random Mutation Hill-Climbing algorithm is a direct search technique mostly used in discrete domains. It repeats the process of randomly selecting a neighbour of a bestso-far solution and accepts the neighbour if it is better than or equal to it. In this work, we propose to use a novel method to select the neighbour solution using a set of independent multiarmed bandit-style selection units which results in a bandit-based Random Mutation Hill-Climbing algorithm. The new algorithm significantly outperforms Random Mutation Hill-Climbing in both OneMax (in noise-free and noisy cases) and Royal Road problems (in the noise-free case). The algorithm shows particular promise for discrete optimisation problems where each fitness evaluation is expensive.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Interpolating Convex and Non-Convex Tensor Decompositions via the Subspace Norm\nAbstract: <lb>We consider the problem of recovering a low-rank tensor from its noisy observation. Previ-<lb>ous work has shown a recovery guarantee with signal to noise ratioO(ndK/2e/2) for recovering<lb>a Kth order rank one tensor of size n\u00d7 \u00b7 \u00b7 \u00b7 \u00d7 n by recursive unfolding. In this paper, we first<lb>improve this bound to O(nK/4) by a much simpler approach, but with a more careful analysis.<lb>Then we propose a new norm called the subspace norm, which is based on the Kronecker prod-<lb>ucts of factors obtained by the proposed simple estimator. The imposed Kronecker structure<lb>allows us to show a nearly ideal O(<lb>\u221a<lb>n+<lb>\u221a<lb>HK\u22121) bound, in which the parameter H controls<lb>the blend from the non-convex estimator to mode-wise nuclear norm minimization. Further-<lb>more, we empirically demonstrate that the subspace norm achieves the nearly ideal denoising<lb>performance even with H = O(1).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Identifying Irregular Power Usage by Turning Predictions into Holographic Spatial Visualizations\nAbstract: Power grids are critical infrastructure assets that face non-technical losses (NTL) such as electricity theft or faulty meters. NTL may range up to 40% of the total electricity distributed in emerging countries. Industrial NTL detection systems are still largely based on expert knowledge when deciding whether to carry out costly on-site inspections of customers. Electricity providers are reluctant to move to large-scale deployments of automated systems that learn NTL profiles from data due to the latter\u2019s propensity to suggest a large number of unnecessary inspections. In this paper, we propose a novel system that combines automated statistical decision making with expert knowledge. First, we propose a machine learning framework that classifies customers into NTL or non-NTL using a variety of features derived from the customers\u2019 consumption data. The methodology used is specifically tailored to the level of noise in the data. Second, in order to allow human experts to feed their knowledge in the decision loop, we propose a method for visualizing prediction results at various granularity levels in a spatial hologram. Our approach allows domain experts to put the classification results into the context of the data and to incorporate their knowledge for making the final decisions of which customers to inspect. This work has resulted in appreciable results on a real-world data set of 3.6M customers. Our system is being deployed in a commercial NTL detection software.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adversarial patrolling with spatially uncertain alarm signals\nAbstract: When securing complex infrastructures or large environments, constant surveillance of every area is not affordable. To cope with this issue, a common countermeasure is the usage of cheap but wide\u2013ranged sensors, able to detect suspicious events that occur in large areas, supporting patrollers to improve the effectiveness of their strategies. However, such sensors are commonly affected by uncertainty. In the present paper, we focus on spatially uncertain alarm signals. That is, the alarm system is able to detect an attack but it is uncertain on the exact position where the attack is taking place. This is common when the area to be secured is wide such as in border patrolling and fair site surveillance. We propose, to the best of our knowledge, the first Patrolling Security Game model where a Defender is supported by a spatially uncertain alarm system which non\u2013deterministically generates signals once a target is under attack. We show that finding the optimal strategy in arbitrary graphs isAPX\u2013hard even in zero\u2013sum games and we provide two (exponential time) exact algorithms and two (polynomial time) approximation algorithms. Furthermore, we analyse what happens in environments with special topologies, showing that in linear and cycle graphs the optimal patrolling strategy can be found in polynomial time, de facto allowing our algorithms to be used in real\u2013life scenarios, while in trees the problem is NP\u2013hard. Finally, we show that without false positives and missed detections, the best patrolling strategy reduces to stay in a place, wait for a signal, and respond to it at best. This strategy is optimal even with non\u2013negligible missed detection rates, which, unfortunately, affect every commercial alarm system. We evaluate our methods in simulation, assessing both quantitative and qualitative aspects.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Factored Frontier Algorithm for Approximate Inference in DBNs\nAbstract: The Factored Frontier (FF) algorithm is a simple approximate inference algorithm for Dynamic Bayesian Networks (DBNs). It is very similar to the fully factorized version of the Boyen-Koller (BK) algorithm, but in\u00ad stead of doing an exact update at every step followed by marginalisation (projection), it always works with factored distributions. Hence it can be applied to models for which the exact update step is intractable. We show that FF is equivalent to (one iteration of) loopy belief propagation (LBP) on the origi\u00ad nal DBN, and that BK is equivalent (to one iteration of) LBP on a DBN where we clus\u00ad ter some of the nodes. We then show em\u00ad pirically that by iterating more than once, LBP can improve on the accuracy of both FF and BK. We compare these algorithms on two real-world DBNs: the first is a model of a water treatment plant, and the second is a coupled HMM, used to model freeway traffic.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: NuMVC: An Efficient Local Search Algorithm for Minimum Vertex Cover\nAbstract: The Minimum Vertex Cover (MVC) problem is a prominent NP-hard combinatorial optimization problem of great importance in both theory and application. Local search has proved successful for this problem. However, there are two main drawbacks in state-of-the-art MVC local search algorithms. First, they select a pair of vertices to exchange simultaneously, which is timeconsuming. Secondly, although using edge weighting techniques to diversify the search, these algorithms lack mechanisms for decreasing the weights. To address these issues, we propose two new strategies: two-stage exchange and edge weighting with forgetting. The two-stage exchange strategy selects two vertices to exchange separately and performs the exchange in two stages. The strategy of edge weighting with forgetting not only increases weights of uncovered edges, but also decreases some weights for each edge periodically. These two strategies are used in designing a new MVC local search algorithm, which is referred to as NuMVC. We conduct extensive experimental studies on the standard benchmarks, namely DIMACS and BHOSLIB. The experiment comparing NuMVC with state-of-the-art heuristic algorithms show that NuMVC is at least competitive with the nearest competitor namely PLS on the DIMACS benchmark, and clearly dominates all competitors on the BHOSLIB benchmark. Also, experimental results indicate that NuMVC finds an optimal solution much faster than the current best exact algorithm for Maximum Clique on random instances as well as some structured ones. Moreover, we study the effectiveness of the two strategies and the run-time behaviour through experimental analysis.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Latent Skill Embedding for Personalized Lesson Sequence Recommendation\nAbstract: Students in online courses generate large amounts of data that can be used to personalize the learning process and improve quality of education. In this paper, we present the Latent Skill Embedding (LSE), a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments. Akin to collaborative filtering for recommender systems, the algorithm does not require students or content to be described by features, but it learns a representation using access traces. We formulate this problem as a regularized maximum-likelihood embedding of students, lessons, and assessments from historical student-content interactions. An empirical evaluation on large-scale data from Knewton, an adaptive learning technology company, shows that this approach predicts assessment results competitively with benchmark models and is able to discriminate between lesson sequences that lead to mastery and failure.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In this paper, we consider the decision-theoretic framework for online learning (DTOL) proposed by Freund and Schapire [FS97]. Previous algorithms for learning in this framework have a tunable learning rate parameter. Tuning the learning rate requires prior knowledge about the sequence and severely limits the practicality of the algorithm. While much progress has been made in the past decade for adaptively tuning the learning rate, all of these methods still ultimately rely on some prior information. We propose a completely parameter-free algorithm for learning in this framework. We show theoretically that our algorithm has a regret bound similar to the best bounds achieved by previous algorithms with optimally-tuned learning rates. We also present a few experiments comparing the performance of the algorithm with that of other algorithms for various tunings.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Finding Coordinated Paths for Multiple Holonomic Agents in 2-d Polygonal Environment\nAbstract: Avoiding collisions is one of the vital tasks for systems of autonomous mobile agents. We focus on the problem of finding continuous coordinated paths for multiple mobile disc agents in a 2-d environment with polygonal obstacles. The problem is PSPACE-hard, with the state space growing exponentially in the number of agents. Therefore, the state of the art methods include mainly reactive techniques and sampling-based iterative algorithms. We compare the performance of a widely-used reactive method ORCA with three variants of a popular planning algorithm RRT* applied to multi-agent path planning and find that an algorithm combining reactive collision avoidance and RRT* planning, which we call ORCA-RRT* can be used to solve instances that are out of the reach of either of the techniques. We experimentally show that: 1) the reactive part of the algorithm can efficiently solve many multi-agent path finding problems involving large number of agents, for which RRT* algorithm is often unable to find a solution in limited time and 2) the planning component of the algorithm is able to solve many instances containing local minima, where reactive techniques typically fail.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Agent Based Approaches to Engineering Autonomous Space Software\u2217\nAbstract: ion Engine\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Effect of Incomplete Meta-dataset on Average Ranking Method\nAbstract: One of the simplest metalearning methods is the average ranking method. This method uses metadata in the form of test results of a given set of algorithms on given set of datasets and calculates an average rank for each algorithm. The ranks are used to construct the average ranking. We investigate the problem of how the process of generating the average ranking is affected by incomplete metadata including fewer test results. This issue is relevant, because if we could show that incomplete metadata does not affect the final results much, we could explore it in future design. We could simply conduct fewer tests and save thus computation time. In this paper we describe an upgraded average ranking method that is capable of dealing with incomplete metadata. Our results show that the proposed method is relatively robust to omission in test results in the meta datasets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Why is Compiling Lifted Inference into a Low-Level Language so Effective?\u2217\nAbstract: First-order knowledge compilation techniques have proven efficient for lifted inference. They compile a relational probability model into a target circuit on which many inference queries can be answered efficiently. Early methods used data structures as their target circuit. In our KR-2016 paper, we showed that compiling to a low-level program instead of a data structure offers orders of magnitude speedup, resulting in the state-of-the-art lifted inference technique. In this paper, we conduct experiments to address two questions regarding our KR-2016 results: 1does the speedup come from more efficient compilation or more efficient reasoning with the target circuit?, and 2why are low-level programs more efficient target circuits than data structures? Probabilistic relational models (Getoor, 2007; De Raedt et al., 2016) (PRMs), or template-based models (Koller and Friedman, 2009), are extensions of Markov and belief networks (Pearl, 1988) that allow modelling of the dependencies among relations of individuals, and use a form of exchangeability: individuals about which there exists the same information are treated identically. The promise of lifted probabilistic inference (Poole, 2003; Kersting, 2012) is to carry out probabilistic inference for a PRM without needing to reason about each individual separately (grounding out the representation) by instead exploiting exchangeability to count undistinguished individuals. The problem of lifted probabilistic inference was first explicitly proposed by Poole (2003), who formulated the problem in terms of parametrized random variables, introduced the use of splitting to complement unification, the parametric factor (parfactor) representation of intermediate results, and an algorithm for summing out parametrized random variables and multiplying parfactors in a lifted manner. This work was advanced by the introduction of counting formulae, the development of counting elimination algorithms, and lifting the aggregator functions (de Salvo Braz, Amir, and Roth, 2005; Milch et al., 2008; Kisynski and Poole, 2009; Choi, de Salvo Braz, and Bui, 2011; Taghipour, Davis, and Blockeel, 2014). The main problem with these proposals is that they are based on variable elimination. Variable \u2217In IJCAI-16 Statistical Relational AI Workshop. Copyright c \u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. elimination (Zhang and Poole, 1994) (VE) is a dynamic programming approach which requires a representation of the intermediate results, and the current representations for such results are not closed under all operations used for inference. An alternative to VE is to use search-based methods based on conditioning such as recursive conditioning (Darwiche, 2001), AND-OR search (Dechter and Mateescu, 2007) and other related works (e.g., Bacchus, Dalmao, and Pitassi (2009)). While for lifted inference these methods require propositionalization in the same cases VE does, the advantage of these methods is that conditioning simplifies the representations rather than complicating them, and these methods exploit context specific independence (Boutilier et al., 1996) and determinism. The use of lifted search-based inference was proposed by Jha et al. (2010), Gogate and Domingos (2011) and Poole, Bacchus, and Kisynski (2011). These methods take as input a probabilistic relational model, a query, and some observations, and output the probability of the query given the observations. Van den Broeck et al. (2011) and Kazemi and Poole (2016) follow a knowledge compilation approach to lifted inference by evaluating a search-based lifted inference algorithm symbolically (instead of numerically) and extracting a target circuit on which many inference queries can be efficiently answered. While the target circuit used by Van den Broeck et al. (2011) is a data structure, Kazemi and Poole (2016) showed that using a low-level program as a target circuit is more efficient and results in orders of magnitude speedup. In a simultaneous work, Wu et al. (2016) showed that compiling to a low-level program is effective for BLOG (Milch et al., 2005) and offers substantial speedup. Two issues remained unanswered in Kazemi and Poole (2016)\u2019s results: 1they compared end-to-end (compiling to a target circuit and reasoning with the circuit) run-times of their work with Van den Broeck et al. (2011)\u2019s weighted first-order model counting, leaving the question of where exactly the speedup comes from, and 2the actual reason behind the speedup gained by compiling to a program instead of a data structure remained untested. In this paper, we answer to these two issues. We conduct our experiments on Markov logic networks (MLNs) (Richardson and Domingos, 2006) and argue that our results also hold for other representations (e.g., (Jaeger, 1997; De Raedt, Kimmig, and Toivonen, 2007; Suciu et al., 2011; Kazemi et al., 2014)). ar X iv :1 60 6. 04 51 2v 1 [ cs .A I] 1 4 Ju n 20 16 Background and Notations A population is a set of individuals (a.k.a. things, entities or objects). The population size is a nonnegative integer indicating the cardinality of the population. A logical variable is written in lower case and is typed with a population. For a logical variable x, we let \u2206x and |\u2206x| represent the population associated with x and its cardinality respectively. A lower case letter in bold represents a tuple of logical variables. Constants, denoting individuals, are written starting with an upper-case letter. A term is a logical variable or a constant. A parametrized random variable (PRV) consists of a k-ary predicate R and k terms ti and is represented as R(t1, . . . , tk). If every ti is a constant, the PRV corresponds to a random variable. When k = 0, we omit the parentheses. A grounding of a PRV can be achieved by replacing each of the logical variables with one of the individuals in their domains. A literal is an assignment of a value to a PRV. We represent R(. . .) = True and R(. . .) = False by r(. . .) and \u00acr(. . .) respectively. A world is a truth assignment to all groundings of all PRVs. A formula is made up of literals connected with logical connectives (conjunctions and disjunctions). Following Kazemi and Poole (2016), we represent a weighted formula (WF) as a triple \u3008L,F,w\u3009, where L is a set of logical variables, F is a formula whose logical variables are a subset of L, and w is a real-valued weight. For a given WF \u3008L,F,w\u3009 and a world \u03c9 , we let \u03b7(L,F,\u03c9) represent the number of assignments of individuals to the logical variables in L for which F holds in \u03c9 . Markov Logic Networks A Markov Logic Network (MLN) consists of a set \u03c8 of WFs. It induces the following probability distribution: Prob(\u03c9) = 1 Z \u220f \u3008L,F,w\u3009\u2208\u03c8 exp(\u03b7(L,F,\u03c9)\u2217w) (1) where \u03c9 is a world and Z = \u2211 \u03c9 \u2032 ( \u220f \u3008L,F,w\u3009\u2208\u03c8 (exp(\u03b7(L,F,\u03c9 \u2032)\u2217w)) (2) is the partition (normalization) function. In this paper, we focus on calculating the partition function as many inference queries on MLNs reduce to calculating the partition function. Following Kazemi and Poole (2016), we assume the formulae in WFs of MLNs are in conjunctive form. Example 1. Consider an MLN over three PRVs R(x,m), S(x,m) and T (x), where \u2206x = {X1,X2,X3,X4,X5} and \u2206m = {M1,M2}, with the following WFs: {\u3008{x,m},r(x,m)\u2227 s(x,m),1.2\u3009, \u3008{x,m},s(x,m)\u2227 t(x),0.2\u3009} and a world \u03c9 in which R(X1,M1), S(X1,M1), S(X1,M2) and T (X1) are True and the other ground PRVs are False. Then \u03b7({x,m},r(x,m)\u2227 s(x,m),\u03c9) = 1 as there is only one assignment of individuals to x and m (x = X1 and m = M1) for which r(x,m)\u2227 s(x,m) holds in \u03c9 and \u03b7({x,m},s(x,m)\u2227 t(x),\u03c9) = 2. Therefore: Pr(\u03c9) = 1 Z (exp(1\u22171.2)\u2217 exp(2\u22170.2)) An MLN can be conditioned on a PRV having no logical variables by replacing the PRV in all formulae of WFs with its observed value. Observations on individuals can be handled by a process called shattering. Example 2. Suppose for the MLN in Example 1 we observe that T (X1) and T (X2) are True. Since we have more information about X1 and X2 compared to other individuals in \u2206x, the individuals in \u2206x are no longer exchangeable. In order to handle this, we create two new logical variables x1 and x2 with \u2206x1 = {X1,X2} representing the individuals for which we have observed T is True, and \u2206x2 = {X3,X4,X5} representing the individuals for which we have not observed T . Then we create new WFs with our new logical variables as follows: {\u3008{x1,m},r(x1,m)\u2227 s(x1,m),1.2\u3009, \u3008{x2,m},r(x2,m)\u2227 s(x2,m),1.2\u3009, \u3008{x1,m},s(x1,m)\u2227 t(x1),0.2\u3009, \u3008{x2,m},s(x2,m)\u2227 t(x2),0.2\u3009} Then we replace t(x1) with True. For every logical variable x in the above MLN, the individuals in \u2206x are now exchangeable. This process is called shattering. We assume our input MLNs have been shattered based on the observations and refer interested readers to (de Salvo Braz, Amir, and Roth, 2005) for the details. An MLN can be also conditioned on some counts: the number of times a PRV with one logical variable is True or False. For a PRV T (x), we let Obs(T (x), i) represent a count observation on T (x) indicating T is True for exactly i out of |\u2206x| individuals. Example 3. Suppose for the MLN in Example 1 we observe Obs(T (x),2). We create two new logical variables x1 and x2 representing the subset of x having T True and False respectively, with |\u2206x1 | = 2 and |\u2206x2 | = 3.1 Then we create new WFs as in Example 2, and replace t(x1) with True and t(x2) with False. Search-based Lifted Inference Rules There are several rules that are used in search-based lifted inference algorithms. In this section, we describe some of these rules using examples. Lifted Decomposition Example 4. Consider the MLN in Example 1. On the relational level, all PRVs are connected to each other and we only have one connected component. On the grounding, however, for every individual Xi \u2208 \u2206x, we have the following WFs mentioning Xi: {\u3008{},r(Xi,M1)\u2227 s(Xi,M1),1.2\u3009, \u3008{},s(Xi,M1)\u2227 t(Xi),0.2\u3009, \u3008{},r(Xi,M2)\u2227 s(Xi,M2),1.2\u3009, \u3008{},s(Xi,M2)\u2227 t(Xi),0.2\u3009} Notice that the WFs mentioning Xi in the grounding are totally disconnected from the other WFs. Therefore, we have 1The domains can be assigned randomly due to the exchangeability of the individuals. |\u2206x| connected components that are equivalent up to renaming of the Xi individuals. In this case, x is called a decomposer of the network. Given the exchangeability of the individuals, the Z of all these connected components are the same. Therefore, we compute the Z for only one of these connected components, e.g., for an MLN with the following WFs, and raise it to the power of |\u2206x|. {\u3008{m},r(X1,m)\u2227 s(X1,m),1.2\u3009, \u3008{m},s(X1,m)\u2227 t(X1),0.2\u3009} In the above MLN, x has been replaced by one of its individuals. We refer to this as decomposing the MLN on logical variable x. While in this example only one logical variable is the decomposer, note that in general a set of logical variables can be the decomposer of an MLN. We point interested readers to (Poole, Bacchus, and Kisynski, 2011) for a detailed analysis of when a set of logical variables x is a decomposer of a network. Lifted Case Analysis Example 5. Consider the resulting MLN in Example 4 after being decomposed on x. We can find the partition function for this MLN by a case analysis on the values of a PRV. Suppose we do a case analysis on S(X1,m). Given that S(X1,m) represents |\u2206m| random variables in the grounding, one may think 2|\u2206m| cases must be considered: one for each assignment of values to the random variables. However, the individuals are exchangeable, i.e. we only care about the number of times S(X1,m) is True, not about the individuals that make it True. Thus, we only consider |\u2206m|+ 1 cases with the ith case being the case where for i out of |\u2206m| individuals S(X1,m) is True. We also multiply the ith case to (|\u2206m| i ) to take into account the number of different assignments to the individuals in \u2206m for which S(X1,m) is exactly i times True. The case analysis for this PRV will then be: Z(M) = \u2211m i=0 (|\u2206m| i ) Z(M|Obs(S(X1,m), i)) where M|Obs(S(X1,m), i) has the following WFs: {\u3008{m1},True\u2227 r(X1,m1),1.2\u3009, \u3008{m2},False\u2227 r(X1,m2),1.2\u3009, \u3008{m1},True\u2227 t(X1),0.2\u3009, \u3008{m2},False\u2227 t(X1),0.2\u3009} Removing False Formulae Example 6. Consider the resulting MLN in Example 5 after the case analysis on S(X1,m). The formulae of the second and the fourth WFs are equivalent to False and can be removed from the MLN. However, removing these WFs causes the random variables in R(X1,m2) to be totally eliminated from the MLN. To address the effect of these variables, we calculate the Z of the MLN having only the first and third WFs and multiply it by 2|\u2206m2 |, i.e. the number of possible assignments to the |\u2206m2 | random variables in R(X1,m2).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Towards Playlist Generation Algorithms Using RNNs Trained on Within-Track Transitions\nAbstract: We introduce a novel playlist generation algorithm that focuses on the quality of transitions using a recurrent neural network (RNN). The proposed model assumes that optimal transitions between tracks can be modelled and predicted by internal transitions within music tracks. We introduce modelling sequences of high-level music descriptors using RNNs and discuss an experiment involving different similarity functions, where the sequences are provided by a musical structural analysis algorithm. Qualitative observations show that the proposed approach can effectively model transitions of music tracks in playlists.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Agent-Agnostic Human-in-the-Loop Reinforcement Learning\nAbstract: Providing Reinforcement Learning agents with expert advice can dramatically improve various aspects of learning. Prior work has developed teaching protocols that enable agents to learn efficiently in complex environments; many of these methods tailor the teacher\u2019s guidance to agents with a particular representation or underlying learning scheme, offering effective but specialized teaching procedures. In this work, we explore protocol programs, an agent-agnostic schema for Human-in-the-Loop Reinforcement Learning. Our goal is to incorporate the beneficial properties of a human teacher into Reinforcement Learning without making strong assumptions about the inner workings of the agent. We show how to represent existing approaches such as action pruning, reward shaping, and training in simulation as special cases of our schema and conduct preliminary experiments on simple domains.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Weighted Graphical Models\nAbstract: Compiling graphical models has recently been under intense investigation, especially for probabilistic modeling and processing. We present here a novel data structure for compiling weighted graphical models (in particular, probabilistic models), called AND/OR Multi-Valued Decision Diagram (AOMDD). This is a generalization of our previous work on constraint networks, to weighted models. The AOMDD is based on the frameworks of AND/OR search spaces for graphical models, and Ordered Binary Decision Diagrams (OBDD). The AOMDD is a canonical representation of a graphical model, and its size and compilation time are bounded exponentially by the treewidth of the graph, rather than pathwidth as is known for OBDDs. We discuss a Variable Elimination schedule for compilation, and present the general APPLY algorithm that combines two weighted AOMDDs, and also present a search based method for compilation method. The preliminary experimental evaluation is quite encouraging, showing the potential of the AOMDD data structure.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper describes a Bayesian method for combining an arbitrary mixture of observational and experimental data in order to learn causal Bayesian networks. Observational data are passively observed. Experimental data, such as that produced by randomized controlled trials, result from the experimenter manipulating one or more variables (typically randomly) and observing the states of other variables. The paper presents a Bayesian method for learning the causal structure and parameters of the underlying causal process that is generating the data, given that (I) the data contains a mixture of observational and experimental case records, and (2) the causal process is modeled as a causal Bayesian network. This learning method was applied using as input various mixtures of experimental and observational data that were generated from the ALARM causal Bayesian network. In these experiments, the absolute and relative quantities of experimental and observational data were varied systematically. For each of these training datasets, the learning method was applied to predict the causal structure and to estimate the causal parameters that exist among randomly selected pairs of nodes in ALARM that are not confounded. The paper reports how these structure predictions and parameter estimates compare with the true causal structures and parameters as given by the ALARM network.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The paper describes some basic approaches to detection of bottlenecks in composite (modular) systems. The following basic system bottlenecks detection problems are examined: (1) traditional quality management approaches (Pareto chart based method, multicriteria analysis as selection of Pareto-efficient points, and/or multicriteria ranking), (2) selection of critical system elements (critical components/modules, critical component interconnection), (3) selection of interconnected system components as composite system faults (via clique-based fusion), (4) critical elements (e.g., nodes) in networks, and (5) predictive detection of system bottlenecks (detection of system components based on forecasting of their parameters). Here, heuristic solving schemes are used. Numerical examples illustrate the approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analysis and visualisation of RDF resources in Ondex\nAbstract: An increasing number of biomedical resources provide their information on the Semantic Web and this creates the basis for a distributed knowledge base which has the potential to advance biomedical research [1]. This potential, however, cannot be realised until researchers from the life sciences can interact with information in the Semantic Web. In particular, there is a need for tools that provide data reduction, visualization and interactive analysis capabilities. Ondex is a data integration and visualization platform developed to support Systems Biology Research [2]. At its core is a data model based on two main principles: first, all information can be represented as a graph and, second, all elements of the graph can be annotated with ontologies. This data model is conformant to the Semantic Web framework, in particular to RDF, and therefore Ondex is ideally positioned as a platform that can exploit the semantic web. The Ondex system offers a range of features and analysis methods of potential value to semantic web users, including: An interactive graph visualization interface (Ondex user client), which provides data reduction and representation methods that leverage the ontological annotation. A suite of importers from a variety of data sources to Ondex (http://ondex.org/formats.html) A collection of plug-ins which implement graph analysis, graph transformation and graph-matching functions. An integration toolkit (Ondex Integrator) which allows users to compose workflows from these modular components In addition, all importers and plug-ins are available as web-services which can be integrated in other tools, as for instance Taverna [3].\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Random Logic Programs: Linear Model\nAbstract: This paper proposes a model, the linear model, for randomly generating logic programs with low density of rules and investigates statistical properties of such random logic programs. It is mathematically shown that the average number of answer sets for a random program converges to a constant when the number of atoms approaches infinity. Several experimental results are also reported, which justify the suitability of the linear model. It is also experimentally shown that, under this model, the size distribution of answer sets for random programs tends to a normal distribution when the number of atoms is sufficiently large.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Evolving Game Skill-Depth using General Video Game AI Agents\nAbstract: Most games have, or can be generalised to have, a number of parameters that may be varied in order to provide instances of games that lead to very different player experiences. The space of possible parameter settings can be seen as a search space, and we can therefore use a Random Mutation Hill Climbing algorithm or other search methods to find the parameter settings that induce the best games. One of the hardest parts of this approach is defining a suitable fitness function. In this paper we explore the possibility of using one of a growing set of General Video Game AI agents to perform automatic playtesting. This enables a very general approach to game evaluation based on estimating the skill-depth of a game. Agent-based playtesting is computationally expensive, so we compare two simple but efficient optimisation algorithms: the Random Mutation HillClimber and the Multi-Armed Bandit Random Mutation HillClimber. For the test game we use a space-battle game in order to provide a suitable balance between simulation speed and potential skill-depth. Results show that both algorithms are able to rapidly evolve game versions with significant skill-depth, but that choosing a suitable resampling number is essential in order to combat the effects of noise.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Mining-Based Compression Approach for Constraint Satisfaction Problems\nAbstract: In this paper, we propose an extension of our Mining for SAT framework to Constraint satisfaction Problem (CSP). We consider n-ary extensional constraints (table constraints). Our approach aims to reduce the size of the CSP by exploiting the structure of the constraints graph and of its associated microstructure. More precisely, we apply itemset mining techniques to search for closed frequent itemsets on these two representation. Using Tseitin extension, we rewrite the whole CSP to another compressed CSP equivalent with respect to satisfiability. Our approach contrast with previous proposed approach by Katsirelos and Walsh, as we do not change the structure of the constraints.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Space-Time Graph Modeling of Ride Requests Based on Real-World Data\nAbstract: This paper focuses on modeling ride requests and their variations over location and time, based on analyzing extensive real-world data from a ride-sharing service. We introduce a graph model that captures the spatial and temporal variability of ride requests and the potentials for ride pooling. We discover these ride request graphs exhibit a well known property called \u201cdensification power law\u201d often found in real graphs modelling human behaviors. We show the pattern of ride requests and the potential of ride pooling for a city can be characterized by the densification factor of the ride request graphs. Previous works have shown that it is possible to automatically generate synthetic versions of these graphs that exhibit a given densification factor. We present an algorithm for automatic generation of synthetic ride request graphs that match quite well the densification factor of ride request graphs from actual ride request data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Variants of RMSProp and Adagrad with Logarithmic Regret Bounds\nAbstract: Adaptive gradient methods have become recently very popular, in particular as they have been shown to be useful in the training of deep neural networks. In this paper we have analyzed RMSProp, originally proposed for the training of deep neural networks, in the context of online convex optimization and show \u221a T -type regret bounds. Moreover, we propose two variants SC-Adagrad and SC-RMSProp for which we show logarithmic regret bounds for strongly convex functions. Finally, we demonstrate in the experiments that these new variants outperform other adaptive gradient techniques or stochastic gradient descent in the optimization of strongly convex functions as well as in training of deep neural networks.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning Equilibria with Partial Information in Decentralized Wireless Networks\nAbstract: In this article, a survey of several important equilibrium concepts for decentralized networks is presented. The term decentralized is used here to refer to scenarios where decisions (e.g., choosing a power allocation policy) are taken autonomously by devices interacting with each other (e.g., through mutual interference). The iterative long-term interaction is characterized by stable points of the wireless network called equilibria. The interest in these equilibria stems from the relevance of network stability and the fact that they can be achieved by letting radio devices to repeatedly interact over time. To achieve these equilibria, several learning techniques, namely, the best response dynamics, fictitious play, smoothed fictitious play, reinforcement learning algorithms, and regret matching, are discussed in terms of information requirements and convergence properties. Most of the notions introduced here, for both equilibria and learning schemes, are illustrated by a simple case study, namely, an interference channel with two transmitter-receiver pairs.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: BayesDB: A probabilistic programming system for querying the probable implications of data\nAbstract: Is it possible to make statistical inference broadly accessible to non-statisticians without sacrificing mathematical rigor or inference quality? This paper describes BayesDB, a probabilistic programming platform that aims to enable users to query the probable implications of their data as directly as SQL databases enable them to query the data itself. This paper focuses on four aspects of BayesDB: (i) BQL, an SQL-like query language for Bayesian data analysis, that answers queries by averaging over an implicit space of probabilistic models; (ii) techniques for implementing BQL using a broad class of multivariate probabilistic models; (iii) a semi-parametric Bayesian model-builder that auomatically builds ensembles of factorial mixture models to serve as baselines; and (iv) MML, a \u201cmeta-modeling\u201d language for imposing qualitative constraints on the model-builder and combining baseline models with custom algorithmic and statistical models that can be implemented in external software. BayesDB is illustrated using three applications: cleaning and exploring a public database of Earth satellites; assessing the evidence for temporal dependence between macroeconomic indicators; and analyzing a salary survey.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On Inconsistency Indices and Inconsistency Axioms in Pairwise Comparisons\nAbstract: Abstract: Pairwise comparisons are an important tool of modern (multiple criteria) decision making. Since human judgments are often inconsistent, many studies focused on the ways how to express and measure this inconsistency, and several inconsistency indices were proposed as an alternative to Saaty\u2019s inconsistency index and inconsistency ratio for reciprocal pairwise comparisons matrices. This paper aims to: firstly, introduce a new measure of inconsistency of pairwise comparisons and to prove its basic properties; secondly, to postulate an additional axiom, an upper boundary axiom, to an existing set of axioms; and the last, but not least, the paper provides proofs of satisfaction of this additional axiom by selected inconsistency indices as well as it provides their numerical comparison.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Spatial database implementation of fuzzy region connection calculus for analysing the relationship of diseases\nAbstract: Analyzing huge amounts of spatial data plays an important role in many emerging analysis and decision-making domains such as healthcare, urban planning, agriculture and so on. For extracting meaningful knowledge from geographical data, the relationships between spatial data objects need to be analyzed. An important class of such relationships are topological relations like the connectedness or overlap between regions. While realworld geographical regions such as lakes or forests do not have exact boundaries and are fuzzy, most of the existing analysis methods neglect this inherent feature of topological relations. In this paper, we propose a method for handling the topological relations in spatial databases based on fuzzy region connection calculus (RCC). The proposed method is implemented in PostGIS spatial database and evaluated in analyzing the relationship of diseases as an important application domain. We also used our fuzzy RCC implementation for fuzzification of the skyline operator in spatial databases. The results of the evaluation show that our method provides a more realistic view of spatial relationships and gives more flexibility to the data analyst to extract meaningful and accurate results in comparison with the existing methods. Keywords\u2014 fuzzy spatial reasoning; spatial data analysis; spatial skyline query;\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Combinatorial Optimization by Learning and Simulation of Bayesian Networks\nAbstract: This paper shows how the Bayesian network paradigm can be used in order to solve com\u00ad binatorial optimization problems. To do it some methods of structure learning from data and simulation of Bayesian networks are in\u00ad serted inside Estimation of Distribution Al\u00ad gorithms (EDA). EDA are a new tool for evo\u00ad lutionary computation in which populations of individuals are created by estimation and simulation of the joint probability distribu\u00ad tion of the selected individuals. We propose new approaches to EDA for combinatorial op\u00ad timization based on the theory of probabilis\u00ad tic graphical models. Experimental results are also presented.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Microkernel Architecture for Constraint Programming\nAbstract: This paper presents a microkernel architecture for constraint programming organized around a number of small number of core functionalities and minimal interfaces. The architecture contrasts with the monolithic nature of many implementations. Experimental results indicate that the software engineering benefits are not incompatible with\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Analogy-Based and Case-Based Reasoning: Two sides of the same coin\nAbstract: Analogy-Based (or Analogical) and Case-Based Reasoning (ABR and CBR) are two similar problem solving processes based on the adaptation of the solution of past problems for use with a new analogous problem. In this paper we review these two processes and we give some real world examples with emphasis to the field of Medicine, where one can find some of the most common and useful CBR applications. We also underline the differences between CBR and the classical rule-induction algorithms, we discuss the criticism for CBR methods and we focus on the future trends of research in the area of CBR.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Detection Algorithms for Communication Systems Using Deep Learning\nAbstract: The design and analysis of communication systems typically rely on the development of mathematical models that describe the underlying communication channel, which dictates the relationship between the transmitted and the received signals. However, in some systems, such as molecular communication systems where chemical signals are used for transfer of information, it is not possible to accurately model this relationship. In these scenarios, because of the lack of mathematical channel models, a completely new approach to design and analysis is required. In this work, we focus on one important aspect of communication systems, the detection algorithms, and demonstrate that by borrowing tools from deep learning, it is possible to train detectors that perform well, without any knowledge of the underlying channel models. We evaluate these algorithms using experimental data that is collected by a chemical communication platform, where the channel model is unknown and difficult to model analytically. We show that deep learning algorithms perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Seer: Empowering Software Defined Networking with Data Analytics\nAbstract: Network complexity is increasing, making network control and orchestration a challenging task. The proliferation of network information and tools for data analytics can provide an important insight into resource provisioning and optimisation. The network knowledge incorporated in software defined networking can facilitate the knowledge driven control, leveraging the network programmability. We present Seer: a flexible, highly configurable data analytics platform for network intelligence based on software defined networking and big data principles. Seer combines a computational engine with a distributed messaging system to provide a scalable, fault tolerant and real-time platform for knowledge extraction. Our first prototype uses Apache Spark for streaming analytics and open network operating system (ONOS) controller to program a network in real-time. The first application we developed aims to predict the mobility pattern of mobile devices inside a smart city environment. Keywords\u2013Big data, data analytics, data mining, knowledge centric networking (KCN), software defined networking (SDN), Seer\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ASHACL: Alternative Shapes Constraint Language\nAbstract: ASHACL, a variant of the W3C Shapes Constraint Language, is designed to determine whether an RDF graph meets some conditions. These conditions are grouped into shapes, which validate whether particular RDF terms each meet the constraints of the shape. Shapes are themselves expressed as RDF triples in an RDF graph, called a shapes graph.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Word and Phrase Translation with word2vec\nAbstract: Word and phrase tables are key inputs to machine translations, but costly to produce. New unsupervised learning methods represent words and phrases in a high-dimensional vector space, and these monolingual embeddings have been shown to encode syntactic and semantic relationships between language elements. The information captured by these embeddings can be exploited for bilingual translation by learning a transformation matrix that allows to match relative positions across two monolingual vector spaces. This method aims to identify high-quality candidates for word and phrase translation more cost-effectively from unlabeled data.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Differentiable Learning of Logical Rules for Knowledge Base Completion\nAbstract: Learned models composed of probabilistic logical rules are useful for many tasks, such as knowledge base completion. Unfortunately this learning problem is difficult, since determining the structure of the theory normally requires solving a discrete optimization problem. In this paper, we propose an alternative approach: a completely differentiable model for learning sets of first-order rules. The approach is inspired by a recently-developed differentiable logic, i.e. a subset of first-order logic for which inference tasks can be compiled into sequences of differentiable operations. Here we describe a neural controller system which learns how to sequentially compose the these primitive differentiable operations to solve reasoning tasks, and in particular, to perform knowledge base completion. The long-term goal of this work is to develop integrated, end-to-end systems that can learn to perform high-level logical reasoning as well as lower-level perceptual tasks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: RobustFill: Neural Program Learning under Noisy I/O\nAbstract: The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task. We additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs. Our best synthesis model achieves 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highlyengineered rule-based system fails entirely.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Learning an Attention Model in an Artificial Visual System\nAbstract: The Human visual perception of the world is of a large fixed image that is highly detailed and sharp. However, receptor density in the retina is not uniform: a small central region called the fovea is very dense and exhibits high resolution, whereas a peripheral region around it has much lower spatial resolution. Thus, contrary to our perception, we are only able to observe a very small region around the line of sight with high resolution. The perception of a complete and stable view is aided by an attention mechanism that directs the eyes to the numerous points of interest within the scene. The eyes move between these targets in quick, unconscious movements, known as \u201csaccades\u201d. Once a target is centered at the fovea, the eyes fixate for a fraction of a second while the visual system extracts the necessary information. An artificial visual system was built based on a fully recurrent neural network set within a reinforcement learning protocol, and learned to attend to regions of interest while solving a classification task. The model is consistent with several experimentally observed phenomena, and suggests novel predictions.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: A semantic embedding of quantified conditional logic in classical higher-order logic is presented.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Multi-lingual and Cross-lingual TimeLine Extraction\nAbstract: In this paper we present an approach to extract ordered timelines of events, their participants, locations and times from a set of multilingual and cross-lingual data sources. Based on the assumption that event-related information can be recovered from different documents written in different languages, we extend the Cross-document Event Ordering task presented at SemEval 2015 by specifying two new tasks for, respectively, Multilingual and Cross-lingual Timeline Extraction. We then develop three deterministic algorithms for timeline extraction based on two main ideas. First, we address implicit temporal relations at document level since explicit time-anchors are too scarce to build a wide coverage timeline extraction system. Second, we leverage several multilingual resources to obtain a single, interoperable, semantic representation of events across documents and across languages. The result is a highly competitive system that strongly outperforms the current state-of-the-art. Nonetheless, further analysis of the results reveals that linking the event mentions with their target entities and time-anchors remains a difficult challenge. The systems, resources and scorers are freely available to facilitate its use and guarantee the reproducibility of results.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: The role of T-cells within the immune system is to confirm and assess anomalous situations and then either respond to or tolerate the source of the effect. To illustrate how these mechanisms can be harnessed to solve real-world problems, we present the blueprint of a T-cell inspired algorithm for computer security worm detection. We show how the three central T-cell processes, namely T-cell maturation, differentiation and proliferation, naturally map into this domain and further illustrate how such an algorithm fits into a complete immune inspired computer security system and framework.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: From rules to runs: A dynamic epistemic take on imperfect information games\nAbstract: In the literature of game theory, the information sets of extensive form games have different interpretations, which may lead to confusions and paradoxical cases. We argue that the problem lies in the mix-up of two interpretations of the extensive form game structures: game rules or game runs which do not always coincide. In this paper, we try to separate and connect these two views by proposing a dynamic epistemic framework in which we can compute the runs step by step from the game rules plus the given assumptions of the players. We propose a modal logic to describe players\u2019 knowledge and its change during the plays, and provide a complete axiomatization. We also show that, under certain conditions, the mix-up of the rules and the runs is not harmful due to the structural similarity of the two.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Semantic Integration & Single-Site Opening of Multiple Governmental Data Sources\nAbstract: In many cases, government data is still \u2018locked\u2019 in several \u2018data silos\u2019, even within the boundaries of a single (inter-)national public organization with disparate and distributed organizational units and departments spread across multiple sites. Opening data and enabling its unified querying from a single site in an efficient and effective way is a semantic application integration and open government data challenge. This paper describes how NARA is using Semantic Web technology to implement an application integration approach within the boundaries of its organization via opening and querying multiple governmental data sources from a single site. The generic approach proposed, namely S3-AI, provides support to answering unified, ontology-mediated, federated queries to data produced and exploited by disparate applications, while these are being located in different organizational sites. S3-AI preserves ownership, autonomy and independency of applications and data. The paper extensively demonstrates S3AI, using the D2RQ and Fuseki technologies, for addressing the needs of a governmental \u201cIT helpdesk support\u201d case.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Accelerating Exact and Approximate Inference for (Distributed) Discrete Optimization with GPUs\nAbstract: Discrete optimization is a central problem in artificial intelligence. The optimization of the aggregated cost of a network of cost functions arises in a variety of problems including (W)CSP, DCOP, as well as optimization in stochastic variants such as Bayesian networks. Inference-based algorithms are powerful techniques for solving discrete optimization problems, which can be used independently or in combination with other techniques. However, their applicability is often limited by their compute intensive nature and their space requirements. This paper proposes the design and implementation of a novel inference-based technique, which exploits modern massively parallel architectures, such as those found in Graphical Processing Units (GPUs), to speed up the resolution of exact and approximated inference-based algorithms for discrete optimization. The paper studies the proposed algorithm in both centralized and distributed optimization contexts. The paper demonstrates that the use of GPUs provides significant advantages in terms of runtime and scalability, achieving up to two orders of magnitude in speedups and showing a considerable reduction in execution time (up to 345 times faster) with respect to a sequential version.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: RIO: Minimizing User Interaction in Debugging of Knowledge Bases\nAbstract: The best currently known interactive debugging systems rely upon some meta-information in terms of fault probabilities in order to improve their efficiency. However, misleading meta information might result in a dramatic decrease of the performance and its assessment is only possible aposteriori. Consequently, as long as the actual fault is unknown, there is always some risk of suboptimal interactions. In this work we present a reinforcement learning strategy that continuously adapts its behavior depending on the performance achieved and minimizes the risk of using lowquality meta information. Therefore, this method is suitable for application scenarios where reliable prior fault estimates are difficult to obtain. Using diverse real-world knowledge bases, we show that the proposed interactive query strategy is scalable, features decent reaction time, and outperforms both entropy-based and no-risk strategies on average w.r.t. required amount of user interaction.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Model-Driven Constraint Programming\nAbstract: Constraint programming can definitely be seen as a model-driven paradigm. The users write programs for modeling problems. These programs are mapped to executable models to calculate the solutions. This paper focuses on efficient model management (definition and transformation). From this point of view, we propose to revisit the design of constraint-programming systems. A modeldriven architecture is introduced to map solving-independent constraint models to solving-dependent decision models. Several important questions are examined, such as the need for a visual highlevel modeling language, and the quality of metamodeling techniques to implement the transformations. A main result is the sCOMMA platform that efficiently implements the chain from modeling to solving constraint problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The ACRV Picking Benchmark: A Robotic Shelf Picking Benchmark to Foster Reproducible Research\nAbstract: Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress as they make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking. The ACRV Picking Benchmark is designed to be reproducible by using a set of 42 common objects, a widely available shelf, and exact guidelines for object arrangement using stencils. A well-defined evaluation protocol enables the comparability of complete robotic systems \u2013 including perception and manipulation \u2013 instead of sub-systems only. Our paper describes this new benchmark challenge and presents results acquired by a baseline system based on a Baxter robot.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: ParaGraphE: A Library for Parallel Knowledge Graph Embedding\nAbstract: Knowledge graph embedding aims at translating the knowledge graph into numerical representations by transforming the entities and relations into continuous low-dimensional vectors. Recently, many methods [1, 5, 3, 2, 6] have been proposed to deal with this problem, but existing single-thread implementations of them are time-consuming for large-scale knowledge graphs. Here, we design a unified parallel framework to parallelize these methods, which achieves a significant time reduction without influencing the accuracy. We name our framework as ParaGraphE, which provides a library for parallel knowledge graph embedding. The source code can be downloaded from https: //github.com/LIBBLE/LIBBLE-MultiThread/tree/master/ParaGraphE.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Efficient Rank Aggregation via Lehmer Codes\nAbstract: We propose a novel rank aggregation method based on converting permutations into their corresponding Lehmer codes or other subdiagonal images. Lehmer codes, also known as inversion vectors, are vector representations of permutations in which each coordinate can take values not restricted by the values of other coordinates. This transformation allows for decoupling of the coordinates and for performing aggregation via simple scalar median or mode computations. We present simulation results illustrating the performance of this completely parallelizable approach and analytically prove that both the mode and median aggregation procedure recover the correct centroid aggregate with small sample complexity when the permutations are drawn according to the well-known Mallows models. The proposed Lehmer code approach may also be used on partial rankings, with similar performance guarantees.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We study Matching and other related problems in a partial information setting where the agents\u2019 utilities for being matched to other agents are hidden and the mechanism only has access to ordinal preference information. Our model is motivated by the fact that in many settings, agents cannot express the numerical values of their utility for different outcomes, but are still able to rank the outcomes in their order of preference. Specifically, we study problems where the ground truth exists in the form of a weighted graph, and look to design algorithms that approximate the true optimum matching using only the preference orderings for each agent (induced by the hidden weights) as input. If no restrictions are placed on the weights, then one cannot hope to do better than the simple greedy algorithm, which yields a half optimal matching. Perhaps surprisingly, we show that by imposing a little structure on the weights, we can improve upon the trivial algorithm significantly: we design a 1.6-approximation algorithm for instances where the hidden weights obey the metric inequality. Using our algorithms for matching as a black-box, we also design new approximation algorithms for other closely related problems: these include a a 3.2-approximation for the problem of clustering agents into equal sized partitions, a 4-approximation algorithm for Densest k-subgraph, and a 2.14-approximation algorithm for Max TSP. These results are the first non-trivial ordinal approximation algorithms for such problems, and indicate that we can design robust algorithms even when we are agnostic to the precise agent utilities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Improving the Scalability of Optimal Bayesian Network Learning with External-Memory Frontier Breadth-First Branch and Bound Search\nAbstract: Previous work has shown that the problem of learning the optimal structure of a Bayesian network can be formulated as a shortest path finding problem in a graph and solved using A* search. In this paper, we improve the scalability of this approach by developing a memoryefficient heuristic search algorithm for learning the structure of a Bayesian network. Instead of using A*, we propose a frontier breadth-first branch and bound search that leverages the layered structure of the search graph of this problem so that no more than two layers of the graph, plus solution reconstruction information, need to be stored in memory at a time. To further improve scalability, the algorithm stores most of the graph in external memory, such as hard disk, when it does not fit in RAM. Experimental results show that the resulting algorithm solves significantly larger problems than the current state of the art.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks\nAbstract: Autonomous driving is one of the most recent topics of interest which is aimed at replicating human driving behavior keeping in mind the safety issues. We approach the problem of learning synthetic driving using generative neural networks. The main idea is to make a controller trainer network using images plus key press data to mimic human learning. We used the architecture of a stable GAN to make predictions between driving scenes using key presses. We train our model on one video game (Road Rash) and tested the accuracy and compared it by running the model on other maps in Road Rash to determine the extent of learning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Network Structure Learning with Integer Programming: Polytopes, Facets, and Complexity\nAbstract: The challenging task of learning structures of probabilistic graphical models is an important problem within modern AI research. Recent years have witnessed several major algorithmic advances in structure learning for Bayesian networks\u2014arguably the most central class of graphical models\u2014especially in what is known as the score-based setting. A successful generic approach to optimal Bayesian network structure learning (BNSL), based on integer programming (IP), is implemented in the gobnilp system. Despite the recent algorithmic advances, current understanding of foundational aspects underlying the IP based approach to BNSL is still somewhat lacking. Understanding fundamental aspects of cutting planes and the related separation problem is important not only from a purely theoretical perspective, but also since it holds out the promise of further improving the efficiency of state-of-the-art approaches to solving BNSL exactly. In this paper, we make several theoretical contributions towards these goals: (i) we study the computational complexity of the separation problem, proving that the problem is NP-hard; (ii) we formalise and analyse the relationship between three key polytopes underlying the IP-based approach to BNSL; (iii) we study the facets of the three polytopes both from the theoretical and practical perspective, providing, via exhaustive computation, a complete enumeration of facets for low-dimensional family-variable polytopes; and, furthermore, (iv) we establish a tight connection of the BNSL problem to the acyclic subgraph problem.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Model-Lite Case-Based Planning\nAbstract: There is increasing awareness in the planning community that depending on complete models impedes the applicability of planning technology in many real world domains where the burden of specifying complete domain models is too high. In this paper, we consider a novel solution for this challenge that combines generative planning on incomplete domain models with a library of plan cases that are known to be correct. While this was arguably the original motivation for casebased planning, most existing case-based planners assume (and depend on) from-scratch planners that work on complete domain models. In contrast, our approach views the plan generated with respect to the incomplete model as a \u201cskeletal plan\u201d and augments it with directed mining of plan fragments from library cases. We will present the details of our approach and present an empirical evaluation of our method in comparison to a state-of-the-art case-based planner that depends on complete domain models.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A SYSTEM OF SERIAL COMPUTATION FOR CLASSIFIED RULES PREDICTION IN NON- REGULAR ONTOLOGY TREES\nAbstract: Objects or structures that are regular take uniform dimensions. Based on the concepts of regular models, our previous research work has developed a system of a regular ontology that models learning structures in a multiagent system for uniform pre-assessments in a learning environment. This regular ontology has led to the modelling of a classified rules learning algorithm that predicts the actual number of rules needed for inductive learning processes and decision making in a multiagent system. But not all processes or models are regular. Thus this paper presents a system of polynomial equation that can estimate and predict the required number of rules of a non-regular ontology model given some defined parameters.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Equilibrium Graphs\nAbstract: In this paper we present an extension of Peirce\u2019s existential graphs to provide a diagrammatic representation of expressions in Quantified Equilibrium Logic (QEL). Using this formalisation, logical connectives are replaced by encircled regions (circles and squares) and quantified variables are represented as \u201cidentity\u201d lines. Although the expressive power is equivalent to that of QEL, the new representation can be useful for illustrative or educational purposes.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Numerical representations of acceptance\nAbstract: Accepting a proposition means that our confidence in this proposition is strictly greater than the confidence in its negation. This paper investigates the subclass of uncertainty measures, expressing confidence, that capture the idea of acceptance, what we call acceptance functions. Due to the monotonicity property of confidence measures, the acceptance of a proposition entails the acceptance of any of its logical consequences. In agreement with the idea that a belief set (in the sense of Giirdenfors) must be closed under logical consequence, it is also required that the separate acceptance of two propositions entail the acceptance of their conjunction. Necessity (and possibility) measures agree with this view of acceptance while probability and belief functions generally do not. General properties of acceptance functions are established. The motivation behind this work is the investigation of a setting for belief revision more general than the one proposed by Alchourr6n, Giirdenfors and Makinson, in connection with the notion of conditioning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MOBA: a New Arena for Game AI\nAbstract: Games have always been popular testbeds for Artificial Intelligence (AI). In the last decade, we have seen the rise of the Multiple Online Battle Arena (MOBA) games, which are the most played games nowadays. In spite of this, there are few works that explore MOBA as a testbed for AI Research. In this paper we present and discuss the main features and opportunities offered by MOBA games to Game AI Research. We describe the various challenges faced along the game and also propose a discrete model that can be used to better understand and explore the game. With this, we aim to encourage the use of MOBA as a novel research platform for Game AI.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Identifying Hazardousness of Sewer-Pipeline Gas-Mixture using Classification Methods A Comparative Study\nAbstract: In this work, we formulated a real-world problem related to sewerpipeline gas detection using the classification-based approaches. The primary goal of this work was to identify the hazardousness of sewer-pipeline to offer safe and non-hazardous access to sewer-pipeline workers so that the human fatalities, which occurs due to the toxic exposure of sewer gas components, can be avoided. The dataset acquired through laboratory tests, experiments, and various literature-sources were organized to design a predictive model that was able to identify/classify hazardous and non-hazardous situation of sewer-pipeline. To design such prediction model, several classification algorithms were used and their performances were evaluated and compared, both empirically and statistically, over the collected dataset. In addition, the performances of several ensemble methods were analyzed to understand the extent of improvement offered by these methods. The result of this comprehensive study showed that the instance-based-learning algorithm performed better than many other algorithms such as multi-layer perceptron, radial basis function network, support vector machine, reduced pruning tree, etc. Similarly, it was observed that multi-scheme ensemble approach enhanced the performance of base predictors. V. K. Ojha IT4Innovations, V\u0160B Technical University of Ostrava, Ostrava, Czech Republic and Dept. of Computer Science & Engineering, Jadavpur University, Kolkata, India E-mail: varun.kumar.ojha@vsb.cz P. Dutta Dept. of Computer & System Sciences, Visva-Bharati University, India E-mail: paramartha.dutta@gmail.com A Chaudhuri Dept. of Computer Science & Engineering, Jadavpur University, Kolkata, India E-mail: atalc23@gmail.com Neural Computing and Applications DOI: 10.1007/s00521-016-2443-0 ar X iv :1 70 7. 00 56 1v 1 [ cs .N E ] 1 6 M ay 2 01 7 2 Varun Kumar Ojha et al.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: We present tropical games, a generalization of combinatorial min-max games based on tropical algebras. Our model breaks the traditional symmetry of rational zero-sum games where players have exactly opposed goals (min vs. max), is more widely applicable than min-max and also supports a form of pruning, despite it being less effective than \u03b1-\u03b2. Actually, min-max games may be seen as particular cases where both the game and its dual are tropical: when the dual of a tropical game is also tropical, the power of \u03b1-\u03b2 is completely recovered. We formally develop the model and prove that the tropical pruning strategy is correct, then conclude by showing how the problem of approximated parsing can be modeled as a tropical game, profiting from pruning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: HANDWRITTEN \u2018BANGLA\u2019 ALPHABET RECOGNITION USING AN MLP BASED CLASSIFIER\nAbstract: The work presented here involves the design of a Multi Layer Perceptron (MLP) based classifier for recognition of handwritten Bangla alphabet using a 76 element feature set Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten characters of Bangla alphabet includes 24 shadow features, 16 centroid features and 36 longest-run features. Recognition performances of the MLP designed to work with this feature set are experimentally observed as 86.46% and 75.05% on the samples of the training and the test sets respectively. The work has useful application in the development of a complete OCR system for handwritten Bangla text.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generalised Discount Functions applied to a Monte-Carlo AI\u03bc Implementation\nAbstract: In recent years, work has been done to develop the theory of General Reinforcement Learning (GRL). However, there are few examples demonstrating the known results regarding generalised discounting. We have added to the GRL simulation platform AIXIjs the functionality to assign an agent arbitrary discount functions, and an environment which can be used to determine the effect of discounting on an agent\u2019s policy. Using this, we investigate how geometric, hyperbolic and power discounting affect an informed agent in a simple MDP. We experimentally reproduce a number of theoretical results, and discuss some related subtleties. It was found that the agent\u2019s behaviour followed what is expected theoretically, assuming appropriate parameters were chosen for the Monte-Carlo Tree Search (MCTS) planning algorithm. Keywords\u2014 Reinforcement Learning, Discount Function, Time Consistency, Monte Carlo\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Computational Complexity of Dominance and Consistency in CP-Nets\nAbstract: We investigate the computational complexity of testing dominance and consistency in CP-nets. Previously, the complexity of dominance has been determined for restricted classes in which the dependency graph of the CP-net is acyclic. However, there are preferences of interest that define cyclic dependency graphs; these are modeled with general CP-nets. In our main results, we show here that both dominance and consistency for general CP-nets are PSPACE-complete. We then consider the concept of strong dominance, dominance equivalence and dominance incomparability, and several notions of optimality, and identify the complexity of the corresponding decision problems. The reductions used in the proofs are from STRIPS planning, and thus reinforce the earlier established connections between both areas.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Resource-Driven Mission-Phasing Techniques for Constrained Agents in Stochastic Environments\nAbstract: Because an agent\u2019s resources dictate what actions it can possibly take, it should plan which resources it holds over time carefully, considering its inherent limitations (such as power or payload restrictions), the competing needs of other agents for the same resources, and the stochastic nature of the environment. Such agents can, in general, achieve more of their objectives if they can use \u2014 and even create \u2014 opportunities to change which resources they hold at various times. Driven by resource constraints, the agents could break their overall missions into an optimal series of phases, optimally reconfiguring their resources at each phase, and optimally using their assigned resources in each phase, given their knowledge of the stochastic environment. In this paper, we formally define and analyze this constrained, sequential optimization problem in both the single-agent and multi-agent contexts. We present a family of mixed integer linear programming (MILP) formulations of this problem that can optimally create phases (when phases are not predefined) accounting for costs and limitations in phase creation. Because our formulations simultaneously also find the optimal allocations of resources at each phase and the optimal policies for using the allocated resources at each phase, they exploit structure across these coupled problems. This allows them to find solutions significantly faster (orders of magnitude faster in larger problems) than alternative solution techniques, as we demonstrate empirically.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: COMBINING THE ANALYTICALHIERARCHY PROCESS AND THEGENETIC ALGORITHM TO SOLVE THE TIMETABLE PROBLEM\nAbstract: The main problems of school course timetabling are time, curriculum, and classrooms. In addition there are other problems that vary from one institution to another. This paper is intended to solve the problem of satisfying the teachers\u2019 preferred schedule in a way that regards the importance of the teacher to the supervising institute, i.e. his score according to some criteria. Genetic algorithm (GA) has been presented as an elegant method in solving timetable problem (TTP) in order to produce solutions with no conflict. In this paper, we consider the analytic hierarchy process (AHP) to efficiently obtain a score for each teacher, and consequently produce a GA-based TTP solution that satisfies most of the teachers\u2019 preferences.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Symbolic Music Data Version 1.0\nAbstract: In this document, we introduce a new dataset designed for training machine learning models of symbolic music data. Five datasets are provided, one of which is from a newly collected corpus of 20K midi files. We describe our preprocessing and cleaning pipeline, which includes the exclusion of a number of files based on scores from a previously developed probabilistic machine learning model. We also define training, testing and validation splits for the new dataset, based on a clustering scheme which we also describe. Some simple histograms are included.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Solving Distributed Constraint Optimization Problems Using Logic Programming\nAbstract: This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) It shows how one can formulate DCOPs as logic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) It experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) It demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs. Under consideration in Theory and Practice of Logic Programming (TPLP).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Solving #SAT and Bayesian Inference with Backtracking Search\nAbstract: Inference in Bayes Nets (BAYES) is an important problem with numerous applications in probabilistic reasoning. Counting the number of satisfying assignments of a propositional formula (#SAT) is a closely related problem of fundamental theoretical importance. Both these problems, and others, are members of the class of sum-of-products (SUMPROD) problems. In this paper we show that standard backtracking search when augmented with a simple memoization scheme (caching) can solve any sum-of-products problem with time complexity that is at least as good any other state-of-the-art exact algorithm, and that it can also achieve the best known time-space tradeoff. Furthermore, backtracking\u2019s ability to utilize more flexible variable orderings allows us to prove that it can achieve an exponential speedup over other standard algorithms for SUMPROD on some instances. The ideas presented here have been utilized in a number of solvers that have been applied to various types of sum-of-product problems. These system\u2019s have exploited the fact that backtracking can naturally exploit more of the problem\u2019s structure to achieve improved performance on a range of problem instances. Empirical evidence of this performance gain has appeared in published works describing these solvers, and we provide references to these works.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Mutation has traditionally been regarded as an important operator in evolutionary algorithms. In particular, there have been many experimental studies which showed the effectiveness of adapting mutation rates for various static optimization problems. Given the perceived effectiveness of adaptive and self-adaptive mutation for static optimization problems, there have been speculations that adaptive and self-adaptive mutation can benefit dynamic optimization problems even more since adaptation and self-adaptation are capable of following a dynamic environment. However, few theoretical results are available in analyzing rigorously evolutionary algorithms for dynamic optimization problems. It is unclear when adaptive and self-adaptive mutation rates are likely to be useful for evolutionary algorithms in solving dynamic optimization problems. This paper provides the first rigorous analysis of adaptive mutation and its impact on the computation times of evolutionary algorithms in solving certain dynamic optimization problems. More specifically, for both individual-based and population-based EAs, we have shown that any time-variable mutation rate scheme will not significantly outperform a fixed mutation rate on some dynamic optimization problem instances. The proofs also offer some insights into conditions under which any time-variable mutation scheme is unlikely to be useful and into the relationships between the problem characteristics and algorithmic features (e.g., different mutation schemes).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Submodular Optimization under Noise\nAbstract: We consider the problem of maximizing a monotone submodular function under noise.<lb>There has been a great deal of work on optimization of submodular functions under various<lb>constraints, resulting in algorithms that provide desirable approximation guarantees. In many<lb>applications, however, we do not have access to the submodular function we aim to optimize,<lb>but rather to some erroneous or noisy version of it. This raises the question of whether prov-<lb>able guarantees are obtainable in presence of error and noise. We provide initial answers, by<lb>focusing on the question of maximizing a monotone submodular function under a cardinality<lb>constraint when given access to a noisy oracle of the function. We show that:<lb>\u2022 For a cardinality constraint k \u2265 2, there is an approximation algorithm whose approxi-<lb>mation ratio is arbitrarily close to 1\u2212 1/e;<lb>\u2022 For k = 1 there is an algorithm whose approximation ratio is arbitrarily close to 1/2. No<lb>randomized algorithm can obtain an approximation ratio better than 1/2 + o(1);<lb>\u2022 If the noise is adversarial, no non-trivial approximation guarantee can be obtained. \u2217Supported by ISF 1241/12;<lb>\u2020Supported by NSF grant CCF-1301976, CAREER CCF-1452961, Google Faculty Research Award, Facebook Faculty<lb>Award.<lb>ar<lb>X<lb>iv<lb>:1<lb>60<lb>1.<lb>03<lb>09<lb>5v<lb>3<lb>[<lb>cs<lb>.D<lb>S]<lb>4<lb>N<lb>ov<lb>2<lb>01<lb>6\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Performance Based Evaluation of Various Machine Learning Classification Techniques for Chronic Kidney Disease Diagnosis\nAbstract: Areas where Artificial Intelligence (AI) & related fields are finding their applications are increasing day by day, moving from core areas of computer science they are finding their applications in various other domains. In recent times Machine Learning i.e. a sub-domain of AI has been widely used in order to assist medical experts and doctors in the prediction, diagnosis and prognosis of various diseases and other medical disorders. In this manuscript the authors applied various machine learning algorithms to a problem in the domain of medical diagnosis and analyzed their efficiency in predicting the results. The problem selected for the study is the diagnosis of the Chronic Kidney Disease. The dataset used for the study consists of 400 instances and 24 attributes. The authors evaluated 12 classification techniques by applying them to the Chronic Kidney Disease data. In order to calculate efficiency, results of the prediction by candidate methods were compared with the actual medical results of the subject. The various metrics used for performance evaluation are predictive accuracy, precision, sensitivity and specificity. The results indicate that decision-tree performed best with nearly the accuracy of 98.6%, sensitivity of 0.9720, precision of 1 and specificity of 1.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Generative Adversarial Imitation Learning\nAbstract: Consider learning a policy from example expert behavior, without interaction with the expert or access to reinforcement signal. One approach is to recover the expert\u2019s cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data, as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Music and Vocal Separation Using Multi-Band Modulation Based Features\nAbstract: The potential use of non-linear speech features has not been investigated for music analysis although other commonly used speech features like Mel Frequency Ceptral Coefficients (MFCC) and pitch have been used extensively. In this paper, we assume an audio signal to be a sum of modulated sinusoidal and then use the energy separation algorithm to decompose the audio into amplitude and frequency modulation components using the non-linear Teager-Kaiser energy operator. We first identify the distribution of these non-linear features for music only and voice only segments in the audio signal in different Mel spaced frequency bands and show that they have the ability to discriminate. The proposed method based on Kullback-Leibler divergence measure is evaluated using a set of Indian classical songs from three different artists. Experimental results show that the discrimination ability is evident in certain low and mid frequency bands (200 1500 Hz).\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In this paper, we reexamine theMovie Graph Argument, which demonstrates a basic incompatibility between computationalism and materialism. We discover that the incompatibility is only manifest in singular classical-like universes. If we accept that we live in a Multiverse, then the incompatibility goes away, but in that case another line of argument shows that with computationalism, the fundamental, or primitive materiality has no causal influence on what is observed, which must must be derivable from basic arithmetic properties.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Conflict and Surprise: Heuristics for Model Revision\nAbstract: Any probabilistic model of a problem is based on assumptions which, if violated, invalidate the model. Users of probability based decision aids need to be alerted when cases arise that are not covered by the aid's model. Diagnosis of model failure is also necessary to control dynamic model construction and revision. This paper presents a set of decision theoretically motivated heuristics for diagnosing situations in which a model is likely to provide an inadequate representation of the process being modeled.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: How to Maximize User Satisfaction Degree in Multi-service IP Networks\nAbstract: Bandwidth allocation is a fundamental problem in communication networks. With current network moving towards the Future Internet model, the problem is further intensified as network traffic demanding far from exceeds network bandwidth capability. Maintaining a certain user satisfaction degree therefore becomes a challenge research topic. In this paper, we deal with the problem by proposing BASMIN, a novel bandwidth allocation scheme that aims to maximize network user\u2019s happiness. We also defined a new metric for evaluating network user satisfaction degree: network worth. A three-step evaluation process is then conducted to compare BASMIN efficiency with other three popular bandwidth allocation schemes. Throughout the tests, we experienced BASMIN\u2019s advantages over the others; we even found out that one of the most widely used bandwidth allocation schemes, in fact, is not effective at all.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: \u03c4 -chain (pronounced tau-chain) is a decentralized peer-to-peer network having three unified faces: Rules, Proofs, and Computer Programs, allowing a generalization of virtually any centralized or decentralized P2P network, together with many new abilities, as we present on this note. \u201cIf law-making is a game, then it is a game in which changing the rules is a move.\u201d Peter Suber presenting Nomic [10]. Document version: 0.2 Feb 6 2015 Document version: 0.21 Feb 9 2015 Document version: 0.22 Feb 12 2015\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Query Answering with Inconsistent Existential Rules under Stable Model Semantics\nAbstract: Traditional inconsistency-tolerent query answering in ontology-based data access relies on selecting maximal components of an ABox/database which are consistent with the ontology. However, some rules in ontologies might be unreliable if they are extracted from ontology learning or written by unskillful knowledge engineers. In this paper we present a framework of handling inconsistent existential rules under stable model semantics, which is defined by a notion called rule repairs to select maximal components of the existential rules. Surprisingly, for R-acyclic existential rules with R-stratified or guarded existential rules with stratified negations, both the data complexity and combined complexity of query answering under the rule repair semantics remain the same as that under the conventional query answering semantics. This leads us to propose several approaches to handle the rule repair semantics by calling answer set programming solvers. An experimental evaluation shows that these approaches have good scalability of query answering under rule repairs on realistic cases.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Game-Theoretic Model and Best-Response Learning Method for Ad Hoc Coordination in Multiagent Systems\nAbstract: The ad hoc coordination problem is to design an autonomous agent which is able to achieve optimal flexibility and efficiency in a multiagent system with no mechanisms for prior coordination. We conceptualise this problem formally using a game-theoretic model, called the stochastic Bayesian game, in which the behaviour of a player is determined by its private information, or type. Based on this model, we derive a solution, called Harsanyi-Bellman Ad Hoc Coordination (HBA), which utilises the concept of Bayesian Nash equilibrium in a planning procedure to find optimal actions in the sense of Bellman optimal control. We evaluate HBA in a multiagent logistics domain called level-based foraging, showing that it achieves higher flexibility and efficiency than several alternative algorithms. We also report on a human-machine experiment at a public science exhibition in which the human participants played repeated Prisoner\u2019s Dilemma and Rock-Paper-Scissors against HBA and alternative algorithms, showing that HBA achieves equal efficiency and a significantly higher welfare and winning rate.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: PDDL+ Planning via Constraint Answer Set Programming\nAbstract: PDDL+ is an extension of PDDL that enables modelling planning domains with mixed discrete-continuous dynamics. In this paper we present a new approach to PDDL+ planning based on Constraint Answer Set Programming (CASP), i.e. ASP rules plus numerical constraints. To the best of our knowledge, ours is the first attempt to link PDDL+ planning and logic programming. We provide an encoding of PDDL+ models into CASP problems. The encoding can handle non-linear hybrid domains, and represents a solid basis for applying logic programming to PDDL+ planning. As a case study, we consider the EZCSP CASP solver and obtain promising results on a set of PDDL+ benchmark problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Emerging ontology authoring methods to add knowledge to an ontology focus on ameliorating the validation bottleneck. The verification of the newly added axiom is still one of trying and seeing what the reasoner says, because a systematic testbed for ontology authoring is missing. We sought to address this by introducing the approach of test-driven development for ontology authoring. We specify 36 generic tests, as TBox queries and TBox axioms tested through individuals, and structure their inner workings in an \u2018open box\u2019-way, which cover the OWL 2 DL language features. This is implemented as a Protege plugin so that one can perform a TDD test as a black box test. We evaluated the two test approaches on their performance. The TBox queries were faster, and that effect is more pronounced the larger the ontology is. We provide a general sequence of a TDD process for ontology engineering as a foundation for a TDD methodology.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: MULTI-TASK GLOH FEATURE SELECTION FOR HUMAN AGE ESTIMATION\nAbstract: In this paper, we propose a novel age estimation method based on gradient location and orientation histogram (GLOH) descriptor and multi-task learning (MTL). The GLOH, one of the state-of-the-art local descriptor, is used to capture the agerelated local and spatial information of face image. As the extracted GLOH features are often redundant, MTL is designed to select the most informative GLOH bins for age estimation problem, while the corresponding weights are determined by ridge regression. This approach largely reduces the dimensions of feature, which can not only improve performance but also decrease the computational burden. Experiments on the public available FG-NET database show that the proposed method can achieve comparable performance over previous approaches while using much fewer features.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: AMSOM: Adaptive Moving Self-organizing Map for Clustering and Visualization\nAbstract: Self-Organizing Map (SOM) is a neural network model which is used to obtain a topology-preserving mapping from the (usually high dimensional) input/feature space to an output/map space of fewer dimensions (usually two or three in order to facilitate visualization). Neurons in the output space are connected with each other but this structure remains fixed throughout training and learning is achieved through the updating of neuron reference vectors in feature space. Despite the fact that growing variants of SOM overcome the fixed structure limitation they increase computational cost and also do not allow the removal of a neuron after its introduction. In this paper, a variant of SOM is proposed called AMSOM (Adaptive Moving Self-Organizing Map) that on the one hand creates a more flexible structure where neuron positions are dynamically altered during training and on the other hand tackles the drawback of having a predefined grid by allowing neuron addition and/or removal during training. Experiments using multiple literature datasets show that the proposed method improves training performance of SOM, leads to a better visualization of the input dataset and provides a framework for determining the optimal number and structure of neurons.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exact Inference in Networks with Discrete Children of Continuous Parents\nAbstract: Many real life domains contain a mixture of discrete and continuous variables and can be modeled as hy\u00ad brid Bayesian Networks (BNs). An important sub\u00ad class of hybrid BNs are conditional linear Gaussian (CLG) networks, where the conditional distribution of the continuous variables given an assignment to the discrete variables is a multivariate Gaussian. Lau\u00ad ritzen's extension to the clique tree algorithm can be used for exact inference in CLG networks. However, many domains include discrete variables that depend on continuous ones, and CLG networks do not allow such dependencies to be represented. In this paper, we propose the first \"exact\" inference algorithm for aug\u00ad mented CLG networks CLG networks augmented by allowing discrete children of continuous parents. Our algorithm is based on Lauritzen's algorithm, and is exact in a similar sense: it computes the exact dis\u00ad tributions over the discrete nodes, and the exact first and second moments of the continuous ones, up to in\u00ad accuracies resulting from numerical integration used within the algorithm. In the special case of softmax CPDs, we show that integration can often be done effi\u00ad ciently, and that using the first two moments leads to a particularly accurate approximation. We show empiri\u00ad cally that our algorithm achieves substantially higher accuracy at lower cost than previous algorithms for this task.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Forgetting and consolidation for incremental and cumulative knowledge acquisition systems\nAbstract: The application of cognitive mechanisms to support knowledge acquisition is, from our point of view, crucial for making the resulting models coherent, efficient, credible, easy to use and understandable. In particular, there are two characteristic features of intelligence that are essential for knowledge development: forgetting and consolidation. Both plays an important role in knowledge bases and learning systems to avoid possible information overflow and redundancy, and in order to preserve and strengthen important or frequently used rules and remove (or forget) useless ones. We present an incremental, long-life view of knowledge acquisition which tries to improve task after task by determining what to keep, what to consolidate and what to forget, overcoming The Stability-Plasticity dilemma [1]. In order to do that, we rate rules by introducing several metrics through the first adaptation, to our knowledge, of the Minimum Message Length (MML) principle [2] to a coverage graph, a hierarchical assessment structure which treats evidence and rules in a unified way. The metrics are not only used to forget some of the worst rules, but also to set a consolidation process to promote those selected rules to the knowledge base, which is also mirrored by a demotion system. We evaluate the framework with a series of tasks in a chess rule learning domain.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Bayesian Network Models for Adaptive Testing\nAbstract: Computerized adaptive testing (CAT) is an interesting and promising approach to testing human abilities. In our research we use Bayesian networks to create a model of tested humans. We collected data from paper tests performed with grammar school students. In this article we first provide the summary of data used for our experiments. We propose several different Bayesian networks, which we tested and compared by cross-validation. Interesting results were obtained and are discussed in the paper. The analysis has brought a clearer view on the model selection problem. Future research is outlined in the concluding part of the paper.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Rule-Based Short Query Intent Identification System\nAbstract: Using SMS (Short Message System), cell phones can be used to query for information about various topics. In an SMS based search system, one of the key problems is to identify a domain (broad topic) associated with the user query; so that a more comprehensive search can be carried out by the domain specific search engine. In this paper we use a rule based approach, to identify the domain, called Short Query Intent Identification System (SQIIS). We construct two different rule-bases using different strategies to suit query intent identification. We evaluate the two rule-bases experimentally. Keywords-Information Retrieval; Question Answering; Named Entity Detection; Query Classification;Rule-Based Systems\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: <lb>x Nomenclature<lb>xiiii List of Abbreviations<lb>xvii Certification<lb>Error! Bookmark not defined.i Acknowledgements<lb>xixx Chapter\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: UbuntuWorld 1.0 LTS - A Platform for Automated Problem Solving & Troubleshooting in the Ubuntu OS\nAbstract: In this paper we present UbuntuWorld 1.0 LTS a platform for developing automated technical support agents in the Ubuntu operating system. Specifically, we propose to use the Bash terminal as a simulator of the Ubuntu environment for a learning-based agent, and demonstrate the usefulness of adopting reinforcement learning (RL) techniques for basic problem solving and troubleshooting in this environment. We provide a plug-and-play interface to the simulator as a python package where different types of agents can be plugged in and evaluated, and provide pathways for integrating data from online support forums like Ask Ubuntu into an automated agent\u2019s learning process. Finally, we show that the use of this data significantly improves the agent\u2019s learning efficiency. We believe that this platform can be adopted as a real-world test bed for research on automated technical support. Building effective conversational agents has long been the holy grail of Artificial Intelligence (Turing 1950). Research in this direction has, however, largely recognized that different modes of conversation require widely different capabilities from an automated agent, depending on the particular context of the interaction; the focus has thus been on approaches targeted at specific applications. For example, conversational agents in the form of chat bots are required to be more creative, responsive and human-like; while for automation in the context of customer service, qualities like precision and brevity are more relevant. Indeed, human agents while providing customer support make a conscious effort to be as structured as possible in their interactions with the user. For successful automation in this particular mode of dialog (that we refer to as end-to-end goal-directed conversational systems or e2eGCS) we identify the following typical characteristics End-to-end. This is the ability of the agent to build and operate on knowledge directly from raw inputs as is available from the world and generate the desired behavior. Goal-directed. The interaction is these settings are targeted at achieving specific goals, i.e. to solve a particular problem or reach a desired state. General purpose. It is infeasible to build fundamentally different support agents for every possible environment, \u2217Bulk of the work was done during an internship (Summer, 2016) at the Thomas J. Watson Research Center, Yorktown, NY. and hence there must be a learning component to the agent that facilitates automated building of domain knowledge. Adaptive. An agent must learn to adapt to its experience and update its knowledge, and this further underlines the importance of an agent\u2019s capability to learn. Integrated. Finally, the agent must be able to interact with the human in the loop and integrate (and subsequently learn from) human intelligence in order to solve a wide variety of problems effectively. One of the canonical examples of such systems is technical support. As in the case of customer service in general, automation for technical support requires an agent ascribing to the e2eGCS paradigm to be able to: \u2022 learn a model or understanding of its environment automatically by means of experience, data and exploration; \u2022 evaluate its knowledge given a context, and learn to sense for more information to solve a given problem; and \u2022 interact with the customer, maybe in multiple turns, in a natural fashion to solve a given problem effectively. In this paper we specifically address the learning problem, and make a first attempt to lay a pathway towards achieving fully fleshed-out e2eGCS of the future. Technical support is a particular instance of customer service that deals with problems related to the operation of a specific piece of technology, which means there often exists an underlying (albeit unspecified) model to the operation of such a system, and the model learning proposition becomes especially attractive in this context. However, the critical problem here is that the engineers who build the technology, the people who use it, and the ones who provide support for it are often distinct from each other. One solution then would be to make the architects of the system also build the support engine following the same software specifications; this quickly becomes intractable (and might well require its own support!). A more worthwhile alternative is to learn this model automatically; such an approach, while being considerably simpler to follow, is also likely to be more effective in capturing domain knowledge and providing directed personalized support. The specific domain we look at in this work is technical support in the Ubuntu operating system. This is undoubtedly a real-world environment where support is most sought after, as evident from the thriving community on the official online ar X iv :1 60 9. 08 52 4v 1 [ cs .A I] 2 7 Se p 20 16 Figure 1: Graph (http://bit.ly/2blmZk1) showing the number of zombie posts from 01/2011 to 07/2016. These are the posts that have remained unanswered for more than 72 hours, and their number is growing exponentially. Ubuntu help forum Ask Ubuntu , a question and answer site for Ubuntu users and developers belonging to the Stack Exchange network of Q&A sites. Ask Ubuntu currently boasts of more than 370k registered users and 238k questions asked till date, and ranks at #3 in the family of 158 Stack Exchange communities in terms of traffic or number of users (as of August 2016). A closer look however reveals that this rank is not an indicator of the quality of support in terms of percentage of questions actually answered (Stack Exchange 2016), Ask Ubuntu operates at a lowly rate of 65%, ranking just five places off the bottom of the list. Further, as shown in Figure 1, the number of posts that go unanswered is exploding in recent times (Ask Ubuntu 2014). While there are many causes that may have led to these dire circumstances, some of which we discuss below, one thing is quite certain Ubuntu needs support, and there isn\u2019t enough of it out there. Motivation Ask Ubuntu\u2019s afflictions may be largely attributed to the following main causes 1. New users clogging up the system with simple problems that experienced users do not care to respond to. 2. Duplicate questions, due to large number of users who do not bother to look up existing solutions before posting. 3. An unhealthy newcomer to expert ratio in the community as a result of Ubuntu\u2019s rapidly growing popularity. 4. The continuous roll out of new software/OS versions and corresponding problems with dependencies. 5. Incompletely specified problems, including insufficient state information and error logs leaving members of the community little to work with. We claim here that a large number of these problems can readily be solved through automation. While it may not be reasonable to expect an automated agent to learn the most nuanced details of the Ubuntu OS and solve niche issues that the experts on Ask Ubuntu are more capable of addressing, the large majority of problems faced by users on the forum are readily addressable, being either (1) simple problems faced by newbies that may be directly solved from the documentation, and hence may be learned from exploration in the terminal; or (2) duplicates of existing issues which may Figure 2: Use case querying Ask Ubuntu for guidance. have already been solved, and hence may be learned using relevant data from Ask Ubuntu. The learning approach then also indirectly addresses issues (3) by freeing up (and in turn tapping into) support from Ask Ubuntu and (4,5) since the domain knowledge built up over time as well as local state information sensed by the integrated support agent may be useful in providing more directed and personalized support. Figure 2 provides an illustration of the kind of tasks we are interested in. Consider the simple task of opening a text file. It can be achieved in a single step using gedit, or it can be arbitrarily harder depending on the actual state of the system the agent might need to install gedit if it is not available, and it may need to access the internet and sudo permissions to do so. We want our agent to learn these workflows and dependencies by itself by exploring the Bash environment so that, for example, when an error comes up regarding administrative rights, the agent knows it needs to execute the sudo command. Of course, this is one of the many traces that the agent will need to explore before it learns the correct choices. Ironically, we want to turn to Ask Ubuntu itself in order to make the agent\u2019s life a little easier. As we noted before, users on Ask Ubuntu have been solving similar problems for a long time, and the solutions to Figure 3: A schematic representation of the UbuntuWorld 1.0 LTS prototype. their issues can provide valuable guidance to the learning agent. For example, Figure 2 shows an example where the learning agent queries a TF/IDF based reverse index on the Ask Ubuntu forum data in Lucene (Lucene 2016) with the terminal output as the context, to receive a suggestion of using sudo in this state. Thus in addition to wanting our RL agent to explore and build a model of Ubuntu, we also want to make sure that the exploration is smart given the abundance of data already available on troubleshooting in Ubuntu in online forums such as Ask Ubuntu. We refer to this as data-driven reinforcement learning. Related Work Bringing AI techniques \u2013 particularly reasoning and decision-making \u2013 to the problem of automated software agents has a rich history within the automated planning community. Of particular importance is the work on building softbots for UNIX by Etzioni et al. (Etzioni, Lesh, and Segal 1993; Etzioni and Weld 1994), which is the most comprehensive previous study on this problem. Indeed, as we introduced earlier, many of the issues that are cataloged in that work remain of importance today. The current work builds upon the work of Etzioni et al., particularly their focus on a goal-oriented approach to the problem (Etzioni et al. 1993); however, it goes beyond that work in actually realizing a learning-based agent framework (in our case, reinforcement learning) for the Ubuntu technical support domain. Succinctly, we seek to automate in the largest possible degree the promise of the softbot approach by: (1) exploiting the Bash shell as a robust simulator for learning agents to explore the world; and (2) using the large amounts of data generated by human experts on the internet. On the learning side, Branavan et al.\u2019s work on using reinforcement learning (RL) to map natural language instructions to sequences of executable actions (Branavan et al. 2009) explores a similar problem setting in a Windows OS domain. However, that work focuses on the application of RL techniques to the language processing problem, and on mapping text instructions to executable actions. In contrast, our work focuses on learning task-oriented models for solving the e2eGCS problem. Thus the most relevant prior explorations into this area are complementary to our work in different ways; while the softbot work lays the groundwork for our architecture, Branavan et al.\u2019s work provides a report on using learning on a related but different problem. Contributions The contributions of the paper are \u2022 We provide a platform UbuntuWorld 1.0 LTS based on the Ubuntu OS, and its interface to the Bash terminal, where different types of agents can be plugged in and evaluated. This can be adopted as a valuable real-world test bed for research in automated technical support. \u2022 We propose data-driven RL as a viable solution to the model learning problem for automated technical support in Ubuntu, by augmenting human intelligence in the form of data from online technical support forums like Ask Ubuntu to aid the traditional RL process.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Comparison of Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer Architectures for Computing Marginals of Probability Distributions\nAbstract: In the last decade, several architectures have been proposed for exact computation of marginals us\u00ad ing local computation. In this paper, we compare three architectures-Lauritzen-Spiegelhalter, Hugin, and Shenoy-Shafer-from the perspective of graphical structure for message propagation, message-passing scheme, computational effi\u00ad ciency, and storage efficiency.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Approximated Structured Prediction for Learning Large Scale Graphical Models\nAbstract: and composed from the conjugate dual of the soft-max and the conjugate dual of the lp norm. Recall that the conjugate dual for the soft-max is the entropy barrier \u01ebH(px,y) over the set of probability distributions \u2206Y (cf. [4] Theorem 8.1), and that the linear shift of the soft-max argument by ey(\u0177) result in the linear shift of the conjugate dual, thus we get the first part of the dual function \u2211 (x,y)(\u01ebH(px,y) + e \u22a4 y px,y). Similarly, the conjugate dual of 1 p \u2016\u03b8\u2016p is 1 q \u2016z\u2016q for the dual norm 1/p+ 1/q = 1 (cf. [2]), where in our case z = \u2211 (x,y),\u0177 px,y(\u0177)\u03a6(x, \u0177)\u2212 d. Theorem 1 The approximation of the structured prediction program in (3) takes the form min \u03bbx,y,v\u2192\u03b1,\u03b8 \u2211\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exact Inference for Relational Graphical Models with Interpreted Functions: Lifted Probabilistic Inference Modulo Theories\nAbstract: Probabilistic Inference Modulo Theories (PIMT) is a recent framework that expands exact inference on graphical models to use richer languages that include arithmetic, equalities, and inequalities on both integers and real numbers. In this paper, we expand PIMT to a lifted version that also processes random functions and relations. This enhancement is achieved by adapting Inversion, a method from Lifted First-Order Probabilistic Inference literature, to also be modulo theories. This results in the first algorithm for exact probabilistic inference that efficiently and simultaneously exploits random relations and functions, arithmetic, equalities and inequalities.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Complexity of Plan Existence and Evaluation in Probabilistic Domains\nAbstract: We examine the computational complexity of testing and finding small plans in prob\u00ad abilistic planning domains with succinct rep\u00ad resentations. We find that many problems of interest are complete for a variety of com\u00ad plexity classes: NP, co-NP, PP, NPPP, co\u00ad NPPP, and PSPACE. Of these, the proba\u00ad bilistic classes PP and NPPP are likely to be of special interest in the field of uncer\u00ad tainty in artificial intelligence and are deserv\u00ad ing of additional study. These results suggest a fruitful direction of future algorithmic de\u00ad velopment.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: A Transformational Characterization of Equivalent Bayesian Network Structures\nAbstract: We present a simple characterization of equivalent Bayesian network structures based on local transformations. The sig\u00ad nificance of the characterization is twofold. First, we are able to easily prove several new invariant properties of theoretical in\u00ad terest for equivalent structures. Second, we use the characterization to derive an ef\u00ad ficient algorithm that identifies all of the compelled edges in a structure. Compelled edge identification is of particular impor\u00ad tance for learning Bayesian network struc\u00ad tures from data because these edges indi\u00ad cate causal relationships when certain as\u00ad sumptions hold.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Ben-Qiong Hu College of Information Management, Chengdu University of Technology, 610059, China Abstract To find all extreme points of multimodal functions is called extremum problem, which is a well known difficult issue in optimization fields. Applying ant colony optimization (ACO) to solve this problem is rarely reported. The method of applying ACO to solve extremum problem is explored in this paper. Experiment shows that the solution error of the method presented in this paper is less than 10\u22128.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Associative Adversarial Networks\nAbstract: We propose a higher-level associative memory for learning adversarial networks. Generative adversarial network (GAN) framework has a discriminator and a generator network. The generator (G) maps white noise (z) to data samples while the discriminator (D) maps data samples to a single scalar. To do so, G learns how to map from high-level representation space to data space, and D learns to do the opposite. We argue that higher-level representation spaces need not necessarily follow a uniform probability distribution. In this work, we use Restricted Boltzmann Machines (RBMs) as a higher-level associative memory and learn the probability distribution for the high-level features generated by D. The associative memory samples its underlying probability distribution and G learns how to map these samples to data space. The proposed associative adversarial networks (AANs) are generative models in the higher-levels of the learning, and use adversarial nonstochastic models D and G for learning the mapping between data and higher-level representation spaces. Experiments show the potential of the proposed networks.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Machine-Part cell formation through visual decipherable clustering of Self Organizing Map\nAbstract: Machine-part cell formation is used in cellular manufacturing in order to process a large variety, quality, lower work in process levels, reducing manufacturing lead-time and customer response time while retaining flexibility for new products. This paper presents a new and novel approach for obtaining machine cells and part families. In the cellular manufacturing the fundamental problem is the formation of part families and machine cells. The present paper deals with the Self Organising Map (SOM) method an unsupervised learning algorithm in Artificial Intelligence, and has been used as a visually decipherable clustering tool of machine-part cell formation. The objective of the paper is to cluster the binary machine-part matrix through visually decipherable cluster of SOM color-coding and labelling via the SOM map nodes in such a way that the part families are processed in that machine cells. The Umatrix, component plane, principal component projection, scatter plot and histogram of SOM have been reported in the present work for the successful visualization of the machine-part cell formation. Computational result with the proposed algorithm on a set of group technology problems available in the literature is also presented. The proposed SOM approach produced solutions with a grouping efficacy that is at least as good as any results earlier reported in the literature and improved the grouping efficacy for 70% of the problems and found immensely useful to both industry practitioners and researchers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Asymmetric Move Selection Strategies in Monte-Carlo Tree Search: Minimizing the Simple Regret at Max Nodes\nAbstract: The combination of multi-armed bandit (MAB) algorithms with Monte-Carlo tree search (MCTS) has made a significant impact in various research fields. The UCT algorithm, which combines the UCB bandit algorithm with MCTS, is a good example of the success of this combination. The recent breakthrough made by AlphaGo, which incorporates convolutional neural networks with bandit algorithms in MCTS, also highlights the necessity of bandit algorithms in MCTS. However, despite the various investigations carried out on MCTS, nearly all of them still follow the paradigm of treating every node as an independent instance of the MAB problem, and applying the same bandit algorithm and heuristics on every node. As a result, this paradigm may leave some properties of the game tree unexploited. In this work, we propose that max nodes and min nodes have different concerns regarding their value estimation, and different bandit algorithms should be applied accordingly. We develop the Asymmetric-MCTS algorithm, which is an MCTS variant that applies a simple regret algorithm on max nodes, and the UCB algorithm on min nodes. We will demonstrate the performance of the Asymmetric-MCTS algorithm on the game of 9 \u00d7 9 Go, 9\u00d7 9 NoGo, and Othello.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Value of Information Lattice: Exploiting Probabilistic Independence for Effective Feature Subset Acquisition\nAbstract: We address the cost-sensitive feature acquisition problem, where misclassifying an instance is costly but the expected misclassification cost can be reduced by acquiring the values of the missing features. Because acquiring the features is costly as well, the objective is to acquire the right set of features so that the sum of the feature acquisition cost and misclassification cost is minimized. We describe the Value of Information Lattice (VOILA), an optimal and efficient feature subset acquisition framework. Unlike the common practice, which is to acquire features greedily, VOILA can reason with subsets of features. VOILA efficiently searches the space of possible feature subsets by discovering and exploiting conditional independence properties between the features and it reuses probabilistic inference computations to further speed up the process. Through empirical evaluation on five medical datasets, we show that the greedy strategy is often reluctant to acquire features, as it cannot forecast the benefit of acquiring multiple features in combination.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Creating Scalable and Interactive Web Applications Using High Performance Latent Variable Models\nAbstract: In this project we outline a modularized, scalable system for comparing Amazon products in an interactive and informative way using efficient latent variable models and dynamic visualization. We demonstrate how our system can build on the structure and rich review information of Amazon products in order to provide a fast, multifaceted, and intuitive comparison. By providing a condensed per-topic comparison visualization to the user, we are able to display aggregate information from the entire set of reviews while providing an interface that is at least as compact as the \u201cmost helpful reviews\u201d currently displayed by Amazon, yet far more informative.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Exact and Approximate Inference in Associative Hierarchical Networks using Graph Cuts\nAbstract: Markov Networks are widely used through out computer vision and machine learning. An important subclass are the Associative Markov Networks which are used in a wide variety of applications. For these networks a good approximate minimum cost solution can be found efficiently using graph cut based move making algorithms such as alphaexpansion. Recently a related model has been proposed, the associative hierarchical network, which provides a natural generalisation of the Associative Markov Network for higher order cliques (i.e. clique size greater than two). This method provides a good model for object class segmentation problem in computer vision. Within this paper we briefly describe the associative hierarchical network and provide a computationally efficient method for approximate inference based on graph cuts. Our method performs well for networks containing hundreds of thousand of variables, and higher order potentials are defined over cliques containing tens of thousands of variables. Due to the size of these problems standard linear programming techniques are inapplicable. We show that our method has a bound of 4 for the solution of general associative hierarchical network with arbitrary clique size noting that few results on bounds exist for the solution of labelling of Markov Networks with higher order cliques.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Answer Set Solvers with Backjumping and Learning (long version)\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Network Fragments: Representing Knowledge for Constructing Probabilistic Models\nAbstract: In ntost current applications of belief networks, domain knowledge is represented by a single belief network that applies to all problem instances in the domain. In more complex domains, problem-specific models must be constructed from a knowledge base encoding probabilistic relationships in the domain. Most work in knowledge-based model construction takes the rule as the basic unit of knowledge. We present a knowledge representation framework that permits the knowledge base designer to specify knowledge in larger semantically meaningful units which we call network fragments. Our framework provides for representation of asymmetric independence and canonical intercausal interaction. We discuss the combination of network fragments to form problem-specific models to reason about particular problem instances. The framework is illustrated using examples from the domain of military situation awareness.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Axiomatic properties of inconsistency indices for pairwise comparisons\nAbstract: Pairwise comparisons are a well-known method for the representation of the subjective preferences of a decision maker. Evaluating their inconsistency has been a widely studied and discussed topic and several indices have been proposed in the literature to perform this task. Since an acceptable level of consistency is closely related with the reliability of preferences, a suitable choice of an inconsistency index is a crucial phase in decision making processes. The use of different methods for measuring consistency must be carefully evaluated, as it can affect the decision outcome in practical applications. In this paper, we present five axioms aimed at characterizing inconsistency indices. In addition, we prove that some of the indices proposed in the literature satisfy these axioms, while others do not, and therefore, in our view, they may fail to correctly evaluate inconsistency.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs\nAbstract: The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer\u2019s output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model. Representations and algorithms from computer graphics, originally designed to produce high-quality images, are instead used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured alphanumeric characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and supports accurate, approximately Bayesian inferences about ambiguous real-world images.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Planning with External Events\nAbstract: I describe a planning methodology for domains with uncertainty in the form of external events that are not completely predictable. The events are represented by enabling conditions and prob\u00ad abilities of occurrence. The planner is goal\u00ad directed and backward chaining, but the subgoals are suggested by analysing the probability of suc\u00ad cess of the partial plan rather than being simply the open conditions of the operators in the plan. The partial plan is represented as a Bayesian be\u00ad lief net to compute its probability of success. Since calculating the probability of success of a plan can be very expensive I introduce two other techniques for computing it, one that uses Monte Carlo simulation to estimate it and one based on a Markov chain representation that uses knowledge about the dependencies between the predicates describing the domain.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: Plausibility models are Kripke models that agents use to reason about knowledge and belief, both of themselves and of each other. Such models are used to interpret the notions of conditional belief, degrees of belief, and safe belief. The logic of conditional belief contains that modality and also the knowledge modality, and similarly for the logic of degrees of belief and the logic of safe belief. With respect to these logics, plausibility models may contain too much information. A proper notion of bisimulation is required that characterises them. We define that notion of bisimulation and prove the required characterisations: on the class of image-finite and preimage-finite models (with respect to the plausibility relation), two pointed Kripke models are modally equivalent in either of the three logics, if and only if they are bisimilar. As a result, the information content of such a model can be similarly expressed in the logic of conditional belief, or the logic of degrees of belief, or that of safe belief. This, we found a surprising result. Still, that does not mean that the logics are equally expressive: the logics of conditional and degrees of belief are incomparable, the logics of degrees of belief and safe belief are incomparable, while the logic of safe belief is more expressive than the logic of conditional belief. In view of the result on bisimulation characterisation, this is an equally surprising result. We hope our insights may contribute to the growing community of formal epistemology and on the relation between qualitative and quantitative modelling.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Counting Belief Propagation\nAbstract: A major benefit of graphical models is that most knowledge is captured in the model structure. Many models, however, produce inference problems with a lot of symmetries not reflected in the graphical structure and hence not exploitable by efficient inference techniques such as belief propagation (BP). In this paper, we present a new and simple BP algorithm, called counting BP, that exploits such additional symmetries. Starting from a given factor graph, counting BP first constructs a compressed factor graph of clusternodes and clusterfactors, corresponding to sets of nodes and factors that are indistinguishable given the evidence. Then it runs a modified BP algorithm on the compressed graph that is equivalent to running BP on the original factor graph. Our experiments show that counting BP is applicable to a variety of important AI tasks such as (dynamic) relational models and boolean model counting, and that significant efficiency gains are obtainable, often by orders of magnitude.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Implementation of Continuous Bayesian Networks Using Sums of Weighted Gaussians\nAbstract: Bayesian networks provide a method of rep\u00ad resenting conditional independence between random variables and computing the prob\u00ad ability distributions associated with these random variables. In this paper, we ex\u00ad tend Bayesian network structures to compute probability density functions for continuous random variables. We make this extension by approximating prior and conditional den\u00ad sities using sums of weighted Gaussian dis\u00ad tributions and then finding the propagation rules for updating the densities in terms of these weights. We present a simple exam\u00ad ple that illustrates the Bayesian network for continuous variables; this example shows the effect of the network structure and approxi\u00ad mation errors on the computation of densities for variables in the network.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Neural Models for Key Phrase Detection and Question Generation\nAbstract: We propose several neural models arranged in a two-stage framework to tackle question generation from documents. First, we estimate the probability of \u201cinteresting\u201d answers in a document using a neural model trained on a questionanswering corpus. The predicted key phrases are then used as answers to condition a sequence-to-sequence question generation model. Empirically, our neural key phrase detection models significantly outperform an entity-tagging baseline system. We demonstrate that the question generator formulates good quality natural language questions from extracted key phrases. The resulting questions and answers can be used to assess reading comprehension in educational settings.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Algorithms for Closed Under Rational Behavior (CURB) Sets\nAbstract: We provide a series of algorithms demonstrating that solutions according to the fundamental game-theoretic solution concept of closed under rational behavior (CURB) sets in two-player, normal-form games can be computed in polynomial time (we also discuss extensions to n-player games). First, we describe an algorithm that identifies all of a player\u2019s best responses conditioned on the belief that the other player will play from within a given subset of its strategy space. This algorithm serves as a subroutine in a series of polynomial-time algorithms for finding all minimal CURB sets, one minimal CURB set, and the smallest minimal CURB set in a game. We then show that the complexity of finding a Nash equilibrium can be exponential only in the size of a game\u2019s smallest CURB set. Related to this, we show that the smallest CURB set can be an arbitrarily small portion of the game, but it can also be arbitrarily larger than the supports of its only enclosed Nash equilibrium. We test our algorithms empirically and find that most commonly studied academic games tend to have either very large or very small minimal CURB sets.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Geometry of Interest (GOI): Spatio-Temporal Destination Extraction and Partitioning in GPS Trajectory Data\nAbstract: Nowadays large amounts of GPS trajectory data is being continuously collected by GPS-enabled devices such as vehicles navigation systems and mobile phones. GPS trajectory data is useful for applications such as traffic management, location forecasting, and itinerary planning. Such applications often need to extract the time-stamped Sequence of Visited Locations (SVLs) of the mobile objects. The nearest neighbor query (NNQ) is the most applied method for labeling the visited locations based on the IDs of the POIs in the process of SVL generation. NNQ in some scenarios is not accurate enough. To improve the quality of the extracted SVLs, instead of using NNQ, we label the visited locations as the IDs of the POIs which geometrically intersect with the GPS observations. Intersection operator requires the accurate geometry of the points of interest which we refer to them as the Geometries NICTA VRL, Department of Computing and Information Systems, The University of Melbourne, Australia Tel.: +61-405967448 E-mail: mousavi@student.unimelb.edu.au Department of Computing and Information Systems, The University of Melbourne, Australia Tel.: +61-383441351 E-mail: aharwood@unimelb.edu.au Department of Computing and Information Systems, The University of Melbourne, Australia Tel.: +61-383441351 E-mail: karus@unimelb.edu.au School of Civil and Environmental Engineering, UNSW, Australia Tel.: +61-383441351 E-mail: maghrebi@unsw.edu.au of Interest (GOIs). In some application domains (e.g. movement trajectories of animals), adequate information about the POIs and their GOIs may not be available a priori, or they may not be publicly accessible and, therefore, they need to be derived from GPS trajectory data. In this paper we propose a novel method for estimating the POIs and their GOIs, which consists of three phases: (i) extracting the geometries of the stay regions; (ii) constructing the geometry of destination regions based on the extracted stay regions; and (iii) constructing the GOIs based on the geometries of the destination regions. Using the geometric similarity to known GOIs as the major evaluation criterion, the experiments we performed using long-term GPS trajectory data show that our method outperforms the existing approaches.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Semantic HMC for Big Data Analysis\nAbstract: Analyzing Big Data can help corporations to improve their efficiency. In this work we present a new vision to derive Value from Big Data using a Semantic Hierarchical Multi-label Classification called Semantic HMC based in a nonsupervised Ontology learning process. We also proposea Semantic HMC process, using scalable Machine-Learning techniques and Rule-based reasoning.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Distributed Graph Coloring: An Approach Based on the Calling Behavior of Japanese Tree Frogs\nAbstract: Graph coloring\u2014also known as vertex coloring\u2014considers the problem of assigning colors to the nodes of a graph such that adjacent nodes do not share the same color. The optimization version of the problem concerns the minimization of the number of used colors. In this paper we deal with the problem of finding valid colorings of graphs in a distributed way, that is, by means of an algorithm that only uses local information for deciding the color of the nodes. Such algorithms prescind from any central control. Due to the fact that quite a few practical applications require to find colorings in a distributed way, the interest in distributed algorithms for graph coloring has been growing during the last decade. As an example consider wireless ad-hoc and sensor networks, where tasks such as the assignment of frequencies or the assignment of TDMA slots are strongly related to graph coloring. The algorithm proposed in this paper is inspired by the calling behavior of Japanese tree frogs. Male frogs use their calls to attract females. Interestingly, groups of males that are located nearby each other desynchronize their calls. This is because female frogs are only able to correctly localize the male frogs when their calls are not too close in time. We experimentally show that our algorithm is very competitive with the current state of the art, using different sets of problem instances and comparing to one of the most competitive algorithms from the literature.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Adaptive Forecasting of Non-Stationary Nonlinear Time Series based on the Evolving Weighted Neuro-Neo-Fuzzy- ANARX-Model\nAbstract: An evolving weighted neuro-neo-fuzzy-ANARX model and its learning procedures are introduced in the article. This system is basically used for time series forecasting. It\u2019s based on neo-fuzzy elements. This system may be considered as a pool of elements that process data in a parallel manner. The proposed evolving system may provide online processing data streams. Index Terms \u2014 Computational Intelligence, time series prediction, neuro-neo-fuzzy System, Machine Learning, ANARX, Data Stream.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Causal Model Analysis using Collider v-structure with Negative Percentage Mapping\nAbstract: A major problem of causal inference is the arrangement of dependent nodes in a directed acyclic graph (DAG) with path coefficients and observed confounders. Path coefficients do not provide the units to measure the strength of information flowing from one node to the other. Here we proposed the method of causal structure learning using collider v-structures (CVS) with Negative Percentage Mapping (NPM) to get selective thresholds of information strength, to direct the edges and subjective confounders in a DAG. The NPM is used to scale the strength of information passed through nodes in units of percentage from interval [0, 1]. The causal structures are constructed by bottom up approach using path coefficients, causal directions and confounders, derived implementing collider v-structure and NPM. The method is self-sufficient to observe all the latent confounders present in the causal model and capable of detecting every responsible causal direction. The results are tested for simulated datasets of non-Gaussian distributions and compared with DirectLiNGAM and ICA-LiNGAM to check efficiency of the proposed method. 1 Background Study: Markov Model, d-separable, v-structures In Bayesian Learning the Markov properties play an important role, which set the criteria for structure analysis. The Markov model is a directed graph which does not contains any bi-directed edges [5]. This criteria does not provides the acyclicity of the model. But using markov model we can find the conditional dependent and independent nodes, provided we have information on prior observations. Sometime it happens to be very difficult to know about prior observations or any of the prior information. Assuming the observed variables are prior, the later ones will be conditionally dependent on the prior ones. Now we need a criteria to observe the posterior effects. In this scenario d-separable provides the criteria of sub-structural learning for conditional dependence and independence of the features. To implement d-separable we need v-structures. The primary definition of v-structure is provided for the undirected graphical models, where two nodes are only connected through an undirected edge [3]. The v-structures in a markov model are the sub-structures where each three of the observed nodes are only connected through two directed edges. For the choice of any three nodes we can permute them in three possible ways using two 1 ar X iv :1 50 9. 04 90 4v 1 [ cs .A I] 1 6 Se p 20 15 directed edges irrespective of their positions. The d-separable criteria is used to construct a set of nodes such that conditioning on which, the paths/edges can be separated between other two nodes in the v-structure. Consider v-structures of a \u2192 b \u2192 c , a \u2190 b \u2192 c and a \u2192 b \u2190 c. In first and second types a and c can be d-separated by observing/conditioning on b, while in the third one conditioning on b makes a and c becomes dependent on each other as ancestor nodes of b remains unobserved.. The third type of v-structure is called a collider. He and Geng [2] applied intervention technique on markov equivalence classes to produce subgraphs with directed edges. They generated v-structures of subgraphs with markov properties to find directions, using conditional probabilities. Markov Blankets can reveal the directions in the nodes based on their relevance of connection inside the blanket. The structural learning of causal model can be shown through faithfulness and relevance of connections using d-separable and v-structures [6]. The faithfulness for markov equivalent classes are beneficial and weak or strong faithful criteria can be derived for Gaussian and uniform distributions, where path coefficients and errors are drawn from intervals [\u22121, 1] and [0, 1] respectively [9]. In following Sections 2 and 3, we provided complete explanation for using collider v-structures as a substructural model and NPM for measuring strength of path coefficients. 2 Proposed Structural Learning Method Every orthodox and modern approach of causal construction lag to define the measure for information passing through directed edges, while path coefficient/connection strength is the information passed on. Depending on the information (path coefficient) either from nodes or external confounders we cannot conclude the directions in causal model. This problem becomes more complicated when it comes to multivariate structure. So we need a measure for these entropies through which we will be able conclude our directions. Before scaling the flow of information, we need a model to work on for causal constructions. The easiest way to build a larger model is, first to build the sub-structures of the bigger model and then arrange these small ones to complete the required structure. The directed acyclic causal graph can be studied as a decomposition of multiple v-structures under the lights of markov model [10]. In our case we used a bottom up approach of arranging multiple v-structures to form a causal DAG. For this type of approach we don\u2019t need any prior information regarding the structure or contributing variables. After deriving all the direction, path coefficients and confounders for the considered vstructures, these can be combined together to provide a complete causal structure. The model of collider v-structure provides the necessary sub-structural analysis in a very detailed way. 2.1 Collider v-structure with NPM (CVS with NPM): To analyze a larger causal structure in a smaller sub-structural level consider the v-structure as defied in the markov model, that is a set of three nodes connected through two directed edges. The collider is a v-structure where two extreme nodes have directed edges towards the middle node. We referred it as collider v-structure whenever an external confounder is present or added to the collider system and we modeled our algorithm suitable to analyze these types of DAG. Below Figure 1 provides the collider v-structures.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Evolving Non-linear Stacking Ensembles for Prediction of Go Player Attributes\nAbstract: The paper presents an application of non-linear stacking ensembles for prediction of Go player attributes. An evolutionary algorithm is used to form a diverse ensemble of base learners, which are then aggregated by a stacking ensemble. This methodology allows for an efficient prediction of different attributes of Go players from sets of their games. These attributes can be fairly general, in this work, we used the strength and style of the players.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: One of the fundamental problems in crowdsourcing is the trade-off between number of workers needed for high-accuracy aggregation and the budget to pay. For saving budget, it is important to ensure high quality of the crowd-sourced labels, hence the total cost on label collection will be reduced. Since the self-confidence of workers often has close relationship with their abilities, a possible way for quality control is to request workers to work on problems only when they feel confident, by means of providing unsure option to them. On the other hand, allowing workers to choose unsure option also leads to the potential danger of budget waste. In this work, we propose the analysis towards understanding when providing unsure option indeed leads to significant cost reduction, as well as how the confidence threshold is set. We also propose an online mechanism, which is alternative for threshold selection when the estimation of the crowd ability distribution is difficult.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: This paper relates the well-known formalism of Linear Temporal Logic [Pnu77] with the logic of propositional schemata introduced in [ACP09]. We prove that LTL is equivalent to a particular class of schemata in the sense that polynomial-time translation algorithms exist from one logic to the other. Some consequences about complexity are given. We report about first experiments and the consequences about possible improvements in existing implementations are analyzed.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Projective simulation applied to the grid-world and the mountain-car problem\nAbstract: We study the model of projective simulation (PS) which is a novel approach to artificial intelligence (AI). Recently it was shown that the PS agent performs well in a number of simple task environments, also when compared to standard models of reinforcement learning (RL). In this paper we study the performance of the PS agent further in more complicated scenarios. To that end we chose two well-studied benchmarking problems, namely the \u201cgrid-world\u201d and the \u201cmountain-car\u201d problem, which challenge the model with large and continuous input space. We compare the performance of the PS agent model with those of existing models and show that the PS agent exhibits competitive performance also in such scenarios.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: On the Complexity of Semantic Integration of OWL Ontologies\nAbstract: We propose a new mechanism for integration of OWL ontologies using semantic import relations. In contrast to the standard OWL importing, we do not require all axioms of the imported ontologies to be taken into account for reasoning tasks, but only their logical implications over a chosen signature. This property comes natural in many ontology integration scenarios, especially when the number of ontologies is large. In this paper, we study the complexity of reasoning over ontologies with semantic import relations and establish a range of tight complexity bounds for various fragments of OWL.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: IBMMS DECISION SUPPORT TOOL FOR MANAGEMENT OF BANK TELEMARKETING CAMPAIGNS\nAbstract: Although direct marketing is a good method for banks to utilize in the face of global competition and the financial crisis, it has been shown to exhibit poor performance. However, there are some drawbacks to direct campaigns, such as those related to improving the negative attributes that customers ascribe to banks. To overcome these problems, attractive long-term deposit campaigns should be organized and managed more effectively. The aim of this study is to develop an Intelligent Bank Market Management System (IBMMS) for bank managers who want to manage efficient marketing campaigns. IBMMS is the first system developed by combining the power of data mining with the capabilities of expert systems in this area. Moreover, IBMMS includes important features that enable it to be intelligent: a knowledge base, an inference engine and an advisor. Using this system, a manager can successfully direct marketing campaigns and follow the decision schemas of customers both as individuals and as a group; moreover, a manager can make decisions that lead to the desired response by customers.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: None\nAbstract: In this paper we present a novel genetic algo-<lb>rithm (GA) solution to a simple yet challenging commercial<lb>puzzle game known as the Zen Puzzle Garden (ZPG). We<lb>describe the game in detail, before presenting a suitable<lb>encoding scheme and fitness function for candidate solutions.<lb>We then compare the performance of the genetic algorithm<lb>with that of the A* algorithm. Our results show that<lb>the GA is competitive with informed search in terms of<lb>solution quality, and significantly out-performs it in terms<lb>of computational resource requirements. We conclude with<lb>a brief discussion of the implications of our findings for game<lb>solving and other \u201creal world\u201d problems.\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Using Belief Theory to Diagnose Control Knowledge Quality\nAbstract: Both humans and artificial systems frequently use trial and error methods to problem solving. In order to be effective, this type of strategy implies having high quality control knowledge to guide the quest for the optimal solution. Unfortunately, this control knowledge is rarely perfect. Moreover, in artificial systems--as in humans--self-evaluation of one\u2019s own knowledge is often difficult. Yet, this self-evaluation can be very useful to manage knowledge and to determine when to revise it. The objective of our work is to propose an automated approach to evaluate the quality of control knowledge in artificial systems based on a specific trial and error strategy, namely the informed tree search strategy. Our revision approach consists in analysing the system\u2019s execution logs, and in using the belief theory to evaluate the global quality of the knowledge. We present a real-world industrial application in the form of an experiment using this approach in the domain of cartographic generalisation. Thus far, the results of using our approach have been encouraging. Knowledge Quality Diagnosis; Belief Theory; Problem Solving; Informed Tree Search Strategy; Cartographic Generalisation\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Modeling context and situations in pervasive computing environments\nAbstract: In pervasive computing environments, various entities often have to cooperate and integrate seamlessly in a situation which can, thus, be considered as an amalgamation of the context of several entities interacting and coordinating with each other, and often performing one or more activities. However, none of the existing context models and ontologies address situation modeling. In this paper, we describe the design, structure and implementation of a generic, flexible and extensible context ontology called Rover Context Model Ontology (RoCoMO) for context and situation modeling in pervasive computing systems and environments. We highlight several limitations of the existing context models and ontologies, such as lack of provision for provenance, traceability, quality of context, multiple representation of contextual information, as well as support for security, privacy and interoperability, and explain how we are addressing these limitations in our approach. We also illustrate the applicability and utility of RoCoMO using a practical and extensive case study. Keywords\u2014Context-aware Computing, Context Modeling and Representation, Situation Modeling\n",
        "output": "LOW"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Value-Decomposition Networks For Cooperative Multi-Agent Learning\nAbstract: We study the problem of cooperative multi-agent reinforcement learning with a single joint reward signal. This class of learning problems is difficult because of the often large combined action and observation spaces. In the fully centralized and decentralized approaches, we find the problem of spurious rewards and a phenomenon we call the \u201clazy agent\u201d problem, which arises due to partial observability. We address these problems by training individual agents with a novel value decomposition network architecture, which learns to decompose the team value function into agent-wise value functions. We perform an experimental evaluation across a range of partially-observable multi-agent domains and show that learning such value-decompositions leads to superior results, in particular when combined with weight sharing, role information and information channels.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Integrating Know-How into the Linked Data Cloud\nAbstract: This paper presents the first framework for integrating procedural knowledge, or \u201cknow-how\u201d, into the Linked Data Cloud. Knowhow available on the Web, such as step-by-step instructions, is largely unstructured and isolated from other sources of online knowledge. To overcome these limitations, we propose extending to procedural knowledge the benefits that Linked Data has already brought to representing, retrieving and reusing declarative knowledge. We describe a framework for representing generic know-how as Linked Data and for automatically acquiring this representation from existing resources on the Web. This system also allows the automatic generation of links between different know-how resources, and between those resources and other online knowledge bases, such as DBpedia. We discuss the results of applying this framework to a real-world scenario and we show how it outperforms existing manual community-driven integration efforts.\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: The Dynamic Controllability of Conditional STNs with Uncertainty\nAbstract: Recent attempts to automate business processes and medical-treatment processes have uncovered the need for a formal framework that can accommodate not only temporal constraints, but also observations and actions with uncontrollable durations. To meet this need, this paper defines a Conditional Simple Temporal Network with Uncertainty (CSTNU) that combines the simple temporal constraints from a Simple Temporal Network (STN) with the conditional nodes from a Conditional Simple Temporal Problem (CSTP) and the contingent links from a Simple Temporal Network with Uncertainty (STNU). A notion of dynamic controllability for a CSTNU is defined that generalizes the dynamic consistency of a CTP and the dynamic controllability of an STNU. The paper also presents some sound constraint-propagation rules for dynamic controllability that are expected to form the backbone of a dynamiccontrollability-checking algorithm for CSTNUs. Introduction and Motivation Workflow systems have been used to model business, manufacturing and medical-treatment processes. However, as Bettini et al. (2002) observed: \u201cIt would greatly enhance the capabilities of current workflow systems if quantitative temporal constraints on the duration of activities and their synchronization requirements can be specified and reasoned about.\u201d Toward that end, Combi et al. (2007; 2009; 2010) presented a new workflow model that accommodates the following key features: tasks with uncertain/uncontrollable durations; temporal constraints among tasks; and branching paths, where the branch taken is not known in advance. Fig. 1 shows a sample workflow from the health-care domain, similar to one presented by Combi and Posenato (2009). In this workflow, all times are in minutes, and: \u2022 tasks are represented by rounded boxes; \u2022 branching points are represented by nine-sided boxes called split or join connectors1; \u2022 tasks and connectors have duration attributes, [x, y]; \u2217Funded in part by the Phoebe H. Beadle Science Fund. Copyright c \u00a9 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Combi and Posenato (2009) used diamonds for connectors. T1 : [2, 4]\n",
        "output": "HIGH"
    },
    {
        "instruction": "In academic research papers, I am defining the IMPACT of a paper as the number of citations per year it gets, after some large amount of time (> 5 years).\nYour task is to predict the IMPACT of a paper, given its title and TLDR. The impact is defined as a binary label: HIGH if the paper will have citations per year more than 75th percentile, LOW otherwise. i.e. the paper is supposed to be in the top 25% of the most cited papers in the field or not.\nHere is the title and TLDR of the paper that you have to predict the impact for. Output the label: HIGH or LOW.\n",
        "input": "Title: Decentralized Constraint Satisfaction\nAbstract: We show that several important resource allocation problems in wireless networks fit within the common framework of Constraint Satisfaction Problems (CSPs). Inspired by the requirements of these applications, where variables are located at distinct network devices that may not be able to communicate but may interfere, we define natural criteria that a CSP solver must possess in order to be practical. We term these algorithms decentralized CSP solvers. The best known CSP solvers were designed for centralized problems and do not meet these criteria. We introduce a stochastic decentralized CSP solver, proving that it will find a solution in almost surely finite time, should one exist, and also showing it has many practically desirable properties. We benchmark the algorithm\u2019s performance on a well-studied class of CSPs, random k-SAT, illustrating that the time the algorithm takes to find a satisfying assignment is competitive with stochastic centralized solvers on problems with order a thousand variables despite its decentralized nature. We demonstrate the solver\u2019s practical utility for the problems that motivated its introduction by using it to find a non-interfering channel allocation for a network formed from data from downtown Manhattan.\n",
        "output": "LOW"
    }
]